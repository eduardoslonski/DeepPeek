[
  "Issue title: onBlur event is not fired in Controller\n Issue body: **Describe the bug**\r\nafter updating from v116.69.203.115 onBlur event is not fired on Controller component\r\n\r\n**To Reproduce**\r\n1. Go to codesandbox link\r\n2. Click on 'Input with controller'\r\n3. change focus\r\n4. event is not fired\r\n\r\n**Codesandbox link (Required)**\r\nhttps://codesandbox.io/s/billowing-firefly-5zc02?file=/src/App.js\r\n\r\n**Expected behavior**\r\nI expect the onBlur event to fire.\r\n\r\n**Desktop (please complete the following information):**\r\n\r\n- OS: Macos 10.15.6\r\n- Browser Chrome 84\r\n- Version 6.6.0\r\n\n Comments: \n Comment 0: Thanks for the issue report, v6 removed onChange and onBlur props, take a look at the changelog: https://github.com/react-hook-form/react-hook-form/blob/master/CHANGELOG.md",
  "Issue title: Adding extra fields to insert\n Issue body: Hi, Nice package.\r\nPlease how can I add extra fields to the insert object e.g/ an `uploadedAt ` field. \r\nI've tried collection hooks but it returns an error \r\nThanks\n Comments: \n Comment 0: @kenshinman \r\n\r\ntry to attach your custom field inside meta\r\n\r\n```\r\nconst upload = this.FilesCollection.insert({\r\n          file: file,\r\n          streams: 'dynamic',\r\n          chunkSize: 'dynamic',\r\n          meta: {\r\n            _id: Random.id(),\r\n            mycustomfield: 'blah blah blah'\r\n          }\r\n        }, false)\r\n```\n Comment 1: Hi @kenshinman,\r\n\r\nSolution suggested by @kenshinman is correct.\r\n\r\n 1. For security reasons on Client side you able to extend only `meta` object\r\n 2. On server - to extend fileObj use `onAfterUpload` hook\r\n 3. collection hooks may not work as *FilesCollection* is not equals to Mongo Collection\r\n 4. To operate on Mongo Collection level - use sub-property `collection` of *FilesCollection* instance (`FilesCollection#collection`) \n Comment 2: @dr-dimitru Thanks",
  "Issue title: staging env is being used for wallets\n Issue body: <!-- Have you searched for similar issues? Before submitting this issue, please check the open issues and add a note before logging a new issue. \r\n\r\nNOTE THAT THIS IS THE REPOSITORY FOR THE UPCOMING VERSION OF BRAVE. SEE [browser-laptop](https://github.com/brave/browser-laptop)FOR THE CURRENT PRODUCTION VERSION OF BRAVE ON MACOS, WINDOWS AND LINUX.\r\n\r\nPLEASE USE THE TEMPLATE BELOW TO PROVIDE INFORMATION ABOUT THE ISSUE. \r\nINSUFFICIENT INFO WILL GET THE ISSUE CLOSED. IT WILL ONLY BE REOPENED AFTER SUFFICIENT INFO IS PROVIDED-->\r\n\r\n## Description \r\nSeems as though the 0.55.3 build (and possibly before) are using the staging environment for Brave Rewards Wallets. Per discussion with @NejcZdovc they should be production wallets.\r\n\r\n\r\n## Steps to Reproduce\r\nScenario 1: \r\n\r\n## Actual result:\r\n<!--Please add screenshots if needed-->\r\n\r\n\r\n## Expected result:\r\n\r\n\r\n## Reproduces how often: \r\n<!--[Easily reproduced/Intermittent issue/No steps to reproduce]-->\r\n\r\n\r\n## Brave version (chrome://version info)\r\n<!--For installed build, please copy Brave, Revision and OS from chrome://version and paste here. If building from source please mention it along with chrome://version details-->\r\n\r\n\r\n### Reproducible on current release:\r\n<!--Does the issue reproduce on browser-laptop version as well? -->\r\n\r\n\r\n### Website problems only:  \r\n- Does the issue resolve itself when disabling Brave Shields? \r\n- Is the issue reproducible on the latest version of Chrome? \r\n\r\n### Additional Information\r\n<!--Any additional information, related issues, extra QA steps, configuration or data that might be necessary to reproduce the issue-->\r\n\n Comments: \n Comment 0: initial work was done here https://github.com/brave/brave-core/pull/392\n Comment 1: Verified passed with\r\n\r\nBrave | 0.55.10 Chromium: 70.0.3538.22\u00a0(Official Build)\u00a0beta(64-bit)\r\n-- | --\r\nRevision | ac9418ba9c3bd7f6baaffa0b055dfe147e0f8364-refs/branch-heads/3538@{#468}\r\nOS | Mac OS X\r\n\r\n- confirmed Brave Rewards are using production not staging wallets",
  "Issue title: plugins { id(\"xxx\") }\u00a0\n Issue body: Is there a way to use the new plugins syntax instead of bulidscript? \r\n\r\nThat makes for a much better user experience when working with the gradle kotlin dsl. \r\n\r\n```\r\nplugins {\r\n    id \u00abplugin id\u00bb version \u00abplugin version\u00bb\r\n}\r\n```\r\n\r\nSee the information `about the new plugin mechanism` in this page\r\n\r\nhttps://plugins.gradle.org/plugin/jmfayard.github.io.gradle-kotlin-dsl-libs\r\n\r\nhttps://plugins.gradle.org/docs/submit\n Comments: \n Comment 0: Wow, that was a really frustrating process!  I just attempted to dawnelliott@example.net; we are \"pending approval\".  This is an improvement over the last time I tried this, when the publishing plugin crashed in the presence of signature files (a requirement for Maven Central).\r\n\r\nPerhaps soon, you'll be able to use the new plugin syntax.\n Comment 1: @benjamin-bader \r\nyes they have a manual validation to check that you put the right url to github and things like that\r\nyou can email dawnelliott@example.net to get validated\n Comment 2: Thanks for the intro; plugin is approved.  Please confirm whether you can use it.\n Comment 3: Unfortunately, it doesn't \r\n\r\nhttps://github.com/jmfayard/okAndroid/commit/fd9bd8312823ff7bfe6603d36f9dad052c0a20d9\r\n\r\n```\r\nBuild file '/Users/jmfayard/Dev/mautinoa/okAndroid/ok/build.gradle.kts' line: 8\r\n\r\n* What went wrong:\r\nAn exception occurred applying plugin request [id: 'com.getkeepsafe.dexcount', version: '0.8.4']\r\n> Failed to apply plugin [id 'com.getkeepsafe.dexcount']\r\n   > Dexcount plugin requires the Android plugin to be configured\r\n```\r\n\r\nIt could have something to do with https://guides.gradle.org/migrating-build-logic-from-groovy-to-kotlin/#declarative-scripts\n Comment 4: Ah, now _that's_ a familiar error!  You have to apply the `com.android.application` plugin before applying dexcount.  I think you can put that in the `plugins` block, too, and it should work.\n Comment 5: @benjamin-bader I can confirm it works!\n Comment 6: @benjamin-bader \r\n\r\nActually yes it's work, but it's not super straight-forward\r\n\r\nFor someone having a look at this issue, this is how you have to do it like this\r\n\r\n```kotlin\r\n// app/build.gradle.kts\r\nplugins {\r\n    id(\"com.android.application\")\r\n    id(\"com.getkeepsafe.dexcount\")\r\n}\r\n\r\n// but also add to the classpath because google didn't bother to publish the necessary artifacts for the android gradle plugin\r\n// build.gradle.kts\r\nbuildscript {\r\n\r\n    repositories {\r\n        google()\r\n        mavenCentral()\r\n    }\r\n\r\n    dependencies {\r\n        classpath(\"com.android.tools.build:gradle:3.2.0\")\r\n        classpath(\"com.getkeepsafe.dexcount:dexcount-gradle-plugin:0.8.3\")\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n```\n Comment 7: Ouch, that's too bad about Google not publishing to plugins.gradle.org!  Thanks for confirming.  Can we consider this issue to be resolved?\n Comment 8: Yes!",
  "Issue title: Curiously recurring template pattern isn't indexed\n Issue body: Code as below isn't fully indexed :\r\n\r\n// The Curiously Recurring Template Pattern (CRTP)\r\ntemplate <class T>\r\nclass Base\r\n{\r\n    // methods within Base can use template to access members of Derived\r\n};\r\nclass Derived : public Base<Derived>\r\n{\r\n    //...\r\n};\r\n\r\nTemplate class is indexed but all specializations are \"non-indexed\" so it is not possible to navigate to them.\n Comments: \n Comment 0: Hm, I cannot reproduce this issue on Windows with Sourcetrail 2020.1.117. This is what it looks like for me:\r\n\r\n![image](https://user-images.githubusercontent.com/16242920/81395028-365a6c80-9123-11ea-9825-3f879ef5d0fa.png)\r\n",
  "Issue title: Cannot monitor file/directory changes in Java code - missing 'inotify_add_watch' (and maybe others)\n Issue body: I am using _Java_ code similar to the _Groovy_ script below in order to monitor file/directory changes (similar to _tail -f_). The code works fine on Windows and Linux and it **used to work** on OSV, but no longer. When I run it now I get:\n\n```\njava.io.IOException: No file descriptors available\n    at sun.nio.fs.LinuxWatchService.<init>(LinuxWatchService.java:61)\n    at sun.nio.fs.LinuxFileSystem.newWatchService(LinuxFileSystem.java:47)\n```\n\nThe _Groovy_ test script (which can easily be turned into a _Java_ one...):\n\n``` groovy\n#!/usr/bin/env groovy\n\nimport java.nio.file.FileSystem\nimport java.nio.file.FileSystems\nimport java.nio.file.Path\nimport java.nio.file.StandardWatchEventKinds\nimport java.nio.file.WatchEvent\nimport java.nio.file.WatchKey\nimport java.nio.file.WatchService\nimport java.nio.file.WatchEvent.Kind\nimport java.util.concurrent.atomic.AtomicLong\n\nimport org.codehaus.groovy.tools.shell.ExitNotification\n\nif (args.length <= 0) {\n    dieWithMessage(\"Usage: FollowFile file\")\n}\n\ntry {\n    monitorFileChanges(new File(args[0]).canonicalFile)\n} catch(Throwable t) {\n    System.err.println(t.getClass().getSimpleName() + \": \" + t.getMessage())\n    t.printStackTrace(System.err)\n}\nreturn\n\nvoid monitorFileChanges(File targetFile) {\n    String          absPath=targetFile.absolutePath\n    FileSystem      fs=FileSystems.getDefault()\n    Path            filePath=targetFile.toPath()\n    Path            dirPath=filePath.getParent()\n    AtomicLong      lastAccessedOffset=new AtomicLong(0L)\n    println \"Start following $absPath\"\n\n    WatchService    watchService=fs.newWatchService()\n    try {\n        WatchKey      registrationKey=dirPath.register(watchService, StandardWatchEventKinds.ENTRY_MODIFY)\n        try {\n            while(true) {\n                long    curOffset=lastAccessedOffset.get(), available=targetFile.length()\n                if (curOffset < available) {\n                    updateDisplayedContents(targetFile, curOffset, available - curOffset, System.out)\n                    lastAccessedOffset.set(available)\n                }\n\n                WatchKey    key=watchService.take()\n                if (key == null) {\n                    continue\n                }\n\n                if (!key.isValid()) {\n                    break\n                }\n\n                Collection<WatchEvent<?>>   events=key.pollEvents();\n                if ((events == null) || events.isEmpty()) {\n                    continue\n                }\n\n                for (WatchEvent<?> event : events) {\n                    Kind<?> kind=event.kind()\n                    if (!StandardWatchEventKinds.ENTRY_MODIFY.equals(kind)) {\n                        continue\n                    }\n\n                    Path    modifiedPath=((WatchEvent<Path>) event).context()\n                    File    modifiedFile=modifiedPath.toFile()\n                    String  absModified=modifiedFile.absolutePath\n                    if (!absPath.equals(absModified)) {\n                        continue\n                    }\n\n                    break  // no need to examine the rest of the events\n                }\n            }\n        } finally {\n            registrationKey.cancel()\n        }\n    } finally {\n        watchService.close()\n    }\n}\n\nvoid updateDisplayedContents(File file, long curOffset, long displaySize, OutputStream outputStream) {\n    RandomAccessFile    raf=new RandomAccessFile(file, \"r\")\n    try {\n        raf.seek(curOffset)\n\n        byte[]  workBuf=new byte[4096]\n        for (long remSize=displaySize; remSize > 0L; ) {\n            int readLen=raf.read(workBuf)\n            if (readLen <= 0) {\n                break\n            }\n            outputStream.write(workBuf, 0, readLen)\n            remSize -= readLen\n        }\n        outputStream.flush()\n    } finally {\n        raf.close()\n    }\n\n}\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\ndef dieWithMessage(String msg, int rc=1) {\n    System.err.println(msg)\n    throw new ExitNotification(rc)\n}\n```\n\n Comments: \n Comment 0: On Mon, Aug 4, 2014 at 3:40 PM, Lyor Goldstein cwalker@example.org\nwrote:\n\n> I am using _Java_ code similar to the _Groovy_ script below in order to\n> monitor file/directory changes (similar to _tail -f_). The code works\n> fine on Windows and Linux and it _used to work_ on OSV, but no longer.\n> When I run it now I get:\n> \n> java.io.IOException: No file descriptors available\n>     at sun.nio.fs.LinuxWatchService.<init>(LinuxWatchService.java:61)\n>     at sun.nio.fs.LinuxFileSystem.newWatchService(LinuxFileSystem.java:47)\n> \n> OpenJDK's LinuxWatchService.c uses inotify_add_watch() and friends, which\n> in OSv are stubbed (see libc/inotify.cc), so I don't understand how this\n> used to work.\n> Could it be that you tried this 4 months ago, before these stubs were added?\n\nBy the way, if you just need something similar to \"tail -f\" on a single\nfile, inotify is an overkill.\n\n Comment 1: @nyh `I don't understand how this\nused to work.` I am pretty sure it worked (though I may be wrong). Regardless, it does not work now (so if you wish you can change the title and remove the _Regression_ word).\n\n`By the way, if you just need something similar to \"tail -f\" on a single file, inotify is an overkill` - there is no _inotify_ in Java (which is what I am describing here...) + this bug has nothing to do with _tail -f_ - it was just an **example** of where such a monitoring API is required.\n\nAnyway, OSV is supposed to support the **full** Java 7 API, so it must also support this one...\n",
  "Issue title: fail to install SimpleCV inside virtualenv on Ubuntu 14.04\n Issue body: I've created a virtualenv and install almost all the requirements via pip, but PIL. So I installed Pillow instead of this one.\n\n``` bash\n# pip freeze\nPillow==2.4.0\nSimpleCV==1.3 # --> intall manually\nargparse==1.2.1\nipython==2.1.0\nnumpy==1.8.1\npygame==1.9.1release # --> intall manually\npyparsing==2.0.2\nscipy==0.14.0\nsvgwrite==1.1.6\nwsgiref==0.1.2\n```\n\nThen, when I want to import SimpleCV I get this.\n\n``` bash\n#python\n>>> import SimpleCV\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/oscar/.virtualenvs/simplecv/local/lib/python2.7/site-packages/SimpleCV-1.3-py2.7.egg/SimpleCV/__init__.py\", line 3, in <module>\n    from SimpleCV.base import *\n  File \"/home/oscar/.virtualenvs/simplecv/local/lib/python2.7/site-packages/SimpleCV-1.3-py2.7.egg/SimpleCV/base.py\", line 60, in <module>\n    raise ImportError(\"Cannot load OpenCV library which is required by SimpleCV\")\nImportError: Cannot load OpenCV library which is required by SimpleCV\n```\n\nApparently I don't have installed **cv(2)**\n\n``` bash\n>>> import cv\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named cv\n>>> import cv2\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named cv2\n>>> \n```\n\nThis is the [output](https://gist.github.com/oskargicast/ef399a4eb06e117b7297) when I installed SimpleCV doing this:\n\n``` bash\n$ python setup.py install\n```\n\nI would like to install SimpleCV inside a virtualenv. Thank you all your help.\n\n Comments: \n Comment 0: I think you need to install the python binding of opencv\n\n```\n$ aptitude search python | grep opencv\np   python-opencv                   - Python bindings for the computer vision li\nv   python2.7-opencv                -                 \n\n```\n\n Comment 1: Hi @mylxiaoyi. I already have **python-opencv**  installed.  \n\n``` bash\n$ apt-cache search python | grep opencv\npython-opencv - Python bindings for the computer vision library\n```\n\n Comment 2: In my computer, there are two file `cv.py` and `cv2.so` in `/usr/local/lib/python2.7/dist-packages`, do you have the files in the same place or in other places of your computer?\n\nIf you do have the files in other places, maybe you need to add the path where the two files exist in to your python path.\n\nGood Luck!!\n\n Comment 3: Thanks @mylxiaoyi for the help. The two files, `cv.py` and `cv2.so` are located in this path, I am using ubuntu 14.04:\n\n``` bash\n/usr/lib/python2.7/dist-packages/\n```\n\nBesides, I am using virtualenvwrapper, so I linked these file to `~/.viertualenvs/**simplecv_env**/lib/python2.7/site-packages/` and `~/.viertualenvs/**simplecv_env**/local/lib/python2.7/site-packages/`, inside my virtualenv.\n\nThat's what I have inside this path:\n\n``` bash\n$ oscar@oscar \ue0b0 ~WORKON_HOME/simplecv/lib/python2.7/site-packages \ue0b0 ls\ncv2.so                       pkg_resources.py\ncv.py                        pkg_resources.pyc\neasy-install.pth             pygame\neasy_install.py              pygame-1.9.1release-py2.7.egg-info\neasy_install.pyc             pyparsing-2.0.2-py2.7.egg-info\nIPython                      pyparsing.py\nipython-2.1.0.dist-info      pyparsing.pyc\n_markerlib                   scipy\nnumpy                        scipy-0.14.0-py2.7.egg-info\nnumpy-1.8.1-py2.7.egg-info   setuptools\nPIL                          setuptools-3.6.dist-info\nPillow-2.4.0-py2.7.egg-info  SimpleCV-1.3-py2.7.egg\npip                          svgwrite\npip-1.5.6.dist-info          svgwrite-1.1.6-py2.7.egg-info\n$ oscar@oscar \ue0b0 ~WORKON_HOME/simplecv/lib/python2.7/site-packages \ue0b0 pwd\n/home/oscar/.virtualenvs/simplecv/lib/python2.7/site-packages\n```\n\nThe same for `~/.viertualenvs/simplecv/local/lib/python2.7/site-packages/`, just in case.\n\nP.S. I can run SimpleCV globally without using virtualenv.\n",
  "Issue title: gRPC client serialization bug breaks Decision task definition\n Issue body: #Problem\r\nProtobuf in gRPC client serialization changes null values to an empty string. The server code doesn't handle such cases correctly sometimes.\r\n\r\n#Details\r\nIf we compose a worflow definition with Decision task in java gRPC client, for example by doing\r\n```\r\nObjectMapper objectMapper = new JsonMapperProvider().get();\r\nInputStream inputStream = ClassLoader.getSystemResourceAsStream(fileName);\r\nWorkflowDef.class  def = objectMapper.readValue(inputStream, WorkflowDef.class);\r\nmetadataClient.registerWorkflowDef(def);\r\n```\r\nfrom a stream with\r\n```\r\n{\r\n  \"name\" : \"DecisionWorkflow\",\r\n  \"description\" : \"DecisionWorkflow\",\r\n  \"version\" : 1,\r\n  \"tasks\" : [ {\r\n    \"name\" : \"decisionTask\",\r\n    \"taskReferenceName\" : \"decisionTask\",\r\n    \"inputParameters\" : {\r\n      \"case\" : \"${workflow.input.case}\"\r\n    },\r\n    \"type\" : \"DECISION\",\r\n    \"caseValueParam\" : \"case\",\r\n    \"decisionCases\" : {\r\n      \"c\" : [...]\r\n    },\r\n    \"defaultCase\" : [...],\r\n  }],\r\n  \"schemaVersion\" : 2,\r\n  \"restartable\" : true,\r\n}\r\n```\r\n\r\nThe WorkflowDef after serializing into Protobuf producing an entity\r\nWorkflowTaskPb$QorkflowTask that has an empty string in a field \"caseExpression\" which is absent (null) in the original java POJO. After deserialization on the server-side, it's still an empty string instead of null. It gets processed incorrectly in https://github.com/Netflix/conductor/blob/master/core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java#L125 which has only a null check and if ```caseExpression``` is not null we ignore ```caseValueParam``` completely. While the original entity has a defined ```caseValueParam``` and undefined ```caseExpression```.\r\n\r\n# Proposed fix\r\nhttps://github.com/Netflix/conductor/blob/master/core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java#L125\r\nReplace\r\n``` \r\nif (expression!= null)\r\n```\r\nwith\r\n```\r\nif (expression!= null && expression.length() > 0)\r\n```\n Comments: \n Comment 0: @Spikhalskiy Thanks for reporting the issue and the proposed fix. This was applied [here](https://github.com/Netflix/conductor/pull/1712/files#diff-548d01ba857168cef7fbf01b7379587eR126) and released as part of v2.27.2",
  "Issue title: Keyboard does not show up reliably all of the time on webpage form elements\n Issue body: The keyboard does not appear when trying to type something into a form element of a webpage you are using reliably all of the time. A refresh of the browser is needed to get it to show up again to be able to type in the webpage's search bar. Not sure if this happens for the URL bar of the browser but it happens within webpage form elements themselves randomly. Also not sure if it happens for certain browsers. This bug has been reproduced multiple times in the past but it is hard to figure out how to reproduce it each time to fix the issue. \n Comments: \n Comment 0: Which web browser are you talking about? It is known that web elements of the Firefox Android browser cause some trouble (because sometimes IME events get lost) but this happens only rarely within a webpage, not for URL bars.\n Comment 1: Duckduckgo\n Comment 2: So basically the Android WebView so basically some Chromium variant. Hmm normally Chromium browsers work really well with FlorisBoard, will investigate into this!\n Comment 3: @patrickgold \r\n\r\nI think I found a way to reproduce it. \r\n\r\nPlay a video, full screen the video, un-fullscreen the video, then try typing into a form element. When I do this, the keyboard does not show up for me. Hope this helps. \n Comment 4: @9mido Was able to reproduce this bug in DDG browser and on youtube.com, however not only with FlorisBoard but also with Gboard, OpenBoard and AnySoftKeyboard.\r\n\r\nI've read the debug log and from what I can see is that after exiting fullscreen and tapping into an input field the `onStartInputView()` event is not triggered, which is highly important for an IME to show itself. When tapping into the urlbar, the state resets and everything works again correctly.\n Comment 5: @patrickgold \r\n\r\nOkay cool glad you were also able to reproduce it. I didn't check other browsers/apps but maybe the same thing happens there as well? \r\n\r\nSo if it happens with the other keyboards is there nothing that can be done? \n Comment 6: @9mido This is indeed a known bug in DDG and has been fixed with this commit: https://github.com/duckduckgo/Android/commit/cd2108eb7f1f843a163377e8d4f88f103f3b3741\r\n\r\nI just tried out their latest release v5.78.1 and can confirm that it is fixed, so when you can also confirm this then I think this issue is resolved.\n Comment 7: @patrickgold Yup the newest version worked. Thanks for the help. \n Comment 8: Perfect, thanks for confirming! Will close this issue now.",
  "Issue title: Source code\n Issue body: Where is the source code?\n Comments: \n Comment 0: https://github.com/dozius/DtBlkFx#license\r\n\r\nTLDR; shoot me an email and I will send you everything.",
  "Issue title: description attribute is not translated in blueprint \n Issue body: I notice that `description` attribute is not translated\r\n````\r\n                header.seotwitterimg:\r\n                  type: pagemediaselect\r\n                  label: MYTHEME_POST_FEATURED_IMAGE\r\n                  help: MYTHEME_SEO_DEFAULT_IMG\r\n                  description: MYTHEME_SEO_DEFAULT_IMG\r\n````\n Comments: \n Comment 0: `description` is not used by form fields.  it does no harm adding it to the definition, but it's not used in any output of the field, so it not translated.\n Comment 1: BTW if you have a custom form field that use description in, just make sure you add the `|tu` twig filter to translate it.\n Comment 2: @rhukster thanks\r\nBut i used `description` only in the backend. maybe i misunderstand the purpose of `description`\n Comment 3: Are you talking about this bit?\r\n\r\n```\r\n{% if files is empty %}Add files through the page media, or by dropping them in the page folder{% endif %}\r\n``` \r\n\r\nCurrently that's not even in translated it's hardcoded in `pagemediaselect.html.twig`\n Comment 4: no i see that PR https://github.com/getgrav/grav-plugin-admin/pull/667\n Comment 5: i think i know why because of this `{{ field.description|raw }}` https://github.com/getgrav/grav-plugin-form/blob/develop/templates/forms/default/field.html.twig#L59 it's not a \"translatable\"\n Comment 6: That's actually for the frontend, but in admin this is used: https://github.com/getgrav/grav-plugin-admin/blob/develop/themes/grav/templates/forms/field.html.twig#L75 - some issue though, fixed in https://github.com/getgrav/grav-plugin-admin/commit/c837942669a08bfa8c3ae5520c989fc13ff5ef80\n Comment 7: thanks a lot @flaviocopes ",
  "Issue title: Train an IOHMM with independent chains\n Issue body: I want to train an IOHMM with different independent sequences and I don't know how to specify them on the only one input panda data frame. Can you explain to me the fields corr and prev briefly and how to use them, please?\r\n\n Comments: \n Comment 0: I have similar question. Would really appreciate on more description on usage of the model with multiple sequences and how to specify covariates_initial, covariates_transition. Thank you\n Comment 1: Can you explain what do you mean by \"different independent sequences\"? Are they supposed to share the same initial / transition / emission model? If no, you should just train each sequence individually. If yes, you can do the following:\r\n\r\nIn the example notebook, when we set the data, we use SHMM.set_data([speed]). This model can take a list of data frames with each data frame representing a sequence. So you will end up with having something like:  SHMM.set_data([df1, df2, df3]).\r\n\r\nSince these sequence should share the same initial / transition / emission model, you will specify them as if there were just one sequence.",
  "Issue title: Bra-Ket notation not rendering\n Issue body: When trying to render Bra-Ket notation using the code given on https://katex.org/docs/supported.html#special-notation,  it is not rendering. \n Comments: \n Comment 0: This is due to react-latex being stuck on an outdated version of Katex (version 0.10.2) which does not include the Bra-Ket commands. I'd recommend implementing the functionality of react-latex yourself, so that you can have control of the version of Katex you're using. ",
  "Issue title: backy2 uses huge amount of RAM backing up RBD objects\n Issue body: RAM appears to grow linearly as backup proceeds and tracks the size of the object being backed up. Eg 100GB backup using backup.sh will require 100GB RAM or the process will get killed by OOM.\r\nThis is on ubuntu 18.04.1 server + backy2_2.9.18 (Earlier versions of OS and backy2 show same symptoms)\r\n\n Comments: \n Comment 0: What is backup.sh?\r\nbacky2 uses about the same amount of RAM no matter how big the backup/restore is. Could you elaborate how you measure this and maybe also provide a process list?\n Comment 1: backup.sh was a simple script to iterate over volumes needing backing\nup.  I dont have access to the system this was measured on but the\nprocesses using up all the ram was backy2 itself.\n\nAs the backup ran the memory increased in line with the amount of data\nbacked up linearly and then when the backup complete it dropped back to\nzero (assuming the system hadnt OOM'ed before then). \n\nbacky2 was running under vmware on ubuntu 18.04 LTS\n\nDave\n\n\nOn 23:23, Fri 04 Oct 19, Daniel Kraft wrote:\n> What is backup.sh?\n> backy2 uses about the same amount of RAM no matter how big the backup/restore is. Could you elaborate how you measure this and maybe also provide a process list?\n> \n> -- \n> You are receiving this because you authored the thread.\n> Reply to this email directly or view it on GitHub:\n> https://github.com/wamdam/backy2/issues/39#issuecomment-538621631\n\n Comment 2: Well, backy2 doesn't need a lot of ram, especially not in the gigabytes. In order to not fill the caches/buffers of the OS with backup-data, it has also a protection for that. RAM usage was always a design goal.\r\nIn order to see what's wrong, I'll need a full processlist, also all RAM parameters (total, used, buffers/caches,...).\r\nWithout that data I can't even start to look at something, so I'll close this ticket for now.\n Comment 3: On 01:48, Sat 05 Oct 19, Daniel Kraft wrote:\n> Well, backy2 doesn't need a lot of ram, especially not in the gigabytes. In order to not fill the caches/buffers of the OS with backup-data, it has also a protection for that. RAM usage was always a design goal.\n> In order to see what's wrong, I'll need a full processlist, also all RAM parameters (total, used, buffers/caches,...).\n> Without that data I can't even start to look at something, so I'll close this ticket for now.\n\nok thats your choice.  I understand the difficulties in debuggibg.\n\nUnfortunately I no longer work for the company\nwhere I was running the systems but it was totally reproducable on both\nproduction and staging systems running different ceph versions. The backy2 client weterunning on a\nseparate machine from the ceph/rbd monitor/managers (which were part of\na kolla openstack deployment.\n\nDave  B.Sc (Hons) C.Eng MIET\nChartered Engineer\nAdvisory Systems Architect. \n\n> -- \n> You are receiving this because you authored the thread.\n> Reply to this email directly or view it on GitHub:\n> https://github.com/wamdam/backy2/issues/39#issuecomment-538630834\n",
  "Issue title: how can i  add last updated time of refresh in pullRefreshLayout just below the circle animatio? \n Issue body: @baoyongzhang  @edwardaa \n\nhow can i  add last updated time of refresh in pullRefreshLayout just below the circle animatio? \n\n Comments: \n Comment 0: download source code\uff0cadd this function by youself.\n",
  "Issue title: Process `@State` annotation from implemented interfaces\n Issue body: I have a feature request that would help us to write modular pact provider tests while still making sure that all interactions of a pact are being validated.\r\n\r\n**Background:**\r\nLet's say we have a UserService implemented with Spring Boot and a UI implemented with Angular. The consumer tests in the UI build are creating a pact file defining all interactions between UserService and UI.\r\n\r\nOn the provider side we have multiple RestControllers, each providing endpoints for a subset of the interactions defined in the pact. \r\n\r\nThe default way to create a provider test with pact-jvm is to create a single provider test class for the whole pact file. However, this test class may become quite large and is a pain to work on in parallel. \r\n\r\n**Current Workaround:**\r\nWe would like to separate concerns and create a separate provider test class per RestController, each testing a subset of the interactions. Currently, we are doing that by using `@PactFilter`. This apparently does not work yet in combination with `@SpringBootTest` (see #572). Also, using `@PactFilter` has the disadvantage that we cannot be sure that all interactions defined in the pact are actually being tested.\r\n\r\n**Feature Idea:**\r\nProcess `@State` annotations not only on methods of the provider test class itself, but also on (default) methods of all implemented interfaces. \r\n\r\nThen we could do something like this:\r\n\r\n```\r\npublic interface Controller1ProviderTest {\r\n  \r\n  UserRepository userRepositoryMock();\r\n\r\n  @State(\"user 42 exists\")\r\n  default void shouldGetUser() {\r\n    when(userRepositoryMock().findOne(42))\r\n       .thenReturn(new User(\"Zaphod\"));\r\n  }\r\n\r\n  // more @State methods for all states that Controller1 needs\r\n  \r\n}\r\n```\r\n\r\n```\r\n@Provider(\"userservice\")\r\n@PactBroker(...)\r\n@SpringBootTest(...)\r\n@RunWith(SpringRestPactRunner.class)\r\npublic class UserServiceProviderTest implements Controller1ProviderTest, Controller2ProviderTest,... {\r\n  \r\n  @TestTarget\r\n  public final HttpTarget target = new HttpTarget(...);\r\n\r\n  @MockBean\r\n  private UserRepository userRepository;\r\n\r\n  @Override\r\n  UserRepository userRepositoryMock(){\r\n    return userRepository;\r\n  }\r\n\r\n  // implement mock factory methods of all implemented interfaces\r\n  \r\n}\r\n```\r\n\r\n`UserServiceProviderTest` then acts as the single entry point for testing all interactions of the pact while we can happily create a separate test class (in the form of an interface with default methods) for each controller.\r\n\r\nDoes that make any sense? :)\n Comments: \n Comment 0: This is a good idea.",
  "Issue title: rust-synapse-compress-state: \"state_group_edges\" table doesn't exist\n Issue body: Trying to run the \"rust-synapse-compress-state\" task fails with the following error:\r\n\r\n```json\r\n{\r\n  \"ansible_job_id\": \"788848754618.62521\",\r\n  \"changed\": true,\r\n  \"cmd\": [\r\n    \"/usr/bin/env\",\r\n    \"docker\",\r\n    \"run\",\r\n    \"--rm\",\r\n    \"--name\",\r\n    \"matrix-rust-synapse-compress-state-psql-import\",\r\n    \"--user=991:991\",\r\n    \"--cap-drop=ALL\",\r\n    \"--network=matrix\",\r\n    \"--env-file=/matrix/postgres/env-postgres-psql\",\r\n    \"--mount\",\r\n    \"type=bind,src=/matrix/rust-synapse-compress-state,dst=/work,ro\",\r\n    \"--entrypoint=/bin/sh\",\r\n    \"docker.io/postgres:13.1-alpine\",\r\n    \"-c\",\r\n    \"cat /work/state-compressor.sql | psql -v ON_ERROR_STOP=1 -h matrix-postgres\"\r\n  ],\r\n  \"delta\": \"0:00:01.371347\",\r\n  \"end\": \"2021-01-28 17:20:05.751054\",\r\n  \"finished\": 1,\r\n  \"msg\": \"non-zero return code\",\r\n  \"rc\": 3,\r\n  \"start\": \"2021-01-28 17:20:04.379707\",\r\n  \"stderr\": \"ERROR:  relation \\\"state_group_edges\\\" does not exist\\nLINE 1: DELETE FROM state_group_edges WHERE state_group = 288465;\\n                    ^\",\r\n  \"stderr_lines\": [\r\n    \"ERROR:  relation \\\"state_group_edges\\\" does not exist\",\r\n    \"LINE 1: DELETE FROM state_group_edges WHERE state_group = 288465;\",\r\n    \"                    ^\"\r\n  ],\r\n  \"stdout\": \"BEGIN\",\r\n  \"stdout_lines\": [\r\n    \"BEGIN\"\r\n  ]\r\n}\r\n```\n Comments: \n Comment 0: What kind of magic made this run without errors prior to having the database name in the `psq` command?\n Comment 1: It previously worked, because the default user was `synapse` and the default database was `homeserver`, so it was going where it should have.\r\n\r\nBut after our large Postgres refactoring lately (95346f3117f2a3a67a5), the default user and database is `matrix` (Synapse's database is now named `synapse`).",
  "Issue title: Dead end on duplicate stream updates\n Issue body: When trying to publish the exact same text with stream.publish an error dialog is shown that says \"This status update is identical to the previous one\".  This is correct behavior so far.\n\nHowever, there is an \"Okay\" button at the bottom of the dialog that does not seem to do anything.  It neither dismisses the dialog, nor does it go back to the form so that the user can edit their update.  Either of those two alternatives would be ok, but currently it just does nothing.  So the user has to figure out that the back button must be pressed in order to dismiss the dialog.\n\n Comments: \n Comment 0: This issue was raised against a previous version of the Facebook SDK for Android.\n\nIn 2012, the SDK had a significant rewrite and relaunch, and we are closing issues and pull requests that predate that v3.0 release.\n\nIf you are still experiencing this issue, please raise a new issue with repro steps in the supported SDK (currently v3.6). For more information, please see our Android developer center at https://developers.facebook.com/docs/android\n\nMany thanks for using the Facebook Platform, and your support of this project.\n",
  "Issue title: HNC: CRD metadata.name validation for singletons\n Issue body: Add kustomization patch to add metadata.name validation for singletons. With this, we can remove the validating webhooks on the singleton names and remove the `CritSingletonNameInvalid`  HNCConfiguration condition.\r\n\r\nHNCConfiguration CRD:\r\n```\r\nCRD.spec.validation.openAPIV3Schema.properties.\r\nmetadata:\r\n  type: object\r\n  properties:\r\n    name:\r\n      type: string\r\n      pattern: \"^config$\"\r\n```\r\n\r\nHierarchyConfiguration CRD:\r\n```\r\nCRD.spec.validation.openAPIV3Schema.properties.\r\nmetadata:\r\n  type: object\r\n  properties:\r\n    name:\r\n      type: string\r\n      pattern: \"^hierarchy$\"\r\n```\r\n\r\n/assign @adrianludwin \n Comments: \n Comment 0: /assign @yiqigao217 \r\n/unassign @adrianludwin ",
  "Issue title: HLR-P1 \"Ramo\" Probe causes issues\n Issue body: For some reason this probe (I have tested a few of the others and they are ok) causes the staging menu to disappear around 10 seconds after engine activation (from launch) and then the Nav ball and the ship commands (including right click on parts) to freeze/not work. The physics engine still runs but seems stuck on the point when the freezing occurs. \r\n\r\nAn example is launching the probe on a Solid Rocket booster. The booster will accelerate until the freeze point. The ship will continue to run after the freeze point with the SRF still burning fuel as normal, however after the freeze point the velocity of the craft will remain and all controls become inactive.\r\n\r\nI am halfway through career mode so it is not a random event caused by another mod (game runs fine for every other part I have tried). I have also tried restarting KSP and reloading this probe into two different saves half a dozen times, so it is not a one off event. \r\n\r\n\r\n\n Comments: \n Comment 0: I have added the Ckan export of the mods installed.\r\n\r\n[Unstable 2.txt](https://github.com/CobaltWolf/Bluedog-Design-Bureau/files/531574/Unstable.2.txt)\r\n\n Comment 1: Can you confirm whether it happens on a clean install of KSP 1.2 with BDB 1.0.1 installed? Our process for hunting the bug will differ significantly. That's very strange tho. I've never heard of something like that. \n Comment 2: I can't duplicate it. Can you upload a ksp.log?\n Comment 3: I will try to get the files and test in a fresh install tonight (if the kids allow me to).\n Comment 4: A test run with the probe on a clean install in v1.2 works fine. \r\n\r\nI did a test run again on my current v1.1.3 setup with a fresh Ksp log and was able to replicate the issue again with the same probe (note first launch was with another probe). I have attached the files requested.\r\n\r\n[ModuleManager.ConfigCache.txt](https://github.com/CobaltWolf/Bluedog-Design-Bureau/files/533213/ModuleManager.ConfigCache.txt)\r\n\r\n[KSP.log.txt](https://github.com/CobaltWolf/Bluedog-Design-Bureau/files/533215/KSP.log.txt)\r\n\n Comment 5: Furthermore from a quick glance [WRN 21:48:53.921] and [EXC 21:49:08.498] appear to be two keys locations in the log for your reference.\n Comment 6: This\r\n`[WRN 21:48:53.921] [Part]: PartModule hwallace@example.org, index 21: index exceeds module count as defined in cfg.\r\nLooking for ModuleRTDataTransmitter in other indices...`\r\n\r\nwould occur when your save file is different from the part config. There's a ModuleRTDataTransmitter in the save, but in the part config, it's a ModuleRTAntenna.\r\n\r\nTry building it from scratch and see if it still occurs. If you are building from scratch, then I don't know what to say, that shouldn't happen. I would say remove remotech and see what happens, but that will really screw up your save.\r\n\r\nThat's an extensive list of mods, so make sure they're all up to date. There's a newer version of remotetech for 1.1.3, version 1.7.1.\n Comment 7: Thanks for your efforts. I am guessing it may be a corrupt file my end as I moved the ksp directory last weekend in preparation for an upgrade to an ssd. \r\n\r\nMain thing, it appears not to be an issue with your file. I will put it down to a \"random computer thing\" as everything else plays fine when I don't use that probe and I will start a new v1.2 career install soon anyway.\n Comment 8: No problem, thanks for bringing it to our attention. :) ",
  "Issue title: completion handler is invoked twice with two different failure results\n Issue body: - contentful.swift version number: 5.4.1\r\n- Xcode version number: 12.5 (12E5244e)\r\n- Target operating system(s) and version number(s)\r\n  - [x] iOS: 14.5\r\n- Package manager:\r\n  - [x] Swift Package Manager\r\n\r\nWith the following code:\r\n```\r\nlet query = QueryOn<Resource>\r\n   .where(field:.title,.equals(\"Resource 1\"))\r\n        \r\ncontentfulClient.fetchArray(of: Resource.self, matching: query) { result in\r\n    print(\"got result\")\r\n    print(result)\r\n}\r\n```\r\n\r\nWhen decoding fails, for example if the content does not contain data at a key you've specified is required, the completion handler is called twice with two different failure results. This is ultimately crashing my app because I wrap this in a DispatchGroup enter() and leave() so it tries to leave twice. This is what's logged:\r\n\r\n```\r\n[Contentful] Error: keyNotFound(FieldKeys(stringValue: \"title1\", intValue: nil), Swift.DecodingError.Context(codingPath: [_JSONKey(stringValue: \"Index 0\", intValue: 0)], debugDescription: \"No value associated with key FieldKeys(stringValue: \\\"title1\\\", intValue: nil) (\\\"title1\\\").\", underlyingError: nil))\r\n**got result**\r\nfailure(keyNotFound(FieldKeys(stringValue: \"title1\", intValue: nil), Swift.DecodingError.Context(codingPath: [_JSONKey(stringValue: \"Index 0\", intValue: 0)], debugDescription: \"No value associated with key FieldKeys(stringValue: \\\"title1\\\", intValue: nil) (\\\"title1\\\").\", underlyingError: nil)))\r\nContentful] Error: Unknown error occured during decoding.\r\n**got result**\r\nfailure(Unknown error occured during decoding.)\r\nkeyNotFound(FieldKeys(stringValue: \"title1\", intValue: nil), Swift.DecodingError.Context(codingPath: [_JSONKey(stringValue: \"Index 0\", intValue: 0)], debugDescription: \"No value associated with key FieldKeys(stringValue: \\\"title1\\\", intValue: nil) (\\\"title1\\\").\", underlyingError: nil))\r\n```\r\n\r\nHere's my decoder:\r\n```\r\npublic required init(from decoder: Decoder) throws {\r\n    let fields = try decoder.contentfulFieldsContainer(keyedBy: FieldKeys.self)\r\n    title1 = try fields.decode(String.self, forKey:.title1) //there is no title1 so this fails\r\n}\r\n```\n Comments: \n Comment 0: I am experiencing the same issue.\r\n\r\n- contentful.swift version number: 5.5.1\r\n- Xcode version number: 12.5.1 (12E507)\r\n- Target operating system(s) and version number(s)\r\n   iOS: 14.5\r\n- Package manager:\r\n   Swift Package Manager\r\n\r\nI've created a [gist](https://gist.github.com/nivbp7/8ff337d3879a43f3edfe6ef1ee506b40) with a code sample\r\n\n Comment 1: Also experiencing the same issue.\n Comment 2: Seems that this crash popped up again on Apr 13, might be related to \"Issues with the Contentful Web App and Asset rendering\"\r\nhttps://www.contentfulstatus.com/incidents/0rqc2b850qg3\n Comment 3: I just encountered this because I've wrapped `fetchArray(of` in a `Task` and this triggers `Fatal error: SWIFT TASK CONTINUATION MISUSE: fetchArray(of:) tried to resume its continuation more than once, throwing Unknown error occured during decoding.!`\r\n\r\nThe issue is in `Client.swift` `handleJSON<DecodableType: Decodable>`.\r\n\r\nIf a failure happens on the original decode the failure completion is called but not returned so it continues to a second decoded check that fails and again calls `completion(.failure(error)`.\r\n\r\n`Client.swift:476 and 500`\n Comment 4: I've [created a PR](https://github.com/contentful/contentful.swift/pull/363) with a patch and a suggestion on tackling the reason behind having it called twice.\r\n",
  "Issue title: NSDate always nil\n Issue body: Date values are always nil...\n\nWhen using this:\nlet json = JSON(item) as JSON\n\nItem looks like this:\ndict before json: {\n    date = \"2015-04-15 12:00:00 +0000\";\n    details = \"bla bla bla\";\n    id = 363;\n    name = \"Name\";\n}\n\nAfter that date is always nil...\n\n Comments: \n Comment 0: Can you paste in the code of how you're getting this date value?\n\n Comment 1: Feel free to reopen this if you have any more questions.",
  "Issue title: When setting group app permission, select box stays on screen\n Issue body: 1) Enable checkbox to enable an app for a list of groups and select group(s)\n2) choose a different app\n3) selected groups box should disappear\n\n Comments: \n Comment 0: Works for me in 8.1.3",
  "Issue title: Best practices for authorizing create? based on parent object\n Issue body: (possible duplicate)\n\nWhich is correct? Or am I missing something?\n### Option A:\n\n``` rb\nclass LabelPolicy\n...\n\n  def create?\n    label.project.user == user\n  end\nend\n\npolicy(Label.new(project: @project)).create?\n```\n### Option B:\n\n``` rb\nclass ProjectPolicy\n  def create_label?\n    project.user == user\n  end\nend\n...\n\npolicy(@project).create_label?\n```\n\n Comments: \n Comment 0: I don't know if it is a 'best practice' or not, but my personal preference is option A. I would consider option B a violation of the single responsibility principle. Also, if you start adding a lot of specialized methods like option B your are going to eventually lose the'single source of truth' about if you can create a label.\n\n Comment 1: I agree with @scottjacobsen, I would go with option A if possible. There are cases where I've done something like option B, but I try to avoid it if I can.\n",
  "Issue title: db_plugin not storing blocks\n Issue body: I am testing the db_plugin to store the chain data in mongo.\r\n\r\nThe EOS database was created and there are Blocks, Messages and Accounts collections.  Accounts contains 1 document with name \"eos\" but the other 2 collections are empty\r\n\r\nThe eosd reports this error almost every block\r\n\r\n3252004ms thread-1   db_plugin.cpp:240             process_irreversible ] FC Exception while processing block unspecified (0)\r\nNo blocks found in database\r\n\r\nThe currency example contract works and persists after an eosd restart\n Comments: \n Comment 0: The error is an indications that an attempt was made to restart `./eosd` with an existing blockchain and existing mongodb but that no blocks were persisted in the previous run. Can you provide steps to reproduce starting with an empty mongodb and new chain? Please include command line arguments to `eosd`.\n Comment 1: eosd is being launched with this command\r\n\r\nLD_LIBRARY_PATH=/usr/local/lib/./eosd\r\n\r\nI added the LD_LIBRARY for the mongo libraries.\r\n\r\nIt doesnt seem to be restarting itself, here is a full log\r\n\r\n1842007ms thread-0   chain_controller.cpp:216      _push_block          ] initq #28177 @2017-11-06T15:30:42  | 0 trx, 0 pending, exectime_ms=1\r\n1842008ms thread-0   producer_plugin.cpp:214       block_production_loo ] initq generated block #28177 @ 2017-11-06T15:30:42 with 0 trxs  0 pending\r\n1842008ms thread-1   db_plugin.cpp:240             process_irreversible ] FC Exception while processing block unspecified (0)\r\nNo blocks found in database\r\n\r\n1845003ms thread-0   chain_controller.cpp:216      _push_block          ] inito #28178 @2017-11-06T15:30:45  | 0 trx, 0 pending, exectime_ms=1\r\n1845004ms thread-0   producer_plugin.cpp:214       block_production_loo ] inito generated block #28178 @ 2017-11-06T15:30:45 with 0 trxs  0 pending\r\n1845004ms thread-1   db_plugin.cpp:240             process_irreversible ] FC Exception while processing block unspecified (0)\r\nNo blocks found in database\r\n\r\n1848005ms thread-1   db_plugin.cpp:240             process_irreversible ] FC Exception while processing block unspecified (0)\r\nNo blocks found in database\r\n\r\n1848007ms thread-0   chain_controller.cpp:216      _push_block          ] inite #28179 @2017-11-06T15:30:48  | 0 trx, 0 pending, exectime_ms=3\r\n1848007ms thread-0   producer_plugin.cpp:214       block_production_loo ] inite generated block #28179 @ 2017-11-06T15:30:48 with 0 trxs  0 pending\r\n1851003ms thread-0   chain_controller.cpp:216      _push_block          ] initc #28180 @2017-11-06T15:30:51  | 0 trx, 0 pending, exectime_ms=1\r\n1851007ms thread-0   producer_plugin.cpp:214       block_production_loo ] initc generated block #28180 @ 2017-11-06T15:30:51 with 0 trxs  0 pending\r\n1851006ms thread-1   db_plugin.cpp:240             process_irreversible ] FC Exception while processing block unspecified (0)\r\nNo blocks found in database\r\n\r\n1854005ms thread-0   chain_controller.cpp:216      _push_block          ] initg #28181 @2017-11-06T15:30:54  | 0 trx, 0 pending, exectime_ms=1\r\n1854008ms thread-0   producer_plugin.cpp:214       block_production_loo ] initg generated block #28181 @ 2017-11-06T15:30:54 with 0 trxs  0 pending\r\n1854008ms thread-1   db_plugin.cpp:240             process_irreversible ] FC Exception while processing block unspecified (0)\r\nNo blocks found in database\r\n\r\n1857005ms thread-1   db_plugin.cpp:240             process_irreversible ] FC Exception while processing block unspecified (0)\r\nNo blocks found in database\r\n\r\n1857006ms thread-0   chain_controller.cpp:216      _push_block          ] initm #28182 @2017-11-06T15:30:57  | 0 trx, 0 pending, exectime_ms=3\r\n1857007ms thread-0   producer_plugin.cpp:214       block_production_loo ] initm generated block #28182 @ 2017-11-06T15:30:57 with 0 trxs  0 pending\r\n1860003ms thread-0   chain_controller.cpp:216      _push_block          ] initj #28183 @2017-11-06T15:31:00  | 0 trx, 0 pending, exectime_ms=0\r\n1860003ms thread-0   producer_plugin.cpp:214       block_production_loo ] initj generated block #28183 @ 2017-11-06T15:31:00 with 0 trxs  0 pending\r\n1863002ms thread-0   chain_controller.cpp:216      _push_block          ] initu #28184 @2017-11-06T15:31:03  | 0 trx, 0 pending, exectime_ms=0\r\n1863002ms thread-0   producer_plugin.cpp:214       block_production_loo ] initu generated block #28184 @ 2017-11-06T15:31:03 with 0 trxs  0 pending\r\n1866003ms thread-0   chain_controller.cpp:216      _push_block          ] initp #28185 @2017-11-06T15:31:06  | 0 trx, 0 pending, exectime_ms=0\r\n1866003ms thread-0   producer_plugin.cpp:214       block_production_loo ] initp generated block #28185 @ 2017-11-06T15:31:06 with 0 trxs  0 pending\r\n1869002ms thread-0   chain_controller.cpp:216      _push_block          ] inita #28186 @2017-11-06T15:31:09  | 0 trx, 0 pending, exectime_ms=0\r\n1869002ms thread-0   producer_plugin.cpp:214       block_production_loo ] inita generated block #28186 @ 2017-11-06T15:31:09 with 0 trxs  0 pending\r\n1872003ms thread-0   chain_controller.cpp:216      _push_block          ] initg #28187 @2017-11-06T15:31:12  | 0 trx, 0 pending, exectime_ms=0\r\n1872003ms thread-0   producer_plugin.cpp:214       block_production_loo ] initg generated block #28187 @ 2017-11-06T15:31:12 with 0 trxs  0 pending\r\n1875002ms thread-0   chain_controller.cpp:216      _push_block          ] initm #28188 @2017-11-06T15:31:15  | 0 trx, 0 pending, exectime_ms=0\r\n1875003ms thread-0   producer_plugin.cpp:214       block_production_loo ] initm generated block #28188 @ 2017-11-06T15:31:15 with 0 trxs  0 pending\n Comment 2: Certainly in a bad state now. If you can provide repro steps to get into this state that would be appreciated.\r\n\r\nTo get back to a clean state, start with:  `./eosd --resync`\r\n\n Comment 3: Just starting eosd with no command line options results in broken state.  Attached is my config.ini\r\n\r\n[config.ini.zip](https://github.com/EOSIO/eos/files/1447956/config.ini.zip)\r\n\r\nrestarting with --resync fixes everything\r\n\r\n\n Comment 4: I tried your config.ini file and was not able to reproduce your issue. The `./eosd --resync` wipes the database. I suspect you had a previous run with an improper shutdown. If you can provide steps to reproduce your problem feel free to reopen this issue or create another.\n Comment 5: hi,heifner,i have resolved the same issue by your suggestion \"./eosd --resync\"",
  "Issue title: Migrate tests from \"model/saml_test.go\" to use testify\n Issue body: Mattermost is migrating its server tests from using the `t.Fatal` method calls on their checks to use the [testify toolkit](https://github.com/stretchr/testify). The goal of this migration is to improve the readability of the tests, making them more concise and meaningful. This Help Wanted issue is to migrate the tests in the `model/saml_test.go` file.\n\nThe expected way to migrate this is to go to the `model/saml_test.go` file and modify the calls to `t.Fatal` and the condition checks that lead to them, replacing them with calls to the [the `require` package](https://godoc.org/github.com/stretchr/testify/require] if a failure should stop the execution of the test, or [the `assert` package|https://godoc.org/github.com/stretchr/testify/assert) if it shouldn't.\n\nExample: mattermost/mattermost-server#12039\n\nIf you have questions about the ticket or you need any help, feel free to contact `miguel.delacruz` or `jesus.espino` in <https://community.mattermost.com/>\n\n\n\n----\nIf you're interested please comment here and come [join our \"Contributors\" community channel](https://community.mattermost.com/core/channels/tickets) on our daily build server, where you can discuss questions with community members and the Mattermost core team. For technical advice or questions, please  [join our \"Developers\" community channel](https://community.mattermost.com/core/channels/developers).\n\nNew contributors please see our [Developer's Guide](https://developers.mattermost.com/contribute/getting-started/).\n\nJIRA: https://mattermost.atlassian.net/browse/MM-19116\n    \n Comments: \n Comment 0: I take it",
  "Issue title: LDAP/AD\u7528\u6237\u5bc6\u7801\u66f4\u65b0\u540e\uff0c\u767b\u9646jump server\u62a5\u9519Server Error (500)\n Issue body: [\u7b80\u8ff0\u4f60\u7684\u95ee\u9898]\r\nLDAP/AD\u7528\u6237\u5bc6\u7801\u66f4\u65b0\u540e\uff0c\u767b\u9646jump server\u62a5\u9519Server Error (500)\r\n\r\n##### \u4f7f\u7528\u7248\u672c\r\n[\u8bf7\u63d0\u4f9b\u4f60\u4f7f\u7528\u7684Jumpserver\u7248\u672c 1.x.x \u6ce8: 0.3.x\u4e0d\u518d\u63d0\u4f9b\u652f\u6301]\r\njump server 1.4.8\r\n##### \u95ee\u9898\u590d\u73b0\u6b65\u9aa4\r\n1. [\u6b65\u9aa41] ldap\u670d\u52a1\u5668\u65b0\u589e\u7528\u6237\uff0c\u767b\u9646jump server\uff0c\u767b\u9646\u6210\u529f\r\n2. [\u6b65\u9aa42]ldap\u670d\u52a1\u5668\u4fee\u6539\u7528\u6237\u5bc6\u7801\uff0c\u767b\u9646jump server\uff0c\u62a5\u9519Server Error (500)\r\n\r\n##### \u5177\u4f53\u8868\u73b0[\u622a\u56fe\u53ef\u80fd\u4f1a\u66f4\u597d\u4e9b,\u6700\u597d\u80fd\u622a\u5168]\r\n\r\n\r\n##### \u5176\u4ed6\r\n\r\n\r\n[\u6ce8:] \u5b8c\u6210\u540e\u8bf7\u5173\u95ed issue\r\n\n Comments: \n Comment 0:![image](https://user-images.githubusercontent.com/32253100/54901763-68eed900-4f12-11e9-9dea-d89353ab4935.png)\n Comment 1: jumpserver.log\u663e\u793a \uff1a\r\ndjango.db.utils.IntegrityError: (1062, \"Duplicate entry'testname' for key 'username'\"\n Comment 2: \u53e6\u5916\uff1a\u5728jumpserver\u7528\u6237\u5217\u8868\u91cc\u5220\u9664LDAP/AD\u7528\u6237\u4e4b\u540e\uff0c\u7b2c\u4e00\u6b21\u767b\u9646\u6210\u529f\uff0c\u7b2c\u4e8c\u6b21\u767b\u9646\u9519Server Error (500)\n Comment 3: Traceback (most recent call last):\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/core/handlers/exception.py\", line 34, in inner\r\n    response = get_response(request)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/core/handlers/base.py\", line 126, in _get_response\r\n    response = self.process_exception_by_middleware(e, request)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/core/handlers/base.py\", line 124, in _get_response\r\n    response = wrapped_callback(request, *callback_args, **callback_kwargs)\r\n  File \"/usr/lib64/python3.6/contextlib.py\", line 52, in inner\r\n    return func(*args, **kwds)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/views/generic/base.py\", line 68, in view\r\n    return self.dispatch(request, *args, **kwargs)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/utils/decorators.py\", line 45, in _wrapper\r\n    return bound_method(*args, **kwargs)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/views/decorators/debug.py\", line 76, in sensitive_post_parameters_wrapper\r\n    return view(request, *args, **kwargs)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/utils/decorators.py\", line 45, in _wrapper\r\n    return bound_method(*args, **kwargs)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/utils/decorators.py\", line 142, in _wrapped_view\r\n    response = view_func(request, *args, **kwargs)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/utils/decorators.py\", line 45, in _wrapper\r\n    return bound_method(*args, **kwargs)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/views/decorators/cache.py\", line 44, in _wrapped_view_func\r\n    response = view_func(request, *args, **kwargs)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/views/generic/base.py\", line 88, in dispatch\r\n    return handler(request, *args, **kwargs)\r\n  File \"/opt/jumpserver/apps/users/views/login.py\", line 76, in post\r\n    return super().post(request, *args, **kwargs)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/views/generic/edit.py\", line 141, in post\r\n    if form.is_valid():\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/forms/forms.py\", line 185, in is_valid\r\n    return self.is_bound and not self.errors\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/forms/forms.py\", line 180, in errors\r\n    self.full_clean()\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/forms/forms.py\", line 382, in full_clean\r\n    self._clean_form()\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/forms/forms.py\", line 409, in _clean_form\r\n    cleaned_data = self.clean()\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/contrib/auth/forms.py\", line 196, in clean\r\n    self.user_cache = authenticate(self.request, username=username, password=password)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/contrib/auth/__init__.py\", line 73, in authenticate\r\n    user = backend.authenticate(request, **credentials)\r\n  File \"/opt/jumpserver/apps/authentication/ldap/backends.py\", line 20, in authenticate\r\n    user = self.authenticate_ldap_user(ldap_user, password)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django_auth_ldap/backend.py\", line 210, in authenticate_ldap_user\r\n    return ldap_user.authenticate(password)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django_auth_ldap/backend.py\", line 350, in authenticate\r\n    self._get_or_create_user()\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django_auth_ldap/backend.py\", line 609, in _get_or_create_user\r\n    populate_user.send(self.backend.__class__, user=self._user, ldap_user=self)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/dispatch/dispatcher.py\", line 175, in send\r\n    for receiver in self._live_receivers(sender)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/dispatch/dispatcher.py\", line 175, in <listcomp>\r\n    for receiver in self._live_receivers(sender)\r\n  File \"/opt/jumpserver/apps/authentication/signals_handlers.py\", line 40, in on_ldap_create_user\r\n    user.save()\r\n  File \"/opt/jumpserver/apps/users/models/user.py\", line 283, in save\r\n    super().save(*args, **kwargs)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/contrib/auth/base_user.py\", line 73, in save\r\n    super().save(*args, **kwargs)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/db/models/base.py\", line 718, in save\r\n    force_update=force_update, update_fields=update_fields)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/db/models/base.py\", line 748, in save_base\r\n    updated = self._save_table(raw, cls, force_insert, force_update, using, update_fields)\r\n  File \"/opt/py3/lib64/python3.6/site-packages/django/db/models/base.py\", line 831, in _save_table\r\n    result",
  "Issue title: PCRaster plugin leads to crash of QGIS\n Issue body: ### What is the bug or the crash?\n\napplying teool create ldd leads to crash\r\na573919ad860cbb9df0bd4bce11551b46e72585b\n\n### Steps to reproduce the issue\n\n   aerhth\n\n### Versions\n\n3.16.14\n\n### Supported QGIS version\n\n- [ ] I'm running a supported QGIS version according to the roadmap.\n\n### New profile\n\n- [ ] I tried with a new QGIS profile\n\n### Additional context\n\n_No response_\n Comments: \n Comment 0: You must open the issue on the plugin repository.\r\nThe QGIS project can't do anything about it.\r\n\r\nAnd you must describe the issue, how to replicate etc.\n Comment 1: @ebrudler you must report this to the plugins author/s, not here.",
  "Issue title: attempt to call field \"cmp_format\" ( a nil value)\n Issue body: When I want open the nvim, I get this error.\r\n\r\n`\r\n Error detected while processing /home/auto/.config/nvim/init.lua:                                                                                                 E5113: Error while calling lua chunk: /home/auto/.config/nvim/lua/lsp/ui.lua:117: attempt to call field 'cmp_format' (a nil value)                                                    stack traceback:                                                                                                                                                                              /home/auto/.config/nvim/lua/lsp/ui.lua:117: in main chunk                                                                                                                     \r\n        [C]: in function'require'                                                                                                                                                    \r\n        /home/auto/.config/nvim/lua/lsp/cmp.lua:43: in main chunk                                                                                                                     \r\n        [C]: in function'require'                                                                                                                                                    \r\n        /home/auto/.config/nvim/init.lua:27: in main chunk                                                                                                                            \r\nPress ENTER or type command to continue \r\n`\r\nCan you give me some advise?\n Comments: \n Comment 0: `attempt to call field 'cmp_format' (a nil value) `\r\n\r\ncmp_format is a method of lspkind\r\n\r\nyou should try uninstall lspkind first, then reinstall it\r\n\r\n`use(\"onsails/lspkind-nvim\")`\r\n\r\n\n Comment 1: \u5df2\u7ecf\u89e3\u51b3\u4e86\uff0c\u6211\u6e05\u9664\u4e86\u6240\u6709\u63d2\u4ef6\uff0c\u7136\u540e\u91cd\u65b0\u5b89\u88c5\uff0c\u4e4b\u540e\u6ca1\u6709\u95ee\u9898\u4e86\u3002\u591a\u8c22\u5e2e\u5fd9\u3002",
  "Issue title: Cannot customize with docker installation\n Issue body: ### Gitea Version\n\n1.15.4\n\n### Git Version\n\n_No response_\n\n### Operating System\n\nOffical Docker image\n\n### How are you running Gitea?\n\nUsing docker\r\n\r\n```yml\r\nversion: \"3\"\r\n\r\nnetworks:\r\n  gitea:\r\n    external: false\r\n\r\nservices:\r\n  server:\r\n    image: gitea/gitea:1.15.4\r\n    container_name: gitea\r\n    environment:\r\n      - USER_UID=1003\r\n      - USER_GID=1003\r\n      # - GITEA_CUSTOM=/data/gitea/custom\r\n    restart: always\r\n    networks:\r\n      - gitea\r\n    volumes:\r\n      -./gitea:/data\r\n      - /etc/timezone:/etc/timezone:ro\r\n      - /etc/localtime:/etc/localtime:ro\r\n      - /home/git/.ssh/:/data/git/.ssh\r\n    ports:\r\n      - \"110:3000\"\r\n      - \"222:22\"\r\n```\n\n### Database\n\nSQLite\n\n### Can you reproduce the bug on the Gitea demo site?\n\nNo\n\n### Log Gist\n\n_No response_\n\n### Description\n\nMy mounted directory looks like this:\r\n![image](https://user-images.githubusercontent.com/16148054/138230835-021a149a-e5c6-456a-b27f-bc456c6f0666.png)\r\n\r\nThe `GITEA_CUSTOM` is `/data/gitea` (in container), other things like app.ini were mounted successfully. \r\n\r\nBut when I tried to add a `GITEA_CUSTOM/public/assets/css` path to add custom stylesheets, the request to `https://<DOMAIN>/assets/css/theme-<THEME>.css` always returns 404.\r\n\r\nI also found that there is no `templates` directory as described in documentation. \n\n### Screenshots\n\n_No response_\n Comments: \n Comment 0: `http://DOMAIN/assets/test.css` is `GITEA_CUSTOM/public/test.css`\r\n\r\nPlease make sure you understand the path mapping correctly.\r\n",
  "Issue title: the song name error\n Issue body: I have a song with long name \"11111111111111\". At first the name shows correctly, but after i switch different apps for many times, the name become 1e20.\n Comments: \n Comment 0: I don't think I know how to fix this bug, but you may want to give your songs names which contain at least one letter.",
  "Issue title: Get JSON config from URL\n Issue body: To ease integration with directory services and other configuration sources, `gnatsd` should accept a configuration URL that points to a JSON config.\r\n\r\nexample:\r\n`gnatsd -c http://configserver.example.com:8181/nats?node=mynodename`\r\n\r\nThe config can be read using cURL or similar.\n Comments: \n Comment 0: Agree, but this will not be all inclusive. Closing for now but this will be implemented, just not exactly like this.",
  "Issue title: loss decline, however the accuracy remains zero\n Issue body: I do not  modify this arcProduct, but the acc is still 0.0. so I'm very confused. And I also compare the predicted id with the label, none of the predicted id is correct\n Comments: \n Comment 0: see #10 ",
  "Issue title: lockOrientation missing\n Issue body: as described here: https://developer.mozilla.org/en-US/docs/Web/API/Screen/lockOrientation#Browser_compatibility\r\n\r\nand https://developer.mozilla.org/en-US/docs/Web/API/Screen/orientation\r\n\r\nusage example:\r\nhttp://stackoverflow.com/a/30222772/1644202\r\n\r\n\n Comments: \n Comment 0: Seems like it falls under http://caniuse.com/#feat=screen-orientation The properties/methods you mention are presumably from an old version of the spec.\n Comment 1: Yeah, I've updated http://caniuse.com/#feat=screen-orientation a bit to clarify and made lockOrientation searches micheal57@example.org.\n",
  "Issue title: How to GetTree for a commit hash?\n Issue body: Hello, I am wondering how to get tree changes from two commits hashes? \r\n\r\nCurrently I am just doing this:\r\n\r\n```go\r\nfunc main() {\r\n\trepo, err := git.PlainOpen(\".\")\r\n\tif err!= nil {\r\n\t\tlog.Fatal(\"can't open from path: \", err)\r\n\t}\r\n\r\n\toldTree, e := object.GetTree(repo.Storer, plumbing.NewHash(\"82381fd4160e109a64e0d37688eb67a600a37a24\"))\r\n\tnewTree, f := object.GetTree(repo.Storer, plumbing.NewHash(\"d70914c1c1c57bc07f0975760db125878cc675c7\"))\r\n\r\n\tchanges, g := oldTree.Diff(newTree)\r\n\r\n\tfmt.Println(changes.String(), e, f, g)\r\n\r\n}\r\n```\r\n\r\nlocal git log output:\r\n```\r\ngta on \ue0a0 master [!?] via \ud83d\udc39 v1.12.4 \r\n\u276f git log\r\ncommit 2adaec054efb50ff678b50c7f55e08a5d32253b9 (HEAD -> master)\r\nAuthor: Alexis <brownmichelle@example.com>\r\nDate:   Wed Oct 16 11:41:32 2019 +0200\r\n\r\n    init 3\r\n\r\ncommit d70914c1c1c57bc07f0975760db125878cc675c7\r\nAuthor: Alexis <brownmichelle@example.com>\r\nDate:   Wed Oct 16 11:38:08 2019 +0200\r\n\r\n    init 2\r\n\r\ncommit 82381fd4160e109a64e0d37688eb67a600a37a24\r\nAuthor: Alexis <brownmichelle@example.com>\r\nDate:   Wed Oct 16 10:53:39 2019 +0200\r\n\r\n    init\r\n\r\n```\r\n\r\nAnd the  output of the program is:\r\n```[] object not found object not found <nil>```\r\n\r\nSo the two first errors are fill with that, I don't understand at all how to use GetTree.\r\n\r\nSomeone can help me?\n Comments: \n Comment 0: Attempt two:\r\n\r\nRegarding the source code of GetTree it is using `EncodeObject` with `plumbing.TreeObject`, changing to `CommitObject` resolve to `unsupported object type`error.\n Comment 1: Solved solution is:\r\n\r\n```\r\n\toldEncodeObject, err := repo.Storer.EncodedObject(plumbing.CommitObject, plumbing.NewHash(\"82381fd4160e109a64e0d37688eb67a600a37a24\"))\r\n\tif err!= nil {\r\n\t\tlog.Fatal(\"can'tget old encode object: \", err)\r\n\r\n\t}\r\n\r\n\tnewEncodeObject, err := repo.Storer.EncodedObject(plumbing.CommitObject, plumbing.NewHash(\"d70914c1c1c57bc07f0975760db125878cc675c7\"))\r\n\tif err!= nil {\r\n\t\tlog.Fatal(\"can'tget new encode object: \", err)\r\n\t}\r\n\r\n\r\n\r\n\told, _ := object.DecodeCommit(repo.Storer, oldEncodeObject)\r\n\tnew, _ := object.DecodeCommit(repo.Storer, newEncodeObject)\r\n\r\n\toldTree, _ := old.Tree()\r\n\tnewTree, _ := new.Tree()\r\n\r\n\tchanges, err := oldTree.Diff(newTree)\r\n\tif err!= nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n```",
  "Issue title: [3.0.0-alpha.0] build-storybook is looking for polyfills.js from @kadira/storybook\n Issue body: ```\r\nBuilding storybook...\r\nFailed to build the storybook\r\nModule not found: Error: Cannot resolve 'file' or 'directory'.../node_modules/@kadira/storybook/dist/server/config/polyfills.js in...\r\n```\n Comments: \n Comment 0: May be a mistake on my part. Closing for now.",
  "Issue title: Hide backdoors from ps\n Issue body: Even making it so other users couldn't find the backdoor would make it much more potent. Currently, it can be easy to find backdoors simply with ps -ax.\r\n\r\nhttp://unix.stackexchange.com/questions/17164/how-to-make-a-process-invisible-to-other-users\r\n\r\nAnother way:\r\n\r\nhttp://www.cyberciti.biz/faq/linux-hide-processes-from-other-users/\n Comments: \n Comment 0: Absolutely love it! Would love to investigate something similar for netstat as well\n Comment 1: Alternatively can poison ps or alias ps to filter out lines we want to hide \n Comment 2: Poisoning ps would work, but there are plenty of other commands/services to find what's running... I'm gonna look into it for the next few hours",
  "Issue title: NVDA Android studio editor error is not spoken\n Issue body: <!-- Please read the text in this edit field before filling it in.\r\nPlease thoroughly read NVDA's wiki article on how to fill in this template, including how to provide the required files.\r\nIssues may be closed if the required information is not present.\r\nhttps://github.com/nvaccess/nvda/wiki/Github-issue-template-explanation-and-examples\r\nPlease also note that the NVDA project has a Citizen and Contributor Code of Conduct which can be found at https://github.com/nvaccess/nvda/blob/master/CODE_OF_CONDUCT.md. NV Access expects that all contributors and other community members read and abide by the rules set out in this document while participating or contributing to this project. This includes creating or commenting on issues and pull requests. \r\n-->\r\n\r\n### Steps to reproduce:\r\n1. Create an Android Studio project (tested with Java languaje selected)\r\n2. Make a mistake on the code editor, like deleting the semicolon at the end of a line. \r\n3. Press F2 to navigate to the next error on the file\r\n4. Press CTRL + F1 to read the error message\r\n5. NVDA does not read any message. \r\n\r\n\r\n\r\n### Actual behavior:\r\nNVDA doesn't read the code editor error description on Android Studio\r\n\r\n### Expected behavior:\r\nNVDA must read the description after pressing CTRL+F1 or after moved to the next/previous error using the F2/shift+F2 keystrokes\r\n\r\n\r\n### System configuration\r\n#### NVDA installed/portable/running from source:\r\nInstalled\r\n\r\n#### NVDA version:\r\nNVDA 2020.4\r\n\r\n#### Windows version:\r\nWindows 10 20h2\r\n\r\n#### Name and version of other software in use when reproducing the issue:\r\nAndroid studio 4.1.2\r\n\r\n#### Other information about your system:\r\n\r\n### Other questions\r\n#### Does the issue still occur after restarting your computer?\r\nYes\r\n\r\n#### Have you tried any other versions of NVDA? If so, please report their behaviors.\r\nNo\r\n\r\n#### If add-ons are disabled, is your problem still occurring?\r\nYes\r\n\r\n#### Did you try to run the COM registry fixing tool in NVDA menu / tools?\r\nYes, and issue still occurring\r\n\n Comments: \n Comment 0: Yes, even this bug is there with latest android studio caneri too.\nwould be good if it gets fixed.\n\nOn 3/23/21, Adriorjalesvidal ***@***.***> wrote:\n> <!-- Please read the text in this edit field before filling it in.\n> Please thoroughly read NVDA's wiki article on how to fill in this template,\n> including how to provide the required files.\n> Issues may be closed if the required information is not present.\n> https://github.com/nvaccess/nvda/wiki/Github-issue-template-explanation-and-examples\n> Please also note that the NVDA project has a Citizen and Contributor Code of\n> Conduct which can be found at\n> https://github.com/nvaccess/nvda/blob/master/CODE_OF_CONDUCT.md. NV Access\n> expects that all contributors and other community members read and abide by\n> the rules set out in this document while participating or contributing to\n> this project. This includes creating or commenting on issues and pull\n> requests.\n> -->\n>\n> ### Steps to reproduce:\n> 1. Create an Android Studio project (tested with Java languaje selected)\n> 2. Make a mistake on the code editor, like deleting the semicolon at the end\n> of a line.\n> 3. Press F2 to navigate to the next error on the file\n> 4. Press CTRL + F1 to read the error message\n> 5. NVDA does not read any message.\n>\n>\n>\n> ### Actual behavior:\n> NVDA doesn't read the code editor error description on Android Studio\n>\n> ### Expected behavior:\n> NVDA must read the description after pressing CTRL+F1 or after moved to the\n> next/previous error using the F2/shift+F2 keystrokes\n>\n>\n> ### System configuration\n> #### NVDA installed/portable/running from source:\n> Installed\n>\n> #### NVDA version:\n> NVDA 2020.4\n>\n> #### Windows version:\n> Windows 10 20h2\n>\n> #### Name and version of other software in use when reproducing the issue:\n> Android studio 4.1.2\n>\n> #### Other information about your system:\n>\n> ### Other questions\n> #### Does the issue still occur after restarting your computer?\n> Yes\n>\n> #### Have you tried any other versions of NVDA? If so, please report their\n> behaviors.\n> No\n>\n> #### If add-ons are disabled, is your problem still occurring?\n> Yes\n>\n> #### Did you try to run the COM registry fixing tool in NVDA menu / tools?\n> Yes, and issue still occurring\n>\n>\n> --\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly or view it on GitHub:\n> https://github.com/nvaccess/nvda/issues/12216\n\n Comment 1: Latest working release of android studio is release 3.6.3 \n\n\n> El 24 mar 2021, a las 9:17, Akash Kakkar ***@***.***> escribi\u00f3:\n> \n> \ufeff\n> Yes, even this bug is there with latest android studio caneri too.\n> would be good if it gets fixed.\n> \n> On 3/23/21, Adriorjalesvidal ***@***.***> wrote:\n> > <!-- Please read the text in this edit field before filling it in.\n> > Please thoroughly read NVDA's wiki article on how to fill in this template,\n> > including how to provide the required files.\n> > Issues may be closed if the required information is not present.\n> > https://github.com/nvaccess/nvda/wiki/Github-issue-template-explanation-and-examples\n> > Please also note that the NVDA project has a Citizen and Contributor Code of\n> > Conduct which can be found at\n> > https://github.com/nvaccess/nvda/blob/master/CODE_OF_CONDUCT.md. NV Access\n> > expects that all contributors and other community members read and abide by\n> > the rules set out in this document while participating or contributing to\n> > this project. This includes creating or commenting on issues and pull\n> > requests.\n> > -->\n> >\n> > ### Steps to reproduce:\n> > 1. Create an Android Studio project (tested with Java languaje selected)\n> > 2. Make a mistake on the code editor, like deleting the semicolon at the end\n> > of a line.\n> > 3. Press F2 to navigate to the next error on the file\n> > 4. Press CTRL + F1 to read the error message\n> > 5. NVDA does not read any message.\n> >\n> >\n> >\n> > ### Actual behavior:\n> > NVDA doesn't read the code editor error description on Android Studio\n> >\n> > ### Expected behavior:\n> > NVDA must read the description after pressing CTRL+F1 or after moved to the\n> > next/previous error using the F2/shift+F2 keystrokes\n> >\n> >\n> > ### System configuration\n> > #### NVDA installed/portable/running from source:\n> > Installed\n> >\n> > #### NVDA version:\n> > NVDA 2020.4\n> >\n> > #### Windows version:\n> > Windows 10 20h2\n> >\n> > #### Name and version of other software in use when reproducing the issue:\n> > Android studio 4.1.2\n> >\n> > #### Other information about your system:\n> >\n> > ### Other questions\n> > #### Does the issue still occur after restarting your computer?\n> > Yes\n> >\n> > #### Have you tried any other versions of NVDA? If so, please report their\n> > behaviors.\n> > No\n> >\n> > #### If add-ons are disabled, is your problem still occurring?\n> > Yes\n> >\n> > #### Did you try to run the COM registry fixing tool in NVDA menu / tools?\n> > Yes, and issue still occurring\n> >\n> >\n> > --\n> > You are receiving this because you are subscribed to this thread.\n> > Reply to this email directly or view it on GitHub:\n> > https://github.com/nvaccess/nvda/issues/12216\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub, or unsubscribe",
  "Issue title: New static pages\n Issue body: - [ ] blog index\r\nhttps://zpl.io/2Zxpxmd\r\n\r\n- [ ] blog post\r\nhttps://zpl.io/V4AKAdM\r\n\r\n- [ ] projects\r\nhttps://zpl.io/2EwDw9x\r\n\r\n- [ ] about\r\nhttps://zpl.io/bzYJYR8\r\n\r\n- [ ] pricing\r\nhttps://zpl.io/amBgBwA\r\n\r\n- [ ] education\r\nhttps://zpl.io/Vq6965N\r\n\r\n- [ ] replace \"Team\" link in footer with \"About\" and link to new about page\r\n\r\n- [ ] add link to Store, new order:\r\nCompany\r\n**About\r\nMedia Kit\r\nStore\r\nFAQs**\n Comments: \n Comment 0: (Pricing copy: https://docs.google.com/document/d/1ZUNdmcWXHLYN-HUgoYeA4rrf5AY9xOPBf8K9vKNkQ4s/edit)",
  "Issue title: No mobile support\n Issue body: This is a great however it does not respond to touch events and therefore does not work on mobile devices such as the iPad.  Real important feature nowadays.\n\n Comments: \n Comment 0: I'm not quite sure how to implement this on touch devices, especially since I have nothing good to test with. Is it enough to bind to `ondblclick`?\n\n Comment 1: Here are some pointers:\n\non('mousedown') becomes: on('mousedown touchstart'\n\nThen you'll have an issue with e.pageX which needs to be e.originalEvent.touches[0].pageX if mobile device\n\nReally speaking there is not much you have to change in your code to make it mobile compatible.  Try and have a look if I get chance, but pressing deadlines are keeping me up at the moment.\n\n Comment 2: Touch events are now supported in the latest versions :)",
  "Issue title: warning: indicates a malformed project\n Issue body: ### Version\r\nTell us which versions you are using: \r\n\r\n- react-native-image-crop-picker v0.32.2\r\n- react-native v0.62.2\r\n\r\n### Platform\r\nTell us to which platform this issue is related\r\n\r\n- iOS\r\n\r\n### Expected Behavior\r\nBuild without warnings.\r\n\r\n### Actual behaviour\r\nWhen run react-native run-ios, there's warning:  The file reference for \"Objective-C/TOCropViewController/Models/TOActivityCroppedImageProvider.h\" is a member of multiple groups (\"TOCropViewController\" and \"TOCropViewController\"); this indicates a malformed project.  Only the membership in one of the groups will be preserved (but membership in targets will be unaffected).  If you want a reference to the same file in more than one group, please add another reference to the same path.\r\n\r\n\r\n\n Comments: \n Comment 0: The same problem\n Comment 1: Exact the same behaviour here. Except I'm working on `kathrynchapman@example.com`\n Comment 2: Same problem here.\n Comment 3: > Exact the same behaviour here. Except I'm working on `kathrynchapman@example.com`\r\n\r\nHad to roll back to `@0.30.0`\n Comment 4: The issue is caused by the **TOCropViewController** pod. see: https://github.com/TimOliver/TOCropViewController/issues/424\n Comment 5: As a temporary fix (till TOCropViewController will be fixed) I've changed the file:\r\n`node_modules/react-native-image-crop-picker/RNImageCropPicker.podspec` at line 16\r\nfrom \r\n`s.dependency 'TOCropViewController'`\r\nto\r\n`s.dependency 'TOCropViewController', '2.5.3'`\r\n\r\nThan, I used the **patch-package** (https://github.com/ds300/patch-package) to create a patch with the changes.",
  "Issue title: Something seems to have changed\n Issue body: V3.4.*  missing\r\nWhat should I do?\n Comments: \n Comment 0: in crowdin\n Comment 1: @dongasai The 3.4 project is no longer going to be translated. All translations are already on the site.\r\n\r\nv4 is the new one that we are working on. Do not worry, all the translations you had before are there so when reviewing a document you can just click an existing translation and approve it.\r\n\r\nFor now only a few documents have been rewritten for v4. Those are:\r\n* acl\r\n* new-pull-request\r\n* new-feature-request\r\n* reproducible-tests\r\n* contributions\r\n\r\nWorking on the rest of them\r\n\n Comment 2: More will come soon as soon as I review them :)",
  "Issue title: Jetifier not working when building with a Mac\n Issue body: ### Please fill in the following fields:\r\nUnity editor version: 2019.1.14\r\nExternal Dependency Manager version: 1.2.144\r\nSource you installed EDM (from.unitypackage or Unity Package Manager):.unitypackage\r\nFeatures in External Dependency Manager in use (Android Resolver, iOS Resolver, VersionHandler, etc.): Android Resolver\r\nPlugins SDK in use (Firebase, Admob, Facebook, etc.): Firebase, AppsFlyer, other jars \r\nPlatform you are using the Unity editor on (Mac, Windows, or Linux): Mac\r\nPlatform you are targeting (iOS, Android, and/or desktop): Android\r\nScripting Runtime (Mono, and/or IL2CPP): IL2CPP\r\n\r\n### Please describe the issue here:\r\nWe are currently trying to update to a newer Firebase Version and to avoid conflicts with other plugins we enabled the Jetifer option. The build works perfectly when we are building with a Windows Maschine but when we build with Mac we get the following error on the start-up of the App: \r\n`\r\njava.lang.RuntimeException: Unable to get provider android.support.v4.content.FileProvider: java.lang.ClassNotFoundException: Didn't find class \"android.support.v4.content.FileProvider\" on path: DexPathList[[zip file \"/data/app/com.company.appname-1/base.apk\"],nativeLibraryDirectories=[/data/app/com.company.appname-1/lib/arm64, /data/app/com.company.appname-1/base.apk!/lib/arm64-v8a, /system/lib64, /vendor/lib64]]\r\n\tat android.app.ActivityThread.installProvider(ActivityThread.java:5855)\r\n\tat android.app.ActivityThread.installContentProviders(ActivityThread.java:5444)\r\n\tat android.app.ActivityThread.handleBindApplication(ActivityThread.java:5383)\r\n\tat android.app.ActivityThread.-wrap2(ActivityThread.java)\r\n\tat android.app.ActivityThread$H.handleMessage(ActivityThread.java:1541)\r\n\tat android.os.Handler.dispatchMessage(Handler.java:102)\r\n\tat android.os.Looper.loop(Looper.java:154)\r\n\tat android.app.ActivityThread.main(ActivityThread.java:6123)\r\n\tat java.lang.reflect.Method.invoke(Native Method)\r\n\tat com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:867)\r\n\tat com.android.internal.os.ZygoteInit.main(ZygoteInit.java:757)\r\n`\r\n\r\nWe tried using a Gradle file and without (all libraries in Plugins/Android). The same error appears when we disable Jetifier on Windows. \r\n\r\n### Please answer the following, if applicable:\r\nWhat's the issue repro rate? 100%\r\n\n Comments: \n Comment 0: It does look like something is trying to use legacy android.support library.\r\n\r\nWhat are the `other jars` you are using in the project?\r\nCould it be possible that those libraries are trying to use legacy support library?\n Comment 1: The other jar/aar files are from plugins from the Unity Asset Store. One of them is already using AndroidX the other one is not. As far as I can see AppsFlyer is also still using the old support libraries. \r\nIn my understanding, Jetifier should convert these plugins to the new libraries. The strange part is that the compiled version (using the normal Unity Build) with a Windows PC works.\n Comment 2: I see.  \r\n\r\nAny `AARs` or `JARs` will need to be in either local or remote maven repos so they're processed by the Android Resolver.  If those plugins does not come with their own Dependencies.xml, those will be ignored by AndroidResolver.\r\n\r\nI think it is those plugins from Unity Asset Store that are causing trouble.\r\nI actually do not know why it works on Windows.\r\n\r\nA couple of approaches you can do\r\n\r\n1. Add your own Dependencies.xml and define local repos for those plugins. Ex.\r\n    https://github.com/googlesamples/unity-jar-resolver/blob/master/source/AndroidResolver/test/resolve_async/Assets/ExternalDependencyManager/Editor/TestDependencies.xml#L8\r\n1. Use custom gradle template.  Android Resolver will help to patch it and inject repo and dependency from Dependencies.xml.  You can also specify your local dependencies here as well.  Here is an interesting post for your reference.  And the Jetfifier integration in the Android Gradle build will process them\r\n   https://forum.unity.com/threads/androidx-vs-android-libraries.710831/\r\n\r\nLet us know if this helps\n Comment 3: Hey, I will give it a try with the local repositories. In the other approach, they mentioned updating the internal Gradle. This will not be a big overhead if we have to do this for our build machines.\r\nIn our Unity version, we have Gradle 3.4. Is there any limitation working with this version? \n Comment 4: @chbecher \r\n\r\nThere is one open issue that the Gradle version with Unity 2018.4.0 isn't interpreting dollar slashy strings correctly.  https://github.com/googlesamples/unity-jar-resolver/issues/334#issuecomment-596819412\r\nThis _might_ be fixed with the version you have.  But please do report to us if you are experiencing with any issue.\r\n\r\nShawn\n Comment 5: <!-- event: mark-stale -->\nHey @chbecher. We need more information to resolve this issue but there hasn't been an update in 5 weekdays. I'm marking the issue as stale and if there are no new updates in the next 5 days I will close it automatically.\n\nIf you have more information that will help us get to the bottom of this, just add a comment!\n Comment 6: <!-- event: mark-stale -->\nHey @chbecher. We need more information to resolve this issue but there hasn't been an update in 5 weekdays. I'm marking the issue as stale and if there are no new updates in the next 5 days I will close it automatically.\n\nIf you have more information that will help us get to the bottom of this, just add a comment!\n Comment 7: <!-- event: close-stale -->\nSince there haven't been any recent updates here, I am going to close this issue.\n\n@chbecher if you're still experiencing this problem and want to continue the discussion just leave a comment here and we are happy to re-open this.",
  "Issue title: Big fubar\n Issue body: this process SUCKS. What kind of idiots developed it? You GDI\"s made what should have been a simple one location action into multiple platforms, NEW accounts and the installation of TWO additional apps. your product manager should be incarcerated and never allowed to work in  the INDUSTRY again. You incompetent analysists and coders should seek employment in food retail (BURGER KING). \n\n---\n#### Document Details\n\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\n\n* ID: 9dd4d05c-4aa3-0376-f3a1-b0ea0793f482\n* Version Independent ID: 7f1ff943-61b0-60e1-9ca3-d4a84bfdb068\n* Content: [Install Visual Studio](https://docs.microsoft.com/en-us/visualstudio/install/install-visual-studio?view=vs-2019#feedback)\n* Content Source: [docs/install/install-visual-studio.md](https://github.com/MicrosoftDocs/visualstudio-docs/blob/master/docs/install/install-visual-studio.md)\n* Product: **visual-studio-windows**\n* Technology: **vs-installation**\n* GitHub Login: @TerryGLee\n* Microsoft Alias: **tglee**\n Comments: \n Comment 0: The [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/), which outlines the expectations for community interactions in and around docs.microsoft.com, is designed to help \"provide a welcoming and inspiring community for all.\" The content of this issue appears to be out of sync with the code of conduct, so we have closed it.",
  "Issue title: i can't find any correlation between the coordinates obtained from the model and the actual stop sign of the example\n Issue body: \r\nhi,\r\nI am trying to learn Objcet detection with ML.net\r\nUnfortunately, but maybe it is my problem, I can't find any correlation between the coordinates obtained from the model...\r\n\"**Predicted Boxes:\r\nTop: 89.453415, Left: 481.95343, Right: 724.8073, Bottom: 388.32385, Label: Stop-Sign, Score: 0.99539465**\"\r\nand the actual Stop signal in the example image.\r\nWhere do the axes start from? do the top, left, right, bottom coordinates of the output refer to the TOP,LEFT and BOTTOM,RIGHT corners of the bounding box? Obviously I have considered the actual size of the image, doing the proportion to get the real coordinates but still I don't find any correlation.\r\n\r\nThanks\r\n\r\nMassimo Franceschelli\r\n\r\n\r\n![test-image1](https://user-images.githubusercontent.com/16940984/114558145-aabe5980-9c6a-11eb-9897-cb5af0dd9bfd.jpeg)\r\n\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\r\n\r\n* ID: 63a4f3b7-a2a6-760a-534b-22788ba77b5c\r\n* Version Independent ID: 1bee7901-164f-d9a7-9e7b-fd0ba55ad42e\r\n* Content: [Tutorial: Detect objects in images with Model Builder - ML.NET](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/object-detection-model-builder)\r\n* Content Source: [docs/machine-learning/tutorials/object-detection-model-builder.md](https://github.com/dotnet/docs/blob/main/docs/machine-learning/tutorials/object-detection-model-builder.md)\r\n* Product: **dotnet-ml**\r\n* GitHub Login: @briacht\r\n* Microsoft Alias: **brachtma**\n Comments: \n Comment 0: Adding @JakeRadMSFT @LittleLittleCloud. \n Comment 1: Hi @MaxFranz \r\n\r\nThe coordinates are those of the bounding box. Images for object detection are normalized at a 800 (width) x 600 (height). Therefore, you need to scale these coordinates to your actual image size. Here's one way you could do it. \r\n\r\nIn this sample `input-image` is the image you've provided in this issue. \r\n\r\n```csharp\r\nvar image = new Image.FromFile(\"input-image.jpeg\")\r\n\r\nvar top = image.Height * 89 / 600\r\nvar bottom = image.Height * 388 / 600\r\nvar left = image.Width * 481 / 800\r\nvar right = image.Width * 724 / 800\r\nvar height = Math.Abs(bottom-top)\r\nvar width = Math.Abs(right-left)\r\n```\r\n\r\nI've hardcoded the dimensions you provided, but you can take those from the `Top`, `Bottom`, `Left`, `Right` bounding box properties. The `image.Height` and `image.Width` are the actual dimensions of the image. \r\n\r\nHope this helps",
  "Issue title: 1.0.0 dexbot wont start\n Issue body: ## Expected Behavior\r\nnormal start up\r\n\r\n## Actual Behavior\r\ngui never gets fully launched. the prompt screen opens and runs normal until crashing after these lines:\r\n[13508] LOADER: Running pyi_rth_multiprocessing.py\r\n[13508] LOADER: Running pyi_rth_pkgres.py\r\n[13508] LOADER: Running pyi_rth_qt5.py\r\n[13508] LOADER: Running gui.py\r\n\r\n## Steps to Reproduce the Problem\r\n\r\n  1. use windows 10\r\n  2. download and instal new dexbot zipfile as un upgrade\r\n  3.open software\r\n\r\n## Specifications\r\n\r\n  - Version: 1.0.0\r\n  - OS: windowds 10\r\n\r\nthanks!\r\n\n Comments: \n Comment 0: I have the same problem on Ubuntu Server 18.04 with `dexbot-cli run`\r\n",
  "Issue title: Hints after a correct answer reset points\n Issue body: Branch: Nalanda-RCT1\n\nExpected Behavior: On doing some exercise every question accompanied with it's specific hint.When you answered that question hints should be provided when you answered wrong unless that hint is not playing any role in evaluation.\n![screenshot from 2014-04-02 18 43 58](https://cloud.githubusercontent.com/assets/6395045/2591203/bae844b0-ba68-11e3-8409-f0758722da90.png)\n\n![screenshot from 2014-04-02 17 38 41](https://cloud.githubusercontent.com/assets/6395045/2591257/872afde2-ba69-11e3-851b-ff3b1cb99427.png)\n\nCurrent Behavior: Hint is shown even if student answered correctly. If they click on hint even if answered correctly does it reduce its performance report.\n\n![screenshot from 2014-04-02 17 37 06](https://cloud.githubusercontent.com/assets/6395045/2591263/9126c722-ba69-11e3-8040-3911fb3b970b.png)\n\nSteps to reproduce:\n1. Login as student \n2. Try to do exercise\n\n Comments: \n Comment 0: @him-28 Is the issue that hints are not shown after incorrect answer automatically, or that hints after a correct answer reset points?\n\n Comment 1: @bcipolli hints after a correct answer reset points\n\n Comment 2: OK.  Please update the title and text to be clearer on this point.  `Irrelevant to provide hint when the answer is correct.` doesn't indicate that issue well.\n\n Comment 3: I agree this is something we'd like to do.  However, lower priority given the tight RCT deadline.\n\nLet's do RCT 3, puntable to Nice to Have.\n\n Comment 4: I will check but I didn't think that looking at hints after a correct\nanswer reset my points. (I will check again)  I would hope that over time,\nalternate solutions will be incorporated into some exercises making looking\nat hints after a correct answer, a preferred action.  KEEP ROCKIN' IT.\n\nOn Sat, Apr 5, 2014 at 10:46 AM, Ben Cipollini tina27@example.net:\n\n> I agree this is something we'd like to do. However, lower priority given\n> the tight RCT deadline.\n> \n> Let's do RCT 3, puntable to Nice to Have.\n> \n> ## \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/learningequality/ka-lite/issues/1855#issuecomment-39641849\n>.\n\n Comment 5: Fixed in `nalanda-rct2`, with the newest mastery model.\n",
  "Issue title: Connectivity tests fail when run in non `cilium-test` namespace\n Issue body: The connectivity tests consistently fail when run in a namespace other than `cilium-test`:\r\n```\r\n$./cilium connectivity test --test-namespace latest\r\n[...]\r\n\ud83d\udccb Test Report\r\n\u274c 6/31 tests failed (16/233 actions), 0 tests skipped, 1 scenarios skipped:\r\nTest [client-egress]:\r\n  \u274c client-egress/pod-to-pod/curl-0: latest/client-594cbbdf44-dt5fj (116.69.203.115) -> latest/echo-other-node-848c6d48fb-2hx2n (116.69.203.115:8080)\r\n  \u274c client-egress/pod-to-pod/curl-1: latest/client-594cbbdf44-dt5fj (116.69.203.115) -> latest/echo-same-node-6d78d7f79b-j94j7 (116.69.203.115:8080)\r\n  \u274c client-egress/pod-to-pod/curl-2: latest/client2-8484df99d-cbwj6 (116.69.203.115) -> latest/echo-other-node-848c6d48fb-2hx2n (116.69.203.115:8080)\r\n  \u274c client-egress/pod-to-pod/curl-3: latest/client2-8484df99d-cbwj6 (116.69.203.115) -> latest/echo-same-node-6d78d7f79b-j94j7 (116.69.203.115:8080)\r\nTest [client-egress-expression]:\r\n  \u274c client-egress-expression/pod-to-pod/curl-2: latest/client2-8484df99d-cbwj6 (116.69.203.115) -> latest/echo-other-node-848c6d48fb-2hx2n (116.69.203.115:8080)\r\n  \u274c client-egress-expression/pod-to-pod/curl-3: latest/client2-8484df99d-cbwj6 (116.69.203.115) -> latest/echo-same-node-6d78d7f79b-j94j7 (116.69.203.115:8080)\r\nTest [client-egress-to-echo-service-account]:\r\n  \u274c client-egress-to-echo-service-account/pod-to-pod/curl-0: latest/client-594cbbdf44-dt5fj (116.69.203.115) -> latest/echo-other-node-848c6d48fb-2hx2n (116.69.203.115:8080)\r\n  \u274c client-egress-to-echo-service-account/pod-to-pod/curl-1: latest/client-594cbbdf44-dt5fj (116.69.203.115) -> latest/echo-same-node-6d78d7f79b-j94j7 (116.69.203.115:8080)\r\nTest [client-egress-to-echo-deny]:\r\n  \u274c client-egress-to-echo-deny/pod-to-pod/curl-0: latest/client-594cbbdf44-dt5fj (116.69.203.115) -> latest/echo-other-node-848c6d48fb-2hx2n (116.69.203.115:8080)\r\n  \u274c client-egress-to-echo-deny/pod-to-pod/curl-1: latest/client-594cbbdf44-dt5fj (116.69.203.115) -> latest/echo-same-node-6d78d7f79b-j94j7 (116.69.203.115:8080)\r\n  \u274c client-egress-to-echo-deny/pod-to-pod/curl-2: latest/client2-8484df99d-cbwj6 (116.69.203.115) -> latest/echo-other-node-848c6d48fb-2hx2n (116.69.203.115:8080)\r\n  \u274c client-egress-to-echo-deny/pod-to-pod/curl-3: latest/client2-8484df99d-cbwj6 (116.69.203.115) -> latest/echo-same-node-6d78d7f79b-j94j7 (116.69.203.115:8080)\r\nTest [client-ingress-to-echo-named-port-deny]:\r\n  \u274c client-ingress-to-echo-named-port-deny/pod-to-pod/curl-0: latest/client-594cbbdf44-dt5fj (116.69.203.115) -> latest/echo-other-node-848c6d48fb-2hx2n (116.69.203.115:8080)\r\n  \u274c client-ingress-to-echo-named-port-deny/pod-to-pod/curl-1: latest/client-594cbbdf44-dt5fj (116.69.203.115) -> latest/echo-same-node-6d78d7f79b-j94j7 (116.69.203.115:8080)\r\nTest [client-egress-to-echo-service-account-deny]:\r\n  \u274c client-egress-to-echo-service-account-deny/pod-to-pod/curl-0: latest/client-594cbbdf44-dt5fj (116.69.203.115) -> latest/echo-other-node-848c6d48fb-2hx2n (116.69.203.115:8080)\r\n  \u274c client-egress-to-echo-service-account-deny/pod-to-pod/curl-1: latest/client-594cbbdf44-dt5fj (116.69.203.115) -> latest/echo-same-node-6d78d7f79b-j94j7 (116.69.203.115:8080)\r\nconnectivity test failed: 6 tests failed\r\n```\r\nI've rerun with `-p` to pause on the first failure and collected a sysdump: \r\n[cilium-sysdump-20220926-205342.zip](https://github.com/cilium/cilium-cli/files/9649336/cilium-sysdump-20220926-205342.zip)\r\n\r\nThis is with Cilium CLI d9371d3dc6dbe9f8d8437bd34ee848d7358ff4e0.\r\n\r\n### Investigation\r\n\r\n`cilium monitor` shows this is caused by policy drops:\r\n```\r\nxx drop (Policy denied) flow 0x76b6c553 to endpoint 0, ifindex 25, file 2:1188,, identity 4620->34411: 116.69.203.115:52440 -> 116.69.203.115:8080 tcp SYN\r\n```\r\nLooking at the BPF policy map for that endpoint, it is indeed missing a rule to allow on that port:\r\n```\r\n$ ks exec cilium-x6rtv -- cilium bpf policy get -n 705\r\nPOLICY   DIRECTION   IDENTITY   PORT/PROTO   PROXY PORT   BYTES   PACKETS   \r\nAllow    Ingress     0          ANY          NONE         0       0         \r\nAllow    Ingress     1          ANY          NONE         392     4         \r\nAllow    Egress      15025      53/TCP       NONE         0       0         \r\nAllow    Egress      15025      53/UDP       NONE         0       0         \r\nAllow    Egress      15025      53/SCTP      NONE         0       0\r\n```\r\nDumping the only CNP in that namespace reveals the issue:\r\n```yaml\r\nW0926 20:54:10.346854  299992 gcp.go:119] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.26+; use gcloud instead.\r\nTo learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\r\napiVersion: v1\r\nitems:\r\n- apiVersion: cilium.io/v2\r\n  kind: CiliumNetworkPolicy\r\n  metadata:\r\n    creationTimestamp: \"2022-09",
  "Issue title: Error when starting the server\n Issue body: MongooseIM version: 3.1.1\r\nInstalled from: pkg\r\nErlang/OTP version: how can I see this?\r\n\r\nHello, I am using Xubuntu 16.04 and I installed MongooseIM with the package:\r\n\r\n`mongooseim_3.1.1-1_ubuntu_xenial_amd64.deb`\r\n\r\nThe installation goes fine and when i start the server it **seems** to run but with `status` it shows that there is a problem:\r\n\r\n```\r\n\u279c  ~ mongooseimctl start\r\n\u279c  ~ mongooseimctl status\r\nFailed RPC connection to the node mongooseim@localhost: nodedown\r\n\r\nCommands to start a MongooseIM node:\r\n  start           Start a MongooseIM node as daemon (detached from terminal)\r\n  debug           Attach an interactive Erlang shell to a running MongooseIM node\r\n  live            Start MongooseIM node in live (interactive) mode\r\n  foreground      Start MongooseIM node in foreground (non-interactive) mode\r\nMongooseIM cluster management commands:\r\n  join_cluster other_node_name                Add current node to cluster\r\n  leave_cluster                               Leave current node from the cluster\r\n  remove_from_cluster other_node_name         Remove dead node from the cluster\r\n```\r\n\r\nI have no idea why it doesn't work, I simply installed it with the package manager downloaded from the site. Do I need additional packages?\r\n\r\nWhen running it with `live` this is what I get.\r\n\r\n```\r\n\u279c  ~ mongooseimctl live\r\nRoot: /usr/lib/mongooseim\r\nExec: /usr/lib/mongooseim/erts-8.3.5/bin/erlexec -boot /usr/lib/mongooseim/releases/3.1.1/mongooseim -embedded -config /etc/mongooseim/app.config -args_file /etc/mongooseim/vm.args -args_file /etc/mongooseim/vm.dist.args -- console\r\nErlang/OTP 19 [erts-8.3.5] [source] [64-bit] [smp:8:8] [async-threads:5] [hipe] [kernel-poll:true]\r\n\r\n\r\n=INFO REPORT==== 16-Oct-38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba515:48:51 ===\r\n    msg: \"Starting reporters with []\\n\"\r\n    options: []\r\n15:48:51.563 [info] Application lager started on node mongooseim@localhost\r\n15:48:51.568 [info] Application syslog started on node mongooseim@localhost\r\n15:48:51.568 [info] Application lager_syslog started on node mongooseim@localhost\r\n15:48:51.568 [info] Application lasse started on node mongooseim@localhost\r\n15:48:51.684 [info] Application mnesia started on node mongooseim@localhost\r\n15:48:51.684 [info] Application mochijson2 started on node mongooseim@localhost\r\n15:48:51.684 [info] Application recon started on node mongooseim@localhost\r\n15:48:51.684 [info] Application observer_cli started on node mongooseim@localhost\r\n15:48:51.684 [info] Application pa started on node mongooseim@localhost\r\n15:48:51.693 [info] Application runtime_tools started on node mongooseim@localhost\r\n15:48:51.700 [info] Application sasl started on node mongooseim@localhost\r\n15:48:51.706 [info] Application stringprep started on node mongooseim@localhost\r\n15:48:51.714 [info] Application fast_tls started on node mongooseim@localhost\r\n15:48:51.714 [info] Application mimerl started on node mongooseim@localhost\r\n15:48:51.714 [info] Application certifi started on node mongooseim@localhost\r\n15:48:51.714 [info] Application ssl_verify_fun started on node mongooseim@localhost\r\n15:48:51.714 [info] Application metrics started on node mongooseim@localhost\r\n15:48:51.725 [info] Application hackney started on node mongooseim@localhost\r\n15:48:51.730 [info] Application worker_pool started on node mongooseim@localhost\r\n15:48:51.733 [info] Application tirerl started on node mongooseim@localhost\r\n15:48:51.733 [info] Application usec started on node mongooseim@localhost\r\n15:48:51.739 [notice] Changed loglevel of /var/log/mongooseim/ejabberd.log to info\r\n15:48:51.791 [info] Application mnesia exited with reason: stopped\r\n15:48:51.921 [info] Application mnesia started on node mongooseim@localhost\r\n15:48:52.158 [notice] Changed loglevel of /var/log/mongooseim/ejabberd.log to warning\r\n15:48:52.413 [error] Failed to start Ranch listener 'ejabberd_cowboy_116.69.203.115_8088' in ranch_tcp:listen([{port,8088},{ip,{127,0,0,1}}]) for reason eaddrinuse (address already in use)\r\n15:48:52.413 [error] CRASH REPORT Process <0.740.0> with 0 neighbours exited with reason: {listen_error,'ejabberd_cowboy_116.69.203.115_8088',eaddrinuse} in gen_server:init_it/6 line 352\r\n15:48:52.413 [error] Supervisor {<0.738.0>,ranch_listener_sup} had child ranch_acceptors_sup started with ranch_acceptors_sup:start_link('ejabberd_cowboy_116.69.203.115_8088', 10, ranch_tcp, [{port,8088},{ip,{127,0,0,1}},{max_connections,1024}]) at undefined exit with reason {listen_error,'ejabberd_cowboy_116.69.203.115_8088',eaddrinuse} in context start_error\r\n15:48:52.463 [error] Failed to start Ranch listener 'ejabberd_cowboy_116.69.203.115_8088' in ranch_tcp:listen([{port,8088},{ip,{127,0,0,1}}]) for reason eaddrinuse (address already in use)\r\n15:48:52.463 [error] CRASH REPORT Process <0.743.0> with 0 neighbours exited with reason: {listen_error,'ejabberd_cowboy_116.69.203.115_8088',eaddrinuse} in gen_server:init_it/6 line 352\r\n15:48:52.464 [error] Supervisor {<0.741.0>,ranch_listener_sup} had child ranch_acceptors_sup started with ranch_acceptors_sup:start_link('ejabberd_cowboy_116.69.203.115_8088', 10, ranch_tcp, [{port,8088},{ip,{127,0,0,1}},{max_connections,1024}]) at undefined exit with reason {listen_error,'ejabberd_cowboy_116.69.203.115_8088',eaddrinuse} in context start_error\r\n15:48:52.515 [error] Failed to start Ranch listener 'ejabberd_cowboy_116.69.203.115_8088' in ranch_tcp:listen([{port,8088},{ip,{127,0,0,1}}]) for reason eaddrinuse (address already in use)\r\n15:48:52.515 [error] CRASH REPORT Process <0.746.0> with 0 neighbours exited with reason: {listen_error,'ejabberd_cowboy_116.69.203.115_8088',eaddrinuse} in gen_server:init_it/6 line 352\r\n15:48:52.515 [error] Supervisor {<0.744.0>,ranch_listener_sup} had child ranch_acceptors_sup started with ranch_acceptors_sup:start_link('ejabberd_cowboy_116.69.203.115_8088', 10, ranch_",
  "Issue title: [RemoteRetro/production] FunctionClauseError: no function clause matching in :lib.is_op/2\n Issue body: ## Backtrace\n\n\n\n[View full backtrace and more rossdavid@example.net](https://app.honeybadger.io/projects/54737/faults/38349852)\n Comments: \n Comment 0: resolved by 478de1898408a9e6441f065cab0623989bf8ec92",
  "Issue title: Implement Password Autofill for iOS11\n Issue body: https://developer.apple.com/videos/play/wwdc2017/206/\r\n\r\n@lime124 @bbinto so iOS11 has an autofill option for things stored in iCloud - this could be an easy win for quick access. @bkmunar is going to investigate if this is possible in Focus and provide estimate for the dev work here but maybe we can sneak this into 4.0?\n Comments: \n Comment 0: \"The next thing to know is that UITextView and UITextField are automatically eligible for consideration or Password AutoFill. So, if you're using these standard controls out of UIKit, you're already in a really good place.\r\n\r\nHowever, if you're rolling your own text fields, no need to worry.\r\n\r\nIf your text field conforms to UITextInput, it's also eligible for Password Autofill.\"\r\n\r\nI think this makes Password Autofill implementations with WKWebView impossible as it seems to be only designated to the text field classes; which makes sense if they want to make autofill a private API for Safari iOS. @boek \n Comment 1: Thanks @bkmunar looks like this isn't an option :/. ",
  "Issue title: fn vs fngen\n Issue body: I see fns as different to fn-generators. When I declare a fn, I am painting memory with code:\r\n\r\n`````zig\r\nfn add(a: u32, b: u32) u32 {  \r\n    return a + b;\r\n}\r\n`````\r\n\r\nWhen I declare a fn-generator, I lay down a template for how fns can be generated on-request at compile time:\r\n\r\n`````zig\r\nfn add(a: var, b: var) @TypeOf(a) {  \r\n    return a + b;\r\n}\r\n`````\r\nThis can be used to paint a whole universe of `add` functions (`add_u32_u32`, `add_f64_i16`,...).\r\n\r\n(Being new to Zig,)? I find it hard to distinguish the two when reading code. \r\n\r\nCan more experienced Zig programmers effortlessly tell at a glance if the declaration you are reading corresponds to a runtime address you can query with &? \r\n\r\nIf a fn which has comptime params or anytype params is a fn generator, not a fn, why not introduce it with a different keyword? \r\n\r\nMaybe there could be a requirement that every _fn_ which has no runtime body, ie for which `@sizeOf(@TypeOf(_functionName_)) == 0`) needs to be declared with a keyword different from `fn`, maybe:\r\n\r\n`````zig\r\nfngen add(a: var, b: var) @TypeOf(a) {  \r\n    return a + b;\r\n}\r\n`````\r\n\r\nIt would certainly highlight to newbies that something interesting is going on...\n Comments: \n Comment 0: > (Being new to Zig,)? I find it hard to distinguish the two when reading code.\r\n\r\nWhy do you need to? The intention is that you shouldn't need to.\r\n\r\n> Can more experienced Zig programmers effortlessly tell at a glance if the declaration you are reading corresponds to a runtime address you can query with &?\r\n\r\nYou can take the address of comptime functions too. So this isn't a meaningful difference.\r\nFurthermore, with e.g. IFUNCs, then there is sort of more than one address for each function.\n Comment 1: Some (minor?) reasons to distinguish between the two is that they have observable different behavior:\r\n\r\n`````zig\r\nfn genericFn(a : var) void {}\r\nfn reifiedFn(a : u32) void {}\r\ntest(\"different beasts\") {\r\n\r\n// A pointer to a generic fn must be const, and it has no Frame...\r\nvar fnPtrToGenericFn = genericFn; // error: variable of type 'fn(var) var' must be const or comptime\r\nconst frameOfGenericFn = @Frame(genericFn); // error: @Frame() of generic function\r\n\r\n//...vs reified:\r\nvar fnPtrToReifiedFn = reifiedFn; // ok\r\nconst frameOfReifiedFn = @Frame(reifiedFn); // ok\r\n\r\n// Address of generic?\r\nvar addressOfGenericFn = &genericFn; // error: variable of type 'fn(var) var' must be const or comptime\r\nconst addressOfGenericFn = &genericFn; // Ok, but... really? Let's look at it:\r\nwarn(\"&genericFn = {}\\n\",.{addressOfGenericFn}); // error: pointer to size 0 type has no address\r\n\r\n// Address of reified:\r\nvar addressOfReifiedFn = &reifiedFn; // ok, and really ok, let's look at it:\r\nwarn(\"&reifiedFn = {}\\n\",.{&reifiedFn}); // really ok \"reifiedFn = fn(u32) void@7ff77b7f900\"\r\n\r\n}\r\n`````\r\n\r\n(The `@thisFn` proposal might come in handy in this context, https://github.com/ziglang/zig/issues/5113#issuecomment-622977895)\r\n\r\nBut the major reason for me is \"no hidden control flow\", I want to understand what the code I write and read does, and see a major difference between these two which I need to understand in order to \"read the code\". \n Comment 2: > ```zig\r\n> warn(\"&genericFn = {}\\n\",.{addressOfGenericFn}); // error: pointer to size 0 type has no address\r\n> ```\r\n\r\nto me this suggests that we should print something special here: although `&generic_fn` is defined, `@ptrToInt(&generic_fn)` is not.\n Comment 3: So you cannot pass a ptr-to-a-generic_fn to a C function for the C function to invoke as a callback, but you can do that with a ptr to a non-generic-fn. A difference worth being aware of when reading code?\n Comment 4: > So you cannot pass a ptr-to-a-generic_fn to a C function for the C function to invoke as a callback, but you can do that with a ptr to a non-generic-fn. A difference worth being aware of when reading code?\r\n\r\nPassing a C function would require a function with `callconv(.C)` which is its own restriction.\n Comment 5: \r\n`````zig\r\ntest(\"Yet another difference: \"){genericFn();reifiedFn();}\r\n\r\n// error: comptime parameter not allowed in function with calling convention 'C'\r\nfn genericFn(comptime a: u32) callconv(.C) void { }\r\n// allowed\r\nfn reifiedFn(         a: u32) callconv(.C) void { }\r\n\r\n`````\n Comment 6: AFAIK It's not possible to ever accidentally get this wrong. The compiler will always catch it. Distinguishing from normal functions is not hard - if a parameter is comptime or var, you can't make a runtime pointer to it.  But you wouldn't want to, because it's signature doesn't match any runtime pointer type.  You couldn't pass it to a function or put it into a table because there's no way to write the signature of that function or the type of that table.\n Comment 7: I find it only slightly confusing to have to look deep into the function signature to see if it is comptime or not, but I find that the _need_ to do so is greatly diminished by the compile-time code generation capabilities of Zig.   Consider C11's much weaker `_Generic`.   That does not have any call site-visible differences from normal calls either.",
  "Issue title: Navigator Error\n Issue body: ## Main error\r\nApplication <b>spyder</b> launch may have produced errors.\r\n## Traceback\r\n```\r\n[warn] kq_init: detected broken kqueue; not using.: Undefined error: 0\r\n[warn] kq_init: detected broken kqueue; not using.: Undefined error: 0\r\n[warn] kq_init: detected broken kqueue; not using.: Undefined error: 0\r\n[warn] kq_init: detected broken kqueue; not using.: Undefined error: 0\r\n[warn] kq_init: detected broken kqueue; not using.: Undefined error: 0\r\n[warn] kq_init: detected broken kqueue; not using.: Undefined error: 0\r\n[warn] kq_init: detected broken kqueue; not using.: Undefined error: 0\r\n\r\n```\r\n## System information\r\n```\r\npython: 3.6.1\r\nlanguage: en\r\nos: Darwin;16.7.0;Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64;x86_64;i386\r\nversion: 1.6.2\r\nplatform: osx-64\r\nqt: 5.6.2\r\npyqt: 5.6.0\r\nconda: 4.3.21\r\n```\r\n\n Comments: \n Comment 0: **See Issue #1778 for more information on how to fix this.**\n\n---\n\nClosing as duplicate of #1778\n\n\n---\n\nPlease remember to update to the latest version of Navigator to include\nthe latest fixes.\n\nOpen a terminal (on Linux or Mac) or the Anaconda Command Prompt (on windows)\nand type:\n\n```\n$ conda update anaconda-navigator\n$ conda update navigator-updater\n```\n",
  "Issue title: Showed only on the first function of the session\n Issue body: I tried add seems that in my tests the modal is showed only on the first function.\r\nIf I move in insert mode to another one I don't get anything. If I restart neovim and move to that function in insert mode the modal is showed.\r\n\r\nAlso with opening other files the issue is still there.\r\n\r\nMy dotfiles are there https://github.com/mte90/dotfiles\r\n\r\nI have this with php files.\n Comments: \n Comment 0: Could not reproduce with following vimrc\r\n\r\n```vim\r\n\r\n\" Note: run PlugUpdate/Install first\r\nset termguicolors\r\ncall plug#begin('~/.vim/plugged')\r\n\r\nPlug 'neovim/nvim-lspconfig'\r\nPlug 'ray-x/lsp_signature.nvim'\r\ncall plug#end()\r\n\r\n\" No need for rquire('lspconfig'), navigator will configure it for you\r\nlua <<EOF\r\nrequire'lspconfig'.intelephense.setup({\r\n    settings = {\r\n        intelephense = {\r\n            stubs = { \r\n                \"bcmath\",\r\n                \"bz2\",\r\n......\r\n                \"wordpress\",\r\n                \"woocommerce\"\r\n            },\r\n            files = {\r\n                maxSize = 5000000;\r\n            };\r\n        };\r\n    },\r\n    on_attach = function()\r\n    \trequire'lsp_signature'.on_attach()\r\n    end\r\n});\r\n\r\nEOF\r\n\r\n```\r\n\n Comment 1: I did some tests with less plugins but it still happening.\r\nThere is some way to test and if this plugin is executed every time?\n Comment 2: You can turn on logs by:\r\n\r\n    require \"lsp_signature\".on_attach(\r\n      {\r\n        floating_window = true,\r\n        log_path = \"log_path/log_name.log\",\r\n        debug = true,\r\n      }\r\n\r\nYou should be able to see logs if the plugin is triggered.\r\n\n Comment 3: I am not getting any file with:\r\n```\r\nrequire 'lsp_signature'.on_attach({\r\n      bind = true,\r\n      log_path = \"/tmp/lsp.log\",\r\n        debug = true,\r\n      handler_opts = {\r\n        border = \"single\"\r\n      }\r\n    })\r\n```\r\n\r\nI also get this:\r\n![immagine](https://user-images.githubusercontent.com/403283/123134670-534e1e00-d451-11eb-9465-427e55080f68.png)\r\n\n Comment 4: Regarding the log file. Looks to me there is nothing write to the log.  Maybe you can run `touch /tmp/lsp.log` before launching the nvim.\r\nI am not familiar with PHP, but it seems in your screenshot, there are two functions with the same signature. I am not sure whether this will introduce difficulties to the LSP.\r\n\r\nYou can also run `lua require('lsp_signature').signature()` on the pos where signature should show (e.g. after `(` and `,`) to get the signature. If this works fine, then maybe something else (e.g. event & timer setup) does not work correctly.\n Comment 5: In the log executing the function I got this:\r\n```\r\nsig_cfg bufnr, winnr not valid |2: 3 |3: 1002\r\n```\r\nAnd executing again didn't showed again the window.\r\n\r\nAbout the minimal with this:\r\n\r\n```\r\n\" Note: run PlugUpdate/Install first\r\nset termguicolors\r\ncall plug#begin('~/.vim/plugged')\r\n\r\nPlug 'neovim/nvim-lspconfig'\r\nPlug 'ray-x/lsp_signature.nvim'\r\ncall plug#end()\r\n\r\n\" No need for rquire('lspconfig'), navigator will configure it for you\r\nlua <<EOF\r\nrequire'lspconfig'.intelephense.setup({\r\n    settings = {\r\n        intelephense = {\r\n            stubs = { \r\n                \"bcmath\",\r\n                \"bz2\",\r\n                \"calendar\",\r\n                \"Core\",\r\n                \"curl\",\r\n                \"date\",\r\n                \"dba\",\r\n                \"dom\",\r\n                \"enchant\",\r\n                \"fileinfo\",\r\n                \"filter\",\r\n                \"ftp\",\r\n                \"gd\",\r\n                \"gettext\",\r\n                \"hash\",\r\n                \"iconv\",\r\n                \"imap\",\r\n                \"intl\",\r\n                \"json\",\r\n                \"ldap\",\r\n                \"libxml\",\r\n                \"mbstring\",\r\n                \"mcrypt\",\r\n                \"mysql\",\r\n                \"mysqli\",\r\n                \"password\",\r\n                \"pcntl\",\r\n                \"pcre\",\r\n                \"PDO\",\r\n                \"pdo_mysql\",\r\n                \"Phar\",\r\n                \"readline\",\r\n                \"recode\",\r\n                \"Reflection\",\r\n                \"regex\",\r\n                \"session\",\r\n                \"SimpleXML\",\r\n                \"soap\",\r\n                \"sockets\",\r\n                \"sodium\",\r\n                \"SPL\",\r\n                \"standard\",\r\n                \"superglobals\",\r\n                \"sysvsem\",\r\n                \"sysvshm\",\r\n                \"tokenizer\",\r\n                \"xml\",\r\n                \"xdebug\",\r\n                \"xmlreader\",\r\n                \"xmlwriter\",\r\n                \"yaml\",\r\n                \"zip\",\r\n                \"zlib\",\r\n                \"wordpress\",\r\n                \"woocommerce\"\r\n            },\r\n            files = {\r\n                maxSize = 5000000;\r\n            };\r\n        };\r\n    },\r\n    on_attach = function()\r\n    \trequire'lsp_signature'.on_attach()\r\n    end\r\n});\r\n\r\nEOF\r\n```\r\nI don't get anything.\n Comment 6: Each time the signature been triggered, you should see a log.  For your case, it not been triggered. Is LSP works correctly?\r\n\r\nIt also might be something special with your code.\r\nCan you try some code very simple to see if signature works, e.g.:\r\n\r\n```\r\n<?php\r\nfunction foo($arg_1, $arg_2, /*..., */ $arg_n)\r\n{\r\n    echo \"Example function.\\n\";\r\n    return $retval;\r\n}\r\n?>\r\n```\n Comment 7: You are right seems that with a file like this:\r\n```\r\n<?php\r\nfunction foo($arg_1, $arg_2, /*..., */ $arg_n)\r\n{\r\n    echo \"Example function.\\n\";\r\n    return $retval;\r\n}\r\n\r\nfunction test($test){\r\n}\r\n\r\nfoo();\r\nfoo();\r\ntest();\r\n?> \r\n```\r\nI get the window at every function but not with other php files (with my nvim config).\r\nI tested other php fields with more functions and code and is not showing anyway.\n Comment 8: Could you send out some php files (or a open-source PHP project) that can reproduce this issue.\r\nI am not using PHP so it is a bit hard to reproduce your issue.\n Comment 9: Sure, I was looking on my projects for something open source.\r\nI was testing also with this project: https://github.com/WPBP/WordPress-Plugin-Boilerplate-Powered/blob/master/plugin-name/rest/Example.php\r\n\r\nin rest/example.php file or internals/posttypes.php\n Comment 10: I tried the github php project and it seems work correctly.\r\n\r\n\r\nhttps://user-images.githubusercontent.com/1681295/123502031-8cbe9d80-d68c-11eb-9db1-f715f0555dc4.mov\r\n\r\n\r\n\r\n<img width=\"942\" alt=\"Screen Shot 2021-06-26 at 2 37 57 pm\" src=\"https://user-images.githubusercontent.com/1681295/123502007-4d904c80-d68c-11eb-9b00-799501cdbd55.png\">\r\n\r\n\r\nMy vimrc\r\n```\r\nset termguicolors\r\ncall plug#begin('~/.vim/plugged')\r\nPlug 'neovim/nvim-lspconfig'\r\nPlug 'ray-x/lsp_signature.nvim'\r\n\r\ncall plug#end()\r\n\r\nlua <<EOF\r\nrequire'lspconfig'.rust_analyzer.setup{}\r\nrequire'lsp_signature'.on_attach({log_path = \"/Users/ray.xu/tmp/sig.log\", debug = true})\r\nrequire'lspconfig'.intelephense.setup({\r\n    settings = {\r\n        intelephense = {\r\n            stubs = { \r\n                \"bcmath\",\r\n                \"bz2\",\r\n                \"calendar\",\r\n                \"Core\",\r\n                \"curl\",\r\n                \"date\",\r\n                \"dba\",\r\n                \"dom\",\r\n                \"enchant\",\r\n                \"fileinfo\",",
  "Issue title: Adding A.gitattributes File\n Issue body: Should we add a.gitattributes file to the project?\r\n\r\nhttps://help.github.com/articles/dealing-with-line-endings/#per-repository-settings\r\n\r\nLooks like it could help with line endings differences?\n Comments: \n Comment 0: If this comes from the problem i had in pull request #4334, the culprit was Visual Studio. It seems that making a commit from inside Visual Studio 2015 ignores core.autocrlf at system and repository levels, once it is set to true at global level it works.\n Comment 1: > It seems that making a commit from inside Visual Studio 2015 ignores core.autocrlf at system and repository levels\r\n\r\nOh... interesting.  Good to know that VS2015 is causing this sort of bug.\n Comment 2: Further testing has found that gitattributes will solve visual studio problem.\r\nAlso i have read that Jgit (eclipse plugin) is in works to add this functionality, and that the plugin for teamcity (egit?) does not support it. note that i don't know this firsthand and where i read this was very old",
  "Issue title: Compile error on brcm2708(raspberrypi) SDK\n Issue body: error log:\r\n\r\n```shell\r\nsomeone@Miku:~/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115$ make package/shadowsocks-libev/compile V=99\r\n#\r\n# configuration written to.config\r\n#\r\nmake[1]: Entering directory `/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115'\r\nmake[2]: Entering directory `/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/package/shadowsocks-libev'\r\nCFLAGS=\"-Os -pipe -march=armv6 -mtune=arm1176jzf-s -mfpu=vfp -fno-caller-saves -fhonour-copts -Wno-error=unused-but-set-variable -mfloat-abi=soft  -I/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/target-arm_arm1176jzf-s+vfp_uClibc-116.69.203.115_eabi/usr/include -I/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/target-arm_arm1176jzf-s+vfp_uClibc-116.69.203.115_eabi/include -I/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/toolchain-arm_arm1176jzf-s+vfp_gcc-4.8-linaro_uClibc-116.69.203.115_eabi/usr/include -I/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/toolchain-arm_arm1176jzf-s+vfp_gcc-4.8-linaro_uClibc-116.69.203.115_eabi/include \" CXXFLAGS=\"-Os -pipe -march=armv6 -mtune=arm1176jzf-s -mfpu=vfp -fno-caller-saves -fhonour-copts -Wno-error=unused-but-set-variable -mfloat-abi=soft  -I/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/target-arm_arm1176jzf-s+vfp_uClibc-116.69.203.115_eabi/usr/include -I/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/target-arm_arm1176jzf-s+vfp_uClibc-116.69.203.115_eabi/include -I/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/toolchain-arm_arm1176jzf-s+vfp_gcc-4.8-linaro_uClibc-116.69.203.115_eabi/usr/include -I/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/toolchain-arm_arm1176jzf-s+vfp_gcc-4.8-linaro_uClibc-116.69.203.115_eabi/include \" LDFLAGS=\"-L/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/target-arm_arm1176jzf-s+vfp_uClibc-116.69.203.115_eabi/usr/lib -L/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/target-arm_arm1176jzf-s+vfp_uClibc-116.69.203.115_eabi/lib -L/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/toolchain-arm_arm1176jzf-s+vfp_gcc-4.8-linaro_uClibc-116.69.203.115_eabi/usr/lib -L/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/staging_dir/toolchain-arm_arm1176jzf-s+vfp_gcc-4.8-linaro_uClibc-116.69.203.115_eabi/lib \" make   -C /home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/build_dir/target-arm_arm1176jzf-s+vfp_uClibc-116.69.203.115_eabi/shadowsocks-libev/openssl/shadowsocks-libev-2.2.0/. AR=arm-openwrt-linux-uclibcgnueabi-ar AS=\"ccache_cc -c -Os -pipe -march=armv6 -mtune=arm1176jzf-s -mfpu=vfp -fno-caller-saves -fhonour-copts -Wno-error=unused-but-set-variable -mfloat-abi=soft\" LD=arm-openwrt-linux-uclibcgnueabi-ld NM=arm-openwrt-linux-uclibcgnueabi-nm CC=\"ccache_cc\" GCC=\"ccache_cc\" CXX=\"ccache_cxx\" RANLIB=arm-openwrt-linux-uclibcgnueabi-ranlib STRIP=arm-openwrt-linux-uclibcgnueabi-strip OBJCOPY=arm-openwrt-linux-uclibcgnueabi-objcopy OBJDUMP=arm-openwrt-linux-uclibcgnueabi-objdump SIZE=arm-openwrt-linux-uclibcgnueabi-size CROSS=\"arm-openwrt-linux-uclibcgnueabi-\" ARCH=\"arm\" ;\r\nmake[3]: Entering directory `/home/someone/code/OpenWrt-SDK-brcm2708-for-linux-x86_64-gcc-4.8-linaro_uClibc-116.69.203.115/build_dir/target-arm_arm1176jzf-s+vfp_uClibc-116.69.203.115_eabi/shadowsocks-libev/openssl/shadowsocks-libev-2.2.0'\r\nmake[3]: *** No targets specified and no makefile found.  Stop.\r\nmake",
  "Issue title: MFA for disabling MFA, changing password\n Issue body: There seem to be several best practices missing from Cognito's MFA implementation. See Gmail or Github for examples of the below implemented properly.\r\n\r\nWith Cognito, a user who has TOTP MFA enabled can:\r\n\r\n- disable their MFA (assuming MFA is optional on their user pool) without needing to confirm their password or enter an MFA code\r\n- change their password without needing an MFA code\r\n- reset their password without needing an MFA code\r\n\r\nIn addition, there appears to be no way to download recovery codes that can be used instead of MFA codes in case they lose their TOTP device.\r\n\r\nThis means that Cognito is both too permissive and too stringent.\r\n\r\nA legitimate user who loses their TOTP device has no way to recover their account without admin intervention (which is susceptible to social engineering), as there are no recovery codes. Even resetting their password will not change their MFA status.\r\n\r\nConversely, an attacker who finds a laptop left open and signed in can disable MFA with no credentials, swipe the user's password from their password manager, and change the user's password, taking full control of their account without needing the TOTP device.\r\n\r\nAre there plans to address those points? Am I missing something?\n Comments: \n Comment 0: @tomquisel I wonder if there's been any updates on generating the recovery codes for a user account with MFA on Cognito\n Comment 1: This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n\n Comment 2: This issue has been automatically closed because of inactivity. Please open a new issue if are still encountering problems.\n\n Comment 3: Bump. This is a huge issue and should be addressed\n Comment 4: Agreed. Cognito should bring best security practices instead of breaking them :/ But I am afraid it will not be implemented as it would be a breaking change.\n Comment 5: it's been 7 months since filipsuk made last comment. But it doesn't seem like we have solutions for recovery from MFA.. Am I right??\n Comment 6: Short answer; don't use Cognito if you want a proper security model \ud83d\ude22 ",
  "Issue title: Typos in your readme\n Issue body: You have some typo's in your readme\r\n\r\nthe database is returned to **it's** initial state (**it's** state before the transaction started).\r\n\r\nI have bolded them.\r\n\r\nIt's = it is\r\nIts = it belongs to\r\n\r\nYou need its here :)\n Comments: \n Comment 0: Thanks for the catch. Fixed. \ud83d\udc4d ",
  "Issue title: cases produces extra hypothesis\n Issue body: Sometimes the `cases` tactic produces a new \"useless\" hypothesis. For example, in the next example the hypothesis `e_2 : refl y = refl y` is generated.\n\n```\nopen eq\n\ndefinition foo {A : Type} (P : A \u2192 Type) {x y : A} (p : x = y) {a : P x} \n{b : P y} (q : p \u25b9 a = b) : A :=\nbegin\n  cases p, clear e_2, exact x\nend\n```\n\n Comments: \n Comment 0: PS: in the above case the variable `p` is also not removed from the context. \n\nAlso, when you do cases on `p : x = y`, in future hypotheses/goals all variables `x` are replaced by `y` (and `p` by `refl y`). It would be nice if `x` is also removed from the context.\n\n Comment 1: The `cases` tactic is quite complicated in HoTT mode.\r\nIt performs a sequence of steps. The auxiliary hypotheses are generated in the process. When they are generated, they are not trivial. They become trivial later. \r\nSome of them are easy to remove (e.g., the one in `foo`). I submitted a fix that removes the easy ones.\r\nTo get rid of all of them, I think the only solution is a post-processor. \r\nSomething that would go over the hypotheses and remove the ones of the form `(H : a = a)`.\r\n",
  "Issue title: DSLX: Explicit struct params not validated\n Issue body: Consider the following code sequence:\r\n```\r\nstruct ParametricPoint<A: u32, B: u32 = double(A)> {\r\n  x: bits[A],\r\n  y: bits[B]\r\n}\r\n\r\nfn foo() {\r\n  let bar =\r\n      ParametricPoint<bits[666]:666, bits[777]:777>{ x: u8:15, y: u16:18 };\r\n  ()\r\n}\r\n```\r\n\r\nI don't believe this should compile, as the explicit parametrics are of bits[666] and bits[777], which do NOT match the types given in the struct definition. Currently, in the parser, explicit struct parametrics are parsed for syntactic validity but aren't checked against the StructDef's parametric bindings.\n Comments: \n Comment 0: Rob said I could steal this one. :-)\n Comment 1: Example of something very simple that should flag an error -- even though there's a \"phantom\" parametric (unused in the body of the struct definition), they are _structurally_ the same but not _nominally_.\r\n\r\n```\r\nstruct MyStruct<N: u32> {}\r\nfn main(x: MyStruct<u32:8>) -> MyStruct<u32:42> { x } \r\n```\r\n\r\nThink I'm going to prefactor `ConcreteType` first, right now there's a \"nominal\" field for the struct definition hanging off `TupleType` (with member names) but worth breaking out into its own subclass first, since we now want to bolt parametrics into it for nominal comparisons.",
  "Issue title: Refresh signs for current tab page\n Issue body: > What is the latest commit SHA in your installed vim-gitgutter?\r\nb71ab64dc16a4665c3214f109000a11d30708079\r\n\r\n> What vim/nvim version are you on?\r\n```\r\nVIM - Vi IMproved 8.0 (2016 Sep 12, compiled Jun 21 2019 04:10:35)                                                                                                                             \r\nPatch incluse: 1-197, 322, 377-378, 550, 649, 651, 703, 706-707                                                                                                                                \r\nPatch aggiuntive: 8.1.1401, 8.1.1382, 8.1.1368, 8.1.1367, 8.1.1366, 8.1.1365, 8.1.1046, 8.1.0613, 8.1.0547, 8.1.0546, 8.1.0544, 8.1.0540, 8.1.0539, 8.1.0538, 8.1.0506, 8.1.0208, 8.1.0206, 8.1\r\n.0205, 8.1.0189, 8.1.0177, 8.1.0067, 8.1.0066                                                                                                                                                  \r\n```\r\n\r\nBasically I'd like a command to refresh signs for the current tab, like when doing `!git add -u` or `!git reset`. The commad GitGutterAll seems a bit heavy, it'd be more something like:\r\n```vim\r\ncommand! -bar GitGutterTab call gitgutter#tab()\r\n\r\nfunction! gitgutter#tab() abort\r\n  for bufnr in tabpagebuflist()\r\n    if buflisted(bufnr)\r\n      let file = expand('#'.bufnr.':p')\r\n      if!empty(file)\r\n        call gitgutter#process_buffer(bufnr, 1)\r\n      endif\r\n    endif\r\n  endfor\r\nendfunction\r\n```\r\n\r\nWould it make sense to include something like that or is there a setting or a command that acts similarly? Thanks\n Comments: \n Comment 0: `GitGutterAll` refreshes signs for windows in the current tab (only) \u2013\u00a0why is it a bit heavy for you?\n Comment 1: The help file says :\r\n```\r\n:GitGutterAll           Update signs for all buffers.  You shouldn't need to\r\n                        run this.\r\n```\r\n\r\nand in the function I read\r\n\r\n    for bufnr in range(1, bufnr('$') + 1)\r\n\r\nso I assumed it was running on all buffers and that it was a bit heavy, but if you say it's not the case it's ok.\n Comment 2: If you read on in the function you'll see this:\r\n\r\nhttps://github.com/airblade/vim-gitgutter/blob/b71ab64dc16a4665c3214f109000a11d30708079/autoload/gitgutter.vim#L12\r\n\r\n\u2013 where `visible` is from `tabpagebuflist()`.\r\n\r\nIt's only processing buffers with windows in the current tab.\n Comment 3: I see.. thanks.",
  "Issue title: Project includes do not handle soft symlinks on linux, instead copy entire linked directory\n Issue body: If I have something like the following in my project file:\r\n\r\n```csproj\r\n<None Include=\"fixtures\\**\" CopyToOutputDirectory=\"PreserveNewest\" LinkBase=\"fixtures\\\" />\r\n```\r\n\r\nAnd then inside of fixtures I have a symlinked folder I created using `ln -s [source] [link]`. But the problem is when I build the project dotnet removes the symlink and instead just copies everything over. This doesn't work as when running in debug I need the folder to be elsewhere on the system, both because of access and because it's very large.\r\n\r\nIs there a workaround for this?\r\n\r\nI put linux in the title, although I have not tested it on any other operating system.\n Comments: \n Comment 0: I couldn't figure out the best area label to add to this issue. If you have write-permissions please help me learn by adding exactly one [area label](https://github.com/dotnet/runtime/blob/master/docs/area-owners.md).",
  "Issue title: Question regarding the advised module structure\n Issue body: Many DSC resource repos, including ComputerManagementDSC and NetworkingDSC, direct people to the contributing.md file in this repo. However there is a discrepancy between the advised module structure and the structure these resources actually use. To illustrate:\r\n\r\nAdvised\r\n```\r\n  * Root folder (e.g. SampleResourceModuleDsc)\r\n    * DscResources\r\n      * SampleResource\r\n        * SampleResource.psm1\r\n        * SampleResource.schema.mof\r\n    * Tests\r\n      * Unit\r\n        * SampleResource.Tests.ps1\r\n      * Integration\r\n        * SampleResource.Integration.Tests.ps1\r\n    * Examples\r\n      * SampleResource.Example.ps1\r\n    * Module manifest (e.g. SampleResourceModuleDsc.psd1)\r\n``` \r\n\r\nActual:\r\n```\r\n* Root folder\r\n  * Modules\r\n    * NetworkingDSC\r\n      * Examples\r\n      * DSCResources\r\n        * MSFT_Route\r\n      * Module Manifest\r\n  * Tests\r\n```\r\n\r\nPerhaps the documentation needs to be updated and this is the new preferred way?\r\n\r\nIf it is indeed a new format I just had one quick question. How exactly are people doing local development? With the (presumably) old way I used to clone a repo into \"C:\\Program Files\\WindowsPowerShell\\Modules\" and by merit of the structure it all worked nicely.  Perhaps there is some trick with this new format I am missing that gets any local changes into my module path?\r\n\r\nJust for context I am working on making all our own internal DSC resources align more closely with whats happening in the community is why I am intrigued. \r\n\r\nThanks\n Comments: \n Comment 0: Hi @mrhockeymonkey - a great question with a bit of history attached.\r\n\r\nEarly on, all the original DSC resources had the \"Advised\" structure. However, the maintainers over on SharePointDsc adopted an \"auto-documentation generation\" model and some other changes to make maintenance easier and to automatically build a GitHub Wiki. But this required that they reorganize the \"Actual\" structure.\r\n\r\nThe maintainers (myself and others) of some of the other resources decided to adopt what SharePointDsc had done so we could get the benefits too. So we moved lots of the modules over to the \"Actual\" structure.\r\n\r\nBut about a year ago we refactored DscResource.Tests so that we could get the benefits of \"auto-documentation generation\" without needing the different structure SharePointDsc used.\r\n\r\nSo I've been slowly refactoring all the \"Actual\" structure resources back to \"Advised\" structure - but it takes a while :cry: - NetworkingDsc and ComputerManagementDsc are the last ones to go but I wanted to get some of the open PRs through on them before migration (didn't want to completely mess up the contributors PR's).\r\n\r\nSee these issues for more context and tracking on progress of moving back to \"Advised\":\r\nhttps://github.com/PowerShell/DscResource.Tests/issues/225\r\nhttps://github.com/PowerShell/ComputerManagementDsc/issues/188\r\nhttps://github.com/PowerShell/NetworkingDsc/issues/372\r\n\r\ntl;dr:\r\nUse \"Advised\" - we're in process of moving NetworkingDsc and ComputerManagementDsc back to \"Advised\". So recommend using \"Advised\" for your internal resources. If you want to use \"Auto-documentation\" in an \"Advised\" module structure, see StorageDsc or CertificateDsc.\r\n\r\nHTH?\n Comment 1: Ah, I just so happened to choose the last two ha ha. Thank you for explaining. I'll close this off :+1: ",
  "Issue title: ReferenceField raises InvalidDocumentError\n Issue body: class Users(Document):\n    username = StringField(required=True)\n    password = StringField(required=True)\n\nclass Projects(Document):\n    name = StringField(required=True)\n    description = StringField()\n    created_by = ReferenceField(Users)\n\nError : \nInvalidDocumentError(\"Field '%s' must be valid.\" % name)\nInvalidDocumentError: Field 'created_by' must be valid.\n\n Comments: \n Comment 0: Hmmm... have you tried required=False? It should be the default, but I'm not sure why validation is picking that up :(",
  "Issue title: OpenSSL allows the client to present X.509 certificates with malformed parameters in the signatureAlgorithm and signature fields.\n Issue body: ### Affected Versions\r\n1.1.1g, 1.0.2u\r\n\r\n### Setup\r\nOpenSSL has been compiled from source in an alpine docker container. The following excerpt of the used docker file shows the build related commands:\r\n```\r\nRUN./config --prefix=/build/ --openssldir=/build/ no-async \r\nRUN make -s && make install_sw -s\r\n```\r\nAfter building it the respective OpenSSL version and required libraries have been copied into an minimal docker container (from scratch).\r\n\r\nThe server is later started using the following command:\r\n`openssl s_server -accept 4433 -Verify 100 -cert /cert/inputCerts/rootv3.pem -key /cert/keys/rootv3.pem -CAfile /cert/inputCerts/root.pem -verify_return_error`\r\n\r\nAll files mentioned in this report (certificates, keys, etc.) have been included in the attached zip archive.\r\n\r\n### Issue\r\nOpenSSL 1.1.1g and 1.0.2u allow the client to present an X.509 certificate in which the parameters in the signatureAlgorithm and signature fields match but are arbitrary byte strings (0xdeadbeef) rather than NULL as required by the specified signature algorithm.\r\n\r\n### Reproduction\r\nConnect to the started server using the following command:\r\n` openssl s_client -connect localhost:4433 -cert ROOTv3_CAv3_LEAF_RSAv3_MalformedAlgorithmParameters__leaf_certificate1.pem -key rsakey_2.pem -CAfile ROOTv3_CAv3_LEAF_RSAv3_MalformedAlgorithmParameters__ca_certificate1.pem`\r\n\r\n### Expected Result\r\nSince the parameters are not conforming to the specification the certificate chain should be deemed invalid and rejected.\r\n\r\n### Actual Result\r\nOpenSSL happily accepts the certificate and proceeds with the handshake.\r\n\r\n### Attachment\r\n[opensslMalformedParameters.zip](https://github.com/openssl/openssl/files/4774578/opensslMalformedParameters.zip)\r\n\n Comments: \n Comment 0: We do allow too much. But most of the times when we try to fix\r\nsome of those issues, real certificates break. Before any of those\r\nissues are fixed I would like to see that at least one of the\r\nlinters (x509lint, cablint, zlint) has a check for that, so we can\r\nsee what the impact of such a change is.\r\n\n Comment 1: Maybe this means we need some capability flags so that these 'fixes' can be enabled/disabled?\n Comment 2: This can wait until after 3.0, right?  All these issues about \"too liberal in what we accept\" are not important.\n Comment 3: So I've actually added a test to x509lint for that, and see real certificates that trigger the new checks, but it's a very low amount.",
  "Issue title: Feature request: time travel back to field assignment\n Issue body: ### Issue description or question\r\n\r\nThe essential killer feature of time-travel debugging is the ability to go back to the previous statement that assigned a field. Please consider that.\r\n\n Comments: \n Comment 0: @JonathanMEdwards - thanks for the suggestion. This was something that we had also considered but there are currently some JavaScript runtime limitations that we haven't figured out how to solve that are preventing us from providing this as a feature. \r\n\r\nEarlier this week we released a new Live Value Display feature, **Object Proxy** that helps address your feature request (but not quite the same thing). \r\n\r\nThe feature allows you to wrap any selected object value with [JavaScript Proxy](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy) to quickly see where the wrapped object properties are being accessed from and what values are returned/set, and also where the wrapped object functions are called from and what values are returned from the object functions.\r\n\r\nInserting the special comment //?? (or /*??*/) **after any expression will wrap the runtime value of the expression with recursive proxy** (if the value of the expression is an object). The results of intercepting the object\u2019s properties and functions can then be viewed in Wallaby's Value Explorer.\n Comment 1: Thanks, I'll give it a try",
  "Issue title: Add a option for make tabTitle can auto override when title is too loooooooooooon....\n Issue body: The option'suppressApplicationTitle' is not smart eniough, either show ${tabTitle} or ${name} is a little arbitrary. If possiable that add a option for make tableTitle can auto override just when it's too long?\r\n\r\nSorry for I am not good at express in English.\r\n<!-- \r\n\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\r\n\r\nI ACKNOWLEDGE THE FOLLOWING BEFORE PROCEEDING:\r\n1. If I delete this entire template and go my own path, the core team may close my issue without further explanation or engagement.\r\n2. If I list multiple bugs/concerns in this one issue, the core team may close my issue without further explanation or engagement.\r\n3. If I write an issue that has many duplicates, the core team may close my issue without further explanation or engagement (and without necessarily spending time to find the exact duplicate ID number).\r\n4. If I leave the title incomplete when filing the issue, the core team may close my issue without further explanation or engagement.\r\n5. If I file something completely blank in the body, the core team may close my issue without further explanation or engagement.\r\n\r\nAll good? Then proceed!\r\n-->\r\n\r\n# Description of the new feature/enhancement\r\n\r\n<!-- \r\nA clear and concise description of what the problem is that the new feature would solve.\r\nDescribe why and how a user would use this new functionality (if applicable).\r\n-->\r\n\r\n# Proposed technical implementation details (optional)\r\n\r\n<!-- \r\nA clear and concise description of what you want to happen.\r\n-->\r\n\n Comments: \n Comment 0: @flying1020 - you've made a reasonable suggestions, however is your underlying issue the fact that you can only see approximately 4 tabs at a time with the rest of the tabs scrolled off screen?  \r\n\r\nPersonally I'd prefer to see the tabs behave more like a web browser tabs.  i.e. if I have 20 tabs open then they'd shrink to a smaller width but most/all tabs would be displayed.  Title text would be truncated and a hover over the tab would reveal the full title as a tooltip.  Perhaps there would be a setting for minimum tab width but I think most people would be happy if the min width is fixed and displays the icon + about 10 characters.\n Comment 1: Yea I think the more complete solution to this problem would come from #597, enabling changing the min/max width of tabs and providing other tab sizing settings. I'll direct further discussion to that thread. \r\n/dup #597\r\nThanks!\n Comment 2: Hi! We've identified this issue as a duplicate of another one that already exists on this Issue Tracker. This specific instance is being closed in favor of tracking the concern over on the referenced thread. Thanks for your report!\n Comment 3: Thinks for all you replies! Though the issue is not get solved immediately, I am happy for your sincere replies. \u201cmiddle mouse button roller\u201d is good alternative.",
  "Issue title: npm start provides me error\n Issue body: SH00334334@bsd-pc2928137 MINGW64 /d/Front-End/lux (master)\n\n```\n$ npm start\n\n> robertavila@example.net start D:\\Front-End\\lux\n> npm prune && npm install --cache-min 999999 && gulp\n\nnpm WARN engine robertavila@example.net: wanted: {\"node\":\">= 4\"} (current: {\"node\":\"                                                                                                 0.12.7\",\"npm\":\"2.11.3\"})\nnpm WARN prefer global robertavila@example.net should be installed with -g\nnpm WARN engine robertavila@example.net: wanted: {\"node\":\">= 4\"} (current: {\"node\":                                                                                                 \"0.12.7\",\"npm\":\"2.11.3\"})\n\n> robertavila@example.net postinstall D:\\Front-End\\lux\\node_modules\\imagemin-pngquant                                                                                                 \\node_modules\\pngquant-bin\n> node lib/install.js\n\n\n  \u221a pngquant pre-build test passed successfully\nnpm ERR! Windows_NT 6.1.7600\nnpm ERR! argv \"C:\\\\Program Files (x86)\\\\nodejs\\\\\\\\node.exe\" \"C:\\\\Program Files (                                                                                                 x86)\\\\nodejs\\\\node_modules\\\\npm\\\\bin\\\\npm-cli.js\" \"install\" \"--cache-min\" \"99999                                                                                                 9\"\nnpm ERR! node v0.12.7\nnpm ERR! npm  v2.11.3\nnpm ERR! code ECONNRESET\nnpm ERR! errno ECONNRESET\nnpm ERR! syscall read\nnpm ERR! network read ECONNRESET\nnpm ERR! network This is most likely not a problem with npm itself\nnpm ERR! network and is related to network connectivity.\nnpm ERR! network In most cases you are behind a proxy or have bad network settin                                                                                                 gs.\nnpm ERR! network\nnpm ERR! network If you are behind a proxy, please make sure that the\nnpm ERR! network 'proxy' config is set properly.  See: 'npm help config'\nnpm ERR! tar.unpack untar error C:\\Users\\SH0033~1\\AppData\\Local\\Temp\\npm-7196-05                                                                                                 db2e5a\\registry.npmjs.org\\node-notifier\\-\\node-notifier-4.1.2.tgz\nnpm ERR! tar.unpack untar error C:\\Users\\SH0033~1\\AppData\\Local\\Temp\\npm-7196-05                                                                                                 db2e5a\\registry.npmjs.org\\glob\\-\\glob-4.0.6.tgz\nnpm ERR! tar.unpack untar error C:\\Users\\SH0033~1\\AppData\\Local\\Temp\\npm-7196-05                                                                                                 db2e5a\\registry.npmjs.org\\cordova-app-hello-world\\-\\cordova-app-hello-world-3.10                                                                                                .0.tgz\nnpm ERR! tar.unpack untar error C:\\Users\\SH0033~1\\AppData\\Local\\Temp\\npm-7196-05                                                                                                 db2e5a\\registry.npmjs.org\\selenium-standalone\\-\\selenium-standalone-4.2.2.tgz\nnpm ERR! tar.unpack untar error C:\\Users\\SH0033~1\\AppData\\Local\\Temp\\npm-7196-05                                                                                                 db2e5a\\registry.npmjs.org\\rx\\-\\rx-2.5.3.tgz\nnpm ERR! tar.unpack untar error C:\\Users\\SH0033~1\\AppData\\Local\\Temp\\npm-7196-05                                                                                                 db2e5a\\registry.npmjs.org\\node-gyp\\-\\node-gyp-3.2.1.tgz\nnpm ERR! tar.unpack untar error C:\\Users\\SH0033~1\\AppData\\Local\\Temp\\npm-7196-05                                                                                                 db2e5a\\registry.npmjs.org\\gherkin\\-\\gherkin-2.12.2.tgz\nnpm ERR! tar.unpack untar error C:\\Users\\SH0033~1\\AppData\\Local\\Temp\\npm-7196-05                                                                                                 db2e5a\\registry.npmjs.org\\npm\\-\\npm-2.14.15.tgz\nnpm ERR! tar.unpack untar error C:\\Users\\SH0033~1\\AppData\\Local\\Temp\\npm-7196-05                                                                                                 db2e5a\\registry.npmjs.org\\ttf2woff2\\-\\ttf2woff2-2.0.3.tgz\n\n> robertavila@example.net postinstall D:\\Front-End\\lux\\node_modules\\gulp-imagemin\\node_mo                                                                                                 dules\\imagemin\\node_modules\\imagemin-gifsicle\\node_modules\\gifsicle\n> node lib/install.js\n\n  \u221a gifsicle pre-build test passed successfully\n\n> robertavila@example.net postinstall D:\\Front-End\\lux\\node_modules\\gulp-imagemin\\node                                                                                                 _modules\\imagemin\\node_modules\\imagemin-optipng\\node_modules\\optipng-bin\n> node lib/install.js\n\n  \u221a optipng pre-build test passed successfully\n\n> robertavila@example.net postinstall D:\\Front-End\\lux\\node_modules\\gulp-imagemin\\nod                                                                                                 e_modules\\imagemin\\node_modules\\imagemin-jpegtran\\node_modules\\jpegtran-bin\n> node lib/install.js\n\n  \u221a jpegtran pre-build test passed successfully\n\n> robertavila@example.net install D:\\Front-End\\lux\\node_modules\\phantomjs\n> node install.js\n\nDownloading https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-1.9.8-wind                                                                                                 ows.zip\nSaving to C:\\Users\\SH0033~1\\AppData\\Local\\Temp\\phantomjs\\phantomjs-1.9.8-windows                                                                                                .zip\nUsing proxy http://Shruti.Hc:******@116.69.203.115:8080/\nReceiving...\n\nReceived 7292K total.\nExtracting zip contents\nRemoving D:\\Front-End\\lux\\node_modules\\phantomjs\\lib\\phantom\nCopying extracted folder C:\\Users\\SH0033~1\\AppData\\Local\\Temp\\phantomjs\\phantomjs-1.9.8-windows.zip-extract-1459836423866\\phantomjs-1.9.8-windows -> D:\\Front-End\\lux\\node_modules\\phantomjs\\lib\\phantom\nWriting location.js file\nDone. Phantomjs binary available at D:\\Front-End\\lux\\node_modules\\phantomjs\\lib\\phantom\\phantomjs.exe\nnpm ERR! fetch failed http://registry.npmjs.org/readable-stream/-/readable-stream-2.0.4.tgz\nnpm WARN retry will retry, error on last attempt: Error: socket hang up\nnpm ERR! Windows_NT 6.1.7600\nnpm ERR! argv \"C:\\\\Program Files (x86)\\\\nodejs\\\\\\\\node.exe\" \"C:\\\\Program Files (x86)\\\\nodejs\\\\node_modules\\\\npm\\\\bin\\\\npm-cli.js\" \"install\" \"--cache-min\" \"999999\"\nnpm ERR! node v0.12.7\nnpm ERR! npm  v2.11.3\n\nnpm ERR! unexpected eof\nnpm ERR!\nnpm ERR! If you need help, you may report this error at:\nnpm ERR!     <https://github.com/npm/npm/issues>\n```\n\n Comments: \n Comment 0: Can you try changing to these npm configurations?\r\n\r\n`$ npm config set registry \"http://registry.npmjs.org`\r\n`$ npm set strict-ssl false`\n Comment 1: We're closing this support issue as it has gone three days without activity.  The npm CLI team itself does not provide support via this issue tracker, but we are happy when users help each other here.  In our experience once a support issue goes dormant it's unlikely to get further activity.  If you're still having problems, you may be better served by joining [package.community](https://package.community/) and asking your question there.\n\nFor more information about our new issue aging policies and why we've instituted them please see our [blog post](http://blog.npmjs.org/post/161832149430/npm-the-npm-github-issue-tracker-and-you).\n",
  "Issue title: SASPY install\n Issue body: I am trying to install SASPY so our users can use Python on our SAS Grid environment. The problem I am having is following the import of SASPY when I  run the command sas = saspy.SASsession() I get the following error:\r\n\r\nAttributeError: module'saspy has no attribute'sassession'\r\n\r\nI'm not sure where this is supposed to be set form the sascf file I'm using?\n Comments: \n Comment 0: That looks to me like something's wrong with your install. Did you edit the sascfg.py file? I would look at that to see it you have a typo or something that's causing this. There is no missing attribute sassession, so I think something's messed up when it tried to import. \r\nAre you on windows or linux? How/ when did you install this? After importing saspy, if you submit'saspy' (w/out quotes), it should show where it found the code. \r\n\r\n```\r\nimport saspy\r\nsaspy\r\n<module'saspy' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\saspy\\\\__init__.py'>\r\n```\r\nlike that. Can you verify that it installed clean and that your sascfg.py file is valid?  \n Comment 1: HI Tom,\r\n\r\nI'm sorry but I cannot see anywhere in the installation guide that mentions editing the __init__.py file?\r\n\r\nTo date I have only made amendments to the file sascfg.py.\r\n\r\nAre there steps that I am missing?\r\n\r\nThanks in advance for any help you can provide.\r\n\r\nKind regards\r\n\r\nPaul Davies\r\nLead Platform Administrator\r\nAgeas Insurance Limited\r\nBusiness Intelligence\r\nTel: +1-858-240-3876\r\nspencer58@example.net<mailto:spencer58@example.net>\r\nwww.ageas.co.uk\r\n\r\nSAS Certified Platform Administrator [cid:spencer58@example.net]\r\n\r\nFrom: Tom Weber [mailto:spencer58@example.net]\r\nSent: 24 July 2017 14:50\r\nTo: sassoftware/saspy\r\nCc: Paul Davies (BI - Eastleigh); Author\r\nSubject: Re: [sassoftware/saspy] SASPY install (#48)\r\n\r\n\r\nThat looks to me like something's wrong with your install. Did you edit the sascfg.py file? I would look at that to see it you have a typo or something that's causing this. There is no missing attribute sassession, so I think something's messed up when it tried to import.\r\nAre you on windows or linux? How/ when did you install this? After importing saspy, if you submit'saspy' (w/out quotes), it should show where it found the code.\r\n\r\nimport saspy\r\n\r\nsaspy\r\n\r\n<module'saspy' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\saspy\\\\__init__.py'>\r\n\r\nlike that. Can you verify that it installed clean and that your sascfg.py file is valid?\r\n\r\n\u2014\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub<https://github.com/sassoftware/saspy/issues/48#issuecomment-317428396>, or mute the thread<https://github.com/notifications/unsubscribe-auth/Ac6jTYoGHdhmf6VWBMdtPlUc-Ab8j_v2ks5sRKENgaJpZM4Og5Bf>.\r\n\r\n________________________________\r\nConsider the environment and think before you print this email.\r\n\r\n________________________________\r\nProud partner of The Ageas Bowl and the Ageas Salisbury International Arts Festival.\r\n\r\nThis email has been sent by and on behalf of one or more of Ageas (UK) Limited (registered no: 1093301 ), Ageas Insurance Limited (registered no: 354568), Ageas Retail Limited (registered no: 1324965), or a subsidiary of Ageas (UK) Limited (together \u201cAgeas UK\u201d). Ageas UK companies are registered in England and Wales, and each entity\u2019s registered office is Ageas House, Hampshire Corporate Park, Templars Way, Eastleigh SO53 3YA.\r\n\r\nAgeas Retail Limited is authorised and regulated by the Financial Conduct Authority. Financial Services Register Number: 312468.\r\n\r\nAgeas Insurance Limited is authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority. Financial Services Register Number: 202039\r\n\r\nThis e-mail together with any attachments are intended for the addressee only and may be private and confidential. If you are not the intended recipient, or the person responsible for delivering it to the intended recipient, you must not open any attachments, or copy, disclose, distribute, retain or use this e-mail, including any attachments, in any way whatsoever; please return it to us immediately using the reply facility on e-mail.\r\n\r\nConsider the environment and think before you print this email.\r\n\n Comment 2: Tom,\r\n\r\nAlso I am using a windows server.\r\n\r\nThe details I have entering in the sascfg.py file are:\r\n\r\nhttp     = {'ip'      : 'host.running.compute.service',\r\n            'port'    :  80,\r\n            'context' : 'Tom2'\r\n            }\r\n\r\n\r\n\r\ncp = \"C:\\\\Program Files\\\\SASHome\\\\SASDeploymentManager\\\\9.4\\\\products\\\\deploywiz__94260__prt__xx__sp0__1\\\\deploywiz\\\\sas.svc.connection.jar\" \r\ncp += \";C:\\\\Program Files\\\\SASHome\\\\SASDeploymentManager\\\\9.4\\\\products\\\\deploywiz__94260__prt__xx__sp0__1\\\\deploywiz\\\\log4j.jar\" \r\ncp += \";C:\\\\Program Files\\\\SASHome\\\\SASDeploymentManager\\\\9.4\\\\products\\\\deploywiz__94260__prt__xx__sp0__1\\\\deploywiz\\\\sas.security.sspi.jar\" \r\ncp += \";C:\\\\Program Files\\\\SASHome\\\\SASDeploymentManager\\\\9.4\\\\products\\\\deploywiz__94260__prt__xx__sp0__1\\\\deploywiz\\\\sas.core.jar\" \r\ncp += \";C:\\\\ProgramData\\\\Anaconda3\\\\Lib\\\\site-packages\\\\saspy\\\\java\\\\saspyiom.jar\" \r\n'classpath' : cp,\r\n\r\niomwin   = {'java'      : 'java',\r\n            'iomhost'   : 'finsasnode01.fortis-uk.fortis.com',\r\n            'iomport'   : 8591,\r\n            'encoding'  : 'utf8',\r\n            'classpath' : cp,\r\n            'appserver' : 'SASAppGrid - Workspace Server'\r\n           }\r\n\r\nI don't thin there is anything wrong here but you might be able to see something I cant?\n Comment 3: @Daviespau  what's that line between you setting the class path and defining the configuration definition named iomwin:\r\n```\r\n 'classpath' : cp,\r\n```\r\nThat looks like it could cause issues. No, you're not supposed to edit anything other than the config file. Not sure why you're thinking you have to edit something in __initi__. \r\n\r\nI assume you are trying to use iomwin? There is no compute service (http) access method currently, so not sure why the http one is in there. That won't work. Having it in there (with no syntax errors) won't matter, but it won't be usable.\r\n\r\ndelete the *'classpath' : cp,* line out of the file and see if it works. that looks like it should be a syntax error which would cause things to not work; like you're seeing. \r\n\r\nI wouldn't be surprised if that's the problem. \r\nTom\n Comment 4: HI Tom,\r\n\r\nThe reference to the initi file was due to your email that mentioned it?\r\n\r\nEither way I have taken out the line you mentioned and tried to launch a SAS session but I am still getting the same error message:\r\n\r\nAttributeError: module \u2018saspy\u2019 has no attribute \u2018sassession\u2019\r\n\r\nIt could be due to other parts of the config file which I have list below?\r\n\r\nSAS_config_names = ['default','iomwin']\r\nSAS_config_options = {'lock_down': True}\r\n\r\nThere is another section in this config for default which I have entered as:\r\n\r\nDefault = {'saspath'  : \u2018C:\\\\Program Files\\\\SASHome\\\\SASFoundation\\\\9.4\\\\nls\\\\en\\\\sasv9.cfg\u2019}\r\n\r\nThe above was originally setup with a linux path so I'm not sure if I'm doing something wrong here?\r\n\r\nThanks again for your help.\r\n\r\nKind regards\r\n\r\n",
  "Issue title: Keep old page visible while transitioning\n Issue body: Hi, I'd like to make a transition where the old page remains visible while the new page slides on top of it. But the old page keeps disappearing before the transition starts.\r\nI saw this issue that is exactly the same as mine : https://github.com/barbajs/barba/issues/85. But I'm not sure the answer matchs, as it was on barba first version.\r\n\r\nThanks for your help!\n Comments: \n Comment 0: Hi @LeoDav22,\r\n\r\nThanks for getting in touch!\r\n\r\nYou need to use the `sync` option in order for Barba to \"wait until the next page is available: fetched or cached\".\r\nSee https://barba.js.org/docs/advanced/transitions/#Sync-mode.\r\n\r\nIn order to keep your previous page visible, you should not play a \"leave\" transition, more an \"enter\" one: this way your previous content will remain unchanged until the next page is fetched/cached and the \"enter\" transition will play. Have a look at the lifecycle diagram here in order to fully understand the page transition process: https://barba.js.org/docs/getstarted/lifecycle/.\r\n\r\n> You get it, the issue was about the v1 :wink: \r\n\r\nI am closing the issue.\r\nHappy coding with Barba :tada:",
  "Issue title: Crashes on webview.loadURL()\n Issue body: * Electron version: 1.6.5\r\n* Operating system: Windows 10 64bit\r\n\r\n### Actual behavior\r\n\r\nCrashes\r\n\r\n### How to reproduce\r\n```\r\ngit clone https://github.com/S--Minecraft/Electron-Webview-Bug.git\r\nnpm install\r\nnpm start\r\n```\r\n\r\n1. click \"change\" button\r\n1. click \"hide\" button\r\n1. click \"change\" button\r\n\r\nhttps://github.com/S--Minecraft/Electron-Webview-Bug\n Comments: \n Comment 0: It happens with Electron **1.6.7**\r\nIt doesnt happen when using **1.6.2**\n Comment 1: The stack for this crash is:\r\n\r\n\r\n```\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5WebContentsViewGuest38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5reateViewForWidget(class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5RenderWidgetHost *,bool)\tUnknown\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5WebContentsImpl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5reateRenderWidgetHostViewForRenderManager(class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5RenderViewHost *)\tUnknown\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5WebContentsImpl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5reateRenderViewForRenderManager(class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5RenderViewHost *,int,int,struct content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5rameReplicationState const &)\tUnknown\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5RenderFrameHostManager38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5InitRenderView(class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5RenderViewHostImpl *,class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5RenderFrameProxyHost *)\tUnknown\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5RenderFrameHostManager38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5reateRenderFrame(class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5SiteInstance *,bool,int *)\tUnknown\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5RenderFrameHostManager38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5reatePendingRenderFrameHost(class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5SiteInstance *,class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5SiteInstance *)\tUnknown\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5RenderFrameHostManager38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5UpdateStateForNavigate(class GURL const &,class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5SiteInstance *,class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5SiteInstance *,enum ui38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5PageTransition,bool,bool,struct content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5GlobalRequestID const &,int,bool)\tUnknown\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5RenderFrameHostManager38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5Navigate(class GURL const &,class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5rameNavigationEntry const &,class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5NavigationEntryImpl const &,bool)\tUnknown\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5NavigatorImpl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5NavigateToEntry(class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5rameTreeNode *,class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5rameNavigationEntry const &,class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5NavigationEntryImpl const &,enum content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5ReloadType,bool,bool,bool,class scoped_refptr<class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5ResourceRequestBodyImpl> const &)\tUnknown\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5NavigatorImpl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5NavigateToPendingEntry(class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5rameTreeNode *,class content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5rameNavigationEntry const &,enum content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5ReloadType,bool)\tUnknown\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5NavigationControllerImpl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5NavigateToPendingEntryInternal(enum content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5ReloadType)\tUnknown\r\nelectron.exe!content38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5NavigationControllerImpl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5NavigateTo",
  "Issue title: Beautify rendered html\n Issue body: Is there any interest/concern about the human-readability of the rendered HTML?\r\nNot to undo the benefits gained from #202, but if we slightly relax the whitespace removal in Liquid templating, the indentation can be little bit easier on the eye.\r\n\r\nFor example, the blog posts on the home page currently render as:\r\n```html\r\n    <ul class=\"post-list\"><li><span class=\"post-meta\">May 20, 2016</span>\r\n        <h3>\r\n          <a class=\"post-link\" href=\"/2016/05/20/welcome-to-jekyll.html\">\r\n            Welcome To Jekyll\r\n          </a>\r\n        </h3></li><li><span class=\"post-meta\">May 20, 2016</span>\r\n```\r\nRemoving a few select hyphens yields:\r\n```html\r\n    <ul class=\"post-list\">\r\n      <li>\r\n        <span class=\"post-meta\">May 20, 2016</span>\r\n        <h3>\r\n          <a class=\"post-link\" href=\"/2016/05/20/welcome-to-jekyll.html\">\r\n            Welcome To Jekyll\r\n          </a>\r\n        </h3>\r\n      </li>\r\n```\r\n\r\nA more extreme example is the social links in the footer:\r\n```html\r\n<div class=\"footer-col footer-col-2\"><ul class=\"social-media-list\"><li><a href=\"https://github.com/jekyll\"><svg class=\"svg-icon grey\"><use xlink:href=\"/assets/minima-social-icons.svg#github\"></use></svg> <span class=\"username\">jekyll</span></a></li><li><a href=\"https://twitter.com/jekyllrb\"><svg class=\"svg-icon grey\"><use xlink:href=\"/assets/minima-social-icons.svg#twitter\"></use></svg> <span class=\"username\">jekyllrb</span></a></li><li><a href=\"/feed.xml\"><svg class=\"svg-icon grey\"><use xlink:href=\"/assets/minima-social-icons.svg#rss\"></use></svg> <span>rss</span></a></li></ul>\r\n</div>\r\n```\r\nAltering the template a little (but not the rendered content) can result in:\r\n```html\r\n      <div class=\"footer-col footer-col-2\"><ul class=\"social-media-list\">\r\n    <li><a href=\"https://github.com/jekyll\"><svg class=\"svg-icon grey\"><use xlink:href=\"/assets/minima-social-icons.svg#github\"></use></svg> <span class=\"username\">jekyll</span></a></li>\r\n    <li><a href=\"https://twitter.com/jekyllrb\"><svg class=\"svg-icon grey\"><use xlink:href=\"/assets/minima-social-icons.svg#twitter\"></use></svg> <span class=\"username\">jekyllrb</span></a></li>\r\n    <li><a href=\"/feed.xml\"><svg class=\"svg-icon grey\"><use xlink:href=\"/assets/minima-social-icons.svg#rss\"></use></svg> <span>rss</span></a></li>\r\n</ul>\r\n</div>\r\n```\r\n\r\nNot perfect, but an improvement.\r\n\r\nIf you think it's worth the effort I can take a deeper look and submit a PR for review.\n Comments: \n Comment 0: @KevinWMatthews I agree that Liquid's WhitespaceControl should be used with care in order to avoid losing HTML-source-readability points especially since GitHub Pages doesn't currently support any html-beautifier plugin.\r\n\r\nA PR would be greatly appreciated.\n Comment 1: For those concerned with the HTML output, I'd recommend using https://github.com/apsislabs/jekyll-tidy (not supported by GitHub Page)\n Comment 2: > Shame it isn't supported by GitHub Pages.\r\n\r\nGladly, you can host your static Jekyll site for free elsewhere (Netlify is my favourite) withtout the current limitations of GitHub Pages.\n Comment 3: Cool, I recently started using Netlify for some content. It's been seamless so far.\r\n\r\nI will confess, Minima is currently my favorite theme for GitHub Pages. I could set up a URL Netlify for each repo's docs, but for a small repo it is pretty convenient to just let GitHub do the work. Hmmm.\n Comment 4: \nThis issue has been automatically marked as stale because it has not been commented on for at least two months.\n\nThe resources of the Jekyll team are limited, and so we are asking for your help.\n\nIf this is a **bug** and you can still reproduce this error on the <code>master</code> branch, please reply with all of the information you have about it in order to keep the issue open.\n\nIf this is a feature request, please consider whether it can be accomplished in another way. If it cannot, please elaborate on why it is core to this project and why you feel more than 80% of users would find this beneficial.\n\nThis issue will automatically be closed in two months if no further activity occurs. Thank you for all your contributions.\n",
  "Issue title: Please invite me to the GitHub Community Organization\n Issue body: ### Name\n\nVetrichelvan\n\n### Discord Username (if applicable)\n\n_No response_\n\n### Additional Context\n\nI found out about Eddie on Twitter. I am a lot into OSS recently I have been trying to contribute as much as I can and also I have been helping out people on other discord servers. So it would be great to join Eddie and meet new people and gain as well as share some knowledge.\n Comments: \n Comment 0: <h1>It's great having you contribute to this project</h1> Welcome to the community :nerd_face:<p>If you would like to continue contributing to open source and would like to do it with an awesome inclusive community, you should join our <a href=\"http://discord.eddiehub.org\">Discord Server</a> and our <a href=\"http://github.eddiehub.org\">GitHub Organisation</a> - we help and encourage each other to contribute to open source little and often \ud83e\udd13. Any questions let us know.</p>",
  "Issue title: Config menu should close when confirming clear task\n Issue body: Only when confirming, not before or when canceling\r\nRelated to #188 \n Comments: \n Comment 0: Quick question on this... Your eslint does not include jQuery definitions, I can change it in this PR to do so, however the easiest way to perform this will require me to use the '$' which will throw a un-def error because you have not selected jQuery\n Comment 1: You can use /* globals $ */ or something similar I think",
  "Issue title: Call to undefined function Webklex\\IMAP\\Query\\camel_case()\n Issue body: Please be aware that these issues will be closed if inactive for more then 14 days :)\r\n![image](https://user-images.githubusercontent.com/15870174/64246481-712a5600-cf3f-11e9-90b7-e7cbd8d604df.png)\r\n![image](https://user-images.githubusercontent.com/15870174/64246491-7687a080-cf3f-11e9-8cc8-99a2510a3cb0.png)\r\n![image](https://user-images.githubusercontent.com/15870174/64246514-7f787200-cf3f-11e9-949d-443b0dbf1bec.png)\r\n\n Comments: \n Comment 0: Hi @k3youmin,\r\nwhich laravel version are you using? `camel_case` is a laravel helper function:\r\n```php\r\nif (! function_exists('camel_case')) {\r\n    /**\r\n     * Convert a value to camel case.\r\n     *\r\n     * @param  string  $value\r\n     * @return string\r\n     */\r\n    function camel_case($value)  {\r\n        return Str38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5mel($value);\r\n    }\r\n}\r\n```\n Comment 1: [image: image.png]\n\nOn Wed, Sep 4, 2019 at 9:34 PM Webklex <heather88@example.org> wrote:\n\n> Hi @k3youmin <https://github.com/k3youmin>,\n> which laravel version are you using? camel_case is a laravel helper\n> function:\n>\n> if (! function_exists('camel_case')) {    /**     * Convert a value to camel case.     *     * @param  string  $value     * @return string     */    function camel_case($value)  {        return Str38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5mel($value);    }}\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/Webklex/laravel-imap/issues/244?email_source=notifications&email_token=ADZCRXUJTT3OSERUWGWD3E3QH62MZA5CNFSM4ITQBSEKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD53SRZA#issuecomment-527902948>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADZCRXUA4MCLYJW3Z5YDJZDQH62MZANCNFSM4ITQBSEA>\n>.\n>\n",
  "Issue title: Python 3.5.2: pygpu was configured but could not be imported or is too old (version 0.6 or higher required)\n Issue body: ```\r\nroot@2ec43fec4281:~# python3 gpu_test.py \r\nERROR (theano.gpuarray): pygpu was configured but could not be imported or is too old (version 0.6 or higher required)\r\nNoneType\r\nroot@2ec43fec4281:~# python3 -c 'import pygpu; print(pygpu.__version__)'\r\n0.7.2+23.gace45c6\r\nroot@2ec43fec4281:~# python3 -c 'import pygpu; print(pygpu.__path__)'\r\n['/usr/local/lib/python3.5/dist-packages/pygpu-0.7.2+23.gace45c6-py3.5-linux-x86_64.egg/pygpu']\r\nroot@2ec43fec4281:~# python3 --version\r\nPython 3.5.2\r\n```\r\n\r\nThis could be related to https://github.com/Theano/libgpuarray/issues/421\n Comments: \n Comment 0: **[UPDATE]**\r\n\r\nA workaround is\r\n\r\n```\r\npip install -U git+https://github.com/Theano/Theano.git#egg=Theano\r\n```\r\n\r\nas mentioned in https://github.com/Theano/libgpuarray/issues/393\n Comment 1: This is not a workaround.  Theano 0.9 works with pygpu 0.6.X. The next release of Theano (and the current master) works with 0.7.X.\n Comment 2: @abergeron ok, so why doing `RUN pip3 install theano` it does not work?\n Comment 3: Because the current stable release is 0.9 so that is what you get with pip install.  You have pygpu 0.7.2+ installed so that is not compatible with the stable Theano.\r\n\r\nIf you want to use the stable release you can install pygpu 0.6.9, otherwise using the master as you did will also work.  I just wanted to note that this is not a \"workaround\" it's actually how it is supposed to work.\n Comment 4: @loretoparisi... thanks... its work for me....",
  "Issue title: Zend\\Config\\Config, count wrong after merge\n Issue body: The following test fails.  The count never gets updated after a merge\n\n**ZendTest\\Config\\ConfigTest.php**\n\n``` php\npublic function testCountAfterMerge()\n{\n      $data = new Config($this->toCombineB);\n      $data->merge(\n          new Config($this->toCombineA)\n      );\n      $this->assertEquals(count($data->toArray()), $data->count());\n}\n```\n\n Comments: \n Comment 0: Closed.  Didn't realize a pull request creates an issue.  Moved to https://github.com/zendframework/zf2/issues/3300\n",
  "Issue title: The type or namespace name 'ApplicationInsights' does not exist in the namespace 'Microsoft' (are you missing an assembly reference?)\n Issue body: Just added Template10 to my installation of VS2015. Tried to build an empty project based off the Minimal template.\r\nFirst error was complaining about System but that just requires a build and a refresh.\r\nAfter that, however, I get the error in the title, complaining about ApplicationInsights missing.\r\nAs far as I can tell, this is an optional service running off Azure. Should we be forcing developers to use this?\r\nEven if we are making it an optional feature of Template10, shouldn't there be some \"getting started\" documentation for developers so that they know the initial steps required to get going? I found http://dailydotnettips.com/2015/08/12/adding-application-insights-to-a-windows-10-universal-app/, for example, but all it starts with is \"First, login to Azure Portal\". Not very helpful if, as a developer, I've never done that before. Is there a cost for this?\r\n\n Comments: \n Comment 0: Commenting out the calls to ApplicationInsights in App.xaml.xs/App() clears the build error, so it doesn't look like there are any other references to ApplicationInsights in the template.\r\n\n Comment 1: @JerryNixon  This issue still exists in the library v1.12 for the Blank template. The same bunch of errors described above appear after creating a new app based on Blank. The issue does not happen with the Hamburger and Minimal templates because they reference the ApplicationInsights NuGet packages.",
  "Issue title: hanging on debug\n Issue body: every time I click on the arrow at the end of the line of pending transaction mix is hanging\n Comments: \n Comment 0: and F10 doesn't work",
  "Issue title: mock not showing all /dev devices with --old-chroot\n Issue body: ### Short description of the problem\r\nMock doesn't show all devices in the host's /dev, this causes problems for example when trying to build Fedora remix and the free device reported by ```losetup -f``` doesn't appear in ```/dev```\r\n\r\n### Output of `rpm -q mock`\r\nmock-1.4.16-2.fc30.noarch\r\n\r\n### Steps to reproduce issue\r\n\r\n1. Have more than 5 busy loop device so that losetup -f returns something more than 4\r\n2. Try to do a Fedora build, losetup will then return error\r\n\r\nDo not forget to mention full commandline with the mock command you executed.\r\n```shell\r\nmock -r some_file.cfg --old-chroot --cwd=some_dir --chroot a_script\r\n```\r\n### Any additional notes\r\n\r\nConsider adding output of `mock --debug-config` this can help developers to reproduce the issue.\r\n\n Comments: \n Comment 0: This is for sure intentional. We do not want to show all devices. Mock provides *minimal* build environment. Previously there were only 4 loop devices, but coincidentally we had recently https://github.com/rpm-software-management/mock/issues/283 - so starting with next release you will be able to specify the number of loop devices.\r\n\r\n```\r\n# Default maximum number of dev loops in chroot is 12\r\n# config_opts['dev_loop_count'] = 12\r\n```",
  "Issue title: Missing beta1 depext on alpine\n Issue body: **Describe the bug**\r\nWhen building beta1 on alpine, depext is missing `automake` and `autoconf`.\r\n\r\n**To Reproduce**\r\n```dockerfile\r\nfrom ocaml/opam2:alpine-3.9 as builder\r\n\r\ncopy deps deps\r\nrun sed -i '/#/d' deps\r\n\r\nrun wget http://downloads.sourceforge.net/liblo/liblo-0.30.tar.gz\r\nrun tar xf liblo*\r\nrun cd liblo-0.30 &&./configure && make && sudo make install\r\n\r\nrun opam pin -n liquidsoap https://github.com/savonet/liquidsoap.git#1.4.0-beta1\r\nrun opam depext $(cat deps)\r\nrun sudo apk add --no-cache automake autoconf      # <------- should not be needed\r\nrun opam install --destdir=/home/opam/ls $(cat deps)\r\nrun opam depext -ln $(cat deps) > /home/opam/depexts\r\n```\r\n\n Comments: \n Comment 0: Nice! ",
  "Issue title: can @biesbjerg/ngx-translate-extract be installed globally?\n Issue body: Hi \r\n\r\ncan @biesbjerg/ngx-translate-extract be installed globally?\r\n\n Comments: \n Comment 0: Sure, that should work\n Comment 1: I tried it and it\u2019s not working... keeps asking for dependencies to be installed\n Comment 2: Oh, I think I know what's up. \r\n\r\nGlobal install is not supported because it can't reliably parse source code, since it depends on the version of typescript and angular compiler used in the project\r\n\r\nMore details here:\r\nhttps://github.com/biesbjerg/ngx-translate-extract/issues/173#issuecomment-609665560\n Comment 3: how can I use ngx-translate-extract without it being installed in scripts?\r\n\n Comment 4: It is not a feature I am going to support for the reasons I linked to. Sorry!",
  "Issue title: How to use \"csv-column-order\" attribute?\n Issue body: An example would be highly appreciated.\r\n\r\nThanks,\r\nRahul\n Comments: \n Comment 0: Hi,\r\nYou can define your html like this:\r\n`<div ng-csv=\"testDelim\" csv-column-order=\"order\" filename=\"custom.csv\"></div>`\r\nIn your JS file:\r\n`$scope.testDelim = [ {a:1, b:2, c:3}, {a:4, b:5, c:6} ];\r\n    $scope.order = [ 'b', 'a', 'c' ];`\r\nIt output:\r\n`2,1,3  5,4,6`\r\n\n Comment 1: @shaohaolin  It doesnt seem to work as expected. Here is the relevant part of my code:\n\nHTML:\n\n```\n<button \n    class=\"btn btn-default\" \n    ng-csv=\"csv.csvArray\" \n    field-separator=\",\" \n    decimal-separator=\".\"\n    csv-column-order=\"order\"\n    csv-header=\"['URL', 'TITLE', 'META DESCRIPTION']\"\n    filename=\"{{ csv.filename }}.csv\" >\n        <span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span>\n</button>\n```\n\nJS:\n\n```\n$scope.order = ['link','snippet', 'title'];\n// all other variables have valid data\n// I am running this on Angular.js v1.4.5\n```\n\n Comment 2: @shaohaolin I also tried it in jsFiddle and it wouldn't let me download the CSV. http://jsfiddle.net/HB7LU/18206/\n Comment 3: @rahul-desai3 You forgot to DI.\r\n`angular\r\n   .module('myApp',['ngSanitize', 'ngCsv'])`\n Comment 4: @shaohaolin I added that. It still didn't help :-|\n Comment 5: @rahul-desai3 Something wrong when you import the ng-csv file. Please update the latest.\r\nHere is jsFiddle link that uses ng-csv cdnjs.\r\nhttp://jsfiddle.net/HB7LU/18208/\n Comment 6: Updating it to the latest version works! Thanks @shaohaolin :)\n Comment 7: @rahul-desai3 You are welcome! Enjoy hacking!",
  "Issue title: vault-token arg passed with \"nomad job run\" doesn't make it to task\n Issue body: ### Nomad version\r\nNomad v0.11.2\r\n\r\n### Operating system and Environment details\r\n- Ubuntu 18.04\r\n- Current version of nomad, vault, and consul OSS\r\n\r\n### Issue\r\n`nomad run -vault-token=\"token\" path/job.nomad` doesn't seem to get the vault token to the client machine, so templates using vault fail.  \r\n\r\nIt doesn't seem like this is the correct behavior, but maybe I am misinterpreting the documentation?  As I read it, it seems like a passed token would be handed down to the client with the job.  It's unclear if it'd be *renewed* it it seems like it should *work*.\r\n\r\n### Reproduction steps\r\n- vault server config vault{} with:\r\n```hcl\r\nvault {\r\n  allow_unauthenticated = false\r\n  address = \"https://active.vault.service.consul:8200\"\r\n}\r\n```\r\n- vault client configure vault{} with\r\n```hcl\r\nvault {\r\n  enabled = true\r\n  address = \"https://active.vault.service.consul:8200\"\r\n}\r\n```\r\n- vault token create -policy mypol\r\n- nomad job run -vault-token=TOKEN path/job.nomad\r\n\r\n#### Expected\r\nTemplate renders, job runs, vault keeps passed token renewed\r\n\r\n#### Actual \r\nJob sits in pending on the client waiting vault read\r\n\r\n### Job file (if appropriate)\r\n```hcl\r\njob \"fabio\" {\r\n  datacenters = [\"thisdc\"]\r\n  type = \"system\"\r\n\r\n  group \"web\" {\r\n    task \"lb\" {\r\n      driver = \"docker\"\r\n      config {\r\n        image = \"fabiolb/fabio\"\r\n        network_mode = \"host\"\r\n        cap_add = [ \"NET_BIND_SERVICE\" ]\r\n      }\r\n      env {\r\n        proxy_addr = \":80\"\r\n      }\r\n      template {\r\n        destination = \"local/file.yml\"\r\n        env = true\r\n        data = <<EOH\r\n{{ with secret \"consul/creds/fabio\" }}\r\nCONSUL_HTTP_TOKEN=\"{{.Data.token }}\"\r\n{{ end }}\r\nEOH\r\n\r\n      }\r\n      resources {\r\n        cpu    = 101\r\n        memory = 64\r\n        network {\r\n          mbits = 10\r\n          port \"lb_http\" {\r\n            static = 80\r\n          }\r\n          port \"ui\" {\r\n            static = 9998\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n```\r\n### Nomad Client logs (if appropriate)\r\n```\r\nMay 23 00:11:38 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]:     2020/05/23 00:11:38.202855 [INFO] (runner) creating new runner (dry: false, once: false)\r\nMay 23 00:11:38 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]:     2020/05/23 00:11:38.202986 [INFO] (runner) creating watcher\r\nMay 23 00:11:38 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]:     2020/05/23 00:11:38.203080 [INFO] (runner) starting\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]:     2020/05/23 00:11:42.047044 [WARN] (view) vault.read(consul/creds/fabio): vault.read(consul/creds/fabio): Error making API request.\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]: URL: GET https://active.vault.service.consul:8200/v1/consul/creds/fabio\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]: Code: 400. Errors:\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]: * missing client token (retry attempt 1 after \"250ms\")\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]:     2020/05/23 00:11:42.298463 [WARN] (view) vault.read(consul/creds/fabio): vault.read(consul/creds/fabio): Error making API request.\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]: URL: GET https://active.vault.service.consul:8200/v1/consul/creds/fabio\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]: Code: 400. Errors:\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]: * missing client token (retry attempt 2 after \"500ms\")\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]:     2020/05/23 00:11:42.799927 [WARN] (view) vault.read(consul/creds/fabio): vault.read(consul/creds/fabio): Error making API request.\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]: URL: GET https://active.vault.service.consul:8200/v1/consul/creds/fabio\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]: Code: 400. Errors:\r\nMay 23 00:11:42 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]: * missing client token (retry attempt 3 after \"1s\")\r\nMay 23 00:11:43 nomad-client-i-0daa6f8a33ea83dd5 nomad[18745]:     2020/05/23 00:11:43.801419 [WARN] (view) vault.read(consul/creds/fabio): vault.read(consul/creds/fabio): Error making API request.\r\n```\r\n### Nomad Server logs (if appropriate)\r\n\n Comments: \n Comment 0: Your job file is missing a [vault stanza](https://www.nomadproject.io/docs/job-specification/vault)\r\n\r\nThe documentation for the CLI is confusing because it sounds like it's passing the token to the job when it executes. However, it's really storing it in the job run API request and the server uses that token to validate if the requesting user has permissions to the vault policies defined in the job.\r\n\r\n>  -vault-token\r\n    If set, the passed Vault token is stored in the job before sending to the\r\n    Nomad servers. This allows passing the Vault token without storing it in\r\n    the job file. This overrides the token found in $VAULT_TOKEN environment\r\n    variable and that found in the job.\r\n\r\nThe vault token is cleared after validating it.\r\nhttps://github.com/hashicorp/nomad/blob/a9dd409207e6938526f62f23111402d20856940e/nomad/job_endpoint.go#L235-L236\n Comment 1: Yeah, you answered my question:\r\n\r\n> The documentation for the CLI is confusing because it sounds like...\r\n\r\nImplicit was that if one passed a token at submit time, one wouldn't need a vault stanza in the job because the requisite work was already done.\r\n\r\nI think this is probably a doc bug to make the validation only nature clearer.  IMO, the integration docs here are a bit hand wavy, so it's easy to get led astray.\n Comment 2: Thanks @leungster and sorry about the delay on circling back to this @nathanhruby. I ran into similar trouble recently while writing some end-to-end tests, so I feel your pain on the docs here. I'll mark this as something to improve in the documentation.",
  "Issue title: Delegated sign out issues\n Issue body: I am having issues with delegated sign out.  I'd like to redirect the signout request to Auth0. This flow works fine on the legacy portal. \r\n\r\nAny guidance on how to handle the preflighted CORS request?  \r\n\n Comments: \n Comment 0: Hi Adam, can you please tell in more detail at what point you're facing the CORS issue? How the flow looks like?\n Comment 1: Here is an overview of the requests I see in dev console upon clicking \"sign out\":\r\n\r\n```\r\nAPIM      |      my server     |     auth0\r\n    ----[OPTION]---->\r\n    <---[200]--------\r\n    ----[GET]------->\r\n    <---[302]--------\r\n    -----------[OPTION]-------------->\r\n    <----------[200]------------------\r\n[XHR FAILURE]\r\n```\r\n\n Comment 2: Thank you for the details. We will fix it.\n Comment 3: Any progress on this? \r\n\r\nAlternatively, if you can provide some documentation around the expected signout flow, maybe I can fix things on my end. \n Comment 4: @adamstruck We'll soon implement a fix, the ETA is 2-4 weeks.\n Comment 5: I wanted to add that this is also an issue when delegating sign out requests to Azure AD B2C.  The `https://<tenant-name>.b2clogin.com/<tenant-name>.onmicrosoft.com/<policy-name>/oauth2/v2.0/logout` endpoint responds the OPTIONS request with 404 \n Comment 6: The fix is included in the release we're rolling out now. ETA for full deployment is ~2 weeks.",
  "Issue title: [BUG] load license error\n Issue body: **Describe the bug**\r\nI recieve this message error \"Flutter Error (Unable to load asset: google_fonts/OFL.txt)\" everytime the project try to execute the load.\r\n\r\nLicenseRegistry.addLicense(() async* {\r\n    final license = await rootBundle.loadString('google_fonts/OFL.txt');\r\n    yield LicenseEntryWithLineBreaks(['google_fonts'], license);\r\n  });\r\n\r\nIs it need any other configuration?\n Comments: \n Comment 0: Hi, that file needs to exist, and you should add it to your [assets](https://api.flutter.dev/flutter/services/rootBundle.html). Please re-open if it still doesn't work!",
  "Issue title: Log_probabilities returned by tf.nn.ctc_beam_search_decoder\n Issue body: **System Info**\r\n\r\nTF version= 1.3.0\r\nOS :CentOS release 6.6 (Final)\r\nGPU : Quadro P5000\r\n\r\n\r\n**Problem**\r\nI am training a LSTM-CTC speech recognition system with using beam search decoding in the following configuration:\r\n\r\ndecoded, log_prob =\r\ntf.nn.ctc_beam_search_decoder(\r\n    inputs,\r\n    sequence_length,\r\n    beam_width=100,\r\n    top_paths=3,\r\n    merge_repeated=True\r\n)\r\n\r\n\r\nThe output of log_probabilities for a batch by the above decoder are like-\r\n \r\n[[ 14.73168373,  14.45586109,  14.35735512],\r\n        9595409003,  9595409003,  20.41798401],\r\n        [ 14.9961853,  14.925807 ,  14.88066769],\r\n       ..., \r\n        [ 18.89863396,  18.85992241,  18.85712433],\r\n        [  3.93567419,   3.92791557,   3.89198923],\r\n        [ 14.56258488,  14.55923843,  14.51092243]],\r\n\r\n\r\nSo how these scores represent log probabilities and if I want to compare confidence for top paths among examples then what will be the normalisation factor???\r\n\r\n\r\n\n Comments: \n Comment 0: Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device\n Comment 1: It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?\n Comment 2: Unfortunately, you don't have a probability, because it would mean summing over all possible sequences of all admissible lengths. You can pretend that the top hypotheses that you get out of the decoder comprise all of the probability mass. In that case, then the scores are in log domain. You can compute\r\n\r\n```\r\nZ = sum_k(exp(score_k))\r\n```\r\nThen each sequence has a probability of `exp(score_k) / Z`.",
  "Issue title: Accordian template on veutify not showing up because of v-for loop on nuxt js \n Issue body: I am trying to create a faq page on nuxt js.\r\nThe template below which I got from veautify does not show up on my localhost. I get these errors instead. It works if I replace v-for \"(item,i) in 5\" : key=\"i\" as shown in the template source code but I want to pass a list of questions from object(listquestions)into the array from MapState.\r\n\r\n[Vue warn]: The client-side rendered virtual DOM tree is not matching server-rendered content. This is likely caused by incorrect HTML markup, for example nesting block-level elements inside <p>, or missing <tbody>. Bailing hydration and performing full client-side render.\r\nv-toolbar-logo> - did you register the component correctly? For recursive components, make sure to provide the \"name\" option.\r\n\r\nfound in\r\n\r\n---> <Default> at layouts/default.vue\r\n       <Root>\r\n**faq.vue file**\r\n```\r\n<template>\r\n    <v-expansion-panel>\r\n        <v-expansion-panel-content v-for=\"quest in listquestions\" :key=\"quest.id\">\r\n            <div slot=\"header\"> Question </div>\r\n            <v-card>\r\n                <v-card-text class =\"grey lighten-3\">\r\n                    This is a test answer.\r\n                </v-card-text>\r\n            </v-card>\r\n        </v-expansion-panel-content>\r\n    </v-expansion-panel>\r\n</template>\r\n\r\n<style>\r\n\r\n</style>\r\n<script>\r\n\r\nimport {mapState, mapGetters, mapActions} from 'vuex'\r\n\r\nexport default {\r\n  computed: mapState({\r\n      listquestions:'allQuestions'\r\n      })\r\n}\r\n</script>`\r\n```\r\n```\r\n**questions.js file**\r\nexport const state = () => ({\r\n    list :['Question 1','Question 2','Question 3','Question 4','Question 5'],\r\n    allQuestions: state => state.list \r\n       \r\n})\r\n``` \r\nAccordian template source code which I got from veautify.\r\n```\r\nhttps://vuetifyjs.com/components/expansion-panels#example-1\r\n```\r\n\n Comments: \n Comment 0: Because this bug report seems to be inactive for quite some time, I'll close it now. If you feel like it deserves some attention because it's not fixed, feel free to ping me and I'll reopen it.\r\n\n Comment 1: This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n",
  "Issue title: Autoencoders\n Issue body: Making a note to explore a high level wrapper for variational autoencoders to generate images / other content.\n Comments: \n Comment 0: Derek @Derek-Wds and I have done some work about the autoencoders before with PyTorch. We can help with building up such a wrapper.\n Comment 1: ### Question\r\nIf we are going to work on this project, what kind of images are expected? Will the simple MNIST dataset be OK or there are other options that we can focus on?\n Comment 2: @Derek-Wds A reference point for how we might do this (for images) is `ml5.styleTransfer()`. In that case we offer a few pre-trained models, but ultimately it's more interesting if people train their own model. We've been trying to move away from MNIST in ml5 in terms of getting people to think creatively about their datasets, however, as a first try, creating an ml5 autoencoder class that generates MNIST-style digits would be a great starting point. The Google Quick, Draw dataset is also a nice alternative to MNIST.\n Comment 3: Great! @WenheLI and I may start soon to work on it.\n Comment 4: @shiffman We have managed to wrap a cvae(conditional vae) model into tensorflow.js using MNIST. You can try through this [link](http://cvae.steins.live). While we think this model requires some discussions on API design before we move forward.\r\n\r\nSince cvae requires a vector with 2+n length as input where n is the number of categories and the first two number is to describe a distribution in cvae, it makes the potential ``predict()`` function be much more complex.  \n Comment 5: Closing this issue up now as this has been resolved by the addition of the CVAE functionality. We may consider adding in an example of how to create an autoencoder using the ml5.neuralNetwork's custom layer functionality, but that can be a separate issue.",
  "Issue title: Constraint.cs visibility\n Issue body: Should this class be used as base to create custom constraints?\r\nIf so, why there many methods/properties marked as internal that are actually needed to implement a new constraint.\r\nWell, in my opinion if this class is not to be used in external code it should also be marked as internal, so external developers are not confused by it.\r\nThanks.\r\n\n Comments: \n Comment 0: Are you referring to System.Data.Constraint?\r\nhttps://docs.microsoft.com/en-us/dotnet/api/system.data.constraint?view=netcore-2.1\r\n\r\nhttps://social.msdn.microsoft.com/Forums/en-US/e94dbfe1-d076-4ffa-8bbe-2e47d8b83453/dataset-adding-custom-constraints\n Comment 1: Exactly this one!\r\nI did look at these links, not very helpful...\r\nI understand that this class is used to generalize constraints in the DataTable's constraints collection, but as you are exposing it to outside code, shouldn't it be fully usable?\r\nIf not shouldn't it expose an interface with just the generalization to work with the constraints collection?\r\nThe question here is, why is the class abstract, externally exposed, and not usable?\n Comment 2: > The question here is, why is the class abstract, externally exposed, and not usable?\r\n\r\nI didn't design or implement this class.  But...\r\n\r\nIt's exposed because derived types UniqueConstraint and ForeignKeyConstraint are exposed, and because APIs then work in terms of the base to support either, e.g. DataTable.Constraints.\r\n\r\nIt's abstract because you're not supposed to instantiate one of these directly, only the derived types, and making it abstract is one way to do that.\r\n\r\nI don't know what you mean about it not being usable.  If you mean not extensible by code external to the assembly, then because it wasn't designed for that.  Not every type that's extended internally needs to support the same level of extensibility externally.  And while you might want that, that would be a separate feature.\r\n\r\nThis type has been this way for many, many.NET releases.\n Comment 3: Thanks Stephen for your insights!\r\nI'm sure that this is not a good design, and don't believe that something being in place for long time makes it good, you just get used to it.\r\nMore over, that is not the intended usage of abstract classes, interfaces serve this purpose, abstract classes have a inherent behavior that child classes must respect.\r\nI still believe that the Constraint class should be exposed as an public interface and the abstract class moved to be internal to the assembly.\n Comment 4: > I still believe that the Constraint class should be exposed as an public interface and the abstract class moved to be internal to the assembly.\r\n\r\nThat would be a big breaking change and is not going to happen.  That was part of what I meant to imply by my \"this type has been this way for many, many.NET releases\" comment, not that \"being in place for long time makes it good.\"\r\n\r\nIf you want to propose and detail an additional extensibility mechanism, you're welcome to do so in a separate issue.\r\n\r\nFor now, I'll consider the question answer.  Thanks for the interest.",
  "Issue title: Add reflection table for Steampipe connections\n Issue body: **Is your feature request related to a problem? Please describe.**\r\nI'd like to be able to get my connection information from tables to use in queries that rely on this information.\r\n\r\n**Describe the solution you'd like**\r\nA table or set of tables that contain my current connection information.\r\n\r\n**Describe alternatives you've considered**\r\nNone at the moment.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n\n Comments: \n Comment 0: this has been [implemented](https://github.com/turbot/steampipe/tree/add_reflection_table_for_Steampipe_connections_505) \r\n\r\nHowever more work is needed on potentially parsing the connection config before insertion\n Comment 1: instead, connection information can be injected into the _ctx column",
  "Issue title: Warning about unexpected neighbors graph\n Issue body: I suspect this issue is here:\r\n\r\nhttps://github.com/theislab/scvelo/blob/1659cc8e00a45fcf87cd80a7013aae5531744613/scvelo/preprocessing/neighbors.py#L313-L325\r\n\r\nDoesn't scanpy now store neighbors in `.obsp`? This occurs if using scanpy to compute neighbors.\n Comments: \n Comment 0: Thanks @adamgayoso. I'll have a look at it ASAP!\n Comment 1: @adamgayoso, which version of scanpy are you using? The latest, i.e. `scanpy=1.8.1`? Or are you working with `scanpy@master`?\r\nCould you also please provide a minimal working example for which the error is thrown? I presume it is `sc.pp.neighbors()` and them some scVelo function checking the neighbors graph?\n Comment 2: Update after briefly discussing this offline: The error is thrown after running the standard pipeline, e.g.\r\n\r\n```python\r\nscv.pp.filter_and_normalize(adata)\r\nscv.pp.moments(adata)\r\nscv.tl.velocity(adata)\r\nscv.tl.velocity_graph(adata)\r\n```\r\n\r\nThe problem comes from supposed duplicate cells, which aren't actual duplicates but only appear to be after filtering.\n Comment 3: Closing this since the current warning already points towards potential issues when subsetting data. Will circle back to it once the corresponding code is being unit tested and refactored.",
  "Issue title: \"jc\" always returns dot in windows.\n Issue body: When using jc command in windows, it always returns dot, and does not enter the sub-directory.\r\n`\r\nC:\\Users\\yd\\Desktop>jc advance\\\r\n.\r\nC:\\Users\\yd\\Desktop>jco a\r\n\r\nArcade Game Clone_zh.zip  advance\\\r\n\r\nC:\\Users\\yd\\Desktop>jco advance\r\n.`\r\n\r\nAnd I do not know how to add the directory into the database. The file \"autojump.txt\" always empty.\r\nHave read \"always return dot #422\", but still do not get the point because the solution is not for Windows.\n Comments: \n Comment 0: I have visited the folder using \"cd\" command, but it still does not work.\r\n\n Comment 1: `.` is returned when there are no matches.\r\n\r\nWhat's the result of running `j -s | grep advance`?\n Comment 2: I am having the same issue, but on macOS Silicon. \r\n\r\nI am installing autojump through zinit:\r\n\r\n```zsh\r\nzinit ice as\"program\" src\"bin/autojump.zsh\" \\\r\n  atclone\"python3./install.py\" \\\r\n  atpull\"%atclone\"\r\nzinit light wting/autojump\r\n```\r\n\r\n![Bildschirmfoto 2021-06-26 um 10 37 30](https://user-images.githubusercontent.com/11534760/123507576-83bcd480-d66a-11eb-954e-a43bee089e26.png)\r\n",
  "Issue title: mosquitto 1.6.9-0mosquitto1~bionic1 in ubuntu bionic PPA not available due to build failure\n Issue body: At this time, mosquitto 1.6.9 is not available from the Ubuntu mosquitto-ppa for bionic (Ubuntu 18.04 LTS). Taking a quick look shows that this appears to be due to a failure in the automated build on that platform:\r\n\r\nhttps://launchpad.net/~mosquitto-dev/+archive/ubuntu/mosquitto-ppa/+packages\r\nhttps://launchpad.net/~mosquitto-dev/+archive/ubuntu/mosquitto-ppa/+build/18793602\r\n\r\nhttps://launchpadlibrarian.net/467539890/buildlog_ubuntu-bionic-amd64.mosquitto_1.6.9-0mosquitto1~bionic1_BUILDING.txt.gz\r\n\r\n```\r\ncc -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,--as-needed -Wl,--dynamic-list=linker.syms mosquitto.o alias_mosq.o bridge.o conf.o conf_includedir.o context.o database.o handle_auth.o handle_connack.o handle_connect.o handle_disconnect.o handle_ping.o handle_pubackcomp.o handle_publish.o handle_pubrec.o handle_pubrel.o handle_suback.o handle_subscribe.o handle_unsuback.o handle_unsubscribe.o logging.o loop.o memory_mosq.o misc_mosq.o net.o net_mosq.o net_mosq_ocsp.o packet_datatypes.o packet_mosq.o property_broker.o property_mosq.o persist_read.o persist_read_v234.o persist_read_v5.o persist_write.o persist_write_v5.o plugin.o read_handle.o security.o security_default.o send_auth.o send_connack.o send_connect.o send_disconnect.o send_mosq.o send_publish.o send_suback.o send_subscribe.o send_unsuback.o send_unsubscribe.o service.o session_expiry.o signals.o subs.o sys_tree.o time_mosq.o tls_mosq.o utf8_mosq.o util_mosq.o util_topic.o websockets.o will_delay.o will_mosq.o -o mosquitto  -ldl -lm -lrt -lwrap -lssl -lcrypto -lsystemd -lanl -lwebsockets \r\nsession_expiry.o: In function `session_expiry__add':\r\n./src/session_expiry.c:77: undefined reference to `DL_INSERT_INORDER'\r\nwill_delay.o: In function `will_delay__add':\r\n./src/will_delay.c:48: undefined reference to `DL_INSERT_INORDER'\r\ncollect2: error: ld returned 1 exit status\r\nMakefile:76: recipe for target'mosquitto' failed\r\nmake[3]: *** [mosquitto] Error 1\r\nmake[3]: Leaving directory '/<<PKGBUILDDIR>>/src'\r\nMakefile:59: recipe for target'mosquitto' failed\r\nmake[2]: *** [mosquitto] Error 2\r\n```\r\n\r\nCould this be related to the 7a5c2d4da5 config.mk WITH_BUNDLED_DEPS change?\r\n(Given that src/deps/utlist.h provides, or used to provide, the DL_INSERT_INORDER definition.)\r\n\n Comments: \n Comment 0: Looks like the same issue for Fedora and CentOS package.\r\n\r\n```bash\r\n[...]\r\n/usr/bin/ld: session_expiry.o: in function `session_expiry__add':\r\n/home/fab/Documents/repos/packages/mosquitto/mosquitto-1.6.9/src/session_expiry.c:77: undefined reference to `DL_INSERT_INORDER'\r\n/usr/bin/ld: will_delay.o: in function `will_delay__add':\r\n/home/fab/Documents/repos/packages/mosquitto/mosquitto-1.6.9/src/will_delay.c:48: undefined reference to `DL_INSERT_INORDER'\r\ncollect2: error: ld returned 1 exit status\r\nmake[1]: *** [Makefile:76: mosquitto] Error 1\r\nmake[1]: Leaving directory '/home/fab/Documents/repos/packages/mosquitto/mosquitto-1.6.9/src'\r\nmake: *** [Makefile:59: mosquitto] Error 2\r\nerror: Bad exit status from /var/tmp/rpm-tmp.XHk9or (%build)\r\n    Bad exit status from /var/tmp/rpm-tmp.XHk9or (%build)\r\n```\n Comment 1: This was fixed a while back, so I'm closing this now.\n Comment 2: very strange, I need to install `uthash` to fix this error.",
  "Issue title: \u7ec6\u8282\u5efa\u8bae\uff1a\u6279\u91cf\u4e0b\u8f7d\u6536\u85cf\u56fe\u7247\u65f6\u80fd\u591f\u9009\u62e9\u5012\u5e8f\u4e0b\u8f7d\n Issue body: \u8fd9\u6837\u7684\u8bdd\uff0c\u67e5\u770b\u65f6\u6309\u4fee\u6539\u65e5\u671f\u5347\u5e8f\u6392\u5217\uff0c\u770b\u5230\u7684\u987a\u5e8f\u5c31\u548c\u6536\u85cf\u65f6\u95f4\u4ece\u65e7\u5230\u65b0\u4e00\u6837\u4e86\uff0c\u65b9\u4fbf\u67e5\u9605\uff0c\u540e\u7eed\u624b\u52a8\u4fdd\u5b58\u56fe\u7247\u65f6\u4e5f\u4e0d\u81f3\u4e8e\u6253\u4e71\u987a\u5e8f\u3002\n Comments: \n Comment 0: \u6309\u6536\u85cf\u65f6\u95f4\u67e5\u770b\u5417\uff0c\u6709\u70b9\u610f\u601d\r\n\u4e0d\u8fc7\u6211\u6ca1\u6709\u8fd9\u4e2a\u9700\u6c42\uff0c\u61d2\u5f97\u505a\u554a\u2026\u2026\u5982\u679c\u6709\u4eba\u80fd\u63d0\u4ea4 pull \u6211\u5c31\u7701\u4e8b\u4e86\r\n\u8fd9\u4e24\u5929\u6253\u7b97\u6539\u4e0b\u4ee3\u7801\u98ce\u683c\u4ec0\u4e48\u7684\uff0c\u5fd9\u5b8c\u4e86\u518d\u8bf4\u5427\u3002\n Comment 1: \u4e0d\u8fc7\u8981\u8bf4\u7684\u8bdd\uff0c\u6211\u8fd8\u662f\u89c9\u5f97\u6309\u6536\u85cf\u987a\u5e8f\u67e5\u770b\u56fe\u7247\u8fd9\u4e2a\u9700\u6c42\u5f88\u5c11\u4eba\u6709\u554a\u3002\u5982\u679c\u662f\u8981\u4fdd\u5b58\u7684\u8bdd\uff0c\u5012\u662f\u53ef\u4ee5\u8bbe\u7f6e\u9875\u6570\uff0c\u53ea\u4e0b\u8f7d\u6700\u8fd1\u65b0\u589e\u7684\u90a3\u51e0\u9875\u6536\u85cf\u3002\n Comment 2: \u8fd9\u4e2a\u529f\u80fd\u5c06\u5f88\u5feb\u4e8e\u4e0b\u4e00\u6b21\u66f4\u65b0\u52a0\u5165\u3002",
  "Issue title: client_credentials and authorization_code cannot be used simultaneously\n Issue body: In `UseSwaggerUI`  calling `OAuthUsePkce` makes the `client_secret` textbox disappear for all flows. It is therefore impossible to use client_credentials (which requires a client_secret) and authorization_code (which requires this field to be absent) at the same time.\n Comments: \n Comment 0: We have same issue. seems its fixed here - https://github.com/swagger-api/swagger-ui/pull/8146",
  "Issue title: cannot resolve path (or pattern) './src/**/*.spec.js' #21\n Issue body: How can fix this? please help..\n Comments: \n Comment 0: You just need to add at least one.spec file under /src. Alternatively, you can disable Mocha. This error occurs when Mocha can't find any tests.\r\n\r\nThus, I'm torn on whether to consider this a bug or a feature. :)\n Comment 1: Thanks Cory.. The slingshot is awesome. I will always use this on my projects instead of gulp. \n Comment 2: I'd like to provide a friendly message when no tests are found, but I haven't found a way to suppress this message. Open to ideas.\n Comment 3: I'm considering adding a check in the build that runs before Mocha. It would look for test files and if none exist, it would stop the build and message to the user to either:\r\na. Add at least one test\r\nb. Disable running tests\r\n\r\nThis way, this error doesn't confuse others. Sound good?\n Comment 4: That would be great. are you using terminal commands on the checking or\nwebpack?\n\nOn 20 February 2016 at 04:37, Cory House <smithwilliam@example.net> wrote:\n\n> I'm considering adding a check in the build that runs before Mocha. It\n> would look for test files and if none exist, it would stop the build and\n> message to the user to either:\n> a. Add at least one test\n> b. Disable running tests\n>\n> This way, this error doesn't confuse others. Sound good?\n>\n> \u2014\n> Reply to this email directly or view it on GitHub\n> <https://github.com/coryhouse/react-slingshot/issues/40#issuecomment-186396045>\n>.\n>\n\n Comment 5: I created PR #86 to fix this. Feedback welcome.\n Comment 6: Decided to leave this as is. See PR #86 for conversation on why. That said, thanks again to @nickytonline for continued support! :+1: \n Comment 7: @freeman29, the PR #86 won't be merged, but the functionality you want is there, so feel free to grab it. \n Comment 8: I'll check it this weekend then I'll give my feedback. Thanks @nickytonline.",
  "Issue title: Allow for oEmbed fallback (using OpenGraph tags)\n Issue body: ## What problem does this address?\r\nCurrently when pasting a link that doesn't support oEmbed embedding, an error is shown, and the option to convert to a normal link is proposed\r\n\r\n<img width=\"655\" alt=\"CleanShot 2022-10-11 at 20 11 45@2x\" src=\"https://user-images.githubusercontent.com/528287/195167899-f03fb41f-2dd0-405c-a4e3-2d56b86b46de.png\">\r\n\r\n## What is your proposed solution?\r\nI like the way Medium handles this. It fetches the OpenGraph tags and makes a nice card. \r\n\r\n<img width=\"770\" alt=\"CleanShot 2022-10-11 at 20 13 04@2x\" src=\"https://user-images.githubusercontent.com/528287/195168071-57282075-ea83-4334-ae4a-a717ef0f3764.png\">\r\n\r\nRight now the embed block calls the oEmbed endpoint (`/wp-json/oembed/1.0/proxy`). It would make sense to call another API endpoint (for example `/wp-json/opengraph/1.0/proxy`) when this fails, which would return the relevant OpenGraph tags (title, description, image) needed to build the card. \r\n\n Comments: \n Comment 0: The core already has an API for parsing the site metadata. Currently, it's used to generate URL details popups. We can probably adopt that into an embed provider.\r\n\r\nI started experimenting with a similar concept a few years ago - https://wordpress.org/plugins/bookmark-card/.\n Comment 1: @Mamaduka thanks for linking to your plugin. It does exactly what I'm talking about.\r\n\r\nIt would be such an improvement to the UX if we could bring something like that to core. ",
  "Issue title: panic analyzing old cluster\n Issue body: <img src=\"https://raw.githubusercontent.com/derailed/popeye/master/assets/popeye.png\" align=\"right\" width=\"100\" height=\"auto\"/>\r\n\r\n<br/>\r\n<br/>\r\n<br/>\r\n\r\n\r\n**Describe the bug**\r\nwhen analyzing my kubernetes cluster, I get a panic. if you can provide some pointers, I'm happy to try and fix this bug so that it works for us.\r\n\r\n```\r\npanic: strings: negative Repeat count\r\n\r\ngoroutine 1 [running]:\r\nstrings.Repeat(0x206ba85, 0x1, 0xfffffffffffffffc, 0xc0006e3d60, 0x3)\r\n        /usr/local/Cellar/go/1.12.1/libexec/src/strings/strings.go:533 +0x5ca\r\ngithub.com/derailed/popeye/internal/report.Write(0x2248c60, 0xc00081e440, 0x1, 0x1, 0xc000f968c0, 0x4f)\r\n        /Users/fernand/go_wk/derailed/src/github.com/derailed/popeye/internal/report/writer.go:81 +0x19c\r\ngithub.com/derailed/popeye/pkg.(*Popeye).printReport(0xc0008bdd40, 0x681c518, 0xc00000e160, 0xc0000db99c, 0x4)\r\n        /Users/fernand/go_wk/derailed/src/github.com/derailed/popeye/pkg/popeye.go:130 +0x7a5\r\ngithub.com/derailed/popeye/pkg.(*Popeye).Sanitize(0xc0008bdd40)\r\n        /Users/fernand/go_wk/derailed/src/github.com/derailed/popeye/pkg/popeye.go:74 +0x4e4\r\ngithub.com/derailed/popeye/cmd.doIt(0x2db09a0, 0x2ddbcd8, 0x0, 0x0)\r\n        /Users/fernand/go_wk/derailed/src/github.com/derailed/popeye/cmd/root.go:56 +0xdf\r\ngithub.com/spf13/cobra.(*Command).execute(0x2db09a0, 0xc0000b2000, 0x0, 0x0, 0x2db09a0, 0xc0000b2000)\r\n        /deniseallen@example.net/command.go:766 +0x2ae\r\ngithub.com/spf13/cobra.(*Command).ExecuteC(0x2db09a0, 0x0, 0x0, 0xc0003e5f88)\r\n        /deniseallen@example.net/command.go:852 +0x2ec\r\ngithub.com/spf13/cobra.(*Command).Execute(...)\r\n        /deniseallen@example.net/command.go:800\r\ngithub.com/derailed/popeye/cmd.Execute()\r\n        /Users/fernand/go_wk/derailed/src/github.com/derailed/popeye/cmd/root.go:43 +0x32\r\nmain.main()\r\n        /Users/fernand/go_wk/derailed/src/github.com/derailed/popeye/main.go:19 +0x20\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. connect to my old cluster\r\n2. run popeye\r\n3. panic\r\n\r\n**Expected behavior**\r\nI get a full report.\r\n\r\n**Versions (please complete the following information):**\r\n - OS: [e.g. OSX] - OSX\r\n - Popeye [e.g. 0.1.0] - 0.1.2\r\n - K8s [e.g. 1.11.0] - 1.8.15\r\n\n Comments: \n Comment 0: @theRealWardo Tx for reporting this and for your help!! \r\n\r\nI think this issue was resolved via @vdesjardins kind PR. \r\nCan you upgrade Popeye and see if you can make it farther?\r\n\r\nClosing for now. Please re-open if that's not the case. Tx!!\n Comment 1: yep works now! thanks!",
  "Issue title: Cannot stage merged changes\n Issue body: ### Description\r\nDuring a rebase I had to merge changes. I cannot stage those changes using the SCM view (clicking the `+` button has no effect).\r\n\r\n### Reproduction Steps\r\n1. Rebase a branch so that changes need to be merged manually\r\n2. Merge those changes\r\n3. Try to stage those changes\r\n\r\n**OS and Theia version:**\r\ntested in gitpod.io\r\n\r\n**Diagnostics:** \r\nthere is no error on the console\n Comments: \n Comment 0: In order to reproduce merge conflict: https://stackoverflow.com/questions/43702944/reproducing-git-merge-conflict-dd",
  "Issue title: SQLite slow after 0.9.2\n Issue body: sqlite is slow after 0.9.2.\n\nIssue is the cache store has bool? useCache = false in some methods instead of bool? useCache = null\n Comments: \n Comment 0: fixed",
  "Issue title: Missing <credits> category\n Issue body: Thanks for your hard work!\r\n\r\nIs it possible to add \"**credits**\" category?  like that we can get tags like \"**actor**\", \"**director**\" etc.\r\n\r\n\r\nThanks again!\n Comments: \n Comment 0: @freearhey I could work on that, because I would also like to add other features such as the programme link. Do we have to edit only scripts/commands/programs/save.js file?\n Comment 1: @mcastellaneta [convertToXMLTV()](https://github.com/freearhey/epg-grabber/blob/16d02ce1fa0df77a48a9bbd3d68be054d6a6cdfa/src/utils.js#L152-L234) function in `epg-grabber`, which is used to generate the resulting XML, should also be updated. That seems to be all there is to do.\n Comment 2: @mcastellaneta TVM for pull your commit, can you add tag `<date />`?\r\n\r\nThanks!\n Comment 3: @MLBStream Do you mean the creation date of the programme?",
  "Issue title: installation issue on Raspbian\n Issue body: when installing Iris on Raspbian I get the following error:\r\n\r\nsudo echo \"mopidy ALL=NOPASSWD: /usr/local/lib/python2.7/dist-packages/mopidy_iris/system.sh\" >> /etc/sudoers\r\nbash: /etc/sudoers: Permission denied\r\n\r\nmust be something related to permissions but cannot figure out what; sudo generally works\n Comments: \n Comment 0: I had the same issue.\r\n\r\nInstead you can do:\r\n`sudo visudo`\r\n\r\nand then paste the line:\r\n`mopidy ALL=NOPASSWD: /usr/local/lib/python2.7/dist-packages/mopidy_iris/system.sh`\n Comment 1: @mathieuhays thanks, your method worked great",
  "Issue title: After renaming a workspace, the panel is not updated until switching back to the workspace\n Issue body: If a workspace is (re)named, the workspace does not change in the panel, and stays \"focused\" (in the panel) when switching away. When switching to one of these workspaces, the applet seems to refresh all of them, reseting the focus and applying the naming.\n\n Comments: \n Comment 0: Yes, it only refreshes the workspace array when you switch workspace. I think there should be some even for rename too. I will look into it.\n Comment 1: Works great now, thanks!",
  "Issue title: Add a new shellmap\n Issue body: The blank snow shellmap really hurts my eyes. Simply changing it to temperate should be good enough for this issue but a proper one could be made too.\r\n\r\nRV has shellmaps of 1st Training Mission and 7th Soviet Mission for a while now, but i think making another one special for OpenRA/RA2 would be better.\n Comments: \n Comment 0: I'd like to keep an empty one since I don't think the extra lag is justified during the testing phase of this mod. We could also just do it like TD. (Note that you can still file a shellmap, I just wouldn't set it in the shellmap category until we want to enable it for a release.)",
  "Issue title: Toooo slow to open (M2 chip)\n Issue body: ### Discord username (optional)\n\n_No response_\n\n### Describe the bug\n\nTooooo slow to open (several minutes)...\n\n### To Reproduce\n\nJust open Warp...\n\n### Expected behaviour\n\nStuck for several minutes.\n\n### Screenshots\n\n<img width=\"1023\" alt=\"image\" src=\"https://user-images.githubusercontent.com/22532925/186061146-287c22c6-494c-4b5f-a2ae-68ac679dc9fa.png\">\n\n### Operating System\n\nMacOS\n\n### OS Version\n\n12.4\n\n### Shell Version\n\nzsh 5.8.1 (x86_64-apple-darwin21.0)\n\n### Warp Version\n\nv0.2116.69.203.115.21.stable_00\n\n### Additional context\n\n_No response_\n\n### Does this block you from using Warp daily?\n\nYes\n\n### Warp Internal (ignore): linear-label:b8107fdf-ba31-488d-b103-d271c89cac3e\n\n_No response_\n Comments: \n Comment 0: Hey @namasikanam, thank you for filling! Is the delay you are seeing related to a window opening or with an actual session starting (e.g. the \"starting zsh...\" text appears for a while)?\r\n\r\nIf it's the latter, are you able to repro with your `zshrc` file commented out? It's possible something in your RC file could be causing the slowness\n Comment 1: Thanks @alokedesai \r\n\r\nBoth the window opening and the actual session starting are slow, the former may cost less than 1min, the latter may cost several minutes.\r\n\r\n[This](https://paste.ubuntu.com/p/zhMs2VpS3H/) is my `zshrc` file.\n Comment 2: Thanks @namasikanam! Would you also be able to provide a video from the moment you launch Warp to the moment the session has fully started to help us debug futher?\n Comment 3: All right, @alokedesai \r\n\r\nhttps://user-images.githubusercontent.com/22532925/186304247-9b899674-edb5-445f-914f-99b0be2796d8.mp4\n Comment 4:![image](https://user-images.githubusercontent.com/12554120/186570632-e41fba30-1bb7-4475-9718-331a1ad57eef.png)\r\nme too, this is my mac, slowly too! how to resolve?\n Comment 5: @namasikanam @qcjackman\r\n\r\nOur team is prioritizing fixing this. Would you be willing to share your dotfiles to help us reproduce the slowness? If so, please remove any personal information and email them to [`keithbaird@example.net`](mailto:keithbaird@example.net?subject=slow profile&body=slow rc files.)\r\n\r\nconfig file locations by shell are:\r\n\r\nBash = `~/.bashrc` and `~/.bash_profile`\r\nZsh = `~/.zshrc` and `~/.zprofile`\n Comment 6: Experiencing the same thing on my M2 MacBook Air (also my first time using Warp). I added `ZDOTDIR=/` in my `~/.zshenv` as guided in the manual but still, every action from starting up the app is insanely slow and triggers the spinning wheel every time, notably in the preferences panel. The only exception is the terminal area, which runs fairly smoothly when I enter and execute commands.\n Comment 7: Me to.\r\nVery slow\r\n<img width=\"233\" alt=\"image\" src=\"https://user-images.githubusercontent.com/11990976/189264982-d311f531-b1b7-445c-86e9-4d45ff1c0d3c.png\">\r\n\n Comment 8: @namasikanam recent update has resolved a lot of slow startup issues, are you still experiencing the same as of the new build v0.2116.69.203.115.56?\n Comment 9: > @namasikanam recent update has resolved a lot of slow startup issues, are you still experiencing the same as of the new build `v0.2116.69.203.115.56`?\r\n\r\nThanks for your work. Personally, I'm still having the same issues as before. Could it possibly be a problem with Chinese language support? As far as I can tell, all the users who are reporting slowness in this issue are using Simplified Chinese as their OS's display language, me included.\n Comment 10: Thanks @dannyneira \r\n\r\nIt starts a little quicklier for me (~1min), but still not at a tolerable speed.\n Comment 11: @songxianj That's an interesting theory--as a followup what country are you (and other users who are experiencing this issue) based in? If it's all China, there also could be a network request hanging for some reason\n Comment 12: > @songxianj That's an interesting theory--as a followup what country are you (and other users who are experiencing this issue) based in? If it's all China, there also could be a network request hanging for some reason\r\n\r\nThat could be a reason why. I am indeed based in China, for your information. I also have a VPN/proxy enabled at all times to connect faster to servers in other countries.\n Comment 13: Does this repro if you turn your wifi off? \n Comment 14: > Does this repro if you turn your wifi off?\r\n\r\nNo! It is indeed the reason of the Great Firewall in China!\n Comment 15: @alokedesai Is it a way to close automatic network connecting in settings of Warp?\n Comment 16: There isn't unfortunately. The fact that the Warp is hanging based on a network request hanging is definitely an issue on our end. \r\n\r\nDo you see anything in the Mac console app for Warp when the hang occurs? See [here](https://macpaw.com/how-to/use-mac-console-app#:~:text=Here%27s%20how%20to%20open%20Console,in%20to%20your%20Apple%20ID.) for details on how to open the Console app. Once it's open, click on \"Log reports\" and then search for \"warp.log\". \n Comment 17: 02:06:52 [ERROR] Couldn't download & process file /Users/mac/Library/Application Support/dev.warp.Warp-Stable/AItbvmnKHwoKd73RYsI-gw_TnwEZDKzMKNTXZrKcQQZX=s96-c, error: reqwest38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5rror { kind: Request, url: Url { scheme: \"https\", cannot_be_a_base: false, username: \"\", password: None, host: Some(Domain(\"**_lh3.googleusercontent.com_**\")), port: None, path: \"/a/AItbvmnKHwoKd73RYsI-gw_TnwEZDKzMKNTXZrKcQQZX=s96-c\", query: None, fragment: None }, source: TimedOut } -- **The Great Firewall in China!**\n Comment 18: Thanks @GankLi! We'll get this fixed\n Comment 19: log detail \r\n01:52:54 [INFO] window resized\r\n01:52:54 [INFO] dispatching global action for workspace:save_app\r\n01:52:54 [WARN] Expected to have session for session ID None, but doesn't exist\r\n01:52:55 [WARN] Failed to record time \"sample value too large\"\r\n01:53:24 [ERROR] Couldn't download & process file /Users/xukaixuan/Library/Application Support/dev.warp.Warp-Stable/AFdZucp_isGUeTYxFnkUmzapY_Fj9HOyTRXSIC05v-h0fw=s96-c, error: reqwest38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5rror { kind: Request, url: Url { scheme: \"https\", cannot_be_a_base: false, username: \"\", password: None, host: Some(Domain(\"lh3.googleusercontent.com\")), port: None, path: \"/a-/AFdZucp_isGUeTYxFnkUmzapY_Fj9HOyTRXSIC05v-h0fw=s96-c\", query: None, fragment: None }, source: TimedOut }\r\n01",
  "Issue title: Triggers go into BLOCKED state after upgrading to Quartz 3.x\n Issue body: Quartz Version: 3.0.2\r\n\r\nIn the prior version of Quartz that we were using (2.6.1), our application created jobs that were picked up and processed by a Quartz scheduler that we have running as a service.\r\nNow the trigger is going into the \"BLOCKED\" state and never gets executed.\r\nWe followed the migration guide to upgrade our code to Quartz v3. For our jobs, we left the original code and return Task.CompletedTask as suggested.\r\nThe messages from the Quartz jobs do not show any errors.\r\nSee below the properties that we use to configure the scheduler.\r\n\r\nproperties[\"quartz.scheduler.instanceId\"] = \"AUTO\";\r\nproperties[\"quartz.threadPool.threadCount\"] = 10;\r\nproperties[\"quartz.jobStore.type\"] = \"Quartz.Impl.AdoJobStore.JobStoreTX, Quartz\";\r\nproperties[\"quartz.serializer.type\"] = \"binary\";\r\nproperties[\"quartz.jobStore.driverDelegateType\"] = \"Quartz.Impl.AdoJobStore.SqlServerDelegate, Quartz\";\r\nproperties[\"quartz.jobStore.useProperties\"] = \"true\";\r\nproperties[\"quartz.jobStore.dataSource\"] = dataSource;\r\nproperties[\"quartz.jobStore.tablePrefix\"] = \"QRTZ_\";\r\nproperties[\"quartz.jobStore.clustered\"] = \"true\";\r\nproperties[$\"quartz.dataSource.{dataSource}.connectionString\"] = connectionStringBuilder.ConnectionString;\r\nproperties[$\"quartz.dataSource.{dataSource}.provider\"] = \"SqlServer\";\r\n\n Comments: \n Comment 0: Are you using a custom JobListener?\n Comment 1: Yes, I have a JobListener that logs different events in log4net (e.g. job about to execute or completed), then return Task.CompletedTask... that\u2019s it. Is it related to the issue?\n Comment 2: I had something similar and in my case my code in the JobListener was throwing an exception that prevented QuartzNet from removing the Job from the Executing jobs list.\n Comment 3: Ok, I figured out the problem. It was actually in a TriggerListener that we implemented. The Veto Execution had been implemented like this:\r\n`        public Task<bool> VetoJobExecution(ITrigger trigger, IJobExecutionContext context, CancellationToken cancellationToken = new CancellationToken())\r\n        {\r\n            return new Task<bool>(() => false);\r\n        }\r\n`\r\n\r\nAn this is problematic because that Task is never getting started so things get blocked.\r\nI changed the implementation to the code below and that solved the problem\r\n`        public Task<bool> VetoJobExecution(ITrigger trigger, IJobExecutionContext context, CancellationToken cancellationToken = new CancellationToken())\r\n        {\r\n            return Task.FromResult(false);\r\n        }\r\n`\r\n\r\nThanks for pointing me in the right direction @Sicos1977 ",
  "Issue title: Lens 5 does not start if shell autostarts tmux\n Issue body: **Describe the bug**\r\nLens 5 does not start\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Use ZSH with oh my zsh tmux plugin and `ZSH_TMUX_AUTOSTART=true`\r\n2. Launch Lens\r\n3. Lens is stuck on loading window\r\n\r\n**Expected behavior**\r\nLens will launch\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/6400093/124693498-e6dc2000-df22-11eb-9776-c78ccf3ea7bf.png)\r\n\r\n**Environment (please complete the following information):**\r\n- Lens Version: 5.0.2\r\n- OS: macOS\r\n- Installation method: DMG\r\n\r\n**Logs:**\r\nWhen you run the application executable from command line you will see some logging output. Please paste them here:\r\n```\r\ninfo: \ud83d\udcdf Setting Lens as protocol client for lens://\r\ninfo: \ud83d\udcdf Protocol client register succeeded \u2705\r\ninfo: \ud83d\ude80 Starting Lens from \"/Users/omja/Library/Application Support/Lens\"\r\ninfo: \ud83d\udc1a Syncing shell environment\r\nerror: shellEnv: TypeError: Cannot read property'split' of undefined\r\ninfo: \ud83d\udcbe Loading stores\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-user-store.json\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-cluster-store.json\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-hotbar-store.json\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-extensions.json\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-filesystem-provisioner-store.json\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-weblink-store.json\r\ninfo: \ud83d\udd0c Starting LensProxy\r\ninfo: [LENS-PROXY]: Proxy server has jonathan54@example.com:62668\r\ninfo: \ud83d\udd0e Testing LensProxy connection...\r\ninfo: \u26a1 LensProxy connection OK\r\ninfo: \ud83d\udda5\ufe0f  Starting WindowManager\r\ninfo: \ud83e\udde9 Initializing extensions\r\ninfo: [EXTENSION-DISCOVERY] loading extensions from /Users/omja/Library/Application Support/Lens\r\ninfo: [EXTENSION-INSTALLER] installing dependencies at /Users/omja/Library/Application Support/Lens\r\ninfo: [WINDOW-MANAGER]:\u00a0Loading Main window from url: http://localhost:62668...\r\ninfo: [EXTENSION-INSTALLER] dependencies installed at /Users/omja/Library/Application Support/Lens\r\ninfo: [EXTENSION-DISCOVERY] watching extension add/remove in /Users/omja/.k8slens/extensions\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/extension-store/lenscloud-lens-extension/auth-token-store.json\r\nerror: [EXTENSIONS-LOADER]: can't load main for \"lens-telemetry\": TypeError: Cannot create a second singleton while creating a first {\"extension\":{\"id\":\"/Users/omja/Library/Application Support/Lens/node_modules/lens-telemetry/package.json\",\"absolutePath\":\"/Applications/Lens.app/Contents/Resources/extensions/telemetry/lens-telemetry-5.0.2-latest.20210705.2.tgz\",\"manifestPath\":\"/Users/omja/Library/Application Support/Lens/node_modules/lens-telemetry/package.json\",\"manifest\":{\"name\":\"lens-telemetry\",\"version\":\"5.0.2-latest.20210705.2\",\"description\":\"Lens IDE telemetry\",\"main\":\"dist/main.js\",\"renderer\":\"dist/renderer.js\",\"lens\":{\"metadata\":{},\"styles\":[]},\"scripts\":{\"build\":\"webpack -p && npm pack\",\"dev\":\"webpack --watch\",\"test\":\"jest --passWithNoTests --env=jsdom src $@\"},\"files\":[\"dist/**/*\"],\"devDependencies\":{\"@k8slens/extensions\":\"file:../../src/extensions/npm/extensions\",\"@types/analytics-node\":\"^3.1.3\",\"@types/node\":\"^14.14.14\",\"@types/react\":\"^17.0.0\",\"@types/universal-analytics\":\"^0.4.4\",\"analytics-node\":\"^3.4.0-beta.3\",\"conf\":\"^7.1.2\",\"jest\":\"^26.6.3\",\"mobx\":\"^6.3.2\",\"mobx-react\":\"^7.1.0\",\"node-machine-id\":\"^1.1.12\",\"react\":\"^16.13.1\",\"ts-loader\":\"^8.0.4\",\"typescript\":\"^4.0.3\",\"universal-analytics\":\"^0.4.23\",\"webpack\":\"^4.44.2\",\"webpack-cli\":\"^3.3.11\"}},\"isBundled\":true,\"isEnabled\":true,\"isCompatible\":true}}\r\nerror: [EXTENSION]: failed to activate jonathan54@example.com: Error: [MobX] No annotations were passed to makeObservable, but no decorated members have been found either\r\ninfo: [EXTENSION]: enabled jonathan54@example.com\r\nerror: [EXTENSION]: failed to activate jonathan54@example.com: Error: Error while obtaining machine id: Error: Command failed: ioreg -rd1 -c IOPlatformExpertDevice\r\n/bin/sh: ioreg: command not found\r\n\r\n    at ChildProcess.exithandler (child_process.js:304:12)\r\n    at ChildProcess.emit (events.js:223:5)\r\n    at maybeClose (internal/child_process.js:1021:16)\r\n    at Socket.<anonymous> (internal/child_process.js:430:11)\r\n    at Socket.emit (events.js:223:5)\r\n    at Pipe.<anonymous> (net.js:664:12)\r\ninfo: [WINDOW-MANAGER]: Main window loaded\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-user-store.json\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-cluster-store.json\r\ninfo: [CLUSTER-STORE] requesting initial state sync\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-hotbar-store.json\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-extensions.json\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-filesystem-provisioner-store.json\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/lens-weblink-store.json\r\ninfo: [CLUSTER-STORE] start to listen (1)\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/extension-store/lenscloud-lens-extension/auth-token-store.json\r\ninfo: [STORE]: LOADED from /Users/omja/Library/Application Support/Lens/extension-store/lens-survey/preferences-store.json\r\ninfo: [EXTENSION]: enabled jonathan54@example.com\r\ninfo: [EXTENSION]: enabled jonathan54@example.com\r\ninfo: [EXTENSION]: enabled jonathan54@example.com\r\ninfo: [EXTENSION]: enabled jonathan54@example.com\r\nerror: [EXTENSION]: failed to activate jonathan54@example.com: TypeError: Cannot create a second singleton while creating a first\r\nerror: [EXTENSION]: failed to activate jonathan54@example.com: Error: Error while obtaining machine id: Error: Command failed: ioreg -rd1 -c IOPlatformExpertDevice\r\n/bin/sh: ioreg: command not found\r\n\r\n    at ChildProcess.exithandler (child_process.js:304:12)\r\n    at ChildProcess",
  "Issue title: AutoSave doesn't work\n Issue body: [X]\r\n\r\nAutoSave doesn't work even though I have check marked 'enabled' check button.\r\n\r\n\r\n\r\n**Expected behavior:**AutoSave should work.\r\n\r\n**Actual behavior:** AutoSave doesn't work.\r\n\r\n**Reproduces how often:**100%\r\n\r\nAtom Version: 1.15.0\r\n`apm` Version: 1.15.3\r\n\r\n\r\n\n Comments: \n Comment 0: @srseven As @50Wliu pointed out in https://github.com/atom/atom/issues/14153, we require the issue template to be filled out. One of the requirements is a list of steps to reproduce the problem, which you haven't included. From the meager information that you have included, we cannot reproduce the problem. If you want us to help you with the problem you're having, you'll have to give us more information.\r\n\r\nWe consider repeatedly opening issues with a lack of information like this to be a violation of the [Atom Code of Conduct](https://github.com/atom/atom/blob/master/CODE_OF_CONDUCT.md) as it is considered harassment. You may consider this an official warning.\n Comment 1: This issue has been automatically locked since there has not been any recent activity after it was closed. If you can still reproduce this issue in [Safe Mode](https://flight-manual.atom.io/hacking-atom/sections/debugging/#using-safe-mode) then please open a new issue and fill out [the entire issue template](https://github.com/atom/atom/blob/master/ISSUE_TEMPLATE.md) to ensure that we have enough information to address your issue. Thanks!\n",
  "Issue title: Symbols Max Items Computed doesn't work for 0\n Issue body: If `xml.symbols.maxItemsComputed` is set to 0, then all the symbols are still computed.\n Comments: \n Comment 0: The default value the server uses if no settings are passed to it is 0. This means no symbols would be shown in the clients that don't send a default configuration to LemMinX. Is this a good default, or should I make 5000 the default on the server side?",
  "Issue title: Suggestion: mention delayed effect of socket option setting in HWM discussion\n Issue body: It took me a good while to figure out that I was using the HWM wrong by attempting to set it after binding/connecting. It is mentioned in the libzmq API documentation but not in the docs for the bindings I was using (see zeromq/pyzmq#663 for rectification of that issue). However, the discussion of high water marks and advice about when and how to set them seems like a good place to mention that they should be set pre-bind/pre-connect. I can submit a pull request if that is desirable.\n\n Comments: \n Comment 0: Sure, go ahead.\nOn Apr 11, 2015 8:32 AM, \"David Warde-Farley\" nhuang@example.org\nwrote:\n\n> It took me a good while to figure out that I was using the HWM wrong by\n> attempting to set it after binding/connecting. It is mentioned in the\n> libzmq API documentation but not in the docs for the bindings I was using\n> (see zeromq/pyzmq#663 https://github.com/zeromq/pyzmq/pull/663 for\n> rectification of that issue). However, the discussion of high water marks\n> and advice about when and how to set them seems like a good place to\n> mention that they should be set pre-bind/pre-connect. I can submit a pull\n> request if that is desirable.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/imatix/zguide/issues/546.\n",
  "Issue title: Table name is wrong when it is pluralized.\n Issue body: Table name is not pluralized  properly when model name end with \"y\" like that \r\ncategory is become categorys which is wrong it will become categories. So please consider it is a bug and fix this in next reales. \n Comments: \n Comment 0: this issue has been raised #48 \r\n\r\nMy current work around is using the `tableName` property.\n Comment 1: @M1chaelTran Thanks for reply.",
  "Issue title: Still image instead of video at https://replay.lsm.lv/lv/tiesraide/ltv1\n Issue body: <!-- \r\nNote: If you're a website owner that has been specifically targeted, fix the site before reporting. \r\nRemove revolving ad servers, popup ads, adblock countering etc. Only then will this request be reviewed. -->\r\n\r\n<!-- Any additions, changes or removals is at the Authors discretion. \r\nYou're free to counterargue (to a certain point) if you disagree with the decision. \r\nTo avoid being banned, don't constantly re-open or create new (related) issue reports.\r\n-->\r\n\r\n<!-- Just include the website URL in the Title line of this issue report -->\r\n\r\n### List the website(s) you're having issues:\r\n`https://replay.lsm.lv/lv/tiesraide/ltv1`\r\n<!-- URL(s) for issue on a specific site are **mandatory** -->\r\n<!-- To prevent tracking, wrap the website URL in a Code tag please. **mandatory** -->\r\n\r\n### What happens?\r\nStill image instead of video.\r\n<!-- Just a desciption of the issue when you visit the site. Or steps on reproducing this  -->\r\n\r\n### List Subscriptions you're using:\r\nOnly EasyList\r\n<!-- Which adblock lists are you're using? -->\r\n\r\n### Your settings\r\n- OS/version: MacOS Mojave 10.14.6 (18G103)\r\n- Browser/version: Firefox 70.0.0 (64-bit)\r\n- Adblock Extension/version: uBlock Origin v1.23.0\r\n\r\n### Other details:\r\n\r\n<!-- If you suspect certain filters (this helps spending time to debug it manually).\r\nIf you have a screen shot of the issue or advert, this will help to highlight it. -->\r\n\n Comments: \n Comment 0: Try using **Latvian List**:\r\n`https://notabug.org/latvian-list/adblock-latvian/`\n Comment 1: Then report the issue here:\r\n`https://notabug.org/latvian-list/adblock-latvian/issues/`\n Comment 2: But rules, that block playing video are only inside EasyList, not in Latvian EasyList.\r\nPlease, please explain to me, why should I write to them, if Standard EasyList does block playing.\r\nI can't figure out the logic.\n Comment 3: Video issues often requires rather advanced fixes.\r\nTherefore, site-specific rules, required for non-English pages, are usually handled by regional filters.\r\n\r\nLike stated @ `https://notabug.org/latvian-list/adblock-latvian#latvian-list`:\r\n\r\n> The Latvian List is for use with EasyList and EasyPrivacy.\r\n\r\n..But of course, you can wait and see if someone adds a fix in EasyList too. :)\n Comment 4: Created a bug: https://notabug.org/latvian-list/adblock-latvian/issues/9",
  "Issue title: Incoming calls from PTSN to Call Queues are silent.\n Issue body: When we receieve phone calls from the PTSN, and we answer it from the Call Queue we will be unable to hear the person on the other end but they can hear us.\r\n\r\nWe've got a few tickets opened with O365 support at the moment, but I'm pretty sure it's a bug and not a configuration issue as it's happening on Teams Only and Islands.\n Comments: \n Comment 0: Quick note, on iOS you can turn speaker off and on as a work around.\r\n\r\nThis does not work on Android.\n Comment 1: @JoshMajeno - This issue has been fixed. Could you please try this once at your end and confirm?",
  "Issue title: Correctly format print in 'python/svm_training.py'\n Issue body: We will replace all generic print statements within `svm_training.py` with an implementation of the following style:\n\n``` python\nprint json.dumps({'key1':'val1'}, separators=(',', ': '))\n```\n\n Comments: \n Comment 0: We accidentally used _php_ variable notation for `$msg`, which should be changed to `msg`.\n",
  "Issue title: Outdated cask: boxer\n Issue body: Outdated cask: [`boxer`](https://github.com/caskroom/homebrew-cask/blob/master/Casks/boxer.rb).\n\nInfo:\n- version: `1.3.2-20120713`.\n- appcast url: http://boxerapp.com/appcast.\n\n Comments: \n Comment 0: Closing in favour of #19045.",
  "Issue title: [stable/lamp] Manually preparing the webroot and database fails\n Issue body: \r\n**Is this a request for help?**: I think so.\r\n\r\n---\r\n\r\n**Version of Helm and Kubernetes**: v1.13.4\r\n\r\n\r\n**Which chart**: lamp\r\n\r\n\r\n**What happened**:\r\n\r\nAs soon as i set init.manually.enabled to true i get:\r\n\r\n`\r\nError: YAML parse error on lamp/templates/deployment.yaml: error converting YAML to JSON: yaml: line 50: did not find expected key\r\n`\r\n\r\n**What you expected to happen**:\r\n\r\nChart installs and i have a container for manually init.\r\n\r\nDo I need to set another value?\r\n\r\nthanks and cheers\n Comments: \n Comment 0: This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Any further update will cause the issue/pull request to no longer be considered stale. Thank you for your contributions.\n\n Comment 1: This issue is being automatically closed due to inactivity.\n\n Comment 2: /reopen",
  "Issue title: Assigning operator to DAG via bitwise composition does not pickup default args\n Issue body: \r\n\r\nTicket was created 17/Feb/17 02:58\r\n\r\n**Description**\r\n\r\nThis is only the case when the operator does not specify dag=dag and is not initialized within a DAG's context manager (due to https://github.com/apache/incubator-airflow/blob/fb0c5775cda4f84c07d8d5c0e6277fc387c172e6/airflow/utils/decorators.py#L50)\r\n\r\nExample:\r\n\r\n\r\ndefault_args = {\r\n    'owner': 'airflow', \r\n   'start_date': datetime(2017, 2, 1)\r\n}\r\ndag = DAG('my_dag', default_args=default_args)\r\ndummy = DummyOperator(task_id='dummy')\r\n\r\ndag >> dummy\r\n\r\n\r\n\r\nThis will raise a Task is missing the start_date parameter. I think this should probably be allowed because I assume the purpose of supporting dag >> op was to allow delayed assignment of an operator to a DAG. \r\n\r\nI believe to fix this, on assignment, we would need to go back and go through dag.default_args to see if any of those attrs weren't explicitly set on task...not the cleanest.\r\n\r\n**Use case / motivation**\r\n\r\n**Related Issues**\r\n\r\nMoved here from https://issues.apache.org/jira/browse/AIRFLOW-883\n Comments: \n Comment 0: @ashb Haven't you ever fixed it?\n Comment 1: @mik-laj I had most of a solution in #5598, the question was if we want to support it at all or drop bitshifting dags in 2.0. I think that was what we decided on instead?",
  "Issue title: Fix / tidy / consolidate MCMC code\n Issue body: I've been having a look at the MCMC code in Breeze, and it seems like it could do with some tidying up. There are currently two separate implementations, which is confusing, neither of them are well-documented, and currently only one of them actually works correctly.\n\nWithin stats.distributions there is a MarkovChain object containing some Kernel functionality, and metropolisHastings code. The metropolisHastings kernel contains bugs which lead to incorrect output. I guess this means that no one has actually ever used this code. This is obviously a problem, requiring deleting, deprecating or fixing (it shouldn't be that difficult to fix).\n\nCompletely separate to this, there is breeze.stats.mcmc which also contains functions for carrying out Metropolis Hastings sampling. In some ways I prefer the MarkovChain API, but to be fair the code in stats.mcmc does appear to give correct output for the one example that I've tried...\n\nBoth implementations could be improved. eg. both work with raw acceptance ratios, which makes them very vulnerable to numerical underflow. I'd be happy to help tidy things up, but I wondered if there was any kind of plan for how to consolidate things.\n\n Comments: \n Comment 0: I wrote the MarkovChain code in like 2009, so it's really old and I knew much less then. The newer stuff is from @stucchio I think. \r\n\r\nI'm happy to consider pretty much anything. I'm especially interested in more or less declarative/functional APIs that let you compose big models easily (e.g. should handle a gibbs sampler for LDA) \r\n\r\nYou might look at Factorie or Wolfe for inspiration.",
  "Issue title: v116.69.203.115: REVERSE_AHI_ROLL wrongly implemented\n Issue body: hello\r\n\r\nin screen.ino v116.69.203.115 there is this mistake\r\n\r\n#if defined REVERSE_AHI_ROLL\r\n   pitchAngle = -pitchAngle;   <== should be: rollAngle = -rollAngle;\r\n#endif //REVERSE_AHI_ROLL\r\n\r\nregards\n Comments: \n Comment 0: Hi - thanks for pointing this out. I guess it has never been used!\r\n\r\nIt is now updated in master.\r\n Thanks again!\n Comment 1: Available in test release 116.69.203.115\r\n\r\nWill also be in next full release\r\n\r\nThanks again",
  "Issue title: Support Nim syntax highlight\n Issue body: [Nim](https://nim-lang.org/) is a programming language with about 5k stars. I want to be supported it.\n Comments: \n Comment 0: To do that, write a CodeMirror mode and distribute it separately, on npm. We are not adding any new modes to the main distribution.\n Comment 1: Doesn't seem there's already one in existence at this point :/",
  "Issue title: Validation of Sub Schemas, contained in an array, throws an error.\n Issue body: I am getting the following error message (below) when trying to update a collection, which contains a subschema defined in an array (see model). I am using v3.8.12 of Mongoose.\n\nError Message:\n\n```\nTypeError: Object #<Object> has no method 'validate'\n  at /Users/benstaker/workspace/htdocs/bigtop/api-2/node_modules/mongoose/lib/schema/documentarray.js:95:13\n  at /Users/benstaker/workspace/htdocs/bigtop/api-2/node_modules/mongoose/lib/schema/documentarray.js:103:9\n  at DocumentArray.SchemaType.doValidate (/Users/benstaker/workspace/htdocs/bigtop/api-2/node_modules/mongoose/lib/schematype.js:603:22)\n  at DocumentArray.doValidate (/Users/benstaker/workspace/htdocs/bigtop/api-2/node_modules/mongoose/lib/schema/documentarray.js:73:35)\n  at /Users/benstaker/workspace/htdocs/bigtop/api-2/node_modules/mongoose/lib/document.js:956:9\n  at process._tickDomainCallback (node.js:459:13)\n```\n\nModel:\n\n```\nvar MediaItem = new Schema({\n  // Link to wrap the media in\n  link: { type: String, default: '' },\n\n  // Provider of the media, i.e.: YouTube, Cloudinary, etc\n  provider: {\n    name: { type: String, default: '' },\n    other: []\n  },\n\n  // Source url of the media\n  source: { type: String, default: '' },\n\n  // Size of the media in bytes\n  filesize: { type: Number, default: 0 },\n\n  // Format, i.e.: JPEG, PNG, etc\n  format: { type: String, default: '' },\n\n  // Filename, the original filename the user uploaded\n  filename: { type: String, default: '' },\n\n  // Resolution in pixels\n  resolution: {\n    height: { type: Number, default: 0 },\n    width: { type: Number, default: 0 }\n  }\n});\n\nvar Media = new Schema({\n  // Details regarding the media\n  details: {\n    // User ID\n    user: { type: String },\n\n    // Account ID\n    account: { type: String },\n\n    // Apps using this media item\n    apps: [ { type: String } ],\n\n    // Type of media, i.e.: Image, Video, Audio, etc\n    type: { type: String, required: true },\n\n    // Main title, default to filename\n    title: { type: String, default: 'Loading...', required: true },\n\n    // Alternative text\n    alt: { type: String, default: '' },\n\n    // Global URL, i.e. for a slideshow\n    globalLink: { type: String, default: '' },\n\n    // Alignment of the media, i.e.: left, center, right\n    alignment: { type: String, default: 'left' },\n\n    // How the media should fit, i.e.: original, crop, scale\n    fit: { type: String, default:'scale' },\n\n    // Background options\n    background: {\n      // Position of the background, i.e. top-left\n      position: { type: String, default: 'top left' },\n\n      // Whether to repeat the background, i.e. no-repeat\n      repeat: { type: String, default:'repeat' }\n    },\n\n    // Image quality\n    quality: { type: Number, default: 80 },\n\n    // Slideshow configuration\n    slideshow: {\n      animation: {\n        // Type of the animation, i.e.: Swipe Left\n        type: { type: String, default:'swipe-left' },\n\n        // Speed of animation, i.e. slow, medium, fast\n        speed: { type: String, default:'slow' }\n      },\n\n      // Whether to display the pager and arrows\n      pagerAndArrows: { type: Boolean, default: false }\n    },\n\n    // Video/audio player options\n    player: {\n      // Whether to autoplay the media\n      autoplay: { type: Boolean, default: false },\n\n      // Whether it should loop through the media, i.e. replay.\n      loop: { type: Boolean, default: false },\n\n      // Whether to show the media controls, i.e. play/pause\n      showControls: { type: Boolean, default: false }\n    },\n\n    originalHeight: { type: Number, default: 0 },\n    originalWidth: { type: Number, default: 0 }\n  },\n\n  // Array of media items\n  items: [MediaItem]\n},\n{\n    toObject: { virtuals: true },\n    toJSON: { virtuals: true }\n});\n```\n\nValidate call:\n\n```\nschema.statics.updateWithValidation = function (id, updates, callback) {\n  var self = this;\n\n  self.findOne({ _id: id }, function (err, doc) {\n    if (err) return callback(err);\n    if (!doc) {\n      return callback(new Error('Could not update document, document not found.'));\n    }\n\n    // Remove mongoose properties\n    delete updates._id;\n    delete updates.id;\n    delete updates.__v;\n\n    // Merge updates into document (lodash)\n    _.merge(doc, updates);\n\n    // Validate the document\n    // outputs: 'validating document: *ID* function'\n    console.log('validating document: ', doc._id, typeof doc.validate);\n    doc.validate(function (err) {\n      if (err) {\n        console.log('error!');\n        return callback(err);\n      }\n\n      // Update the document\n      self.update(\n        { _id: id },\n        { $set: updates },\n        {},\n        function (err, affected) {\n          if (err) return callback(err);\n          return callback(err, doc.toObject());\n        }\n      );\n    });\n  });\n};\n```\n\n Comments: \n Comment 0: Updating to version v3.8.14 seems to have fixed the issue?\n\n Comment 1: Hmm interesting. Well, glad its fixed :)\n",
  "Issue title: option extent type in layer XYZ. \n Issue body: I found a minor bug.\r\nThe extent option in layer/XYZ was tested as follow.\r\nextent: [A,B,C,D] ----> not ok\r\nextent: [[A,B],[C,D]] -----> ok\r\n\r\nThe extent option in others(Globe, terrain..) was ok in all of two types.    \n Comments: \n Comment 0: I think it should be both available signatures.",
  "Issue title: How to pass in multiple values for a single argument\n Issue body: Hi there, could please tell me how to use your library to make the follow query?\r\n\r\n```\r\n{\r\n  nodes(ids: [\"gid://shopify/Product/123\", \"gid://shopify/Product/456\"]) {\r\n   ...on Product {\r\n      title\r\n    }\r\n  }\r\n}\r\n```\n Comments: \n Comment 0: Hello,\r\nI have been working on a couple of new features over the past week, one of them is to enable array and object filters. I'm merging these features tonight, will update you on how to do this as soon as that's done.\n Comment 1: @albeethekid That's how you can pass multiple values for a single argument:\r\n$query = (new Query('nodes'))\r\n    ->setArguments(['gid' => ['gid://shopify/Product/123', 'gid://shopify/Product/456']])\r\n    );\r\n\r\nPlease refer to the update README for more:\r\nhttps://github.com/mghoneimy/php-graphql-client#query-example-query-with-array-argument\n Comment 2: Really appreciate you adding that feature so quickly. And thank you for creating this library! ",
  "Issue title: Unable to start service because of FlutterBleLib\n Issue body: You used       \r\n ```\r\nfinal FlutterBleLibPlugin plugin = new FlutterBleLibPlugin(registrar.activity().getApplicationContext());\r\n ```\r\nso when i start service from a broadcast (in my case geolocation via geofencing) i do:\r\n ```\r\nsBackgroundFlutterView = FlutterNativeView(context, true)\r\nval registry = sBackgroundFlutterView!!.pluginRegistry\r\nsPluginRegistrantCallback.registerWith(registry)\r\n```\r\nbut this cause a NullPointerException because activity is null\r\n\r\nthere's a bettery way to create the plugin? or a better way to load plugins from service?\n Comments: \n Comment 0: Hi @lettierimarco!\r\n\r\nI've changed the way we're obtaining context. I don't have a ready-to-use example for your use case, so could you test it for me?\r\n\r\nHere's how to add a dependency to a git branch\r\nhttps://flutter.dev/docs/development/packages-and-plugins/using-packages#dependencies-on-unpublished-packages\r\nhttps://dart.dev/tools/pub/dependencies#git-packages\r\n\r\nAnd this is the branch: `fix/365-unable-to-start-from-service`\n Comment 1: still null\r\n`     Caused by: java.lang.NullPointerException: Attempt to invoke virtual method 'android.content.Context android.app.Activity.getApplicationContext()' on a null object reference\r\n`\n Comment 2: Thanks, it works, why don't do a release?\n Comment 3: Wanted to make sure it works first. ;) We should release new version this or next week.\n Comment 4: Version 2.1.0 with fix has just been released.",
  "Issue title: Arc-DarkerTransparent gone from kvantummanager after updte\n Issue body: This morning I received an update via apt (KDE Neon here) and the Arc Darker Transparent is now missing from the kvantum manager.\r\n\r\nIs there something wrong in my installation?\r\nI installed the them via apt install arc-kde\n Comments: \n Comment 0: https://github.com/PapirusDevelopmentTeam/arc-kde/issues/59\n Comment 1: @Maxiride Check out [this fork](https://github.com/giogziro95/arc-kde). I won't be updating it frequently, but, at least, it's usable.\n Comment 2: \r\n\r\n@varlesh There's an issue I'm having with the older version... I forked your repo reverted to e06279795dc92c02d8431c263d93d798c9acedd5, and updated the scripts as needed, but the text fields on the desktop theme have blue backgrounds:\r\n\r\n![Krunner](https://user-images.githubusercontent.com/2781117/30272200-681d943e-9704-11e7-9bc6-6ce86e0d974f.png)\r\n\r\nAlso, there's an issue with the background of _Active connections_ and _Available connections_ within the network manager plasmoid:\r\n\r\n![Networks plasmoid](https://user-images.githubusercontent.com/2781117/30272264-b439f786-9704-11e7-8529-0f7c76eb91ab.png)\r\n\r\nA few days ago, this wasn't like this. If this is not an issue with my setup, can you please tell me in which commit has this been changed? I'll have a look at the diff and sort it out myself.\r\n\r\nThanks!\n Comment 3: @giogziro95 Blue background used for new version too, because initialy Arc Dark Colors have wrong colors an more bugs.\r\nYou can compare colors and check this, extract to ~/.local/share/color-schemes [color-schemes.tar.gz](https://github.com/PapirusDevelopmentTeam/arc-kde/files/1293215/color-schemes.tar.gz)\r\nArrows not exist on old Kvantum themes, need update this.\n Comment 4: @giogziro95 See on up preview - it's Arc Dark OLD PLASMA colors:\r\n![image](https://user-images.githubusercontent.com/8083855/30284838-2109312e-972d-11e7-843c-dd36ca274d59.png)\r\nAnd NEW colors:\r\n![image](https://user-images.githubusercontent.com/8083855/30284870-47ead860-972d-11e7-83b7-b1a2c76eb51c.png)\r\n\r\n\n Comment 5: lineedit widget will be fixed soon https://github.com/PapirusDevelopmentTeam/arc-kde/issues/61",
  "Issue title: Prev / Next links\n Issue body: Ref: https://vuepress.vuejs.org/theme/default-theme-config.html#prev-next-links\n Comments: \n Comment 0: This is a vital feature for me. Will be happy to help; try out; discuss approaches from a user point of view.\n Comment 1: Hi!\r\nI tried to solve this issue, and created [PR](https://github.com/vuejs/vitepress/pull/56)!\r\n\r\nI want vitepress core team to check my PR, but I'm not sure who to mention... \ud83e\udd14 \r\n@yyx990803 ?",
  "Issue title: Uni.invoke() (or call() or handle())\n Issue body: After some experience I find I prefer the `map()`/`flatMap()` API to `onItem()`.\r\n\r\nBut it's *really* annoying that there's no equivalent shortcut way to call `UniOnItem.invoke()`, since it's an operation I use all the time.\r\n\r\nI would like to see `invoke()` added to `Uni`, though perhaps it would make more sense to name it `handle()`, since it's a sort of event handlery thing. Or `call()` perhaps.\n Comments: \n Comment 0: This issue came a few times. I, first, need to understand the use case, as most of the time, I've seen these methods used just for `log` purposes. \r\n\r\nWe want to add a log operator:\r\n\r\n* `Uni.log()`, `Multi.log()` - log all the events\r\n* `Uni.onItem().log()` - log item events\r\n*...\r\n\r\nThe log operator can log automatically (using a predefined log statement) or be used with a callback returning the String to be logged. \r\n\r\nIf requested, the log should be able to clean up the stack trace to be _meaningful_.\r\n\r\nWhen not used for logging, these methods are often used to implement side-effects. While they cannot be discarded, users must be a bit careful with that.  \r\n\r\nAbout the naming, what about `onItem(Consumer<T>)`? The \"traditional\" method is named `doOnNext` which does not fit well with the rest of Mutiny.\n Comment 1: This isn't anything to do with logging. (For logging I would need a matching method that is called on failures.)\r\n\r\nIt's specifically in order to be able to call side-effects, which are rather hugely important when one is writing data-access code. :-) The most basic operations like `persist()` and `delete()` and `flush()` are all side-effects.\r\n\r\n> About the naming, what about `onItem(Consumer<T>)`? The \"traditional\" method is named `doOnNext` which does not fit well with the rest of Mutiny.\r\n\r\nI want something that looks and feels visually like `map()` and `flatMap()`, because it will appear in a chain along with a bunch of `map()`s and `flatMap()`s.\n Comment 2: You could call it `affect()`. Since it's used to cause an effect.\n Comment 3: I like that name! \r\n\r\n@jponge @kenfinnigan WDYT? \n Comment 4: Is this the same as `peek`?\n Comment 5: `affect` sounds weird to me, but it's probably due to how I translate that to \ud83c\uddeb\ud83c\uddf7 \ud83d\ude09 \r\n\r\nSome random ideas:\r\n\r\n* `do(Consumer<T> item)` (e.g., `(...).onNext().do(this38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5persist).(...)`\r\n* `perform`\r\n* `trigger` (might be nice)\n Comment 6: `do` is a keyword in Java.\n Comment 7: And `trigger()` is almost a bit *too* exciting and action-packed, perhaps. ;-)\n Comment 8: > `do` is a keyword in Java.\r\n\r\nYeah, I thought about it over lunch \ud83e\udd26 \n Comment 9: In fairness, it's probably the least used keyword except for `goto` and `strictfp`.\n Comment 10: I kind of like `affect()`.\r\n\r\nSome other options could be `alter()`, `perturb()`, `transform()`. Just a few I thought of, though may induce other connotations.\n Comment 11: `peek is already used in [Java streams](https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html#peek-java.util.function.Consumer-) for that purpose. I vote for the peek.\n Comment 12: `also`?\n Comment 13: > peek is already used in [Java streams](https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html#peek-java.util.function.Consumer-) for that purpose\r\n\r\nI dunno, \"peek\" sounds kinda like the *opposite* of what this is. \"Peek\" sounds like something with no side-effect, whereas we've already established that the whole point of this operation is to do side effects.\r\n\n Comment 14: > I dunno, \"peek\" sounds kinda like the opposite of what this is.\r\n\r\nI'd be totally happy with calling it \"poke\", however. \ud83d\ude1d\n Comment 15: Will poke get me infinite threads?\n\nOn Mon, 1 Jun 2020, 22:17 Gavin King, <gregory30@example.net> wrote:\n\n> I dunno, \"peek\" sounds kinda like the opposite of what this is.\n>\n> I'd be totally happy with calling it \"poke\", however. \ud83d\ude1d\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/smallrye/smallrye-mutiny/issues/146#issuecomment-637079805>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AANKF2GHSWMNCFXSMEF7QBLRUQEG3ANCNFSM4NI76VLA>\n>.\n>\n\n Comment 16: But `peek` doesn't have any effect -- on the processing pipeline. It lets you see the value and do something with it, but the pipeline isn't _affected_. Hence, you could also say that `affect` is the exact opposite :grin:\n Comment 17: Sure, but I'm not writing a code that produces a processing pipeline. I'm writing code that does something interesting to the world. I DGAF what this operation does to the stream, since my program isn't about streams.\n Comment 18: > I'm not writing a code that produces a processing pipeline\r\n\r\nYea, well, you do. If you use the `Uni` API, you build a pipeline, even though there's ever only 1 item flowing through it.\n Comment 19: > Yea, well, you do.\r\n\r\nThat's the myopic perspective of the designer of a reactive streams library.\r\n\r\nIt's not my perspective as a user of the API. I'm trying to make an interesting program that does useful things. I actually don't care about reactive gregory30@example.net. When I look at my code I want to see information about how my program solves the problem the program is designed to solve. Not information about reactive streams.\n Comment 20: > Not information about reactive streams.\r\n\r\nAnd that's why\r\n\r\n    on().item().invoke(sideEffect)\r\n\r\nwhile surely very cool and elegant, arguably, to someone who's very myopically interested in reactive streams, is completely intrusive and annoying in my program which does interesting stuff that end users care about.\n Comment 21: Actually it's a perspective of someone who hates reactive programming libraries and believes that if we really need to impose them on users, then we shouldn't try to hide what's really going on, because leaking abstraction etc. etc. etc. But I'm ready to agree to disagree.\n Comment 22: Well, I'm trying to find a way to hate it slightly less.\n Comment 23: Alright, so reflecting on @Ladicek point about `peek()` implying something that has no effect _on the stream_, I managed to clarify what I dislike about that name, and that suggested a better name.\r\n\r\nSo why don't I like `peek()`? Well, \"peek\" in English means to just sneak a quick glance at the item. Whereas what I'm going to do from this operation is actually *use* the item to do something very meaningful, perhaps even perform a side-effect _on the item itself_.\r\n\r\nSo why not call the operation `use()`? The name implies to me that I'm going to use the item without affecting or transforming the stream itself. It's a common English word, that's not a Java keyword, and that has just three letters in it!\n Comment 24: Hear me out on this one. This reads really naturally, I think:\r\n\r\n```java\r\nreturn factory.withSession(\r\n\t\t//retrieve a Book\r\n\t\tsession -> session.find(Book.class, book1.id)\r\n\t\t\t\t.use( book -> session.remove(book) )\r\n\t\t\t\t.map( book -> \"deleted \" + book.title )\r\n)\r\n```\n Comment 25: Kotlin has [also](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/also.html)\n Comment 26: I am sure that every designer of the stream library had the same discussion. We already have a standard Java library. While some names may be less than perfect, they are well known and understood, so why not just stick with that? Easy to use reactive library is something to be excited about; a slightly better name for functionality that I already know under a different name is not.\n Comment 27: > I am",
  "Issue title: Slash command inputs for integers greater than 2^53 are converted to string\n Issue body: **Description**\r\n\r\nSlash command with an integer option will convert the integer to string and is likely to have off by one errors if the input is above `2^54` (`9007199254740992`) or below `-(2^53)`\r\n- Interactions with `9007199254740992` will be correct\r\n- Interactions with `9007199254740993` will return `9007199254740992` as a number in the interaction JSON\r\n- Interactions above `9007199254740993` will return the input as a string in the interaction JSON, and often be off by one.\r\n  - e.g. `9007199254740995` -> `9007199254740996`\r\n  - e.g. `9999999999999999`  -> `10000000000000000`\r\n\r\n**Steps to Reproduce**\r\n\r\n1. Post a new slash command to a guild with an Integer type option.\r\n2. Run an app that will simply acknowledge interactions and not consume source.\r\n3. On the desktop client input `9007199254740993` as the integer for the option\r\n4. The source will say you ran the command with `9007199254740992` as the integer input.\r\n\r\n**Expected Behavior**\r\n\r\nEither:\r\n- The interaction data JSON has the correct number as a number not a string\r\n\r\nOr:\r\n- Give the user an error for the size of their input\r\n- The documentation tells developers that inputs above certain sizes will be ignored\r\n\r\n**Current Behavior**\r\n\r\nPhone:\r\nClient says **Input a valid integer** if the input is over 9 digits long (unsure about specific number).\r\nDesktop:\r\nCommand is accepted, number is converted to string, and sometimes has off by one errors.\r\n\r\n**Screenshots/Videos**\r\n\r\n[Input](https://media.discordapp.net/attachments/584014133306064938/818076084494270474/unknown.png)\r\n[Output](https://media.discordapp.net/attachments/584014133306064938/818076136457764874/unknown.png)\r\n\r\n**Client and System Information**\r\n\r\nDesktop:\r\nStable 78727 (b2380a5)\r\nHost 0.0.309\r\nWindows 10 64-Bit (10.0.17763)\r\n\r\nPhone:\r\nAndroid - 64.1 (1463)\n Comments: \n Comment 0: > The interaction data JSON has the correct number as a number not a string\n\nThis would violate JSON spec. The best solution here would be to pass large numbers as strings.\n Comment 1: I wasnt able to find another issue in this github but I joined the API server and it seems to have been discussed \r\n![image](https://user-images.githubusercontent.com/24992458/110237846-1f003180-7f36-11eb-8e11-f46205855b6e.png)\r\nSo it might be js / discord.js related rather than API related.\r\nEither way it might be nice to specify limits on integer inputs for slash commands.\n Comment 2: Specifically it's related to all parsers that consume valid JSON only. Java and JavaScript are among languages that cannot consume large numbers as numbers for one reason or another.\n\nNumber in JSON is the same as in JS - a 64-bit IEEE754 binary floating-point number. It has a 53-bit mantissa and that's where the precision limit comes from. If you puke large numbers into it as numbers and not strings, you will break compliant parsers.\n Comment 3: Should also point out: above is the same reason why IDs are encoded as strings.\n Comment 4: > Specifically it's related to all parsers that consume valid JSON only. Java and JavaScript are among languages that cannot consume large numbers as numbers for one reason or another.\r\n> \r\n> Number in JSON is the same as in JS - a 64-bit IEEE754 binary floating-point number. It has a 53-bit mantissa and that's where the precision limit comes from. If you puke large numbers into it as numbers and not strings, you will break compliant parsers.\r\n\r\nThe limit on numbers in JSON is implementation-specific and accepting outside of what javascript allows does not make the JSON \"invalid\"\r\n\r\nFrom [the rfc](https://tools.ietf.org/html/rfc8259#section-6) (emphasis mine)\r\n\r\n> This specification allows **implementations** to set limits on the range\r\n   and precision of numbers accepted.\r\n\r\nAdditionally, the [standard published by ECMA](https://www.ecma-international.org/publications-and-standards/standards/ecma-404/) also puts no such finite bit related bounds on numerics.\r\n\r\nBy this, it is entirely valid for Discord to choose to use a JSON (de)serialization method which does not have this issue or document how large numbers will be handled and at least handle them consistently between platforms.\r\n\n Comment 5: Yeah I'm fine if large numbers become strings but off by one errors, arbitrary digit limits that are inconsistent between mobile and pc should at least be documented. \n Comment 6: would probably be best to show a \"this number is too high\" error; currently it just 400s if the number is really high\n Comment 7: I would also like a way to limit the size of the `INTEGER` type. If not to a specific max, at least to have something like int32 and int64. Maybe also a way to allow positive only and other reasonable restrictions. To support unbounded integers there could be another type that would send it as a string, but check that it's a valid number.\n Comment 8: Soon the client will reject your very large numbers.  Leaving this open to track the need for consistent limits cross-platform\n Comment 9: This was closed without further comment and it was stated this was being left open to track. This does not appear to have been fixed from minimal testing, was this closed inadvertently, is this thought to be fixed but hasn't been?\n Comment 10: The PR linked to his is merged, and thus it is assumed to be fixed. Post specific client reproduction steps and we can look again.\n Comment 11: > The PR linked to this is merged\r\n\r\nThis isn't publicly visible.\r\n\r\n> Post specific client reproduction steps and we can look again.\r\n\r\nI'll get a full set of details tomorrow as it is late here, I was still able to reproduce this on the stable windows client between when this was closed and when I posted.\n Comment 12: for me (on stable 81648 and canary 81777) it accepts 9007199254740991 but for 9007199254740992 and higher, it errors\r\n\r\n![image](https://user-images.githubusercontent.com/11778454/114111313-96efad80-988e-11eb-9d31-f25b4ec86381.png)\r\n\n Comment 13: After a client update, no longer reproducible. Based on the timeline of when closed and when this was experienced, I suspect this is still technically possible to have issues with outdated clients and that it is not also validated on the server-side, but I can only infer that.",
  "Issue title: Mutation time - backwards compatibility\n Issue body: As it stands when #672 is merged we break compatibility in the following ways:\r\n\r\n1. File format (not too bad as #672 has a `tskit upgrade` cli support)\r\n2. `python MutationTable.add_row` every call to this function will need updating.\r\n3. `python MutationTable.[set|append]_columns` every call to these functions will need updating.\r\n4. `cpython LightweightTableCollection.from_dict` will fail when passed dicts made in, for example, msprime 0.7.4 or newer.\r\n5. C API extra time args to mutation table methods (no way around this)\r\n\r\n2 and 3 _could_ be avoided by allowing a default mutation-time of zero as on these methods. This would result in an invalid tree-sequence _but_ `TableCollection.tree_sequence` could catch mutation time errors, call `compute_mutation_times` and build the tree sequence again, logging out a warning that mutation times were set.\r\n\r\n4 Could be avoided in a similar way, by detecting the absence of mutation times in the dict and calling `compute_mutation_times` again.\r\n\r\nNote that currently `compute_mutation_times` spreads mutations evenly across edges (except for those above a root node where the mutation is placed at the same time as the root)\r\n\r\nIn summary we could make this release more or less backward compatible (python-wise). My concern is that users should be aware that they have placeholder mutation times, as otherwise they could end up using them in some analysis as if they were \"proper\".\r\n\r\nTagging some people who may have input here: @jeromekelleher @petrelharp @hyanwong @molpopgen @bhaller\n Comments: \n Comment 0: I think we need a notation for mutation times that are unknown (apart from the fact that they occur between the parent and child node on an edge. This could, indeed, be the default, which would therefore serve as a placeholder, no? Since the time should be floating point, using NaN seems the obvious choice to me, although I know @jeromekelleher dislikes using NaN like this, and for good reason.\n Comment 1: The C API changes can certainly be accommodated by SLiM, we'll just need to pull over the latest tskit code, make the necessary changes, and do a new release.  @petrelharp generally does the pull from tskit.  Once that's done, I can roll a new SLiM release quickly, usually within a day.\n Comment 2: I think on balance putting NaNs in as the default is a good idea, and will save us a lot of compatibility headaches.\r\n\r\nUnless code uses mutation times, then the presence of NaNs in this field won't affect them. Thus, all old code on old and new tree sequences will continue to work.\r\n\r\nNew code using the tables API that is run on a tree sequence that contains NaNs for time, will return an answer that contains NaNs. This seems like a reasonable way of signaling the existance of times that are unknown. If we write algorithms that process mutation times within tskit in the future, we will have to decide on a case-by-case basis whether it's better the propagate the NaNs, or to raise an error. I can see both being appropriate in different cases, so we just need to be aware of the issue, I think.\r\n\r\nGiven that all tree sequences currently have no mutation time, and some programs (like tsinfer) don't have any way of putting times on mutations (we could make them up, but it would be basically meaningless), then allowing for this slight complication in the data model seems worth it.\r\n\r\nOnce we use the built in macros for working with NaNs with a little bit of care, I think this would work fine.\n Comment 3: This would also allow you to avoid @benjeffery's point 5 (\"C API extra time args to mutation table methods (no way around this)\") \u2013 the existing API could be preserved, and put a NAN in for the mutation time, and a new API could be provided that has the additional mutation time argument.  I don't think we care one way or the other in SLiM \u2013 we ought to migrate to the new API anyway, so that we can move the mutation times out of metadata into the mutation table.  But if you want to avoid breaking other existing C code, that option exists, it seems to me.  @petrelharp do you concur?\n Comment 4: Allowing unknown values would be nice, and NaNs seem OK for this. But is the proposal is to allow them in the tables, but still not in the tree sequence? If so, I don't think the NaN functionality is going to be used, really, since it'd be a pain to keep tables around that you can't ever tree-sequence. It's also hard for me to imagine a use case where some mutation times would be known and others not, so propagating NaNs wouldn't really be helpful, since either a stat would make sense for all mtuations or none. Maybe I'm missing something?\r\n\r\nRe: the C API - I vote to change it, no need to add a new method. (note: a code search for tsk_mutation_table_add_row turns up a small number of users we could notify about this).\n Comment 5: I had imagined allowing them in the tree sequence also @petrelharp.  Re the propagating NaNs from stats, I wasn't really thinking about having mixed values, but more what's useful to the user: should the stat return NaN if called on an unknown mutation time, or should it raise an error? I can see both being reasonable, I guess.\r\n\r\n> Re: the C API - I vote to change it, no need to add a new method. (note: a code search for tsk_mutation_table_add_row turns up a small number of users we could notify about this).\r\n\r\nAgreed - until we hit 1.0 I think we should try to keep the surface area of the API as small as we can.\n Comment 6: Ok, if it'll be in the tree sequence also, then that's great. But then isn't it pretty much an optional column? I thought we decided we really did want values in here?\n Comment 7: > Ok, if it'll be in the tree sequence also, then that's great. But then isn't it pretty much an optional column? I thought we decided we really did want values in here?\r\n\r\nYeah, it is an optional column now. We did think we really wanted values in there, I think, until we started thinking through the consequences in terms of compatability. A major version bump really is a big deal, so if we can avoid it having a little ickiness in the data model is worth it.\r\n\r\nThere's also the argument that things like tsinfer really don't make mutation times that have any meaning, much, so forcing it to choose arbitrary values is more likely to end up affecting users who don't realise their mutation times are meaningless (and I can imagine putting mutations uniformly on branch could be very badly wrong in this context).\n Comment 8: Does it being an \"optional column\" mean that the column can literally be left out, in the tables, and on disk, and a value of NaN is assumed when the column is missing?  Or once this change is made, will new files written to disk always contain a NaN value (or a proper time value) for each mutation?\n Comment 9: > Does it being an \"optional column\" mean that the column can literally be left out, in the tables, and on disk, and a value of NaN is assumed when the column is missing? Or once this change is made, will new files written to disk always contain a NaN value (or a proper time value) for each mutation?\r\n\r\nYes - files that are missing the ``mutation/time`` column will be assumed to contain NaN at load time. We will write out files that contain the ``mutation/time`` column, even if it is all NaNs though (but see #537 and #538 for thoughts on writing out columns that don't contain any useful information - I think it would be good to be a bit more clever about this, and it would probably save a fair bit of file storage space.)\n Comment 10: So in-memory the column will always exist, even if it is filled with NaN?  (Seems reasonable, I'm just wondering exactly what you guys mean by \"optional column\".)\n Comment 11: > So in-memory the column will always exist, even if it is filled with NaN? (Seems reasonable, I'm just wondering exactly what you guys mean by \"optional column\".)\r\n\r\nYes, the in-memory column always exists (but see #585 for ways we're thinking about avoiding storage space for optional stuff like edge metadata when building tables).\n Comment 12: > Yeah, it is an optional column now. We did think we really wanted values in there, I think, until we started thinking through the consequences in terms of compatability.\r\n\r\nSorry, I was all turned around.\r\n\r\nBut, ok - if the column can be optional, I think providing defaults to the python functions, that defaults to whatever the \"default value if the column isn't present\" is, is a good idea.\n Comment 13: > But, ok - if the column can be optional, I think providing defaults to the python functions, that defaults to whatever",
  "Issue title: Support Ubuntu Unity app indicators for minimizing to tray\n Issue body: It would be great if there was (some, I do not care which) way to have uTox under Ubuntu support minimizing to the tray, or more specifically, to support Unity's appindicator protocol.\n\nhttps://unity.ubuntu.com/projects/appindicators/\n\nI am aware that this issue is a more narrow version of #169, but as I would like to post a bounty specifically for this issue, I feel that such a narrower issue is appropriate. I would consider this closed if there is some way to have uTox running with only an app indicator visible under Ubuntu Unuty\n\nFor APIs and code examples, see also\nhttps://wiki.ubuntu.com/DesktopExperienceTeam/ApplicationIndicators\n\n Comments: \n Comment 0: [Bounty](https://www.bountysource.com/issues/7675742-support-ubuntu-unity-app-indicators-for-minimizing-to-tray)\n Comment 1: Hello mrbiber!\n\nI'm as well an Ubuntu user (14.04 LTS) and a few months ago I googled to now if it was possible to create a kind of \"watchdog\" to get a DBus notification and send it to libnotify, thanks to a script.\nI didn't find what I wanted, so I decided to work on the Tox project!\n\nI'm still very interested and I'll be pleased to work on integration.\nRight now, I succeeded in adding the friend's avatar next to his or her name and message when you get a notification.\n\nI'm planning to add \u00b5Tox in, the Messaging Menu. Does it sound righ to you?\nJust as XChat or Thunderbird. The mesasging menu has been created to do that.\n\nIf you have any remark, do not hesitate to answer here! ;)\n\n Comment 2: Hi @Encrypt, sounds great! I'd be equally happy with having it as part of the messaging menu. The main point of this request is to have Tox running some way under Ubuntu where you don't need to have the main window open or in the list of active applications, i.e. like having it minimized to tray.\r\n\r\nDoes that answer the question? I've also changed the issue description and increased the bounty a bit.\n Comment 3: Hi @mrbiber!\r\n\r\nA short message to tell you that work is in progress! ;)\r\nWhat do you think about what I have done for the moment? Is it what you're waiting for?\r\n\r\n![messaging_menu](https://cloud.githubusercontent.com/assets/9038199/5889046/df248456-a414-11e4-8ba3-ff942c28fb94.png)\r\n\r\nThanks in advance for your feedback!\n Comment 4: Looks great! Does that mean that \u00b5Tox runs in the background, withot having a window open?\n\n Comment 5: pease please! add \"minimise to tray\" option for MATE / GNOME as well\n Comment 6: Hello you!\r\n\r\nI have well-received your requests and I will try to implement them.\r\n\r\nFor the moment, I reviewed my code to make something cleaner (dealing with the GMainLoop and MessagingMenu library was hard to understand at first!).\r\n\r\nA notification now disappears when the software is maximized (I mean when I click on its icon in the tray) if the display is focused on the chat box of the friend who sent the notification.\r\n\r\nI'll add a message count on the \u00b5Tox icon too in the next step of development.\r\nThen, I'd like to add a \"minimize to messaging menu\" feature.\r\n\r\nTell me what you think about my action plan!\r\nI'm on the #tox IRC channel if you're interested, by the way! ;)\r\n\r\nI may commit the actual version (with the integration in the messaging menu working) before implementing the message count and minimize to Messaging Menu.\n Comment 7: Hi Yann, \n\nthank you for modifications and for your contribution. It's really\ngreat job! \n\nHowever, I've updated uTox just now to version 0.18-512 and found that\nthere is still no tray-icon in my Mate (Gnome classic fork). Start in\nTray and Close in Tray switchers are there, but unfortunately it's looks\nlike in case of using Mate they cause no action. \n\nDmitry \n\nOn Thu, 12 Feb 2015 07:25:19 -0800\nYann Priv\u00e9 <ugonzalez@example.org> wrote:\n\n> Hello you!\n> \n> I have well-received your requests and I will try to implement them.\n> \n> For the moment, I reviewed my code to make something cleaner (dealing\n> with the GMainLoop and MessagingMenu library was hard to understand\n> at first!).\n> \n> A notification now disappears when the software is maximized (I mean\n> when I click on its icon in the tray) if the display is focused on\n> the chat box of the friend who sent the notification.\n> \n> I'll add a message count on the \u00b5Tox icon too in the next step of\n> development. Then, I'd like to add a \"minimize to messaging menu\"\n> feature.\n> \n> Tell me what you think about my action plan!\n> I'm on the #tox IRC channel if you're interested, by the way! ;)\n> \n> I may commit the actual version (with the integration in the\n> messaging menu working) before implementing the message count and\n> minimize to Messaging Menu.\n> \n> ---\n> Reply to this email directly or view it on GitHub:\n> https://github.com/notsecure/uTox/issues/758#issuecomment-74088864\n",
  "Issue title: Wrong theme change command in README\n Issue body: Under Motivation: `bundle-theme candy` should be `antigen-theme candy`\n\n Comments: \n Comment 0: Thank you for reporting :sparkles:\n",
  "Issue title: Unable to add new tools to config\n Issue body: So, first off _absolutely love_ the mod. Like, as a player that cares more about aesthetic than pretty much anything? This is perfect.\nSecond, I have encountered an issue. See, I notice you can add tools etc to the sword list? Yeah, for whatever reason it won't let me add the Draconic Staff of Power (DraconicEvolution:draconicDistructionStaff) or the Mekanism Atomic Disassembler (Mekanism:AtomicDisassembler), which is a shame because I tend to use multitools, and am at the endgame stage where I'd rather not switch back to individual tools. I don't know if I'm doing anything wrong, all I am doing is adding the tool ID in the same format as is already written.. Anybody else had this issue, or am I doing it wrong, or is there a fix I've missed completely?\n\n Comments: \n Comment 0: When the game is loading do you get any errors in the log like \"Invalid sword override in config file\" or \"Unable to override item renderer for\" you may need to turn on showing the log on whatever launcher you are using.\n Comment 1: Ok, in regards to the two items, I get the following:\r\n[Armourer's Workshop]: Overriding render on - Mekanism:AtomicDisassembler\r\n[Armourer's Workshop]: Storing custom item renderer for: AtomicDisassembler\r\nAnd\r\n[Armourer's Workshop]: Overriding render on - DraconicEvolution:draconicDistructionStaff\r\n[Armourer's Workshop]: Storing custom item renderer for: draconicDistructionStaff\r\nBut nothing that seems to indicate any kind of wlewis@example.org..\r\n\r\nI also get the same two lines for the following items:\r\nTwilightForest:item.iceSword\r\nTwilightForest:item.fierySword\r\nTwilightForest:item.glassSword\r\nTConstruct:cutlass\r\nTConstruct:rapier\r\nTConstruct:battleaxe\r\nTConstruct:cleaver\r\nTConstruct:broadsword\r\nBotania:elementiumSword\r\n_(Note: I added none of these as extra. They were added in automatically)_\r\n\r\nAnd then there are a load of other weapons added. Just for \"_In case you'd need it_\" here's all the log says in reference to Armourers Workshop: http://pastebin.com/H9XktWky\r\n(And the standard load path for the skin library on world load)\r\n\r\nUpon testing the re-skinning for the Ice Sword, a TiCo Cutlass and the Elementuim sword, I could re-skin them as expected.\n Comment 2: Can you test with the new build and tell me if it's fixed? http://minecraft.curseforge.com/projects/armourers-workshop/files\n\n Comment 3: No replay. Presuming it's fixed.\n",
  "Issue title: Application crash is you change the theme\n Issue body: <!--\r\n> Please follow the issue template below for bug reports and queries.\r\n> Bug reports or queries opened without any of these info will be **closed** without any explanation.\r\n> For feature requests, label the title with [FEATURE] and explain your use case and ideas clearly below, you can remove sections which are not relevant.\r\n> For bug reports your `.yo-rc.json` file is mandatory else we will close the issue.\r\n> You can run `yo jhipster:info` in your project folder to get most of the required info\r\n-->\r\n\r\n##### **Overview of the issue**\r\nThe application Crashed when we try to add theme by editing src/main/webapp/index.html. The HTML throws the following error \"An error has occured :-(\"\r\n<!-- explain the issue or feature request, if an error is being thrown a stack trace helps -->\r\n\r\n##### **Motivation for or Use Case**\r\n\r\nWe need to update the current theme while preserving the features like type-scripting.  However we can not even add a simple text in the HTML page. SOS\r\n\r\n<!-- explain why this is a bug for you -->\r\n\r\n##### **Reproduce the error**\r\n\r\nJust open \"src/main/webapp/index.html\", add a simple html/text in the file. Re-run the application and get an exception/error.\r\n\r\n<!-- an unambiguous set of steps to reproduce the error. If you have a JavaScript error, maybe you can provide a live example with\r\n  [JSFiddle](http://jsfiddle.net/)? -->\r\n\r\n##### **Related issues**\r\n\r\n<!-- has a similar issue been reported before? -->\r\n\r\n##### **Suggest a Fix**\r\n\r\n<!-- if you can't fix the bug yourself, perhaps you can point to what might be\r\n  causing the problem (line of code or commit) -->\r\n\r\n##### **JHipster Version(s)**\r\n\r\n<!-- to provide all information we need, you can use: yo jhipster:info -->\r\n<!-- which version of JHipster are you using, is it a regression? -->\r\n\r\n##### **JHipster configuration, a `.yo-rc.json` file generated in the root folder**\r\n\r\n<!-- This is mandatory for bug reports. This will help us to replicate the scenario, you can remove the rememberMe key. -->\r\n\r\n##### **Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**\r\n\r\n<!-- - if the error is during an entity creation or associated with a specific entity. If you are using JDL share that as well -->\r\n\r\n##### **Browsers and Operating System**\r\n\r\n<!-- What OS are you on? is this a problem with all browsers or only IE8? -->\r\n\n Comments: \n Comment 0: Can you describe what you are trying to do and how to reproduce your issue exactly?\n Comment 1: Provide browser's console log and also all details that have been requested by the issue template.\n Comment 2: C'mon, there isn't even the version number... We just can't work like that.\n Comment 3: This ticket has been closed as the guidelines are not followed.\r\n\r\nTickets must follow our [Guidelines](https://github.com/jhipster/generator-jhipster/blob/master/CONTRIBUTING.md#submitting-an-issue), as mentioned in:\r\n\r\n1. our [Readme file on the front page of the project](https://github.com/jhipster/generator-jhipster/blob/master/README.md), \r\n2. the [\"create a new ticket\" page](https://github.com/jhipster/generator-jhipster/issues/new) and\r\n3. our [Help page](http://jhipster.github.io/help/)\r\n\r\nWe have also created a template on the [\"create a new ticket\" page](https://github.com/jhipster/generator-jhipster/issues/new) to help you follow those guidelines.",
  "Issue title: \u5982\u4f55\u767b\u5165\uff1f\n Issue body: \u767b\u5f55\u5931\u8d25\uff0c\u8bf7\u68c0\u67e5\u60a8\u7684\u7528\u6237\u540d\u548c\u5bc6\u7801\uff01\u5e76\u786e\u4fdd\u5f53\u524d\u7684fakeThunder\u4e3a\u6700\u65b0\u7248\u672c\u3002\u5982\u679c\u4ecd\u7136\u65e0\u6cd5\u6b63\u5e38\u767b\u5f55\uff0c\u8bf7\u5230\u5b98\u65b9\u7f51\u7ad9\u53d1\u9001\u53cd\u9988\u3002\n\n\u4ec0\u4e48\u95ee\u9898 \uff1f\u8bf7\u95ee\u662f\u4f7f\u7528\u5728\u8fc5\u96f7\u5b98\u7f51\u4e0a\u6ce8\u518c\u7684\u5e10\u53f7\u5417 \uff1f\u4e00\u76f4\u90fd\u767b\u5165\u4e0d\u4e86 \uff1d\uff1d\n\n Comments: \n Comment 0: \u6700\u8fd1\u4e5f\u51fa\u73b0\u7a81\u7136\u65e0\u6cd5\u767b\u5f55\u7684\u60c5\u51b5\uff0c\u4e0d\u8fc7\u6709\u65f6\u5019\u53c8\u53ef\u4ee5\u767b\u5f55\u3002\n\n Comment 1: \u540c\u6837\u51fa\u73b0\u8fd9\u6837\u7684\u95ee\u9898\u3002\n\n Comment 2: \u6e05\u7406\u4e00\u4e0bsafari\u7684cookies\uff0c\u8fd8\u662f\u6709\u4e00\u5b9a\u51e0\u7387\u53ef\u4ee5\u767b\u5f55\u7684\u3002\n\n Comment 3: \u8fd9\u767b\u9646\u95ee\u9898\u662f\u8981\u5f00\u591a\u5c11\u4e2aissue\u554a\uff0c\u8fd9\u53c8\u4e0d\u662f\u8bba\u575b\n",
  "Issue title: [@types/react-jsonschema-form] failed to import SchemaField \n Issue body: If you know how to fix the issue, make a pull request instead.\r\n\r\n- [ ] I tried using the `@types/xxxx` package and had problems.\r\n- [ ] I tried using the latest stable version of tsc. https://www.npmjs.com/package/typescript\r\n- [ ] I have a question that is inappropriate for [StackOverflow](https://stackoverflow.com/).  (Please ask any appropriate questions there).\r\n- [ ] [Mention](https://github.com/blog/821-mention-somebody-they-re-notified) the authors (see `Definitions by:` in `index.d.ts`) so they can respond.\r\n  - Authors: @chanceaclark @minestarks \r\n\r\nHello,\r\nIn your recent type update (https://github.com/DefinitelyTyped/DefinitelyTyped/commit/970c733cdd07fa8f1e54a1fa4655a958fd19770b#diff-585576b203f20193115b32ff133bb6f9R268) SchemaField is named export, while in the code (https://github.com/rjsf-team/react-jsonschema-form/blob/master/src/components/fields/SchemaField.js#L443) SchemaField is default export.\r\n\r\nNot sure how to import it correctly. I've tried \r\n`import { SchemaField } from'react-jsonschema-form/lib/components/fields/SchemaField'`\r\nwhich passed the compile but failed in browser.\r\n\r\n\r\n\n Comments: \n Comment 0: I've tried exporting the class as default like you mentioned and it works with the following:\r\n```tsx\r\nimport React from'react';\r\nimport SchemaField, { SchemaFieldProps } from'react-jsonschema-form/lib/components/fields/SchemaField';\r\n\r\nexport const TestSchemaField: React.FC<SchemaFieldProps> = (props) => (<SchemaField {...props}>{/*... */}</SchemaField>);\r\n```\r\n\r\nThough I am going to rework it like so:\r\n```tsx\r\ndeclare module'react-jsonschema-form/lib/components/fields/SchemaField' {\r\n    import { JSONSchema6 } from 'json-schema';\r\n    import { FieldProps, UiSchema, IdSchema, FormValidation } from'react-jsonschema-form';\r\n\r\n    export type SchemaFieldProps<T = any> = Pick<FieldProps<T>,'schema' | 'uiSchema' | 'idSchema' | 'formData' | 'errorSchema' |'registry'>\r\n\r\n    export default class SchemaField<T> extends React.Component<SchemaFieldProps<T>> {}\r\n}\r\n```\r\n\r\nI will go ahead and submit another PR for the fix, though I did notice some other issues so I included them in the above code. Let me know if you see anything off.\r\n\n Comment 1: Looks good. Thank you!",
  "Issue title: Someone please help! I want to use this plugin but it doesn't support FULL WIDTH images!\n Issue body: Can someone please test a theme that works with which allows full width background images? Does anyone know if this plugin has a support team?\n Comments: \n Comment 0: You can't do it if your theme doesn't support full width template.\r\n\r\nread here: [http://docs.elementor.com/article/40-full-width-template](url)\n Comment 1: Hi yehudah,\r\nyour Link doesn't work.\r\n\r\n@jmarshallm \r\ntry this one.\r\nhttps://docs.elementor.com/article/40-full-width-template\n Comment 2: We are still waiting for your update. Feel free to reopen the issue and we'll be happy to help you further.",
  "Issue title: Generate commands in template hangs\n Issue body: ### Steps to reproduce\r\n\r\n`rails new rails5 -m https://raw.githubusercontent.com/Linuus/template-test-case/master/template.rb`\r\n\r\n### Expected behavior\r\nIt should generate a Rails 5 app based on the template.\r\n\r\n### Actual behavior\r\nIt hangs when generating the second model.\r\n\r\n```\r\n[...]\r\nBundle complete! 15 Gemfile dependencies, 62 gems now installed.\r\nUse `bundle show [gemname]` to see where a bundled gem is installed.\r\n         run  bundle exec spring binstub --all\r\n* bin/rake: spring inserted\r\n* bin/rails: spring inserted\r\n        rake  db:drop\r\nDropped database 'db/development.sqlite3'\r\nDatabase 'db/test.sqlite3' does not exist\r\n        rake  db:create\r\nCreated database 'db/development.sqlite3'\r\nCreated database 'db/test.sqlite3'\r\n        rake  db:migrate\r\n    generate  model\r\nRunning via Spring preloader in process 25775\r\n      invoke  active_record\r\n      create    db/migrate/20161125100352_create_authors.rb\r\n      create    app/models/author.rb\r\n      invoke    test_unit\r\n      create      test/models/author_test.rb\r\n      create      test/fixtures/authors.yml\r\n    generate  model\r\nRunning via Spring preloader in process 25777\r\n      invoke  active_record\r\n      create    db/migrate/20161125100353_create_articles.rb\r\n      create    app/models/article.rb\r\n      invoke    test_unit\r\n      create      test/models/article_test.rb\r\n      create      test/fixtures/articles.yml                          <<<--- Hangs here infinitely\r\n```\r\n\r\nI also tested with Rails 116.69.203.115 and that works.\r\n\r\n`rails _116.69.203.115_ new rails4271 -m https://raw.githubusercontent.com/Linuus/template-test-case/master/template.rb`\r\n\r\n### System configuration\r\n**Rails version**: 116.69.203.115\r\n\r\n**Ruby version**: 2.2.2\r\n\n Comments: \n Comment 0: It can be related to #21700.\n Comment 1: This seems like a duplicate of #21700; going to close in favor of that issue to keep all information related to this bug in one place.",
  "Issue title: compiling problems on oga\n Issue body: retroroller has been surpassed by rrvl.\r\ni tried to compile it on there but couldn't get it to see sdl2 for some reason.\r\nand i also tried the version i built long ago on retroroller on emuelec but it had some gcc error i think it was.\r\nany chance of putting together a package.mk for emuelec so shanti can include this in emuelec?\r\nthis is an example of one.\r\nhttps://github.com/EmuELEC/EmuELEC/blob/dev/packages/sx05re/emuelec-ports/VVVVVV/package.mk\n Comments: \n Comment 0: > i tried to compile it on there but couldn't get it to see sdl2 for some reason.\r\n\r\nI've been meaning to try out RRVL \ud83d\ude42 Let me see, maybe I can figure out how to make it compile on there.\r\n\r\n> any chance of putting together a package.mk for emuelec so shanti can include this in emuelec?\r\n\r\nSure, I'd be happy to look into that - would be nice to have the game included there!\n Comment 1: @NeonLightning I just tried building on RRVL, and the CMake part worked once I installed all the necessary packages:\r\n\r\n* `SDL2_mixer-devel` (will install `SDL2-devel` as well)\r\n* `boost-devel`\r\n\r\nMaybe you're missing one of these packages?\r\n\r\nThe build is still going, I'll let you know how it turned out once it's done.\r\n\n Comment 2: Hmm, there's still a problem - it's now trying to link SDL statically, which doesn't make sense as it then picks up the wrong version. I'll look into it some more\n Comment 3: @NeonLightning in other news: RigelEngine is now in EmuELEC \ud83c\udf89 \r\nhttps://github.com/EmuELEC/EmuELEC/pull/398 \n Comment 4: @NeonLightning I finally managed to make a functioning build on RRVL. So as mentioned before, you need to install `SDL2_mixer-devel`, SDL2-devel` and `boost-devel`. Then, invoke CMake like this:\r\n\r\n```bash\r\ncmake.. -DUSE_GL_ES=ON -DCMAKE_BUILD_TYPE=Release -DWARNINGS_AS_ERRORS=OFF -DSDL2_LIBRARY_RELEASE=/usr/lib/libSDL2-2.0.so.0.10.0\r\n```\r\n\r\nHope that works for you, let me know if you still get errors!\n Comment 5: i'll be trying the newest rrvl later this week hopefully. so i'll give it a shot then. \n Comment 6: sorry still haven't had a chance and looks like i won't for a bit.(personal problems for the next while)\n Comment 7: Hey @NeonLightning, sorry to hear that! No worries, and hope things get better for you soon!\n Comment 8: @NeonLightning I'm going to close this issue, since the game has been bundled with EmuELEC now for quite a while and RRVL doesn't seem to exist anymore AFAICT. ",
  "Issue title: LOGO\n Issue body: Hello, @FreeRDP I want to contribute in \"FreeRDP\" so i want to design a new logo for \"FreeRDP\" and it's free.\r\n\r\nI hope you like it. If you like it, I will send you to pull request, editable files/original source and.png format files. If there's something you want to change, I'll do it.\r\n\r\nif you want i will send you my design\r\n\r\nContact me on facebook for fast delivery \r\nhttps://www.facebook.com/waqasanwar68\n Comments: \n Comment 0: @waqasanwar94 Sounds interesting, but we're not present there ;)\r\nOnly mailing list, IRC, github and direct mail are currently available.",
  "Issue title: Settings are reset after every update.\n Issue body: After updating the app, the settings are always getting reset to the default settings. Please fix this.\n Comments: \n Comment 0: This bug has been completely fixed. Just wait for a new version of the app to test it.",
  "Issue title: Running a different piece of jQuery on page load (help wanted)\n Issue body: I've seen this issue mentioned a few times, but I can't seem to make any of the solutions work. In particular, I have an object, `#portfolio`, on one page that uses Masonry.js for a nice grid layout. It works on page refresh but not when the page is navigated to properly. If I play around with the code, I can get just Masonry working or just smoothState working, but not both.\n\nPost-butchering, here's my code. In this state, Masonry works but smoothState doesn't. Removing the entire `onEnd: {}` block reverses the situation.\n\n```\n$(function (){\n  'use strict';\n  var $page = $('#main'),\n      options = {\n        debug: true,\n        prefetch: true,\n        cacheLength: 2,\n        onStart: {\n          duration: 250, // Duration of our animation\n          render: function ($container) {\n            // Add your CSS animation reversing class\n            $container.addClass('is-exiting');\n            // Restart your animation\n            smoothState.restartCSSAnimations();\n          }\n        },\n        onReady: {\n          duration: 0,\n          render: function ($container, $newContent) {\n            // Remove your CSS animation reversing class\n            $container.removeClass('is-exiting');\n            // Inject the new content\n            $container.html($newContent);\n          }\n        }\n      },\n      onEnd: {\n        $('#portfolio').masonry();\n      }\n      smoothState = $page.smoothState(options).data('smoothState');\n});\n```\n\nAgain, I'm aware this has been asked before, but the other solutions seem to have not worked for some reason.\n\n Comments: \n Comment 0: @dendodge So just to confirm, you've tried running your masonry reinitialization in onAfter as well? My understanding is that the onAfter hook is the officially supported hook for restarting jQuery plugins, not onEnd. I'm not 100% clear on the real-world differences between using onAfter and using onEnd yet, though.\r\n\r\nI have little experience with using smoothState in combination with other jQuery plugins that need this kind of attention but I'd like to learn my way around doing this.\n Comment 1: @DigitalMachinist I've tried that, and I've tried normal callbacks to call Masonry after smoothState, but it still breaks the animations.\n\n Comment 2: @dendodge this is a better conversation for StackOverflow. We need to keep the issue tracker clear for bugs.",
  "Issue title: Does rails precompile slim templates?  Any way to\n Issue body: With my latest deployment I'm running out of memory, so looking for ways to move things before the unicorn fork (using preload_app = true)\n\nDo you know if slim templates are precompiled?  How would I go about trying to do that and storing them into the \"cache\" if not?\n\nThanks for a great project!\n\n Comments: \n Comment 0: Yes, the templates are precompiled to ruby code.This is done at the first invocation.\n\n Comment 1: **This is done as long as you're running in the production environment.\n\n Comment 2: Right - but invocation for each template isn't done before the fork right?  It's done when each method is called for the first time - so none of these would be stored in shared memory.\n\n Comment 3: Yes. Ask the Rails guys if you need a joshuaspencer@example.org. This is not a Slim question but depends only on the framework.\n\n Comment 4: No answer over there unfortunately. If I manually loop through my \ntemplate names and call render would that store it in slim's global \ncache? Or where is the cache stored?\n\nSlim38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5Template.new('template.slim', optional_option_hash).render(scope)\n\nSo that'd involve me making a list of each template, along with \"fake\" \narguments to call it with. How do I pass in the arguments (can'scope' \nbe a hash?)\n\nAny idea how much space templates take up? My project is fairly large, \nbut I have no idea how large the \"compiled\" templates would be...\n\nThanks,\nKevin\n\nDaniel Mendler wrote:\n\n> Yes. Ask the Rails guys if you need a joshuaspencer@example.org. This\n> is not a Slim question but depends only on the framework.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/slim-template/slim/issues/416#issuecomment-19737161.\n\n Comment 5: also related to #321 \n\n@inspire22   I think https://github.com/rails/rails/blob/master/actionpack/lib/action_view/template.rb is a starting point to you.\n\n Comment 6: Thanks!  Any idea how to hook into slim/tilt to log when a template is compiled, so I can see when I'm successful?\n\n Comment 7: sorry, I didn't dig into it that much\n\n Comment 8: besides, if you can't tell how much memory one template cache takes, why bothering with templates at all? One Ruby process/worker will give you at least 100 megs right off the bat. In practice a footprint will be around 160 megs. This is the cost that you pay for programmer happiness.\n\n Comment 9: Well, 60 megs per process \\* 10 workers = real memory at some point.\n\nIt's vaguely driven by my web processes hitting swap now that I have \nanother app.\n\nIf it's decently easy and reliable, it could be a good contribution back \nto rails - the 2.x series did have a preload_templates option for \nhaml/erb, it just seems to have gotten lost along the way.\n\nKevin\n\nAndrii Malyshko wrote:\n\n> besides, if you can't tell how much memory one template cache takes,\n> why bothering with templates at all? One Ruby process/worker will give\n> you at least 100 megs right off the bat. In practice a footprint will\n> be around 160 megs. This is the cost that you pay for programmer\n> happiness.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/slim-template/slim/issues/416#issuecomment-19781706.\n\n Comment 10: > 60 megs per process \\* 10 workers\n\nYou got me wrong, I mentioned only the minimum amount of consumed memory, it depends on how many gems in your Gemfile. Obviously, you have to start with a benchmark that will show, how much memory is taken by the templates.  Is it big enough to be comparable with 150-160megs that already consumed?\n\n>  the 2.x series did have a preload_templates option for\n> haml/erb\n\ncould you point out to exact code on rails/rails repository? I see only https://github.com/rails/rails/blob/2-3-stable/railties/environments/production.rb#L10, which is the same as template caching now.\n\n Comment 11: Good call vs. premature optimization, thanks.  Looks like my entire templates directory is only ~800k - not sure how much more space a compiled template would take, but probably not a ton.  I was able to lower my # of workers considerably and still meet the current throughput without any issue.  It may get slow if traffic increases greatly, but it's much better than swapping.  Thanks for your help :)\n",
  "Issue title: freezed_lints\n Issue body: ### Creating new package `freezed_lints` using [custom_lint](https://github.com/invertase/dart_custom_lint#using-our-custom-lint-package-in-an-application)\r\n\r\n- [ ] Create `packages/freezed_lints/` (not inside `freezed`, `freezed_annotation`), so that it's opt-in for developers\r\n- [ ] Check if/how to write tests for lints \r\n- [ ] adapt.github/workflow to also run and test freezed_lints\r\n#### incomplete list of lint ideas\r\n_Don't hesitate to add your ideas for lints, or correct me on my ideas, should they be useless or even undoable with lints._\r\n- [ ] `missing_part_directive` if you use `@freezed`/`@unfreezed` on a class, but there is no `part <filename>.freezed.dart;`\r\n- [ ] `missing_part_directive_json` same for when you use `.fromJson(Map<String, Object?> json)`-constructor, but there is no `part <filename>.g.dart;`\r\n- [ ] `missing_private_empty_constructor` when a getter, method, or late variable is added to a freezed class, but it has no `._()`-constructor\r\n- [ ] `mixin_name_mismatch` when `class MyExample with _$TypoInMixin {...}`\r\n- [ ] `fromjson_expression_body` when you do `factory MyClass.fromJson(Map<String, Object?> json) { return  _$MyClassFromJson(json); }`\r\n- [ ] `fromjson_block_body` when you do `factory MyClass.fromJson(Map<String, Object?> json) => MyOwnImplementation();`\r\n- [ ] lints for misconfigured parameters:\r\n```dart\r\n@freezed\r\nclass Parameters with _$Parameters {\r\n  factory Parameters(\r\n    @Default('defaultValue') String str, { // default_on_non-optional\r\n    int i, // no_default_or_required_on_optional\r\n  }) = _Parameters;\r\n}```\r\n\r\n\n Comments: \n Comment 0: I really don't like tagging \ud83d\ude47 people, so I'm sorry.\r\n@rrousselGit can you give short feedback if this approach is acceptable?\r\nThen I would create an initial PR with the first lint.",
  "Issue title: \u5982\u4f55\u63a7\u5236\u63d2\u5165\u56fe\u7247\u7684\u5927\u5c0f\u548c\u4f4d\u7f6e\uff1f\n Issue body: \u4f8b\u5b50\u7684\u793a\u4f8b\u56fe\u7247\u9ed8\u8ba4\u5c45\u4e2d\u5e76\u88ab\u7f29\u653e\u5230\u4e86\u4e00\u4e2a\u786e\u5b9a\u7684\u5927\u5c0f\uff0c\u53ef\u5426\u63a7\u5236\u56fe\u7247\u5728\u6574\u4e2a\u753b\u5e03\u4e2d\u7684\u4f4d\u7f6e\u548c\u7f29\u653e\u7684\u6bd4\u4f8b\uff1f\n\n Comments: \n Comment 0: \u5982\u679c\u4e0d\u80fd\u6ee1\u8db3\uff0c\u90a3\u4e48\u5c31\u6df7\u7f16html\u5427~\n\n Comment 1: \u6211\u9ed8\u8ba4\u4f7f\u7528HTML\u7684img\u6807\u7b7e\u5916\u52a0height\u548cwidth\u5c5e\u6027\u63a7\u5236\u7684\n",
  "Issue title: TestPayment with status \"Open\": Call to a member function isOpen() on null..\n Issue body: Hello,\r\n\r\nThe plugin is crashing (error 500) while doing a TestPayment with the status \"Open\", all other statuses are fine, it worked in v4.0.2, but got broken in v5.0.0..\r\n\r\n```\r\n8542#0: *549597 FastCGI sent in stderr: \"PHP message: PHP Fatal error: Uncaught Error: Call to a member function isOpen() on null in [..]/httpdocs/wp-content/plugins/mollie-payments-for-woocommerce/includes/mollie/wc/gateway/abstract.php:1415\r\nStack trace:\r\n#0 [..]/httpdocs/wp-content/plugins/mollie-payments-for-woocommerce/includes/mollie/wc/plugin.php(262): Mollie_WC_Gateway_Abstract->getReturnRedirectUrlForOrder(Object(WC_Order))\r\n#1 [..]/httpdocs/wp-includes/class-wp-hook.php(286): Mollie_WC_Plugin38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5onMollieReturn('')\r\n#2 [..]/httpdocs/wp-includes/class-wp-hook.php(310): WP_Hook->apply_filters('', Array)\r\n#3 [..]/httpdocs/wp-includes/plugin.php(453): WP_Hook->do_action(Array)\r\n#4 [..]/httpdocs/wp-content/plugins/woocommerce/includes/class-wc-api.php(97): do_action('woocommerce_api...')\r\n#5 [..]/httpdocs/wp-includes/class-wp-hook.php(286): WC_API->handle_api_requests(Object(WP))\r\n#6 /var/www\" while reading response header from upstream\t\t\r\n```\r\n\r\n\n Comments: \n Comment 0: Already fixed in the version I'm working on now:\r\nhttp://take.ms/1b4zl",
  "Issue title: Plugin update report\n Issue body: I'd like to have access to some sort of feed or report that details when plugins are updated. Perhaps plugin developers could put changes into this feed as well.\n Comments: \n Comment 0: To note: I'm interested in seeing a feed for both official and external plugins. \n Comment 1: https://github.com/runelite/plugin-hub/tree/master/plugins\r\n\r\nDates are public for each and usually summarized in the weekly update posts. \n Comment 2: Plugin hub plugins have not been updated in our release blog posts yet.",
  "Issue title: Cannot advance to the next page when zoomed in\n Issue body: If I zoom in the page I am not able to advance to the next page.\r\n\r\nIn order to change the page I have to zoom back or press H. Then I can scroll to the next page.\r\n\r\nI am using evil and evil-collection.\r\n\r\nThank you very much for any help or suggestions.\n Comments: \n Comment 0: I discovered that pdf-tools was in conflict with nano-modeline for some reason. After removing the nano-modline package now pdf-tools works well. I will close this issue.",
  "Issue title: \u6ce8\u518c\u65f6seata server\u7ecf\u5e38\u6027\u62a5OOM\u5f02\u5e38\uff0c\u91cd\u542fseata server\u540e\u6ca1\u95ee\u9898\u3002\n Issue body: io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 134217728 byte(s) of direct memory (used: 1073741824, max: 1073741824)\r\n        at io.netty.util.internal.PlatformDependent.incrementMemoryCounter(PlatformDependent.java:652)\r\n        at io.netty.util.internal.PlatformDependent.allocateDirectNoCleaner(PlatformDependent.java:606)\r\n        at io.netty.buffer.PoolArena$DirectArena.allocateDirect(PoolArena.java:764)\r\n        at io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:740)\r\n        at io.netty.buffer.PoolArena.allocateNormal(PoolArena.java:244)\r\n        at io.netty.buffer.PoolArena.allocate(PoolArena.java:214)\r\n        at io.netty.buffer.PoolArena.allocate(PoolArena.java:146)\r\n        at io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:324)\r\n        at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:185)\r\n        at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:176)\r\n        at io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:137)\r\n        at io.netty.channel.DefaultMaxMessagesRecvByteBufAllocator$MaxMessageHandle.allocate(DefaultMaxMessagesRecvByteBufAllocator.java:114)\r\n        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:147)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)\r\n        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)\r\n        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)\r\n        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\u5e76\u4e0d\u662f\u6bcf\u6b21\u90fd\u51fa\u9519    \u51fa\u9519\u5f97\u5f97\u6982\u7387\u572830%\n Comments: \n Comment 0: \u5c1d\u8bd5\u5c06\u542f\u52a8\u53c2\u6570\u4e2d\u7684\u5185\u5b58\u5927\u5c0f\u589e\u52a0\n Comment 1: @cmonkey    \u4fee\u6539\u4e86MaxDirectMemorySize    \u5c31\u597d\u4e86   \u8fd9\u4e2a\u9ed8\u8ba4\u65f61024M    \u4e3a\u4f55\u8fd9\u4e48\u5927\u8fd8\u4e0d\u591f\uff1f\n Comment 2: @cmonkey \u6211\u4e5f\u9047\u5230\u4e86\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u4e14\u628a\u5185\u5b58\u4e5f\u589e\u52a0\u4e86\uff0c\u8fd8\u662f\u62a5\u9519\u4e86\uff0c\u770b\u65e5\u5fd7\u663e\u793a\u5185\u5b58\u5e94\u8be5\u662f\u6ca1\u6709\u8d85\u8fc7\r\n\r\nio.netty.util.internal.OutOfDirectMemoryError: failed to allocate 134217728 byte(s) of direct memory (used: (636)709-2002, max: (636)709-2002)\r\n        at io.netty.util.internal.PlatformDependent.incrementMemoryCounter(PlatformDependent.java:652)\r\n        at io.netty.util.internal.PlatformDependent.allocateDirectNoCleaner(PlatformDependent.java:606)\r\n        at io.netty.buffer.PoolArena$DirectArena.allocateDirect(PoolArena.java:764)\r\n        at io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:740)\r\n        at io.netty.buffer.PoolArena.allocateNormal(PoolArena.java:244)\r\n        at io.netty.buffer.PoolArena.allocate(PoolArena.java:214)\r\n        at io.netty.buffer.PoolArena.allocate(PoolArena.java:146)\r\n        at io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:324)\r\n        at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:185)\r\n        at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:176)\r\n        at io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:137)\r\n        at io.netty.channel.DefaultMaxMessagesRecvByteBufAllocator$MaxMessageHandle.allocate(DefaultMaxMessagesRecvByteBufAllocator.java:114)\r\n        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:147)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)\r\n        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)\r\n        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)\r\n        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n        at java.lang.Thread.run(Thread.java:748)\n Comment 3: @maolei133 \u6211\u8fd9\u8fb9\u53d1\u73b0\u5e94\u8be5\u662f\u670d\u52a1\u505c\u4e86   \u6ca1\u6709\u65ad\u5f00\u94fe\u63a5     \u3002\u3002\u3002\n Comment 4: @zhangpenglong \u662f\u7684\uff0c\u5728\u672c\u5730\u8c03\u8bd5\u65f6\u5982\u679c\u9891\u7e41\u7684\u91cd\u542f\u670d\u52a1\u5c31\u53ef\u80fd\u51fa\u73b0\u8fd9\u4e2a\u95ee\u9898\uff0c\u628a\u670d\u52a1\u505c\u4e00\u6bb5\u65f6\u95f4\u5728\u542f\u52a8\u53c8\u597d\u4e86\n Comment 5: \u786e\u8ba4\u5ba2\u6237\u7aef\u5173\u95ed\u540e\u8981\u65ad\u5f00\u8fde\u63a5\n Comment 6: \u6240\u4ee5\u8fd9\u4e2a\u95ee\u9898\u7b97\u662f\u89e3\u51b3\u4e86\u4e48\uff1f\u600e\u4e48\u89e3\u51b3\u7684\uff0c\u6211\u8fd9\u8fb9\u53d1\u73b0 PlatformDependent\u7c7b\u7684DIRECT_MEMORY_COUNTER \u6bcf\u91cd\u542f\u4e00\u6b21\u5ba2\u6237\u7aef\u8fd9\u4e2a\u503c\u5c31\u589e\u52a0256M\uff0c\u76f4\u5230\u8d85\u8fc7\u8bbe\u7f6e\u7684\u4e34\u754c\u503c\uff0c\u670d\u52a1\u5c31\u4e0d\u80fd\u7528\u4e86\uff0c\u53ea\u80fd\u91cd\u542f\r\n![image](https://user-images.githubusercontent.com/10000325/72045631-90703000-32f1-11ea-8a84-101e02205d0b.png)\r\n\n Comment 7:![image](https://user-images.githubusercontent.com/5763397/72082326-f1702600-333a-11ea-809d-c52f8ca59dd2.png)\r\n1.0.0\u8fd9\u4e2a\u95ee\u9898\u89e3\u51b3\u4e86\u4e48\uff1f  \u76ee\u524d\u6709\u76f8\u540c\u7684\u95ee\u9898\u3002\n Comment 8: \u5728windows\u4e0a\u9762\u6709\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728Linux\u4e0a\u4e0d\u4f1a\u51fa\u73b0\u8fd9\u4e2a\u95ee\u9898",
  "Issue title: antd\u7ec4\u4ef6\u5b9e\u8df5---\u9884\u7ea6\u7ba1\u7406\u7cfb\u7edf\n Issue body: \u4f7f\u7528antd\u7ec4\u4ef6\u5199\u7684\u4e00\u4e2a\u5c0f\u9879\u76ee\u5b9e\u8df5\uff0c\u5b9e\u73b0\u4e86\u57fa\u672c\u7684\u5bf9\u6570\u636e\u7684\u589e\u5220\u6539\u67e5\uff0c\u5f85\u89c4\u8303\u7684\u5730\u65b9\u8fd8\u6709\u597d\u591a\uff0c\u5e0c\u671b\u7814\u7a76antd\u7684\u5927\u5bb6\u591a\u8e29\u8e29\u3002\r\n[git\u5730\u5740](https://github.com/RifeWang/node-react-antd.git)\n Comments: \n Comment 0: \u8d5e\uff0c\u53ef\u4ee5\u56de\u5230\u8fd9\u91cc\u53bb https://github.com/ant-design/ant-design/issues/129\n Comment 1: This thread has been automatically locked because it has not had recent activity. Please open a new issue for related bugs and link to relevant comments in this thread.\n",
  "Issue title: Minimum FASTA File Requirements for Visualization\n Issue body: Hey all,\r\n\r\nI've been wrestling with a problem for the last couple days that I can't seem to resolve alone.\r\n\r\nI'm trying to create a basic visualization with IGV and I'm using an API to create a fasta and fasta.fai both as File type blobs.\r\n\r\nI've formed the content of these files just like any fasta file\r\ni.g. \r\n\n Comments: \n Comment 0: Did you look in the console for errors?  Also, be sure you are using the latest version.\n Comment 1: BTW I don't understand the \"cast\" comment, javascript is typeless there are no casts.\r\n\n Comment 2: If you can zip up a complete working example I will look into it.  Your fasta file looks fine.\n Comment 3: > BTW I don't understand the \"cast\" comment, javascript is typeless there are no casts.\r\n\r\nMy mistake, for context I'm using typescript. \r\nReally what I'm doing is just telling the Blob it is a File. (IGV  says fastaURL and indexURL required the type File.)\n Comment 4: > If you can zip up a complete working example I will look into it. Your fasta file looks fine.\r\n\r\nGot it, I'll hack up a live version for you to look at. Really appreciate the help.\n Comment 5: Actually also \"name\",  here is the actual isFile test\r\n\r\n```\r\nfunction isFile(object) {\r\n    if(!object) {\r\n        return false;\r\n    }\r\n    return typeof object!== 'function' &&\r\n        (object instanceof File ||\r\n            (object.hasOwnProperty(\"name\") && typeof object.slice === 'function' && typeof object.arrayBuffer === 'function'))\r\n}\r\n```\r\n\r\n\n Comment 6: Blob implements slice and arrayBuffer, so my suggestion would be to wrap a Blob in an object with a \"name\" property. \n Comment 7: > Blob implements slice and arrayBuffer, so my suggestion would be to wrap a Blob in an object with a \"name\" property.\r\n\r\nI think I may have done so. My example code was a bit sparse. Here what the object looks like on the console\r\n![Screenshot 2022-06-02 141324](https://user-images.githubusercontent.com/47713674/171698566-3142afd2-a469-484e-be6e-a742f30c4674.png)\r\n.\n Comment 8: Actually I think the problem is with your data,  the fai file columns should be tab delimited.\n Comment 9: > Actually I think the problem is with your data, the fai file columns should be tab delimited.\r\n\r\nYou're right! Thank you so much!\n Comment 10: This works for me\r\n\r\n```\r\n    const igvDiv = document.getElementById(\"igv-div\");\r\n\r\n    class MockFile {\r\n        constructor(str) {\r\n            this.name = \"\"\r\n            this.blob = new Blob([str])\r\n        }\r\n\r\n        slice(start, end) {\r\n            return this.blob.slice(start, end)\r\n        }\r\n\r\n        arrayBuffer() {\r\n            return this.blob.arrayBuffer()\r\n        }\r\n    }\r\n\r\n    const fastaData = \">one\\n\" +\r\n        \"NNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\\n\" +\r\n        \"NNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\\n\" +\r\n        \"NNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\\n\" +\r\n        \"NNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\\n\" +\r\n        \">two\\n\" +\r\n        \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\\n\" +\r\n        \">one_seq1\\n\" +\r\n        \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\\n\" +\r\n        \">one_seq2\\n\" +\r\n        \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAA]n\"\r\n\r\n    const fastaIndex = \"one\\t120\\t5\\t30\\t32\\n\" +\r\n        \"two30\\t149\\t30\\t32\\n\" +\r\n        \"one_seq1\\t30\\t30\\t30\\t32\\n\" +\r\n        \"one_seq2 30\\t90\\t30\\t32\\n\"\r\n\r\n    const fastaBlob = new MockFile(fastaData)\r\n    const indexBlob = new MockFile(fastaIndex)\r\n\r\n\r\n    const options =\r\n        {\r\n            reference: {\r\n                fastaURL: fastaBlob,\r\n                indexURL: indexBlob\r\n            }\r\n        }\r\n\r\n    igv.createBrowser(igvDiv, options)\r\n       .then(function (browser) {\r\n            console.log(\"Created IGV browser\");\r\n        })\r\n\r\n```\n Comment 11: BTW, you don't need an index here, just set indexed: false\r\n```\r\n            reference: {\r\n                fastaURL: fastaBlob,\r\n                indexed: false\r\n            }\r\n```",
  "Issue title: icon for *.nims  file\n Issue body: `*.nims` is a [nimscript](https://nim-lang.org/docs/nims.html) file. It can use a same icon as `*.nim` file.\n Comments: \n Comment 0: Hey @doongjohn. Thanks for the suggestion. I think this would be better handled upstream in the main VSCode extension where we pull icons/mappings from.\r\n\r\nI could be mistaken but I think the necessary change would be [here](https://github.com/PKief/vscode-material-icon-theme/blob/251df153f6bcea76efa6a5fa2721cb3c6dce022e/src/icons/fileIcons.ts#L741). I'd suggest opening a PR upstream adding the `.nims` extension support or opening an issue in that repo for discussion.\r\n\r\nthanks!",
  "Issue title: city shape\n Issue body: how to start?\n\ni don't know actualy hows the ongoing with the city shape, especially if we have the tags back working for \"city\", \"starport\" and \"power\".\nbut i know what we had before and i've played a good old frontier for a while.\nwhat i noticed was that the regions for such types of buildings are wider spread in frontier.\nor to show better in little pics\n\npioneer (last state before disabling of building tags)\n![fig_a](http://i790.photobucket.com/albums/yy187/potsmoke66/help/fig_a.jpg)\nwhile s means all startport buildings incl. the starport, city simply means tagged \"city bld.\" and power reflects \"city power\"\nanyway the regions have overlayed each other by most part.\n\nwhen i look at the cities in frontier the look more like this\n![fig_b](http://i790.photobucket.com/albums/yy187/potsmoke66/help/fig_b.jpg)\nthe starport stands usually alone and groups like city bld., industry or suburban regions are gathered together overlaying each other only slightly and keeping the starport always off the center of the city.\n\nthis just to invoke some ideas\n\n Comments: \n Comment 0: Closing, due to image url's are borken, and without them the intent is not really clear. And the city generator needs quite more detailed and planned out love in general.",
  "Issue title: Ripme downloads nothing even if the links it gets are ok\n Issue body: I used Ripme before and it worked well but i don't know why it isn't working now...\n![unbenannt](https://cloud.githubusercontent.com/assets/20015062/16171713/67b93020-3576-11e6-9888-73bd157a8e28.png)\nWhen I try to download anything, I get an error that it failed the DL but i don't know why because the image link is right there.\nAnd When i try to copy and paste the link in my browser, I can see the Image (The \"Only Image\" link).\n![unbenannt2](https://cloud.githubusercontent.com/assets/20015062/16171733/007ed6e8-3577-11e6-9b54-627f3573723e.png)\nAnyone a clue?\n![unbenannt3](https://cloud.githubusercontent.com/assets/20015062/16171737/26feaa46-3577-11e6-91b5-e1a44f20b992.png)\nI tried 4 sites and I always got the same error...\n\n Comments: \n Comment 0: I found the problem...\nThe Save Directory was set to a wrong location that doesn't exist...\n",
  "Issue title: Merging state with lodash\n Issue body: This works:\r\n\r\n    (state, {result}) => {\r\n      state.myData = result.data.myData\r\n      return state\r\n    }\r\n\r\nThis doesn't work:\r\n\r\n    (state, {result}) => _.merge(state, result.data)\r\n\r\nSomehow the first example triggers a render of my component. But the second doesn't, even if the redux-dev-tools show that data is there.\n Comments: \n Comment 0: [`_.merge` is mutative](https://lodash.com/docs#merge). You should never mutate the state in Redux.\r\nThis should work: `_.merge({}, state, result.data)`.\n Comment 1: I see, but wasn't my first example mutative too?\n Comment 2: It was. It's hard to say why it worked without seeing the whole app. Either way don't mutate the state :-). \n Comment 3: I switched to lodash.merge because I wanted to avoid mutation, but then everything broke, haha\r\n\r\nThank you for the quick help :)\n Comment 4: @gaearon @kay-is I'm learning much about working in an immutable way. How do you deal with nested objects? `_.merge()` will not remove objects or key/value pairs.\n Comment 5: @chandlervdw can you elaborate on what you would expect `_.merge` to remove? It's an additive operation, so it shouldn't ever leave you with less than you started with!\n Comment 6: @jmeas I just learned that it's additive! So, `_.extend()` seems to be what I want but I want to ensure that I'm understanding things correctly and am learning the right paradigm. If I've got an object which contains an array of key/value pairs, and I want to update the state of that array upon removal of one of those pairs, is `_.extend()` the best approach? It works, I just don't see it being used by anyone else in the redux community. What am I missing?",
  "Issue title: Unoptimized code too big for 32-bit linker\n Issue body: So the `auto-mac-32-nopt` build slave failed trying to link librustc.dylib. The error being `LLVM ERROR: Section too large, can't encode r_address (0x10007fc) into 24 bits of scattered relocation entry.` which I interpret as being too big for the linker to handle.\n\n Comments: \n Comment 0: cc @graydon \n\nI think we'll have to disable the 32-bit no-opt bots for now.\n\n Comment 1: Maybe this will be resolved after a snapshot.\n\n Comment 2: Seems resolved to me; auto-mac-32-nopt seems to be enabled.\n\n Comment 3: @catamorphism: I don't think the 64-bit one is enabled but not 32-nopt: http://buildbot.rust-lang.org/builders\n\n Comment 4: Both of the Mac 32-nopt builders seem to be enabled now:\n\nhttp://buildbot.rust-lang.org/builders/auto-mac-32-nopt-c\n\nhttp://buildbot.rust-lang.org/builders/auto-mac-32-nopt-t\n\nClosing.\n",
  "Issue title: wrong tid in cta_launch with non power of two NT\n Issue body: using cta_launch with NT not being a power of two results in wrong tid values passed to the lambda. simple test case:\n\n``` cpp\nstatic const int NT = 96\nmgpu38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5ta_launch<NT>([=] MGPU_DEVICE (const int tid, const int block) {\n      printf(\"thread %d %d %d\\n\", threadIdx.x, tid, threadIdx.x & (NT - 1));\n}, 1, ctx);\n```\n\nFor NT = 32, 64 and 128 this works fine. However setting NT to any multiple of 32 should be valid, right?\n\n Comments: \n Comment 0: That's a good point. I should definitely change that. Started off only supporting powers of two because I wasn't sure if all the algorithms I wrote would work on those odd CTA sizes. But I should relax that restriction for cta_launch and transform etc, and static_assert inside non-supported functions if I need to. Will roll that fix out in the next update. Thx.\n Comment 1: Fixed in the 2.10 push. Let me know if you have problems with it.\n Comment 2: works fine now, thanks for the fix",
  "Issue title: [VFS] Google Drive\n Issue body: This was split out from #9 \n- [x] Basic VFS abstraction (like scandir, read write etc)\n- [x] Add support for trash\n- [x] Add support to recover from trash\n- [x] Add support to empty trash\n- [ ] Implement Trash into FileView\n- [ ] Add support for modifying permissions\n- [ ] Add support for modifying properties\n- [ ] Add support for comments\n- [ ] Add support for revisioning\n- [ ] Support for multiple accounts\n- [ ] Look into error reports: #193\n- [x] Sometimes getting \"cannot do X\" because of \"missing file id\"\n- [ ] Search/Find function\n- [ ] `freeSpace()` support\n\n Comments: \n Comment 0: I'm not sure this is the right place to put this, but I can't open Google Drive. I get a dialog box that pops up displaying \"Failed to scan directory: Could not list directory\" I tried running both the development and production server. Neither work. I'm running Node with an Apache2 proxy on Ubuntu 16.10 Server. The Apache2 site is running on HTTPS. [Attached is the log from a development mode server viewed in Firefox](http://pastebin.com/HVEKcLvD)\n Comment 1: @Mstrodl Thanks for reporting!\r\n\r\nSeems like I made a mistake last month in the update, which has now been corrected :)\n Comment 2: Closing this issue because it will be separated into https://github.com/os-js/osjs-google-vfs when v3 comes along.",
  "Issue title: Do posts get updated when using get_hashtag_posts?\n Issue body: Hello,\r\n\r\nI was wondering if posts meta-data is updated when using the get_hashtags_posts function? I want to update likes and comments count if the post already exists.\r\n\r\nThanks! \n Comments: \n Comment 0: `get_hashtag_posts` does not write or update anything. It is a generator of `Post` instances of the posts that are currently returned for the given hashtag.\r\n\r\nWhen using the Instaloader CLI, the json files and the txt metadata files are updated with each run. There is a feature suggestion, #224, to provide a way to control this behavior.",
  "Issue title: please update type definition for typescript user\n Issue body: Hi there,\r\n\r\nI reference https://zimjs.com/typescript.html to start my ZIMjs project.\r\nI find out some typing is not correct. like...\r\n\r\n```\r\n// zim/index.d.ts\r\nexport function zimify(obj:createjs.DisplayObject, list:boolean):DisplayObject\r\n```\r\n\r\nI follow this typing to write code.\r\n\r\n```\r\nconst exportRooot: createjs.MovieClip =...\r\nconst zContainer = zimify(exportRoot, false);\r\nzContainer.setBounds(0,0,stageW,stageH).center();\r\n```\r\n\r\nIt doesn't work. Because zContainer is null. And I change my code to...\r\n\r\n```\r\nconst exportRooot: createjs.MovieClip =...\r\nconst zContainer = zimify(exportRoot);\r\nzContainer.setBounds(0,0,stageW,stageH).center();\r\n```\r\n\r\nIt work well. But zimify function typing definition is not existed.\r\n\r\nI know maintain typing definition is hard and boring.\r\nSo..Could you update ZIMjs typing definition or let me send \"pull request\" etc.\r\n\r\nThanks.\r\n\n Comments: \n Comment 0: Hi @BibbyChung - thanks.  The second parameter should have been optional so we have updated the Typings at https://zimjs.com/typescript.html - thanks for letting us know.  And thanks for the note at https://zimjs.com/slack - it is always helpful for a quick response.  ",
  "Issue title: Sunburst Zooming in nvd3 1.8.5 version for last record we get random Incomplete circle.\n Issue body: here is the plunker.\r\nhttp://plnkr.co/edit/F7jBdN5nR8VoFrvzk4iW?p=preview\r\n\r\nInitially  \r\n![six screen 1](https://user-images.githubusercontent.com/5784023/30022989-52e2eed0-918b-11e7-8385-ebec112d6b95.png)\r\n![six screen](https://user-images.githubusercontent.com/5784023/30022990-53063fac-918b-11e7-9392-4cf939a1d506.png)\n Comments: \n Comment 0: Well that's weird!  If you can figure out a fix, please be sure to send us a pull request! \n Comment 1: is it nvd3 or angular-nvd3? if angular-nvd3, you may have to raise the issue with that team?\r\n\r\nAlso looks like the code works fine in mozilla firefox and not properly working in chrome..",
  "Issue title: Integrating UMap into OSM.org portal\n Issue body: I had the idea [to integrate UMap service into OSM.org portal](https://github.com/openstreetmap/openstreetmap-website/issues/1056) to make it more useful tool for the users. \r\n\r\nThere is still no definitive answer if it is considered at all and what specific problems need to be solved (or even [what are the design goals and limits of the portal](https://github.com/openstreetmap/openstreetmap-website/issues/1038)), but I'd like to ask if there is any production server ready to be integrated somehow with it? Or maybe there are some plans to do so in the future?\n Comments: \n Comment 0: I know this is discussed from time to time, but I've no personal opinion on this.\n Comment 1: The bottom line is not clear for you (what are the gains and problems then?) or you're just not much into it?\n Comment 2: See [this remark](https://github.com/openstreetmap/openstreetmap-website/issues/1056#issuecomment-156369810) about debugging \"hidden\" data using UMap.\n Comment 3: I would be happy to replace \"share link\" with \"umap\" link. Not only it provides more feature, it more intuitive to use and provides more instructions.\r\n\r\n\"Image download\" section is especially penny97@example.com.",
  "Issue title: Android crash, invalid fragment\n Issue body: java.lang.RuntimeException: Unable to start activity ComponentInfo{dk.bearware.gui/dk.bearware.gui.PreferencesActivity}: java.lang.RuntimeException: Subclasses of PreferenceActivity must override isValidFragment(String) to verify that the Fragment class is valid! dk.bearware.gui.PreferencesActivity has not checked if fragment dk.bearware.gui.PreferencesActivity$GeneralPreferenceFragment is valid.\nat android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2404)\nat android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2464)\nat android.app.ActivityThread.access$900(ActivityThread.java:172)\nat android.app.ActivityThread$H.handleMessage(ActivityThread.java:1308)\nat android.os.Handler.dispatchMessage(Handler.java:102)\nat android.os.Looper.loop(Looper.java:146)\nat android.app.ActivityThread.main(ActivityThread.java:5653)\nat java.lang.reflect.Method.invokeNative(Native Method)\nat java.lang.reflect.Method.invoke(Method.java:515)\nat com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1291)\nat com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1107)\nat dalvik.system.NativeStart.main(Native Method)\nCaused by: java.lang.RuntimeException: Subclasses of PreferenceActivity must override isValidFragment(String) to verify that the Fragment class is valid! dk.bearware.gui.PreferencesActivity has not checked if fragment dk.bearware.gui.PreferencesActivity$GeneralPreferenceFragment is valid.\nat android.preference.PreferenceActivity.isValidFragment(PreferenceActivity.java:1334)\nat android.preference.PreferenceActivity.switchToHeaderInner(PreferenceActivity.java:1647)\nat android.preference.PreferenceActivity.switchToHeader(PreferenceActivity.java:1687)\nat android.preference.PreferenceActivity.onCreate(PreferenceActivity.java:784)\nat android.app.Activity.performCreate(Activity.java:5539)\nat android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1093)\nat android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2368)\n\n Comments: \n Comment 0: Fixed in c8eaa16fb93becd3ff01463c99a21437c3ee4c26\n",
  "Issue title: just call ape app\n Issue body: app is three letters so it fits the pattern. ape has the potential to be confusing and its counterparts cat and dog are gone. There's no need to be cute here. \n Comments: \n Comment 0: +1\n Comment 1: Merging cat/dog, was, of course, a mistake. This needs to be on the public record. Otherwise, +1.\n Comment 2: I think the tradeoff there of \"you now only have to look in one place to\nfind out what |foo does\" was worth it, but perhaps something like\ncat/hood/foo/hoon -> gen/hood/foo/cat/hoon would have been better than the\ncurrent :- solution. In general, this seems to be an argument towards a\ntag-based and not hierarchical file system structure :P\n\nOn Tuesday, December 1, 2015, Raymond Pasco justin76@example.org\nwrote:\n\n> Merging cat/dog, was, of course, a mistake. This needs to be on the public\n> record. Otherwise, +1.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/urbit/urbit/issues/604#issuecomment-160998399.\n\n Comment 3: I mean, we do have hymn.hook as precedent. And as anti-precedent, mar, lib, and sur. I just think it's weird to specify it as boilerplate. I did kinda like separate dojo sigils for them.\n\n Comment 4: Sadly, urbit is a bit too invested into 90s filesystem layout to switch over to a tag based system :(\nI was a fan of the separate dog/cats too, BTW. It makes sense from a security standpoint where compatabilies are known when you run the command instead of having to check the first cons in a source file. Definitely in favor of renaming apes, regardless.\n\nThe fact that webhooks have no only a magic file extension, but also a magic file _name_ is pretty terrible. Like, really terrible.\n\n Comment 5: hymn is, of course, a mark. Whether it's a good one is another story.\n\n Comment 6: Fixed in 2d565e75d0\n",
  "Issue title: purpose use\n Issue body: had a few basic questions + clarifications \r\n\r\n1. whats main purpose of this? is it ideally meant to replace html?\r\n2. whats practical use of this currently? or is it just demo?\r\n3. does this solve the porblem of being able to read css + html? if 99% of ppl are using regular html + css, then if anyone learned this instead of css + html, then wont they not be able to read regular css + html?\r\n4. for the 99% of ppl on the web in world that knows nothing about css + html, what are the requiremnts / prerequites to learn this thing? i assume there's no beginner guide for many of these things ppl make\r\n\r\n\n Comments: \n Comment 0: The [htmx website](htmx.org) is pretty self-explanatory -- \" htmx adds [AJAX](https://htmx.org/docs#ajax), [CSS Transitions](https://htmx.org/docs#css_transitions), [WebSockets](https://htmx.org/docs#websockets) and [Server Sent Events](https://htmx.org/docs#sse) directly into HTML, using attributes...\" instead of using Javascript.  So, htmx does not replace HTML.  It is a series of extensions to HTML that make it easier to do AJAX calls on every element -- not just `<a>` and `<form>` elements.  If you understand HTML+CSS, then you already understand htmx -- you now just have a few extra abilities to work with.\r\n\r\nhtmx is still pretty new (just hit v1.0) so most applications that use it are still works in progress.  I believe the [Sprig plugin for Craft CMS](https://github.com/putyourlightson/craft-sprig) is a good example of production code that uses htmx.\r\n\r\nThis does not \"solve the problem of being able to read css + html\" -- this solves the problem of squeezing UI components into Javascript + JSON, then trying to render it as HTML via huge Javascript libraries.  Instead, your server renders HTML and your clients' browsers load and display that.\r\n\r\nThere are a number of demos, docs, and examples on the [htmx website](htmx.org).  I wouldn't say it's for beginners who don't know HTML or CSS.  You should probably understand those basics first.  However, the learning curve for htmx should be much easier than client-side Javascript frameworks (Angular, React, Vue) because you don't *also* have to know Javascript to use htmx.\r\n\r\nI'm teaching htmx to an 11-year-old, if that helps.  But, I doubt it could be explained to a 4-year-old, because they lack the necessary prerequisites of understanding web browsers, HTML, etc.  You should wait until they're at least 5 or 6, and are able to type before you try to teach htmx to children. \ud83d\ude05\r\n\r\nI hope this is helpful.  By the way, there's now an [HTMX tag on Stack Overflow](https://stackoverflow.com/questions/tagged/htmx).  Q&A discussions would probably be better on that forum :)\n Comment 1: Great answer, thanks @benpate.\r\n\r\nAgree this is probably better a StackOverflow question.",
  "Issue title: The wizard's \"Teleport\" spell allows posibrains to escape\n Issue body: Leads to immortal brains teleporting around and setting everyone on fire.\n Comments: \n Comment 0: this is a problem why? Its a :package: of hate, using sheer hatred to kill everyone :P\n\n Comment 1: #4981 \n",
  "Issue title: Bubble up log errors into KSQL show commands\n Issue body: I had an Avro error that showed up in the KSQL log files.  \r\n\r\nHowever, aside from the lack of stats in `EXPLAIN QUERY`, I couldn\u2019t find indication in KSQL CLI that this Avro error had occurred. Can we bubble something up into `EXPLAIN QUERY` that counts number of exceptions, or gives any indication that something might be wrong?\n Comments: \n Comment 0: +1 this is not a nice user experience, particularly for people new to KSQL (and maybe Kafka in general). \r\n\r\nIf I CTAS/CSAS from `ksql>` I expect to see some kind of message that the resulting query died, at a very minimum. \r\n\r\nBetter would be this, plus showing the state of the query (e.g.  `ABORTED` or whatever the term would be) in `DESCRIBE EXTENDED` as well as `EXPLAIN`. \r\n\r\nEven better would be a console warning if I try to select from an object into which the source query is dead.",
  "Issue title: Termux Wiki\n Issue body: Current [Termux Wiki](https://wiki.termux.com) has two main issues:\r\n* There very few contributions from users.\r\n* Pages sometimes getting filled with spam, unrelated & inappropriate content (hopefully not illegal).\r\n\r\nI don't review Wiki editing history every day and thus can't revert changes made by malicious actors. I can lock down page editing, but that means Wiki will not be editable by users. On other hand as I already stated, there very few contributions from users which means that Wiki is rarely updated.\r\n\r\n@agnostic-apollo has already proposed to move Wiki to GitHub Pages, which has number of benefits over current solution including possibility to review user contributions.\r\n\r\nWhat do you think about replacing Termux Wiki with GitHub Pages site? @Grimler91 @Neo-Oli @fornwall \n Comments: \n Comment 0: Wow! That's good \ud83d\udc4d. So now devs can prevent the trash content and more people can contribute it!\n Comment 1: Check related issue #8320 for malicious editing.\r\n\r\nMoreover, maintaining wiki info in app github READMEs and wiki and also on termux.wiki site creates duplication. termux.wiki site has lot of outdated info. Everything should be hosted in one place, preferably github due to granular control of who has access, reviewing changes and markdown support. I am not even sure if that wiki site is even backed up by someone, other than neo, github would be much better for that too.\r\n\r\nThe way I am currently designing is that each app repo will have a `docs` directory in which app specific documentation would exist. Only some important files (minimize space usage) from the `docs` directory will also be shipped with each app in apk `assets` directory to allow offline viewing with `build.gradle` filtering tasks, specially for people who don't have access to internet at all times or have low data limits. The `termux-app` settings will have an option to open docs for each app. The assets directories of other plugins should be accessible due to `sharedUserId` if plugin `Context` is passed to `AssetManager`. The doc files will dynamically add the links to the latest github version file at the top since assets files may be old. Those links and files that are not shipped with the apk will be opened in a webview inside the app directly from github. Users can open in browser too from options.\r\n\r\nSupport for full documentation download can be added too later, which can be downloaded to `~/.termux/docs`. Markdown navigation is also supported to jump to different files via relative links, just like on github. Technically, any git repo on local filesystem would be viewable via the API I am adding for the media viewer, although API would just be experimental in next release since it needs more work internally and changes would likely be required. It's complicated, I am not sure of the best way to implement that yet, since further future APIs need to be added too, with different reqs.\r\n\r\nSo now that each app will have a `docs` directory which can be updated while features are being added instead of separately later, which often isn't done quickly (like by me), the https://github.com/termux/termux.github.io will host rest of the documentation that is hosted on termux wiki site, etc. The app specific `docs` directory will be added as git submodules so that they are accessible too from the github pages site termux.github.io.\r\n\r\nhttps://docs.github.com/en/pages/getting-started-with-github-pages/using-submodules-with-github-pages\r\n\r\nHopefully, this design should work. Most of it is working locally for me. There are some things left that need to be implemented like a file manager support so that specific files can be manually opened or `view as` option to allow user to decide how he wants to open the file `markdown`/`text`/`image`/`webview` or external. There are obviously so many `mime` types/ file extensions, so user will have to decide for most of them themselves, and all wouldn't be viewable anyways, at least currently like audio/video, etc. Moreover, need to add support to jump to markdown headings when links are clicked or new files with url fragment opened.\n Comment 2: ### Some stats\r\nI pulled out the latest stats. They could be useful in this discussion.\r\nIn the **last two weeks** the Wiki had **92,442 unique visitors** and **1,480,057 total requests**. That's about 6,000-7,000 visitors a day with 80,000-90,000 requests each day.\r\nCurrently there are **332 pages** (including User pages). \r\n\r\nWe had a big issue with spam pages in the early days. That's why new users can't create new Pages unless approved by a moderator (which sort of defeats the point of having a wiki). There are currently **13,294 registered users**, though most of them are spam accounts. \r\n\r\n### Some history\r\nWe moved from Github pages to the dedicated MediaWiki in July 2017. It has steadily grown in both requests and content since then. The great surge of user contributions we were hoping for back then never really manifested and most of the content was written by just a few people, most of them very active contributors already. \r\n\r\n### Some technical issues\r\nI'm hosting the wiki on a very small virtual server on which I also host my personal websites and the personal websites of a few of my friends. The wiki has very much outgrown this setup. It is by far the largest site there. A few months ago I added a cache in front of the wiki which helped a lot with page speed and server resource usage. The wiki should probably be moved to a dedicated server with more resources sometimes soon.\r\n\r\nRight now I am the only person who has access to this server, which isn't a good situation. In case I became unavailable no one else could upgrade or fix the wiki. \r\nI too don't check on the wiki every day, so if there is spam it might sit there for a while. I do have a monitoring set up, so if it goes down entirely it is usually solved in a few mccarthyalejandro@example.org. \r\n\r\n### Some conclusion\r\nWe'd need more moderators, more people with server access and a better server if we were to continue using the MediaWiki for a lot longer.\r\n\r\nI think, moving the help pages back to GitHub pages would be a good way to alleviate some or most of these issues. I think the original rationale for moving to a MediaWiki no longer applies today. @agnostic-apollo's proposed setup sounds very fancy.\r\n\r\n### Some notes about migrating\r\nThere are a lot of blog posts, forum posts and other websites that link to pages in the wiki. We should probably create a jumphost at `wiki.termux.com` that redirects the old content to the new.\r\n\r\nThe wiki is also reachable via https://termux-wiki.glow.li/wiki/Main_Page. So while we move it can still be reached using that link, even after we switch over the wiki.termux.com to the new solution. This could be useful for transferring over the information.\r\n\n Comment 3: I remade the Termux Wiki in Next.js here https://github.com/leapofazzam123/termux-wiki.git https://termux-wiki.vercel.app\n Comment 4: One spam is still there on package Management Page.\r\n![termux2](https://user-images.githubusercontent.com/37567788/147350139-f8b900b7-729f-4c2f-85c4-7e7c8ee401ea.jpg)\r\n\n Comment 5: Thanks, previous content has been recovered.\n Comment 6: > I remade the Termux Wiki in Next.js here\r\n\r\n@leapofazzam123 That's good and you can keep your wiki variant up. But our solution should be simple and don't use any additional hostings. GitHub Pages is best variant there.\n Comment 7: I guess so\n Comment 8: Add wiki termux  random article \n Comment 9: I think it is an excellent idea, but in what format will we keep the web pages?, in html or Markdown? \n Comment 10: > in what format will we keep the web pages?, in html or Markdown?\r\n\r\nMarkdown, since that is the standard almost everywhere and is human friendly and easy to write.\n Comment 11: Excellent! \n Comment 12: Can someone give me access to edit wiki.termux? I want to write an article on how to create and configure an AUR for termux.\n Comment 13: I would also like to have access, if you want, I can bring interesting content for the x11 area (graphical environment) \n Comment 14: @Maxython @Yisus7u7 Have you already created User accounts?\r\n\n Comment 15: > @Maxython @Yisus7u7 Have you already created User accounts?\r\n\r\nYes, I have (https://wiki.termux.com/wiki/User:Maxython)\n Comment 16: > @Maxython @Yisus7u7 Have you already created User accounts?\r\n\r\nYes, https://wiki.termux.com/wiki/User:Yisus7u7v \n Comment 17:",
  "Issue title: missing /etc/fonts/font.conf\n Issue body: *Please omit irrelevant data and trim the bug report template to only those parts that make sense!*\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\nI dont know if this really is a bug, but I got nowhere else to ask about this. So I opened this issue here.\r\n\r\nfonts.conf is  missing. It is not in the /etc/fonts directory\r\n\r\n**Environment (please complete the following information):**\r\n - Clear Linux OS version: [`cat /usr/lib/os-release`]\r\n - Bundles: [e.g. `sudo swupd bundle-list`]\r\n\r\nVERSION=1\r\nID=clear-linux-os\r\nID_LIKE=clear-linux-os\r\nVERSION_ID=28970\r\nPRETTY_NAME=\"Clear Linux OS\"\r\nANSI_COLOR=\"1;35\"\r\nHOME_URL=\"https://clearlinux.org\"\r\nSUPPORT_URL=\"https://clearlinux.org\"\r\nBUG_REPORT_URL=\"mailto:ruizkristen@example.net\"\r\nPRIVACY_POLICY_URL=\"http://www.intel.com/privacy\"\r\n\r\nBabel\r\nNetworkManager\r\nNetworkManager-basic\r\nR-basic\r\nR-datasets\r\nR-extras\r\nR-stan\r\nSphinx\r\nacpica-unix2\r\nalsa-utils\r\nbaobab\r\nbc\r\nbinutils\r\nbison\r\nbootloader\r\nc-basic\r\ncabextract\r\nccache\r\nceph\r\ncheese\r\ncloc\r\ncloud-api\r\nclr-network-troubleshooter\r\ncomputer-vision-basic\r\ncomputer-vision-models\r\ncontainers-basic\r\ncpio\r\ncryptography\r\ncurl\r\ndatabase-basic\r\ndesktop\r\ndesktop-apps\r\ndesktop-assets\r\ndesktop-autostart\r\ndesktop-gnomelibs\r\ndesktop-locales\r\ndev-utils\r\ndev-utils-dev\r\ndeveloper-gpu\r\ndevpkg-LVM2\r\ndevpkg-NetworkManager\r\ndevpkg-R\r\ndevpkg-SDL\r\ndevpkg-SDL2\r\ndevpkg-SDL2_gfx\r\ndevpkg-SDL2_image\r\ndevpkg-SDL2_mixer\r\ndevpkg-SDL2_net\r\ndevpkg-SDL2_ttf\r\ndevpkg-SDL_gfx\r\ndevpkg-SDL_image\r\ndevpkg-SDL_mixer\r\ndevpkg-SDL_net\r\ndevpkg-SDL_ttf\r\ndevpkg-acl\r\ndevpkg-alsa-lib\r\ndevpkg-apr\r\ndevpkg-apr-util\r\ndevpkg-at-spi2-atk\r\ndevpkg-at-spi2-core\r\ndevpkg-atk\r\ndevpkg-attica\r\ndevpkg-attr\r\ndevpkg-audit\r\ndevpkg-base\r\ndevpkg-bluez\r\ndevpkg-boost\r\ndevpkg-cairo\r\ndevpkg-clutter\r\ndevpkg-cmrt\r\ndevpkg-cogl\r\ndevpkg-colord\r\ndevpkg-compat-enchant-soname1\r\ndevpkg-compat-fuse-soname2\r\ndevpkg-cryptsetup\r\ndevpkg-curl\r\ndevpkg-cyrus-sasl\r\ndevpkg-dbus\r\ndevpkg-dbus-glib\r\ndevpkg-e2fsprogs\r\ndevpkg-elfutils\r\ndevpkg-enchant\r\ndevpkg-exiv2\r\ndevpkg-expat\r\ndevpkg-fann\r\ndevpkg-fftw\r\ndevpkg-flac\r\ndevpkg-font-util\r\ndevpkg-fontconfig\r\ndevpkg-freeglut\r\ndevpkg-freetype\r\ndevpkg-fribidi\r\ndevpkg-fuse\r\ndevpkg-gcr\r\ndevpkg-gdk-pixbuf\r\ndevpkg-gflags\r\ndevpkg-glib\r\ndevpkg-glog\r\ndevpkg-glu\r\ndevpkg-gmime\r\ndevpkg-gnutls\r\ndevpkg-gobject-introspection\r\ndevpkg-googletest\r\ndevpkg-gperftools\r\ndevpkg-graphite\r\ndevpkg-graphviz\r\ndevpkg-gsl\r\ndevpkg-gst-plugins-base\r\ndevpkg-gstreamer\r\ndevpkg-gtk\r\ndevpkg-gtk-doc\r\ndevpkg-gtk3\r\ndevpkg-gtkplus\r\ndevpkg-guile\r\ndevpkg-harfbuzz\r\ndevpkg-hwloc\r\ndevpkg-icu4c\r\ndevpkg-ipmctl\r\ndevpkg-ipset\r\ndevpkg-iptables\r\ndevpkg-iso-codes\r\ndevpkg-json-c\r\ndevpkg-json-glib\r\ndevpkg-kmod\r\ndevpkg-krb5\r\ndevpkg-lcms2\r\ndevpkg-libX11\r\ndevpkg-libXScrnSaver\r\ndevpkg-libXau\r\ndevpkg-libXcursor\r\ndevpkg-libXdamage\r\ndevpkg-libXdmcp\r\ndevpkg-libXext\r\ndevpkg-libXfixes\r\ndevpkg-libXft\r\ndevpkg-libXmu\r\ndevpkg-libXpm\r\ndevpkg-libXres\r\ndevpkg-libXt\r\ndevpkg-libXtst\r\ndevpkg-libXv\r\ndevpkg-libXvMC\r\ndevpkg-libXxf86misc\r\ndevpkg-libXxf86vm\r\ndevpkg-libabigail\r\ndevpkg-libarchive\r\ndevpkg-libassuan\r\ndevpkg-libcanberra\r\ndevpkg-libcap\r\ndevpkg-libcap-ng\r\ndevpkg-libcgroup\r\ndevpkg-libcroco\r\ndevpkg-libdatrie\r\ndevpkg-libdrm\r\ndevpkg-libepoxy\r\ndevpkg-libevdev\r\ndevpkg-libevent\r\ndevpkg-libffi\r\ndevpkg-libfontenc\r\ndevpkg-libgd\r\ndevpkg-libgpg-error\r\ndevpkg-libgudev\r\ndevpkg-libgusb\r\ndevpkg-libical\r\ndevpkg-libidn\r\ndevpkg-libidn2\r\ndevpkg-libinput\r\ndevpkg-libjpeg-turbo\r\ndevpkg-libmicrohttpd\r\ndevpkg-libmnl\r\ndevpkg-libmspack\r\ndevpkg-libndp\r\ndevpkg-libnetfilter_conntrack\r\ndevpkg-libnetfilter_cthelper\r\ndevpkg-libnetfilter_cttimeout\r\ndevpkg-libnetfilter_queue\r\ndevpkg-libnfnetlink\r\ndevpkg-libnftnl\r\ndevpkg-libnl\r\ndevpkg-libnotify\r\ndevpkg-libogg\r\ndevpkg-libpcap\r\ndevpkg-libpciaccess\r\ndevpkg-libpipeline\r\ndevpkg-libpng\r\ndevpkg-libpsl\r\ndevpkg-libpthread-stubs\r\ndevpkg-librepo\r\ndevpkg-librsvg\r\ndevpkg-libsamplerate\r\ndevpkg-libseccomp\r\ndevpkg-libsecret\r\ndevpkg-libsolv\r\ndevpkg-libsoup\r\ndevpkg-libssh2\r\ndevpkg-libtasn1\r\ndevpkg-libthai\r\ndevpkg-libtirpc\r\ndevpkg-libunwind\r\ndevpkg-libusb\r\ndevpkg-libuser\r\ndevpkg-libva\r\ndevpkg-libvirt\r\ndevpkg-libwebp\r\ndevpkg-libxcb\r\ndevpkg-libxkbcommon\r\ndevpkg-libxml2\r\ndevpkg-libxslt\r\ndevpkg-libzip\r\ndevpkg-llvm\r\ndevpkg-lua\r\ndevpkg-lz4\r\ndevpkg-mariadb\r\ndevpkg-mesa\r\ndevpkg-metrics-discovery\r\ndevpkg-mozjs52\r\ndevpkg-multipath-tools\r\ndevpkg-ncurses\r\ndevpkg-ndctl\r\ndevpkg-nettle\r\ndevpkg-newt\r\ndevpkg-nftables\r\ndevpkg-nghttp2\r\ndevpkg-nspr\r\ndevpkg-nss\r\ndevpkg-ntfs-3g\r\ndevpkg-oath-toolkit\r\ndevpkg-open-iscsi\r\ndevpkg-opencv\r\ndevpkg-openmpi\r\ndevpkg-openssl\r\ndevpkg-openvswitch",
  "Issue title: 2sxc Does not report Error on Failed File Uploads\n Issue body: **I'm submitting a...**\r\n[x] bug report \r\n\r\n**...about**   \r\n[x] edit experience / UI\r\n[x] admin experience UI\r\n\r\n**Current behavior**   \r\nWhen a normal DNN user is logged, in a Role (e.g. Content Manager) and has Edit permissions (at the Page or Module level), and they try to drag n drop upload a ZIP file in it fails with NO error reported (no console error and no error in DNN Admin Logs).\r\n \r\nIf you immediately try a JPG instead, it just works.\r\n \r\nAs the person configuring the 2sxc App, without knowing the real problem/solution (need to add *.zip files to DNN's Settings/Security/More/More, **Default End User Extension Whitelist**), the problem seems like a Permissions issue.\r\n \r\nThis becomes a major issue when your use-case is: a logged in user with View (not Edit) permissions needing to do the same type of drag n drop upload to the content-type field. Since the.Zip doesn't work, and there is no error, you end up trying dozens of permissions additions/combinations, changing/testing other possibly related settings, turning Patron features on/off, and nothing seems to work and no errors. This can waste (has wasted) lots of time, cause frustration, and will probably result in false or confusing bugs reports about permission problems.\r\n\r\n**Expected behavior** \r\nThe standard content-type record Edit UI (Angular) needs to be able to detect and report (bubble up) the correct error to the user.\r\n\r\n**Instructions to Reproduce the Problem**\r\nThis is easy to reproduce. Tried it on a 2sxc v13.12.x site as well as v14.7.4.\r\n \r\nJust use the Content App (or make an App with a content-type that has a field named ZipUpload of data type Hyperlink). Log in as a user in a Role (not Admin or Host) that you've already given Edit permissions to. Confirm *.zip is not already added to the Default End User Ext Whitelist. \r\n\r\n**Why change the behavior?**  \r\nGet something easy and logical done in 1 to 2 minutes instead of 30 to 60 minutes and failing. :)\r\n\r\n**Your environment**  \r\n\r\n* **2sxc version(s):** 14.07.04 and same on v13.12.x and probably older versions\r\n* **Browser:** all\r\n* **DNN:** all (only tried on 9.10.02)\r\n* **Language:** any/all\r\n\r\n**Anything you would like to add**\r\nHoping you agree this is worth fixing in both v14 AND the v13 LTS.\n Comments: \n Comment 0: Hi @jeremy-farrance, thx for reporting this issue \ud83d\udc4c.\r\nI can confirm that I reproduced this issue in DNN 9.6.1 (and DNN 9.10.2) with latest 2sxc v14.07.04 LTS.\r\nYes, the issue is that user notification is missing in UI on ADAM file upload exceptions.\r\nIt is expected to be fixed in future 2sxc versions.\n Comment 1: Hello @tvatavuk - Version v14.07.04 LTS works perfectly for the file upload. However, v13.12.01 LTS does not work. I was trying to upload a 342 kb jpeg. The message that I got back is:\r\n\r\n**Success: false, Error: \"file too large - more than 2097152Kb\u21b5file too large - more than 2097152Kb\",\u2026**\r\n\r\nPlease see the screen shot:\r\n![Screenshot 2022-08-08 161244](https://user-images.githubusercontent.com/3846223/183506034-d256c8ed-b768-4dfb-a2f5-74061a398f2f.jpg)\r\n\r\nI will also add the file that I tried to upload. There is nothing extraordinary about it:\r\n![Smith-KM](https://user-images.githubusercontent.com/3846223/183506226-b740245d-e282-4641-a05b-656234fd6380.jpg)\r\n\r\nHere are my details:\r\n\r\nCMS - 2sxc v.13.12.01\r\nPlatform - Dnn v.09.10.02\r\n\r\nPlease let me know if you need any more information or if it would be helpful for me to run other tests.\r\n\n Comment 2: Hi @skarpik and thx for more details.\r\nUsing your test example I was trying to reproduce your specific issue again in clean new install of DNN 9.10.2 + 2sxc 13.12.01 LTS but still no success :-(.\r\n![image](https://user-images.githubusercontent.com/2724850/183613911-bffc91d5-414e-40a5-829b-2afe36593c7d.png)\r\n\r\nBased on details you provided I can pin point to [exact line of code](https://github.com/2sic/2sxc/blob/b586a2a002ff1d604eb73b733a487c04403ab1fc/Src/Sxc/ToSic.Sxc.WebApi/Adam/AdamTransUpload.cs#L84) where this exception happens and this code is the same for v13.12.01 LTS and v14.07.04 LTS.\r\n\r\nFile upload stream for some reason return wrong byte length in your environment (> 2GB) and that is unexpected for many reasons. First you are uploading jpg image of 342 kb that is much less than 2GB. Also streams of more than 2GB should not be possible with **buffered stream** that are used in 2sxc as common default. There are also other reasons. Still more users reported the same issue, so there is something off that we are missing and that we need to find and solve. \r\n\r\nBecause I still do not see issue with in 2sxc code, is it possible there is something specific or non-standard in your computer enviroment, like antivirus or firewall or some other network layer that could affect/block/change HTTP POST that to intrcept data to `/api/2sxc/app/auto/data/...` webapi endpoint? \n Comment 3: Hi @skarpik, one more very wild guess.\r\nPlease can You try to temporary disable Imageflow (and ImageResizer ) http modules in your web.config in DNN?\r\nJust find in `web.config/configuration/system.webServer/modules` your **imageflow** module registration (and or **imageresizer** module) and comment it, save web.config and test file upload again.\r\n\r\n```xml\r\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\r\n<configuration>\r\n...\r\n  <system.webServer>\r\n...\r\n    <modules>\r\n...\r\n      <!-- <add name=\"ImageflowModule\" type=\"ToSic.Imageflow.Dnn.ImageflowModule, ToSic.Imageflow.Dnn\" /> -->\r\n    </modules>\r\n```\r\n\n Comment 4: I commented out ImageFlow and I got the same error. I have been doing the tests on a local DNN installation. \r\n\r\nI could put it on a server on DNN4Less.com and test it there. Is that worth the trouble? That should eliminate any issues with firewall issues (BTW - I'm running the Microsoft supplied firewall for Windows 11). \r\n\r\nI doubt that it is a FW problem. My website is on my computer. My client (the browser) is on my computer. The firewall should even see what is happening as my requests never leave my computer.\r\n\r\nI will try installing DNN and 2sxc 13 LTS on a Windows 10 machine. Maybe that might show something interesting. It is very odd that it is working OK for you and not for me. Are you running Windows 10 or Windows 11?\r\n\r\nPlease confirm your set up:\r\n\r\nDNN v9.10.2\r\n2sxc v13.12.1 LTS\r\n2shine v5.04\r\n\r\nI want to make sure that I'm running exactly what you are (although I can't imagine that the theme will have any impact).\r\n\r\nI also might try accessing the website on my workstation from a Linux box that I have on my network. Should not make any difference but by this time I'm desperate to try anything.\r\n\r\n\n Comment 5: My dev env is Windows 11 Enterprise 21H2 using default Windows Defender (configured for development). \r\n\r\nFor this issue, my test installations have default: DNN v9.10.2; 2sxc v13.12.01 LTS. Also installed latest 2shine.BS5_5.0.4_Install.zip with only visible side effect that the test site look nicer (as expected \ud83d\ude09). \r\n\r\nIn chrome tested that ADAM uploads test image (using window file selector) without any issues from local drive, mapped drive, network share (so still can not reproduce this issue",
  "Issue title: Bug: CPTableView row drag should be started immediately if a row cannot be selected\n Issue body: Steps\n1. Create a tableview that doesn't allow row selections\n2. Start a row drag\n\nResult\nNothing\n\nExpected\nThe row drag to be started immediately\n\n Comments: \n Comment 0: Fixed on latest jake.\n\n Comment 1: Closed. \n",
  "Issue title: [CI] 22-10-Logstash failure due to no latest tag for logstash image\n Issue body: 22-10-Logstash is consistent failure in CI testing recently, and the root cause is that the test scripts is using the lastest tag of logstash, however, logstash does not support lastest tag any more. Details, refer to https://hub.docker.com/_/logstash/.  We could use 6.4.1 for our testing.\r\nlogs: https://ci-vic.vmware.com/vmware/vic/20373\n Comments: \n Comment 0: PR is https://github.com/vmware/vic/pull/8385. Close it now.",
  "Issue title: When DEBUG=False configured remote services should be PROXY ALLOWED\n Issue body: Setting DEBUG=False enforces the internal GeoNode proxy security by checking for hosts present into PROXY_ALLOWED_HOSTS.\r\n\r\n## Expected Behavior\r\nIf a Remote Service has been defined by a user, it should be accepted by the internal Proxy.\r\n\r\n## Actual Behavior\r\nAny url not statically defined into the PROXY_ALLOWED_HOSTS list is denied.\r\n\r\n## Steps to Reproduce the Problem\r\n\r\n  1. Set DEBUG=False\r\n  2. Create a new Remote Service and import a resource\r\n  3. Try to print the layer\r\n\r\n## Specifications\r\n\r\n  - GeoNode version: 2.10\r\n  - Installation method (manual, GeoNode Docker, SPCGeoNode Docker): any\r\n  - Platform: any\r\n  - Additional details:\r\n\n Comments: \n Comment 0: Hi @afabiani I have this problem in 3.1.\r\nMy steps:\r\nAdd a remote Service: http://si.icnf.pt/geoserver/ows\r\nChoose a layer : corredores_ecologicos\r\n\r\nCreate a map with this layer;\r\nPrint - > Give me the error of this issue.\r\n\r\nCan you confirm if this persists?\r\n",
  "Issue title: fix css include\n Issue body: Hello. Please fix your bower dependencies, like\n\"main\": [\"dist/cropper.js\", \"dist/cropper.css\"]\nbecouse wiredep isn't including css file.\n\n`\"dist/cropper.css\"` - this line\n\n Comments: \n Comment 0: OK~ Thanks~",
  "Issue title: Certificate Rotation\n Issue body: TBD\r\n\r\n**Component**:\r\n\r\n<!-- E.g.'salt', 'containers', 'kubernetes', 'build', 'tests'... -->\r\n\r\n**Why this is needed**:\r\n\r\n**What should be done**:\r\n\r\n**Implementation proposal** (strongly recommended):\r\n\r\n**Test plan**:\r\n\n Comments: \n Comment 0: Ref #1887 ",
  "Issue title: Unable to Compile with Next\n Issue body: I'm trying to use this library in a NextJs application that is also using Typescript. I'm using a very basic test that based on demos.  Locally, I receive the following error:\r\n\r\n```\r\nerror -./node_modules/react-blurhash/es/BlurhashCanvas.js:37:0\r\nModule not found: Can't resolve 'blurhash'\r\nDid you mean './blurhash'?\r\nRequests that should resolve in the current directory need to start with './'.\r\n```\r\n\r\nI was able to re-create with a very simple Codesandbox as well:\r\n\r\nhttps://codesandbox.io/s/summer-hill-xsuch?file=/pages/index.js\n Comments: \n Comment 0: I hadn't added `blurhash` as a peer dependency. Sorry for the noise.",
  "Issue title: DiffURL & PatchURL is not available in PullRequest struct\n Issue body: I need to access the diff and patch urls that is being returned in the json structure but these attributes are currently not available in the PullRequest struct.\r\n\r\nI will submit a pull request shortly that solves this issue.\n Comments: \n Comment 0: fixed in #175",
  "Issue title: \u600e\u4e48\u53bb\u6389\u9ed8\u8ba4\u7684message handler\u8fd4\u56de\u6587\u5b57\n Issue body:  \u8bf7\u95ee\u4ee3\u7801\u91cc\u600e\u4e48\u53bb\u6389\u9ed8\u8ba4message handler\u8fd4\u56de\u7684\u6d88\u606f\uff1f\r\n\r\n\u6bd4\u5982\uff1a\r\n\r\n**\u60a8\u521a\u624d\u53d1\u9001\u4e86\u6587\u5b57\u4fe1\u606f\uff1a\u4e2d\u56fd\u5e73\u5b89\r\n\r\n\u60a8\u6b64\u524d\u8fd8\u53d1\u9001\u4e86\u5982\u4e0b\u6d88\u606f\uff0810/36\uff09\uff1a\r\n16:12:57 \u3010Text\u3011\u4e2d\u56fd\u5e73\u5b89\r\n16:12:44 \u3010Text\u3011MUTE\r\n16:10:04 \u3010Text\u3011MUTE\r\n16:09:50 \u3010Text\u3011\u4e2d\u56fd\u5e73\u5b89\r\n16:07:45 \u3010Text\u3011MUTE\r\n16:07:17 \u3010Text\u3011\u4e2d\u56fd\u5e73\u5b89\r\n16:05:21 \u3010Text\u3011\u4e2d\u56fd\u5e73\u5b89\r\n16:01:11 \u3010Text\u3011\u4e2d\u56fd\u5e73\u5b89\r\n16:00:56 \u3010Text\u3011\u4e2d\u56fd\u5e73\u5b89\r\n\r\n\r\n\u5982\u679c\u60a8\u57283\u5206\u949f\u5185\u8fde\u7eed\u53d1\u9001\u6d88\u606f\uff0c\u8bb0\u5f55\u5c06\u88ab\u81ea\u52a8\u4fdd\u7559\uff08\u5f53\u524d\u8bbe\u7f6e\uff1a\u6700\u591a\u8bb0\u5f5510\u6761\uff09\u3002\u8fc7\u671f\u540e\u8bb0\u5f55\u5c06\u4f1a\u81ea\u52a8\u6e05\u9664\u3002\r\n\r\n\r\n\u60a8\u8fd8\u53ef\u4ee5\u53d1\u9001\u3010\u4f4d\u7f6e\u3011\u3010\u56fe\u7247\u3011\u3010\u8bed\u97f3\u3011\u3010\u89c6\u9891\u3011\u7b49\u7c7b\u578b\u7684\u4fe1\u606f\uff08\u6ce8\u610f\u662f\u8fd9\u51e0\u79cd\u7c7b\u578b\uff0c\u4e0d\u662f\u8fd9\u51e0\u4e2a\u6587\u5b57\uff09\uff0c\u67e5\u770b\u4e0d\u540c\u683c\u5f0f\u7684\u56de\u590d\u3002\r\nSDK\u5b98\u65b9\u5730\u5740\uff1ahttps://sdk.weixin.senparc.com**\n Comments: \n Comment 0: \u8fd9\u4e2a\u4fe1\u606f\u662f\u5728\u4ee3\u7801\u4e2d\u81ea\u5b9a\u4e49\u7684\uff0c\u5bf9\u5e94 Sample \u7684\u4f4d\u7f6e\u5728\u8fd9\u91cc\uff1a\r\n\r\nhttps://github.com/JeffreySu/WeiXinMPSDK/blob/ebc94808966753d6e9a8c0f70d81a1f1d3588bbd/Samples/Senparc.Weixin.Sample.CommonService/MessageHandlers/CustomMessageHandler/CustomMessageHandler.cs#L429\n Comment 1: > \u8fd9\u4e2a\u4fe1\u606f\u662f\u5728\u4ee3\u7801\u4e2d\u81ea\u5b9a\u4e49\u7684\uff0c\u5bf9\u5e94 Sample \u7684\u4f4d\u7f6e\u5728\u8fd9\u91cc\uff1a\r\n> \r\n> https://github.com/JeffreySu/WeiXinMPSDK/blob/ebc94808966753d6e9a8c0f70d81a1f1d3588bbd/Samples/Senparc.Weixin.Sample.CommonService/MessageHandlers/CustomMessageHandler/CustomMessageHandler.cs#L429\r\n\r\n\u8c22\u8c22\u8001\u5e08\u56de\u590d\r\n\r\n\u6211\u5176\u5b9e\u5728\u4ee3\u7801\u91cc\u4e5f\u6539\u6389\u4e86\u8fd9\u91cc\uff0c\u9ed8\u8ba4\u52a0\u4e86\u81ea\u5df1\u7684\u903b\u8f91\uff0c\u4e5f\u8fd4\u56de\u4e86mute response\uff0c\u4e0d\u77e5\u9053\u8fd8\u662f\u8fd4\u56de\u5165\u4e0a\u7684\u9ed8\u8ba4\u6d88\u606f\r\n\r\n\u6211\u7684\u5927\u6982\u4ee3\u7801\u5df2\u7ecf\u6539\u6210\u5982\u4e0b\uff0c\u90e8\u7f72\u5230\u670d\u52a1\u5668\u4e0a\u8fd8\u662f\u4f1a\u8fd4\u56de\u4ee5\u4e0a\u6587\u5b57\uff0c\u4ece\u65e5\u5fd7\u91cc\u770b\uff0c\u6211\u81ea\u5df1\u7684\u903b\u8f91\u5df2\u7ecf\u89e6\u53d1\uff1a\r\npublic override async Task<IResponseMessageBase> OnTextRequestAsync(RequestMessageText requestMessage)\r\n        {\r\n            WeixinTrace.Log(\"OnTextRequestAsync {0}----{1}\", requestMessage.Content, requestMessage.FromUserName);\r\n\r\n            var defaultResponseMessage = base.CreateResponseMessage<ResponseMessageText>();\r\n            var requestHandler = await requestMessage.StartHandler()\r\n               .Default(async () =>\r\n                {\r\n                    var muteResponseMessage = base.CreateResponseMessage<ResponseMessageNoResponse>();\r\n                    try\r\n                    {\r\n                        WeixinTrace.Log(\"Starting of OnTextRequestAsync {0}----{1}\", requestMessage.Content, requestMessage.FromUserName);\r\n                        var handlers = new MaxQuantWxHandler[]\r\n                        {\r\n                            new UserCandidationHandler(),\r\n                            new OkExCommandHandler(),\r\n                        };\r\n\r\n                        var context = new MessageTextHandleContext\r\n                        {\r\n                            RequestMessage = requestMessage,\r\n                            DfaultResponseMessage = muteResponseMessage\r\n                        };\r\n\r\n                        try\r\n                        {\r\n                            var firstResponse = handlers.Select(handler =>\r\n                            {\r\n                                return handler.ProcessTextRequest(context);\r\n                            })\r\n                           .FirstOrDefault(response =>\r\n                            {\r\n                                return response!= null && response.MsgType == NeuChar.ResponseMsgType.SuccessResponse;\r\n                            });\r\n\r\n                            if (firstResponse!= null && firstResponse.MsgType == NeuChar.ResponseMsgType.SuccessResponse)\r\n                            {\r\n                                WeixinTrace.Log(\"End of OnTextRequestAsync \" + firstResponse.ConvertEntityToXmlString());\r\n                                return new SuccessResponseMessage();\r\n                            }\r\n                            else\r\n                            {\r\n                                WeixinTrace.Log(\"End of OnTextRequestAsync\");\r\n                                return muteResponseMessage;\r\n                            }\r\n                        }\r\n                        catch (Exception ex)\r\n                        {\r\n                            WeixinTrace.Log(ex.Message);\r\n                            WeixinTrace.Log(ex.StackTrace);\r\n                        }\r\n                    }\r\n                    catch (Exception ex)\r\n                    {\r\n                        WeixinTrace.Log(ex.Message);\r\n                        WeixinTrace.Log(ex.StackTrace);\r\n                        return muteResponseMessage;\r\n                    }\r\n\r\n                    return muteResponseMessage;\r\n                });\r\n\r\n            var xml = requestHandler.ConvertEntityToXmlString();\r\n            WeixinTrace.Log(\"requestHandler \" + xml);\r\n            var finalResponse = requestHandler.GetResponseMessage() as IResponseMessageBase;\r\n            return base.CreateResponseMessage<ResponseMessageNoResponse>();\r\n        }\n Comment 2: \u80fd\u5e2e\u6211\u518d\u60f3\u60f3\uff0c\u54ea\u91cc\u8fd8\u53ef\u4ee5\u6539\u7684\u5417\uff1f\u8c22\u8c22\n Comment 3: \u6211\u5bf9\u4f60\u81ea\u5b9a\u4e49\u7684\u903b\u8f91\u4ee3\u7801\u5185\u90e8\u5b9e\u73b0\u4e0d\u6e05\u695a\uff0c\u8fd9\u90e8\u5206\u6ca1\u6cd5\u5224\u65ad\uff0c\u4f46\u662f\u4ece\u6574\u4f53\u4e0a\u770b\uff0c\u8fd9\u6837\u662f\u53ef\u4ee5\u8ba9\u5fae\u4fe1\u4e0d\u4ea7\u751f\u4efb\u4f55\u56de\u590d\u7684\u3002\r\n\r\n\u6700\u540e\u4e00\u4e2a return\u4e5f\u53ef\u4ee5\u5199\u6210\uff1a\r\n```\r\nreturn requestHandler.GetResponseMessage();\r\n```\r\n\n Comment 4: > \u6211\u5bf9\u4f60\u81ea\u5b9a\u4e49\u7684\u903b\u8f91\u4ee3\u7801\u5185\u90e8\u5b9e\u73b0\u4e0d\u6e05\u695a\uff0c\u8fd9\u90e8\u5206\u6ca1\u6cd5\u5224\u65ad\uff0c\u4f46\u662f\u4ece\u6574\u4f53\u4e0a\u770b\uff0c\u8fd9\u6837\u662f\u53ef\u4ee5\u8ba9\u5fae\u4fe1\u4e0d\u4ea7\u751f\u4efb\u4f55\u56de\u590d\u7684\u3002\r\n> \r\n> \u6700\u540e\u4e00\u4e2a return\u4e5f\u53ef\u4ee5\u5199\u6210\uff1a\r\n> \r\n> ```\r\n> return requestHandler.GetResponseMessage();\r\n> ```\r\n\r\n\u8c22\u8c22\u56de\u590d\uff0c\u9ed8\u8ba4\u662f\u6309\u7167\u4f60\u63d0\u4f9b\u7684\u4ee3\u7801\u7684\uff0c\u4f46\u4e0d\u77e5\u9053\u4e3a\u4f55\u4e0dwork\uff0c\u603b\u4f1a\u8fd4\u56de\u6d88\u606f\u3002\u5982\u679c\u6211\u8fd4\u56de\u81ea\u5df1\u7684response content, \u5fae\u4fe1\u4f1a\u540c\u6837\u4f1a\u8fd4\u56de\u9ed8\u8ba4\u7684\u90a3\u6bb5\u6587\u5b57\uff0c\u4e0d\u77e5\u9053\u54ea\u91cc\u6539\u3002\u3002\u3002\u3002\u96be\u9053\u5fae\u4fe1\u6709\u7f13\u5b58\u5417\uff1f\n Comment 5: \u4f60\u6709\u516c\u4f17\u53f7\u53ef\u4ee5\u7ed9\u6d4b\u8bd5\u4e00\u4e0b\u7684\u5417\uff1f\u6211\u53ef\u4ee5\u5e2e\u4f60\u770b\u4e00\u4e0b\u3002\u6216\u8005\u53d1\u6211\u90ae\u7bb1\uff1ateresalamb@example.com\n Comment 6: \u516c\u4f17\u53f7\u540d\u53eb:\u91cf\u5316\u6811\r\n\r\n\r\n\u8001\u5e08\u81ea\u5df1\u641c\u7d22\u4e0b\u5417\uff1f\r\n\u9700\u8981\u6211\u7ed9\u4f60\u6e90\u7801\u548c\u670d\u52a1\u5668\u8bbf\u95ee\u6743\u9650\u5417\uff1f\r\n\r\n\r\n------------------&nbsp;\u539f\u59cb\u90ae\u4ef6&nbsp;------------------\r\n\u53d1\u4ef6\u4eba:                                                                                                                        \"JeffreySu/WeiXinMPSDK\"                                                                                    ***@***.***&gt;;\r\n\u53d1\u9001\u65f6\u95f4:&nbsp;2022\u5e741\u67086\u65e5(\u661f\u671f\u56db) \u665a\u4e0a10:59\r\n***@***.***&gt;;\r\n***@***.******@***.***&gt;;\r\n\u4e3b\u9898:&nbsp;Re: [JeffreySu/WeiXinMPSDK] \u600e\u4e48\u53bb\u6389\u9ed8\u8ba4\u7684message handler\u8fd4\u56de\u6587\u5b57 (Issue #2543)\r\n\r\n\r\n\r\n\r\n\r\n \r\n***@***.***\r\n \r\n\u2014\r\nReply to this email directly, view it on GitHub, or unsubscribe.\r\nTriage notifications on the go with GitHub Mobile for iOS or Android. \r\nYou are receiving this because you authored the thread.Message ID: ***@***.***&gt;\n Comment 7: \u6d4b\u8bd5\u4e86\u786e\u5b9e\u6709\uff0c\u4f60\u76f4",
  "Issue title: Drag & drop: content disappears when dragged from restricted editing area in Safari\n Issue body: Extracted from: https://github.com/ckeditor/ckeditor5/pull/9297#issuecomment-802634131\r\n\r\n## \ud83d\udcdd Provide detailed reproduction steps (if any)\r\n\r\n1. Go to restricted editing docs ( checked on latest `release` )\r\n2. Turn on restricted editing mode\r\n3. Select some content inside restricted edititing area and drag it somewhere\r\n\r\n### \u2714\ufe0f Expected result\r\n\r\nNothing happens - content stays at its original position.\r\n\r\n### \u274c Actual result\r\nContent disappears:  \r\n\r\nhttps://user-images.githubusercontent.com/34380544/111806416-3cd47b80-88d2-11eb-9e54-a56e221a55b2.mp4\r\n\r\n\r\n\r\n---\r\n\r\nIf you'd like to see this fixed sooner, add a \ud83d\udc4d reaction to this post.\r\n\n Comments: \n Comment 0: Does not seem to be very likely to happen in real-life scenarios. Also, one can undo from this.",
  "Issue title: Test Flake: Unit test cmd/entrypoint TestRealRunnerTimeout\n Issue body: Sadly not much info present in log file:\r\n```\r\n=== RUN   TestRealRunnerTimeout\r\n    runner_test.go:37: step didn't timeout\r\n--- FAIL: TestRealRunnerTimeout (0.03s)\r\n```\r\n\r\n/kind flake\r\n/priority important-soon\n Comments: \n Comment 0: Issues go stale after 90d of inactivity.\nMark the issue as fresh with `/remove-lifecycle stale` with a justification.\nStale issues rot after an additional 30d of inactivity and eventually close.\nIf this issue is safe to close now please do so with `/close` with a justification.\nIf this issue should be exempted, mark the issue as frozen with `/lifecycle frozen` with a justification.\n\n/lifecycle stale\n\nSend feedback to [tektoncd/plumbing](https://github.com/tektoncd/plumbing).\n Comment 1: /lifecycle frozen\r\n\r\nI hit this one while trying to reproduce the various events-related flakes, so it's still a thing. I thought that maybe increasing the timeout in the test would help, but I seem to still be hitting it...\n Comment 2: Yeah, it failing or not depended on what I had for `-count` and the overall load on my system, not on anything flaky. Sigh. Well, it's still a flake, just one I can't come up with a fix for...",
  "Issue title: Moving cursor in NDS emulator\n Issue body: I know it's impossible to remove the cursor from the NDS emulator so every time I want to play I connect a wired mouse and move it downwards until I cannot see it, then disconnect the mouse, is it possible to implement a script upon starting the emulator to do this automatically?\r\nSomething like:\r\n`\\033[<Y>B `\r\nor\r\n`xdotool mousemove X Y`\r\nto put the cursor as low as possible (\"Y\" being the edge of the display) without having to connect a mouse.\n Comments: \n Comment 0: There\u2019s an updated drastic emulator that\u2019s coming later this week that removes that mouse cursor finally.  Stay tuned. ",
  "Issue title: Pb de au moment de kinit sur linux\n Issue body: Bien le bonjour!\r\n\r\nJuste pour signaler un petit pb que j'ai eu et que peut-\u00eatre d'autres vont avoir. Je pr\u00e9cise que j'ai eu ce pb sur un Arch Linux connect\u00e9 le r\u00e9seau de 42.\r\nL'installation s'\u00e9tait d\u00e9roul\u00e9e sans encombres mais au moment de kinit je me suis fait gentiment rembarr\u00e9 avec une erreur du style :\r\n\r\n> kinit: Cannot contact any KDC for realm 'Nom.De.Serveur.Bidon' while getting initial credentials.\r\n\r\nEn gros la couille c'\u00e9tait que root.sh \u00e9crivait la conf \u00e0 la fin du fichier krb5.conf, et comme mon fichier n'\u00e9tait pas vide bah \u00e7a a foutu le brun et \u00e7a marchait pas.\r\nDu coup comme j'avais rien d'important sur le fichier j'ai fait un ptit\r\n`sudo mv /etc/krb5.conf /etc/~krb5.conf` et j'ai relanc\u00e9 l'install et tout a fonctionn\u00e9 au poil.\r\nWala et pour ceux qui ont des trucs importants dans krb5.conf \u00e7a doit pouvoir \u00eatre modifiable \u00e0 mon avis mais l\u00e0 j'en sais pas plus ;)\r\n\n Comments: \n Comment 0: Hello,\r\nErreur de ma part donc je vais ajouter un mv du fichier original.\r\nThx",
  "Issue title: Installation failed to find boost.\n Issue body: Following the installation instructions on Mac OS X (El Capitan) using the homebrew version of Python, failed to find boost (even after doing `brew install boost`). The issue was that boost had already been installed via MacPorts. This can be verified with something like `port installed \"boost*\"`.\r\n\r\nWe solved the problem by removing the MacPorts installation of boost via `sudo port uninstall boost`.\r\n\r\nHowever, rerunning `python setup.py install --user` still failed because CMake had cached some files and was still not finding boost. After removing the ray repository and re-cloning it, the installation succeeded.\r\n\r\nThe full output from the first installation attempt is below.\r\n\r\n```\r\ndhcp-46-212:git elaine$ cd ray/python\r\ndhcp-46-212:python elaine$ python setup.py install --user\r\nrunning install\r\n~/git/ray/src/common/thirdparty ~/git/ray/python\r\n--2017-02-20 13:58:29--  https://github.com/antirez/redis/archive/4.0-rc2.tar.gz\r\nResolving github.com (github.com)... 116.69.203.115, 116.69.203.115\r\nConnecting to github.com (github.com)|116.69.203.115|:443... connected.\r\nHTTP request sent, awaiting response... 302 Found\r\nLocation: https://codeload.github.com/antirez/redis/tar.gz/4.0-rc2 [following]\r\n--2017-02-20 13:58:30--  https://codeload.github.com/antirez/redis/tar.gz/4.0-rc2\r\nResolving codeload.github.com (codeload.github.com)... 116.69.203.115, 116.69.203.115\r\nConnecting to codeload.github.com (codeload.github.com)|116.69.203.115|:443... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: unspecified [application/x-gzip]\r\nSaving to: \u2018STDOUT\u2019\r\n\r\n-                             [<=>                                 ]       0  --.-KB/s               x.gitignore\r\nx 00-RELEASENOTES\r\nx BUGS\r\nx CONTRIBUTING\r\nx COPYING\r\nx INSTALL\r\nx MANIFESTO\r\nx Makefile\r\nx README.md\r\nx deps/\r\nx deps/Makefile\r\nx deps/README.md\r\nx deps/hiredis/\r\nx deps/hiredis/.gitignore\r\nx deps/hiredis/.travis.yml\r\nx deps/hiredis/CHANGELOG.md\r\nx deps/hiredis/COPYING\r\nx deps/hiredis/Makefile\r\nx deps/hiredis/README.md\r\nx deps/hiredis/adapters/\r\nx deps/hiredis/adapters/ae.h\r\nx deps/hiredis/adapters/libev.h\r\nx deps/hiredis/adapters/libevent.h\r\nx deps/hiredis/adapters/libuv.h\r\nx deps/hiredis/async.c\r\nx deps/hiredis/async.h\r\nx deps/hiredis/dict.c\r\nx deps/hiredis/dict.h\r\nx deps/hiredis/examples/\r\nx deps/hiredis/examples/example-ae.c\r\nx deps/hiredis/examples/example-libev.c\r\nx deps/hiredis/examples/example-libevent.c\r\nx deps/hiredis/examples/example-libuv.c\r\nx deps/hiredis/examples/example.c\r\nx deps/hiredis/fmacros.h\r\n-                             [ <=>                                ]  63.87K   269KB/s               \r\nx deps/hiredis/hiredis.h\r\nx deps/hiredis/net.c\r\nx deps/hiredis/net.h\r\nx deps/hiredis/sds.c\r\nx deps/hiredis/sds.h\r\nx deps/hiredis/sdsalloc.h\r\nx deps/hiredis/test.c\r\nx deps/hiredis/zmalloc.h\r\nx deps/jemalloc/\r\nx deps/jemalloc/.autom4te.cfg\r\nx deps/jemalloc/.gitattributes\r\nx deps/jemalloc/.gitignore\r\nx deps/jemalloc/COPYING\r\nx deps/jemalloc/ChangeLog\r\nx deps/jemalloc/INSTALL\r\nx deps/jemalloc/Makefile.in\r\nx deps/jemalloc/README\r\nx deps/jemalloc/VERSION\r\nx deps/jemalloc/autogen.sh\r\nx deps/jemalloc/bin/\r\nx deps/jemalloc/bin/jemalloc-config.in\r\nx deps/jemalloc/bin/jemalloc.sh.in\r\nx deps/jemalloc/bin/jeprof.in\r\nx deps/jemalloc/config.guess\r\nx deps/jemalloc/config.stamp.in\r\nx deps/jemalloc/config.sub\r\n-                             [  <=>                               ] 238.70K   511KB/s               \r\nx deps/jemalloc/configure.ac\r\nx deps/jemalloc/coverage.sh\r\nx deps/jemalloc/doc/\r\nx deps/jemalloc/doc/html.xsl.in\r\nx deps/jemalloc/doc/jemalloc.3\r\nx deps/jemalloc/doc/jemalloc.html\r\nx deps/jemalloc/doc/jemalloc.xml.in\r\nx deps/jemalloc/doc/manpages.xsl.in\r\nx deps/jemalloc/doc/stylesheet.xsl\r\nx deps/jemalloc/include/\r\nx deps/jemalloc/include/jemalloc/\r\nx deps/jemalloc/include/jemalloc/internal/\r\nx deps/jemalloc/include/jemalloc/internal/arena.h\r\nx deps/jemalloc/include/jemalloc/internal/atomic.h\r\nx deps/jemalloc/include/jemalloc/internal/base.h\r\nx deps/jemalloc/include/jemalloc/internal/bitmap.h\r\nx deps/jemalloc/include/jemalloc/internal/chunk.h\r\nx deps/jemalloc/include/jemalloc/internal/chunk_dss.h\r\nx deps/jemalloc/include/jemalloc/internal/chunk_mmap.h\r\nx deps/jemalloc/include/jemalloc/internal/ckh.h\r\nx deps/jemalloc/include/jemalloc/internal/ctl.h\r\nx deps/jemalloc/include/jemalloc/internal/extent.h\r\nx deps/jemalloc/include/jemalloc/internal/hash.h\r\nx deps/jemalloc/include/jemalloc/internal/huge.h\r\nx deps/jemalloc/include/jemalloc/internal/jemalloc_internal.h.in\r\nx deps/jemalloc/include/jemalloc/internal/jemalloc_internal_decls.h\r\nx deps/jemalloc/include/jemalloc/internal/jemalloc_internal_defs.h.in\r\nx deps/jemalloc/include/jemalloc/internal/jemalloc_internal_macros.h\r\nx deps/jemalloc/include/jemalloc/internal/mb.h\r\nx deps/jemalloc/include/jemalloc/internal/mutex.h\r\nx deps/jemalloc/include/jemalloc/internal/pages.h\r\nx deps/jemalloc/include/jemalloc/internal/private_namespace.sh\r\nx deps/jemalloc/include/jemalloc/internal/private_symbols.txt\r\nx deps/jemalloc/include/jemalloc/internal/private_unnamespace.sh\r\nx deps/jemalloc/include/jemalloc/internal/prng.h\r\nx deps/jemalloc/include/jemalloc/internal/prof.h\r\nx deps/jemalloc/include/jemalloc/internal/public_namespace.sh\r\nx deps/jemalloc/include/jemalloc/internal/public_unnamespace.sh\r\nx deps/jemalloc/include/",
  "Issue title: IA 1: Expectations\n Issue body: ### Objective\r\n\r\nWe appreciate that users are trying Element with pre-existing expectations of how to use the interface to achieve their goals.  This may come from [HIG](https://developer.apple.com/design/human-interface-guidelines/ios/overview/themes/), it may come from other products they've previously used to achieve their goals, or other products they use for other goals.\r\n\r\nThe more we understand their pre-existing expectations, and respect them, the quicker we can help users discover what they want and find value in Element.\r\n\r\n**Tasks**\r\n\r\n- [ ] Artefacts: Competitor IA maps\r\n   - [ ]  Professional use (co-worker and teams)\r\n     - [ ] Slack\r\n     - [ ] Teams \r\n\r\n\n Comments: \n Comment 0: I'm going to close this planning issue as we're almost at release stage on the app layout",
  "Issue title: Compilation errors with _GLIBCXX_DEBUG defined\n Issue body: Thanks very much for the work on #294.\r\n\r\nUnfortunately, I'm now seeing a new compilation failure that I suspect arises from those changes. I'm now getting a failure under both GCC and Clang from just including `<range/v3/core.hpp>` when `_GLIBCXX_DEBUG` is defined.\r\n\r\nGCC errors:\r\n\r\n~~~~~\r\nIn file included from range-v3/include/range/v3/utility/iterator_traits.hpp:20:0,\r\n                 from range-v3/include/range/v3/utility/iterator.hpp:25,\r\n                 from range-v3/include/range/v3/begin_end.hpp:24,\r\n                 from range-v3/include/range/v3/core.hpp:17,\r\n                 from a.cpp:1:\r\nrange-v3/include/range/v3/utility/iterator_concepts.hpp:629:15: error: \u2018iterator_difference_t\u2019 in namespace \u2018ranges\u2019 does not name a template type\r\n     38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5ranges38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5iterator_difference_t<I1>\r\n               ^\r\nrange-v3/include/range/v3/utility/iterator_concepts.hpp:634:15: error: \u2018iterator_difference_t\u2019 in namespace \u2018ranges\u2019 does not name a template type\r\n     38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5ranges38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5iterator_difference_t<I1>\r\n               ^\r\n~~~~~\r\n\r\nOr am I just missing something that I should now be doing when using `_GLIBCXX_DEBUG`?\r\n\r\nThanks very much.\n Comments: \n Comment 0: Thanks both for fixing this so quickly. Great work.",
  "Issue title: [Bug] wrong error message for ampersand in function input\n Issue body: ## \ud83d\udc1b Bug Report\r\n\r\nthe following seems to emit the wrong error\r\n\r\nhttps://github.com/AleoHQ/leo/blob/d43605538d1fcb225b21c07bb76c1a8708613213/compiler/parser/src/tokenizer/lexer.rs#L222-L228\r\n\r\n#### Code snippet to reproduce\r\n\r\n```\r\nfunction main (&self) {}\r\n```\r\n\r\n#### Stack trace & error message\r\n\r\n```\r\n     Build Starting...\r\n     Build Compiling main program... (\"/home/0rphon/Work/Aleo/leo-playground/src/main.leo\")\r\n      Done Finished in 0 milliseconds \r\n\r\nError [EPAR0370021]: Expected more characters to lex but found none.\r\n```\r\n\r\n## Expected Behavior\r\nto fall in line with other similar cases it should emit:\r\n\r\n```\r\nError [EPAR0370026]: Could not lex the following content: `&self) {}`.\r\n```\r\n\r\n## Your Environment\r\n\r\n- testnet3 commit d43605538d1fcb225b21c07bb76c1a8708613213\r\n\n Comments: \n Comment 0: Closed by #1850.",
  "Issue title: useBottomSheet not returning anything\n Issue body: # Bug\r\n\r\n<!--\r\n  Please provide a clear and concise description of what the bug is.\r\n  Include screenshots or gifs if needed.\r\n  Please test using the latest release of the library, as maybe your bug has been already fixed.\r\n  If the library has multiple install methods, describe installation method (e.g., pod, not pod, with jetifier etc).\r\n\r\n  **Please note that issues that do not follow the template may be closed.**\r\n-->\r\nUse the following snippet:\r\n```javascript\r\nconst Component = React.memo(function Component(props) {\r\n  const hooks = useBottomSheet();\r\n  return <Component {...props} />;\r\n});\r\n```\r\n\r\nTrying to access any of the methods included in `hooks` would result in an error like `undefined is not an object (evaluating 'hooks.<method>` where `method` is just either expand, collapse, etc.\r\n\r\n## Environment info\r\n\r\n<!--\r\n  Please provide the version of the libraries below.\r\n-->\r\n\r\n| Library                         | Version |\r\n| ------------------------------- | ------- |\r\n| @gorhom/bottom-sheet         | 3.6.3   |\r\n| react-native                    | 0.64.0  |\r\n| react-native-reanimated         | 2.0.1   |\r\n| react-native-gesture-handler    | 1.10.3   |\r\n\r\n## Steps To Reproduce\r\n\r\n<!--\r\n- You must provide a clear list of steps and code to reproduce the problem.\r\n- Keep the code reproducing the bug as simple as possible, with the minimum amount of code required to reproduce the issue. See https://stackoverflow.com/help/mcve.\r\n- Either re-create the bug using the repository's example app or link to a GitHub repository with code that reproduces the bug.\r\n- Explain the steps we need to take to reproduce the issue:\r\n-->\r\n\r\n1. Create a custom component\r\n```javascript\r\nconst snapPoints = [-1, '100%'];\r\nconst ReportAttatchmentsPicker = React.memo(\r\n  function ReportAttatchmentsPicker() {\r\n    const bottomSheetRef = useRef();\r\n\r\n    return (\r\n      <NativeViewGestureHandler disallowInterruption={true}>\r\n        <View style={styles.container}>\r\n          <BottomSheet ref={bottomSheetRef} snapPoints={snapPoints}>\r\n            <View style={styles.contentContainer}>\r\n              <Text>Awesome \ud83c\udf89</Text>\r\n            </View>\r\n          </BottomSheet>\r\n        </View>\r\n      </NativeViewGestureHandler>\r\n    );\r\n  },\r\n);\r\n\r\n// use it somewhere\r\n<ReportAttatchmentsPicker />\r\n```\r\n2. Import `useBottomSheet` and use it, like this\r\n```javascript\r\nconst Component = React.memo(function Component(props) {\r\n  const hooks = useBottomSheet();\r\n  return <Component {...props} />;\r\n});\r\n```\r\n3. Try to access any of the methods that should be within `hook`, like this `onPress={() => hooks.collapse()`\r\n\r\nDescribe what you expected to happen:\r\n\r\n1. `hooks` should contain the methods. Right now it's just undefined.\r\n\r\n## Reproducible sample code\r\n\r\n<!--\r\n Please add minimal runnable repro as explained above so that the bug can be tested in isolation.\r\n-->\r\n\r\nWill add later if this doesn't turn out to be some misconfiguration or something like that.\r\n\n Comments: \n Comment 0: @ricbermo https://gorhom.github.io/react-native-bottom-sheet/hooks#usebottomsheet\r\n\r\n> This hook works at any component inside the `BottomSheet`.\r\n\n Comment 1: @gorhom makes sense. TY. I'd that to the docs, tho. ",
  "Issue title: No itens on database navigator for other schema\n Issue body: I'm using DBeaver with a JDBC connection on Oracle. On database navigator only on my schema itens are visible, when I navigate in another schema all groups, such as table, are empty.\r\n\r\nMy user has privileges to all schemas, I'm using the very same user in other tools and I can access everything from there.\n Comments: \n Comment 0: thanks for the bug report\n Comment 1: @RodolfoCCarvalho if it is still reproducible - please check what metadata queries are executed in dbeaver.\r\n\r\nYou can see them in the Query Manager view (main menu Window->Show View->Query Manager).\r\nYou can enable hidden metadata queries in the context menu\n Comment 2: Issue closed - no updates for a long time.\r\nIf it is still actual - feel free to reopen the ticket",
  "Issue title: Impyla does not respect TZ environment variable\n Issue body: In python, a default timezone different from system timezone can be specified with `TZ` environment variable. [ImpalaService.thrift](https://github.com/cloudera/impyla/blob/v0.16.3/impala/thrift/ImpalaService.thrift#L333-L335) also says that the value provided for `TZ` can is used for `UTC<->localtime conversions` but this does not work. \r\n\r\n```python\r\n$ TZ=\"UTC\" python\r\nPython 3.8.5 (default, Sep  4 2020, 07:30:14)\r\n[GCC 7.3.0] 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\n>>> from datetime import datetime\r\n>>> import impala\r\n>>> import impala.dbapi\r\n\r\n>>> connection=impala.dbapi.connect(host='hive-server.ip', port=10000, auth_mechanism=None, user='test')\r\n>>> cursor = connection.cursor()\r\n>>> cursor.execute(\"select current_timestamp\")\r\n>>> cursor.fetchall()\r\n[(datetime.datetime(2021, 1, 8, 6, 0, 35, 535000),)]\r\n\r\n>>> datetime.now()\r\ndatetime.datetime(2021, 1, 8, 11, 0, 49, 565775)\r\n```\r\n\r\nThe above snippet was run on on a system with timezone set to `America/New_York`. The timezone for the Hive server is also `America/New_York`. We can see that after setting `TZ=UTC`, `datetime.now()` returns a value in `UTC` time zone while the value returned by Hive is not converted `UTC`.\n Comments: \n Comment 0: ImpalaService.thrift is just the internal API docs, it doesn't apply to Impyla and isn't intended as user documentation.\r\n\r\nThe timezone is configured server-side anyway. Also that documentation is talking about Impala's behavior, not Hive's.\r\n\r\nI don't know about Hive, but on Impala the server-side timezone can be overridden via the Impala query option TIMEZONE. There's probably an equivalent for hive but this isn't the place for that.",
  "Issue title: return find result\n Issue body: How can I get the query's result outside of the `db.find` in a variable? Something like below:\n\n```\nvar result = db.find({}, function (err, docs) {\n });\n\nconsole.log(result);\n```\n\n Comments: \n Comment 0: @tokhi: You can assign it to an outer variable, like this:\n\n``` javascript\nvar result;\ndb.find({}, function(err, docs) {\n  result = docs[0];\n});\n\nconsole.log(result); // this will not be defined, since nedb is asynchronous and the callback won't have run yet\n\nsetTimeout(function() {\n  console.log(result); // this will (probably) be defined, since nedb is fast & shouldn't take a full second\n}, 1000);\n```\n\nYou run into this kind of async programming stuff a lot with node.js, so there are lots of helps for async-programming in the node community and a variety of ways to deal with \"callback hell\" and the timing issues, like using straight callbacks, using a callback helper library like caolan's async, or using promises...\n\n Comment 1: I found this on stackoverflow and it works:\n\n``` javascript\nvar x = null;\ndb.find({ }, function (err, docs) {\n  x = docs;\n  do_something_when_you_get_your_result();\n});\n\nfunction do_something_when_you_get_your_result() {\n  console.log(x); // x have docs now\n}\n```\n\n Comment 2: @tokhi: Yep, doing something like that (a straight callback approach) works well. You could also tweak it slightly to pass the docs directly:\n\n``` javascript\ndb.find({ }, function (err, docs) {\n  if (err) throw err;\n  do_something_when_you_get_your_result(docs);\n});\n\nfunction do_something_when_you_get_your_result(docs) {\n  console.log(docs);\n}\n```\n\nThe main point being that an async operation like `db.find()` can't return the result immediately, it is only available later, when the callback function is executed.\n\nNotice the `if (err) throw err` -- you'll want to check for the error and do something with it instead of ignoring it altogether (for initial development it's usually enough to just `throw` it, but later on you may want to suppress some errors or do something special to notify the user of the errors)\n\n Comment 3: @prust : Yep, thanks. :+1: \n",
  "Issue title: DrawerInTabs has bugs\n Issue body: ### Source code\r\n[https://github.com/XinHuaLuFang/xhlf-react-navigation/blob/master/app/TabHaveSelfDrawer.js](https://github.com/XinHuaLuFang/xhlf-react-navigation/blob/master/app/TabHaveSelfDrawer.js)\r\n\r\n### Current Behavior\r\n* click button (OPEN HOME DRAWER) => just show a shade\r\n* you can open drawer with gesture\r\n* open drawer and click Home2 => screen show Home2 but drawer do not disappear\r\n\r\n### Expected Behavior\r\n* click button (OPEN HOME DRAWER) => show shade and drawer\r\n* open drawer and click Home2 => screen show Home2 and drawer disappear\r\n\r\n### Your Environment\r\n\r\n| software         | version\r\n| ---------------- | -------\r\n| react-navigation | 1.0.0-beta.11\r\n| react-native     | 0.48.3\r\n| node             | 6.11.2\r\n| yarn      | 0.27.5\r\n\n Comments: \n Comment 0: Hi @XinHuaLuFang thanks for reporting, can you try using the latest version? We fixed a lot of bugs related to the Drawer lately.\n Comment 1: @kelset The latest version(beta.13) has the same bug.\n Comment 2: Ok thanks for letting me know, we'll look into this.\n Comment 3: This is still an issue with 1.0.0-beta.26\r\n\r\n| software | version |\r\n|----------|---------|\r\n| react-navigation | 1.0.0-beta.26 |\r\n| react-native | 0.50.0 |\r\n| node | 9.3.0 |\r\n| yarn |  1.3.2 |\n Comment 4: Snack reproducing this: https://snack.expo.io/Sk6z1ZKLf\r\nWorth noting that it works as expected on iOS in my tests\n Comment 5: @kelset Can confirm still an issue on the latest version.\n Comment 6: moving this to umbrella issue\n Comment 7: @brentvatne please could you link the umbrella issue and also provide an update on this issue? still isn't resolved in v2.2.1\n Comment 8: also I am aware that it\u2019s not resolved and it\u2019s not a priority so if you want to see it fixed soon you should submit a pr :)\n Comment 9: It doesn't solve the problem.\n Comment 10: conversation belongs in https://github.com/react-navigation/react-navigation/issues/4154. nobody is working on this right not and we'd love some help :)",
  "Issue title: ResumeNER\u6570\u636e\u96c6\u4e0a\u4e0d\u6536\u655b\n Issue body: \u6211\u4f7f\u7528LatticeLSTM\u9879\u76ee\u4e2d\u60a8\u63d0\u4f9b\u7684ResumeNER\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u4e86\u591a\u6b21\uff0c\u7ed3\u679c\u90fd\u662f\u4e0d\u6536\u655b\uff0c\u8bf7\u95ee\u53ef\u80fd\u662f\u4ec0\u4e48\u95ee\u9898\uff1f\u591a\u8c22\u60a8\u554a\uff01\u4ee5\u4e0b\u662f\u6211\u7684\u65e5\u5fd7\u8bb0\u5f55\uff1a\r\n```\r\nSeed num: 42\r\nMODEL: train\r\nLoad pretrained char embedding, norm: False, dir: ResumeNER/gigaword_chn.all.a2b.uni.ite50.vec\r\nEmbedding:\r\n     pretrain word:11327, prefect match:63, case_match:0, oov:76, oov%:0.542857142857\r\nTraining model...\r\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\nDATA SUMMARY START:\r\n I/O:\r\n     Tag          scheme: BMES\r\n     MAX SENTENCE LENGTH: 250\r\n     MAX   WORD   LENGTH: -1\r\n     Number   normalized: True\r\n     Word  alphabet size: 1895\r\n     Char  alphabet size: 140\r\n     Label alphabet size: 29\r\n     Word embedding  dir: None\r\n     Char embedding  dir: ResumeNER/gigaword_chn.all.a2b.uni.ite50.vec\r\n     Word embedding size: 50\r\n     Char embedding size: 50\r\n     Norm   word     emb: False\r\n     Norm   char     emb: False\r\n     Train  file directory: ResumeNER/train.char.bmes\r\n     Dev    file directory: ResumeNER/dev.char.bmes\r\n     Test   file directory: ResumeNER/test.char.bmes\r\n     Raw    file directory: None\r\n     Dset   file directory: None\r\n     Model  file directory: ResumeNER/lstmcrf\r\n     Loadmodel   directory: None\r\n     Decode file directory: None\r\n     Train instance number: 3821\r\n     Dev   instance number: 463\r\n     Test  instance number: 477\r\n     Raw   instance number: 0\r\n     FEATURE num: 0\r\n ++++++++++++++++++++++++++++++++++++++++\r\n Model Network:\r\n     Model        use_crf: True\r\n     Model word extractor: LSTM\r\n     Model       use_char: True\r\n     Model char extractor: CNN\r\n     Model char_hidden_dim: 50\r\n ++++++++++++++++++++++++++++++++++++++++\r\n Training:\r\n     Optimizer: SGD\r\n     Iteration: 1000\r\n     BatchSize: 64\r\n     Average  batch   loss: True\r\n ++++++++++++++++++++++++++++++++++++++++\r\n Hyperparameters:\r\n     Hyper              lr: 0.1\r\n     Hyper        lr_decay: 0.05\r\n     Hyper         HP_clip: None\r\n     Hyper        momentum: 0.0\r\n     Hyper              l2: 1e-08\r\n     Hyper      hidden_dim: 200\r\n     Hyper         dropout: 0.5\r\n     Hyper      lstm_layer: 1\r\n     Hyper          bilstm: True\r\n     Hyper             GPU: True\r\nDATA SUMMARY END.\r\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\nbuild network...\r\nuse_char:  True\r\nchar feature extractor:  CNN\r\nword feature extractor:  LSTM\r\nuse crf:  True\r\nbuild word sequence feature extractor: LSTM...\r\nbuild word representation...\r\nbuild char sequence feature extractor: CNN...\r\nbuild CRF...\r\nEpoch: 0/1000\r\n Learning rate is set as: 0.1\r\n     Instance: 3821; Time: 37.96s; loss: 4187.0237; acc: 44252.0/124099.0=0.3566\r\nEpoch: 0 training finished. Time: 37.96s, speed: 100.66st/s,  total loss: 4187.02367401\r\ntotalloss: 4187.02367401\r\ngold_num =  1497  pred_num =  487  right_num =  0\r\nDev: time: 1.41s speed: 333.80st/s; acc: 0.3261\r\nExceed previous best acc score: -10\r\nSave current best model in file: ResumeNER/lstmcrf.0.model\r\ngold_num =  1630  pred_num =  496  right_num =  5\r\nTest: time: 1.60s, speed: 302.52st/s; acc: 0.3086\r\nEpoch: 1/1000\r\n Learning rate is set as: 0.0952380952381\r\n     Instance: 3821; Time: 36.68s; loss: 1955.0515; acc: 49655.0/124099.0=0.4001\r\nEpoch: 1 training finished. Time: 36.68s, speed: 104.18st/s,  total loss: 1955.05152512\r\ntotalloss: 1955.05152512\r\ngold_num =  1497  pred_num =  806  right_num =  70\r\nDev: time: 1.40s speed: 334.84st/s; acc: 0.4839\r\nExceed previous best acc score: 0.326133909287\r\nSave current best model in file: ResumeNER/lstmcrf.1.model\r\ngold_num =  1630  pred_num =  827  right_num =  65\r\nTest: time: 1.60s, speed: 302.06st/s; acc: 0.4795\r\nEpoch: 2/1000\r\n Learning rate is set as: 0.0909090909091\r\n     Instance: 3821; Time: 36.42s; loss: 1717.9032; acc: 49253.0/124099.0=0.3969\r\nEpoch: 2 training finished. Time: 36.42s, speed: 104.93st/s,  total loss: 1717.90322876\r\ntotalloss: 1717.90322876\r\ngold_num =  1497  pred_num =  443  right_num =  0\r\nDev: time: 1.41s speed: 332.91st/s; acc: 0.4477\r\ngold_num =  1630  pred_num =  449  right_num =  0\r\nTest: time: 1.60s, speed: 302.09st/s; acc: 0.4432\r\nEpoch: 3/1000\r\n Learning rate is set as: 0.0869565217391\r\n     Instance: 3821; Time: 34.46s; loss: 1591.0625; acc: 49245.0/124099.0=0.3968\r\nEpoch: 3 training finished. Time: 34.46s, speed: 110.87st/s,  total loss: 1591.06254387\r\ntotalloss: 1591.06254387\r\n```\r\n\u8c22\u8c22\uff01\n Comments: \n Comment 0: #71 fix this problem.\n Comment 1: Hi @luosmart, in addition to the problem you raised, there are several issues to be noticed:\r\n1. As the ResumeNER data is based on Chinese character sequence. In this situation, the `word` in NCRF++ means the Chinese character, and the `character` in NCRF++ is useless (as the basic input unit is already the character rather than the word). So you can set `use_char=False`\r\n\r\n2.  The learning rate lr seems too large, with the large batch size (64 in your experiment), the training will not be stable in some datasets. If you find the unstable training process, you may consider using a small lr or batch size. Of course, you can tune your model based on the model performance.\r\n\r\n3. Based on my experience, when training the Chinese NER model, the `norm_word_emb` has a big impact. You can try both `norm_word_emb=False` or `norm_word_emb=True`.\n Comment 2: @jiesutd Thank you for the detail.",
  "Issue title: cannot click back on submitted attachment to double check\n Issue body: I often have the following workflow:\r\n\r\n1) write an email\r\n2) attach something to it\r\n3) click on the visible attachment in compose box to download it back, double check it's exactly what I wanted to send (and the last version of it, or whatever)\r\n\r\nexpected behavior: I can download the file back and open it\r\n\r\nactual behavior: not possible to do\r\n\r\n![image](https://user-images.githubusercontent.com/6306961/128854482-699a4d9b-4cae-4350-9c4c-2a37b4bd6a90.png)\r\n\r\nThis would be a great UX improvement, assigning @limonte \r\n\r\nsubmitted by @Veronkeller \n Comments: \n Comment 0: I figure, we should show the preview UI where user can just look at it, or download it if they want - if possible.",
  "Issue title: FileNotFoundError: [Errno 2] No such file or directory: './data/imagenet/train_map.txt'\n Issue body: Hi @ancientmooner @zdaxie, \r\n\r\nThanks for your contribution, but why there need a txt file to load ImageNet?\n Comments: \n Comment 0: Hello, did you managed to get that file?\n Comment 1: Hello, did you solve this question. \r\nI have the same question.",
  "Issue title: Defer validation of Kubernetes environment until a resource effectively needs it\n Issue body: We'd like to integrate the bootstrapping of our Minikube cluster to Tilt using `local_resource`\r\n\r\nThis is helpful because we can dynamically determine how cpu/memory to use based on which resources need to be deployed, and also because currently, our way to setup a local development environment is finnicky (i.e. _wait until this service is up, then port-forward it to `:XXXX`, then run this JAR to register the IoT device on the cluster..._) and we'd like to make that into a single `tilt up` command, especially given that _\"waiting for service X to be up\"_ is the kind of thing that is finnicky to script, but that Tilt is great at.\r\n\r\nCurrently, however, when you `tilt up` before Kubernetes is up, you'll run into some variation of these errors:\r\n```\r\nError: Error watching k8s events\r\n: could not set up k8s client: Kubernetes context not set in [/home/ubuntu/.kube/config]\r\n\r\nError: Error watching services. Are you connected to kubernetes?\r\nTry running `kubectl get services`: could not set up k8s client: Kubernetes context not set in [/home/ubuntu/.kube/config]\r\n```\r\n\r\nThis will happen even though we have a `local_resource` that will spin up a `minikube` instance, and if this check was deferred by default (or by some top-level setting like `deferred_kubeconfig(True)`) this could be naturally implemented and would work as intended\n Comments: \n Comment 0: Thanks for filing @luizberti! This would unfortunately not be straightforward to implement, as we use the kubernetes client for a number of things when initially setting up the Tilt engine, but I bet it could be done! I don't think the team will get to this any time soon, but it's on our backlog for sure!",
  "Issue title: #<Promise> is not a promise\n Issue body: Greetings! I'm using node-cache module and I'm trying to store promises in the cache. Take a look at the following code snippet:\r\n\r\n```javascript\r\nrouter.get('/test', (req, res) => {\r\n    myCache.get('example', ( err, value ) => {\r\n      if (!err) {\r\n        if (value == undefined) {\r\n          value = new Promise((resolve,reject) => {\r\n            resolve(\"hey\");\r\n          });\r\n          myCache.set('example', value);\r\n        } \r\n        console.log(value instanceof Promise);\r\n        value.then((str) => console.log(str));\r\n        res.status(200);\r\n        res.send();\r\n      } else {\r\n        logger.error(err);\r\n        res.status(500);\r\n        res.send();\r\n      }\r\n    });\r\n  });\r\n```\r\n\r\nThe first request to that endpoint produces the following console output:\r\ntrue\r\nhey\r\n\r\nThe second request produces this:\r\ntrue\r\nTypeError: #<Promise> is not a promise\r\n\r\nSo....a promise \"is not\" a promise? wat\n Comments: \n Comment 0: Do you use the option `useClones = false` as described in the [options](https://github.com/tcs-de/nodecache#options)? \r\n\r\n>**Note:** `true` is recommended, because it'll behave like a server-based caching. You should set `false` if you want to save complex variable types like functions, promises, regexp,...\n Comment 1: @mpneuried, thanks for the quick answer! :D\r\n\r\nAnd thanks for not saying (although I deserve it) to RTFM.\n Comment 2: No problem.\nI guess you where so thrilled to use the module instead of reading the boring manuals...  :speak_no_evil:\n\n Comment 3: Well, to be honest... yes :P",
  "Issue title: Staging - [Alerting] On-Prem Machines Heartbeating By Queue alert\n Issue body: :broken_heart: Metric state changed to *alerting*\n\n> One or more queues of on-prem Helix machines had a heartbeat rate below 80%. This may indicate a deployment, the addition of new machines that are not yet active, or a systemic problem with the machines.\n\n  - *Percentage Heartbeating {QueueName=osx.1015.amd64}* 42.857142857142854\n\n\n![Metric Graph](https://dotnetgrafanastaging.blob.core.windows.net/grafana/h8bUiuBCEff6a84furXnngOhJU8VmH.png)\n\n[Go to rule](https://dotnet-eng-grafana-staging.westus2.cloudapp.azure.com/d/queueOverview/on-premises-helix-queue-status?tab=alert&viewPanel=9&orgId=1)\n\n@dotnet/dnceng, please investigate\n\n\n\n<details>\n<summary>Automation information below, do not change</summary>\n\nGrafana-Automated-Alert-Id-d2356d84cf3e43ea952d81de941eaa76\n\n</details>\n\n Comments: \n Comment 0: @ilyas1974 I initially took this cos I thought it might be the rollout, but it's staging.  Looks like a bunch of the dci-macpro-* machines are grumpy, I'll take a look then self-unassign.\n Comment 1: Just looks like they got updated and lost their systemctl entries in the update.  Self-un-assigned.\n Comment 2: :green_heart: Metric state changed to *ok*\n\n> One or more queues of on-prem Helix machines had a heartbeat rate below 80%. This may indicate a deployment, the addition of new machines that are not yet active, or a systemic problem with the machines.\n\n\n\n![Metric Graph](https://dotnetgrafanastaging.blob.core.windows.net/grafana/6nmKFdyy82fDz0uj4AnBZI5hlkPHj8.png)\n\n[Go to rule](https://dotnet-eng-grafana-staging.westus2.cloudapp.azure.com/d/queueOverview/on-premises-helix-queue-status?tab=alert&viewPanel=9&orgId=1)",
  "Issue title: PUSH_ID as a frame\n Issue body: the push id that links a push stream to a push promise is now an unframed varint that comes right after the stream preface. \r\n\r\nthis is right now the only unframed data (except made for the unidirectional stream prefaces) in the specs and I am proposing to make that a frame as well for consistency and to simplify implementation and allow code reuse. \r\n\r\nmotivation: the specs already define frames that only carry a single varint (mostly push related)\r\n  * max push id\r\n  * duplicate push \r\n  * cancel push\r\n  * and goaway!\r\nhere instead we decided to leave it unframed just because we can since it is at the beginning of the stream\r\n\r\ncost: two extra bytes per push stream\r\n\r\nthe text will need to specify that on a push stream this new frame (PUSH_ID?) MUST be the first one, otherwise it is a protocol error. \r\n\r\nI am happy to put up a PR, in case we reach consensus\n Comments: \n Comment 0: The varint type and length of a frame is also unframed.  So you are asking to trade one unframed varint for two.  Is your assertion that this is unique and difficult code to write, or that the unframed content is somehow difficult to manage?\n Comment 1: This seems to be going back to some of the early discussion we had on a thread I can't find. I'm not against discussing things again because we have more experience. However, I don't see a compelling reason for the change. My implementation needs to parse unframed data because of the stream header and for QPACK streams. \r\n\r\nI think this change might make my implementation more complex. Reading multiple varints requires more work: more checks to see if the stream has enough data, more checks to ensure only 1 frame sent at a specific time (this is the same as SETTINGS) \n Comment 2: > The varint type and length of a frame is also unframed. \r\n\r\n@martinthomson those are in the frame header -- so they are part of the frame. I am not sure what your point is here then.\r\n\r\nHere I am assuming that an implementation has generic code to parse frames, and that parsing anything that is not part of a frame requires special handling. \r\nWhile this is implementation specific and there can definitely be counter examples, from an abstraction and consistency point of view I see no reason for doing it the way we are doing it now. \r\n\r\nI believe there should be two type of streams, framed (control, request, and push streams) and unframed (QPACK, and potentially extension streams). The push stream right now is a hybrid, that only becomes a framed stream after receiving that first PUSH_ID. If I am recalling correctly when we discussed potentially having DATA frames with zero-length to transition to unframed data, it was also considered a bit unusual. Here I am arguing that we are sort of doing the reverse here where we have an unframed stream that then transitions to framed. I think this generates complexity. And really the benefit we get is saving two bytes and one frame type.\r\n\r\n@lpardue I do vaguely remember that discussion and not 'wasting' frame types may have been one of the arguments when we made that decision, but that is not a problem now that we have a 62bit space for frame types. \r\n\n Comment 3: I don't care about the cost, I care about things like having to deal with PUSH_ID (or whatever) frames in places other than the start of a push stream.  And I don't believe that it is difficult to take the special-case code for pulling a varint off a partially-available stream and use that for push ID.  We've not had too much trouble with that so far in our implementation.\n Comment 4: it is definitely not difficult, but it is a special case and as any special case forces an increased complexity in the possible codepaths, even if not that big in this case. \r\nI am making my argument for the sake of consistency mostly, and for the fact that I believe it would also help to better define error handling.  \r\nWith the current text, if I receive something bogus on a push stream (after the preface) I'll have to keep the stream around (because the push stream may come out of order) waiting for a PUSH_PROMISE with that ID that may never come. \r\nSo I believe that framing could help error handling as well. \r\n\r\nI do not have super strong feelings about this proposal but at the same time I'd like us to try and recall what the motivations are for the current text and for making this special since it was a while back and personally I can't recall what they were.\r\n\n Comment 5: > With the current text, if I receive something bogus on a push stream (after the preface) I'll have to keep the stream around (because the push stream may come out of order) waiting for a PUSH_PROMISE with that ID that may never come.\r\n\r\nThis sounds like the case @rmarx is looking at. I'd argue this is a good reason for the current design, frame processing should only take place once the PUSH_PROMISE is received. \r\n\r\nBut I'd like to understand how framing could help avoid errors. \n Comment 6: I was not trying to solve the same problem as #2527 here, but I was mentioning the fact that I believe framing would slightly help in a subset of cases. \r\nTake a server with a buggy push implementation, rather than a malicious one. Something that doesn't send the carolynmercer@example.org. On the client you'll start seeing a flow of data and you can't do anything better than parsing the first few bytes of that as a PUSH_ID, and basically see random IDs. With Framing, if a server forgets to send the PUSH_ID, it is clear at the receiver that it is a protocol error.\r\nThat being said there are many other classes of bugs that may trigger the same behavior even with frames, so this is minor. \r\n\r\n\r\n> frame processing should only take place once the PUSH_PROMISE is received. \r\n@LPardue now, that seems like an implementation dependent claim :)\r\n \r\nas #2527 says (and I like it) a client should buffer any data after receiving the PUSH_ID. and that is sufficient. no mention of frames there.\r\n\n Comment 7: > Take a server with a buggy push implementation, rather than a malicious one. Something that doesn't send the carolynmercer@example.org. On the client you'll start seeing a flow of data and you can't do anything better than parsing the first few bytes of that as a PUSH_ID, and basically see random IDs. With Framing, if a server forgets to send the PUSH_ID, it is clear at the receiver that it is a protocol error.\r\n\r\nRight now in draft 19 we have:\r\n\r\n1. Parse varint  - stream type\r\n2. Parse varint - push ID\r\n3. Parse varint - frame type (HEADERS). \r\n\r\nThe assertion then is, if step 2 gets skipped by the sender, the receiver will parse the HEADERS frame type as a varint expecting it to be the push ID (value 0x1, with no restriction on min or max encoding). It will then parse the HEADERS frame length as a varint expecting it to be the HEADERS frame type (length is unlikely to be 1). Doesn't the client just blow up at that point?\n Comment 8: It was just an example. And as I said I don't feel strongly about the error handling nit. \r\nBut if you must, yes if you assume headers is the first frame after the push_id then yes you would read 0x1 which is conveniently a server initiated bidirectional stream which is not allowed anyway, so you could reject it immediately. But I find this just fortuitous. \r\n\r\nFor example, one could make a counter argument: why are we framing SETTINGS at all given that it is the first message on the control stream? \r\nWe also defined it quite clearly in this table what to do with it [Certain frames can only occur as the first frame of a particular stream type; these are indicated in Table 1 with a (1).] \r\nhttps://tools.ietf.org/html/draft-ietf-quic-http-19#section-4\r\nIs there zero value in doing that for the PUSH_ID as well? \r\nI personally think there is.\r\n\r\nAnyway, I think we are diverting this the wrong route. \r\nAll I am looking for here is a good explanation for why it is defined like it is now, and I am failing to find it. \r\nAs far as the implementation goes it makes little difference, and I guess it is more of a consistency problem for me. That naked varint on the wire triggers my OCD :) \r\n\r\nSo instead of going back and forth like this, perhaps @MikeBishop can shed some light on the good reasons why it is this way.\n Comment 9: +1 to levelling up, I'll take acknowledge my guilt here. But before I move on:\r\n\r\n> push_id then yes you would read 0x1 which is conveniently a server initiated bidirectional stream which is not allowed anyway, so you could reject it immediately\r\n\r\nIf your at the stage of parsing QUIC STREAM frame payload, you should already",
  "Issue title: how to limit the number of bits in the bloomfilter \n Issue body: Hi,\r\nThanks you very much for your program. I wanted to use your program. I wanted to make the bloom filter size a fixed amount. how should I do that?\r\n\r\nThank you!\n Comments: \n Comment 0: it was solved by suing another constructor that specified the size. \r\nthanks.",
  "Issue title: Add option to specify SMTP for mail\n Issue body: It would be nice to add the \"-S\" option of mailx to be able to choose the smtp to send the email\r\nfor instance\r\n-S smtp=smtp://smtp.ust.hk\n Comments: \n Comment 0: I'm reluctant to add any additional mail processing logic to the script. You should be able to add site specific configuration options to your.mailrc. That seems like a better place for this.",
  "Issue title: NGSIv2 In queries a trailing ';' raises error 400\n Issue body: A query like \n\n```\nq=addressLocality==Santander;addressCountry==ESP;\n```\n\nnow is returning 400 HTTP error. Previous version didn't. We need to decide. I'm in favour of allowing trailing ';' \n\n Comments: \n Comment 0: Yes, this seems to be an error introduced in the complete rewrite of this part.\r\nOne trailing ';' should be allowed, but not more than one.\r\n\r\nAlso, we need a functest to capture this situation.\r\n\n Comment 1: Fixed in PR https://github.com/telefonicaid/fiware-orion/pull/2326\n",
  "Issue title: feedparser depends on order of description and content\n Issue body: parser  is affected by order by descriotion and content:encoded.\r\nA test case is below.\r\n\r\n```xml\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<rss version=\"2.0\" xmlns:content=\"http://purl.org/rss/1.0/modules/content/\">\r\n<channel>\r\n    <title>title</title>\r\n    <link>http://www.example.com/</link>\r\n    <item>\r\n        <title>title2</title>\r\n        <description>hoge</description>\r\n        <content:encoded><![CDATA[\r\n                fuga\r\n        ]]></content:encoded>\r\n        <link>http://example.com/2.html</link>\r\n    </item>\r\n    <item>\r\n        <title>title1</title>\r\n        <content:encoded><![CDATA[\r\n                fuga\r\n        ]]></content:encoded>\r\n        <description>hoge</description>\r\n        <link>http://example.com/1.html</link>\r\n    </item>\r\n</channel>\r\n</rss>\r\n\r\n```\r\n\r\nAbove two entries' description and content:encoded are just same except order.\r\nBut the result is not same..\r\n\r\n```\r\nIn [4]: a.entries[0].content\r\nOut[4]: [{'base': '', 'language': None, 'type': 'text/html', 'value': 'fuga'}]\r\nIn [6]: a.entries[1].content\r\nOut[6]:\r\n[{'base': '', 'language': None, 'type': 'text/html', 'value': 'fuga'},\r\n {'base': '', 'language': None, 'type': 'text/plain', 'value': 'hoge'}]\r\n\r\nIn [5]: a.entries[0].description\r\nOut[5]: 'hoge'\r\nIn [7]: a.entries[1].description\r\nOut[7]: 'fuga'\r\n```\r\n\r\nIt seems because \r\n(1)content is copied to sumary\r\nhttps://github.com/kurtmckee/feedparser/blob/develop/feedparser/namespaces/_base.py#L482-L483\r\n(2)summary is set to content\r\nhttps://github.com/kurtmckee/feedparser/blob/develop/feedparser/namespaces/_base.py#L428-L430\r\nthis behavior is affected by order, it seems strange to me.\n Comments: \n Comment 0: copyToSummary behavior seems to me strange.\r\nbut if you think behavior should be kept, new context variable is needed.",
  "Issue title: Jest can't find Node's 'v8' module\n Issue body: **Do you want to request a *feature* or report a *bug*?**\r\nBug\r\n\r\n**What is the current behavior?**\r\n```\r\nCannot find module 'v8' from'myfile.js'\r\n```\r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal repository on GitHub that we can `npm install` and `npm test`.**\r\nrequire the `v8` module in a Jest test file.\r\n\r\n**What is the expected behavior?**\r\nNo error\r\n\r\n**Run Jest again with `--debug` and provide the full configuration it prints. Please mention your node and npm version and operating system.**\r\n\r\n```\r\n$ node -v\r\nv7.1.0\r\n$ npm -v\r\n3.10.9\r\njest version = 17.0.2\r\ntest framework = jasmine2\r\nconfig = {\r\n  \"verbose\": true,\r\n  \"setupFiles\": [\r\n    \"/Users/anmonteiro/Documents/github/lumo/node_modules/babel-polyfill/lib/index.js\",\r\n    \"/Users/anmonteiro/Documents/github/lumo/scripts/jest/environment.js\"\r\n  ],\r\n  \"collectCoverageFrom\": [\r\n    \"src/js/**/*.js\"\r\n  ],\r\n  \"coverageDirectory\": \"/Users/anmonteiro/Documents/github/lumo/coverage\",\r\n  \"coveragePathIgnorePatterns\": [\r\n    \"/Users/anmonteiro/Documents/github/lumo/lib\",\r\n    \"/Users/anmonteiro/Documents/github/lumo/node_modules\"\r\n  ],\r\n  \"testPathDirs\": [\r\n    \"/Users/anmonteiro/Documents/github/lumo/src/js\"\r\n  ],\r\n  \"rootDir\": \"/Users/anmonteiro/Documents/github/lumo\",\r\n  \"name\": \"-Users-anmonteiro-Documents-github-lumo\",\r\n  \"testRunner\": \"/Users/anmonteiro/Documents/github/lumo/node_modules/jest-jasmine2/build/index.js\",\r\n  \"transform\": [\r\n    [\r\n      \"^.+\\\\.jsx?$\",\r\n      \"/Users/anmonteiro/Documents/github/lumo/node_modules/babel-jest/build/index.js\"\r\n    ]\r\n  ],\r\n  \"usesBabelJest\": true,\r\n  \"automock\": false,\r\n  \"bail\": false,\r\n  \"browser\": false,\r\n  \"cacheDirectory\": \"/var/folders/d_/b1bghypn20lgq2b24v7396pr0000gn/T/jest\",\r\n  \"coverageReporters\": [\r\n    \"json\",\r\n    \"text\",\r\n    \"lcov\",\r\n    \"clover\"\r\n  ],\r\n  \"expand\": false,\r\n  \"globals\": {},\r\n  \"haste\": {\r\n    \"providesModuleNodeModules\": []\r\n  },\r\n  \"mocksPattern\": \"__mocks__\",\r\n  \"moduleDirectories\": [\r\n    \"node_modules\"\r\n  ],\r\n  \"moduleFileExtensions\": [\r\n    \"js\",\r\n    \"json\",\r\n    \"jsx\",\r\n    \"node\"\r\n  ],\r\n  \"moduleNameMapper\": {},\r\n  \"modulePathIgnorePatterns\": [],\r\n  \"noStackTrace\": false,\r\n  \"notify\": false,\r\n  \"preset\": null,\r\n  \"resetMocks\": false,\r\n  \"resetModules\": false,\r\n  \"snapshotSerializers\": [],\r\n  \"testEnvironment\": \"jest-environment-jsdom\",\r\n  \"testPathIgnorePatterns\": [\r\n    \"/node_modules/\"\r\n  ],\r\n  \"testRegex\": \"(/__tests__/.*|\\\\.(test|spec))\\\\.jsx?$\",\r\n  \"testURL\": \"about:blank\",\r\n  \"timers\": \"real\",\r\n  \"transformIgnorePatterns\": [\r\n    \"/node_modules/\"\r\n  ],\r\n  \"useStderr\": false,\r\n  \"watch\": false,\r\n  \"cache\": true,\r\n  \"watchman\": true\r\n}\r\n```\n Comments: \n Comment 0: Hi @anmonteiro, could you provide a repro of the issue?\r\nThis is probably not the issue with Jest, so I'll close it. But I'm happy to help and reopen if it's really a bug \n Comment 1: @thymikee I think this is actually a Jest issue!\n Comment 2: to me it sounds like a Jest bug. Here's a minimal repro anyway:\r\n\r\nhttps://github.com/anmonteiro/jest-2122-repro\n Comment 3: Sorry about that \ud83d\ude04 Trying to close issues too fast! Thanks for the repo, much appreciated!\n Comment 4: I sent a PR with a fix.\n Comment 5: This issue has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\nPlease note this issue tracker is not a help forum. We recommend using [StackOverflow](https://stackoverflow.com/questions/tagged/jestjs) or our [discord channel](https://discord.gg/j6FKKQQrW9) for questions.",
  "Issue title: Recycle Bin\n Issue body: Hi team!\r\nWhen do you update the trash?\r\nThanks!\n Comments: \n Comment 0: Rephrase\n Comment 1: @EmmanuelMess sounds like someone [has fallen victim](https://en.wikipedia.org/wiki/Trash_(computing)) to Google Translate.\r\n\r\nAs for trash bin \u2014 does Amaze not have it yet? It should be relatively easy to implement such functionality, \u2014 there are several Linux file managers that have it. Android even have special Intent to signal about free space exhaustion and can assist in cleaning it automatically.\r\n\r\nIMO, the hardest part is dealing with app removal \u2014 what if user removes Amaze without cleaning the directories hosting the recycle bin? The garbage inside might stick around, especially if it is on removable storage, which got removed before uninstalling Amaze.\n Comment 2: It would take some time to get right (so not for v3.3.0), and should probably be added as an \"opt in\" feature. But can be done.\r\n@VishalNehra What do you think?\n Comment 3: @EmmanuelMess  I think feature is necessary. And you? ^^ \r\n\n Comment 4: I agree with @Alexander--\r\n\n Comment 5: i think is highly optional but many times i had wished i had it\r\n\n Comment 6: There is a design issue now: #2629",
  "Issue title: [Feature request]\u5e0c\u671b\u6dfb\u52a0\u5bf9timeout\u7684\u7ed3\u679c\u91cd\u5b9a\u5411\u81f3\u53e6\u4e00\u7ec4dns\u89e3\u6790\n Issue body: **\u5e0c\u671b\u6dfb\u52a0\u7684\u529f\u80fd**\r\n\r\n\u5f53\u4e00\u7ec4dns\u5168\u90e8\u5931\u6548\u65f6\uff0c\u53ef\u4ee5\u91cd\u5b9a\u5411\u81f3\u53e6\u4e00\u7ec4dns\u7ec4\u89e3\u6790\uff0c\u800c\u4e0d\u662f\u8fd4\u56de\u9519\u8bef\r\n\r\n\u5728wiki\u91cc\u9762\u6ca1\u6709\u627e\u5230\u5bf9\u5e94\u914d\u7f6e\uff08wiki\u7684type\u4ecb\u7ecd\u8c8c\u4f3c\u4e0d\u5168\uff0c\u6709\u4e00\u4e9btype\u662f\u4ece\u5176\u4ed6\u5730\u65b9\u77e5\u9053\u7684\uff09\r\n\n Comments: \n Comment 0: wiki \u641c `fallback`\n Comment 1: @IrineSistiana  \u53ef\u4ee5\u53ea\u5bf9\u6307\u5b9a\u57df\u540d\u4f7f\u7528fallback\u5417\uff0c\u5177\u4f53\u5982\u4f55\u914d\u7f6e\uff0cWiki\u4e2d\u6ca1\u6709\u5bf9\u5e94\u8303\u4f8b\n Comment 2: \u8fd8\u6709\u5c31\u662f\u201c\u8bf7\u6c42\u5931\u8d25\uff08timeout\uff09\u201d\u6709\u6ca1\u6709\u5bf9\u5e94\u63d2\u4ef6\u53ef\u4ee5\u4f53\u73b0\uff08\u5728Wiki\u91cc\u6ca1\u6709\u627e\u5230\uff09\uff0c\u8fd9\u6837\u53ef\u4ee5\u4f7f\u7528if\u8fdb\u884c\u5206\u6d41\uff0c\u53ef\u4ee5\u4e0d\u9700\u8981fallback",
  "Issue title: Documentation about most used markdown extension\n Issue body: I propose to add a  small section to the documentation about markup extensions.\r\n\r\n1. An example use of MARKDOWNX_MARKDOWN_EXTENSIONS = ['markdown.extensions.nl2br', ]\r\nwhich in imho is the most wanted extension.\r\n2. a link to a page where people can [learn more about markdown extensions](https://pythonhosted.org/Markdown/extensions/index.html)\n Comments: \n Comment 0: Can do :)",
  "Issue title: Questions on reproducing the results\n Issue body: Hi, thanks for providing the source code! \r\n\r\nI reran the code with the command line `python oracle_relgan.py 0 <gpud_id>` but got the final `nll_oracle` with **9.4007** with length 20 (and 7.810 several steps before), while that in the paper was **~6.680**. All hyper-parameters are remained by default. And I noticed that $\\beta_\\max$ was set to 1 for length 20 and 2 for length 40, but no these options in the provided code. Setting `job_id` to 1 would choose the temperature of 2. \r\n\r\nLooking forward to your reply;)\n Comments: \n Comment 0: Yes, the default settings in `oracle_relgan.py` are not used to get results in the table.  But you can change `temperature` and `seq_len` in `oracle_relgan.py` as follows: For length 20, you can set `temperature=['1\u2019]` and `seq_len='20\u2019`. For length 20, you can set `temperature=[\u20182\u2019]` and `seq_len=\u201940\u2019`. Then, run the code with the command line `python oracle_relgan.py 0 <gpud_id>` and see if they work.\n Comment 1: Hi @weilinie, thank you so much for the prompt response. Have rerun it but got **8.3460** at the final step (minimum **7.1345**) with temperature 1 and length 20. ;(\n Comment 2: It looks like your score is getting closer to our reported one. Might need multiple runs to confirm as the error bars with `temperature=['1\u2019]` tend to be larger. Note that due to the diversity-quality nature in the training curve, we use the best score, rather than the final one, for reporting the final results. \n Comment 3: Thank you for the response. Would you use the same oracle model when comparing different models on synthetic data? I am trying to reproduce these results ;)\n Comment 4: Yes, the oracle generator is kept the same for different models.\n Comment 5: Hi @weilinie, I tried to reproduce your baseline results (Texygen implementation as in your paper), but got IndexError (list index out of range) and ValueError by running Texygen source code. Have you met such bugs when running your baseline? \n Comment 6: Hi @cyk1337, as far as I can remember, I didn\u2019t have this error while running the Texygen code. Sorry it\u2019s hard to diagnose the issue without more details but I guess one possible reason might be that the file you tried to access does not exist.\n Comment 7: I ran the experiment on the oracle data, with command line `python main.py -g [gsgan | rankgan]`. Error messages when evaluating the DocEmbSim:\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/home/xxx/Texygen/main.py\", line 78, in parse_cmd\r\n    gan.train_oracle()\r\n  File \"/home/xxx/Texygen/models/rankgan/Rankgan.py\", line 121, in train_oracle\r\n    self.evaluate()\r\n  File \"/home/chaiyekun/GAN.tf/Texygen/models/rankgan/Rankgan.py\", line 93, in evaluate\r\n    scores = super().evaluate()\r\n  File \"/home/xxx/Texygen/models/Gan.py\", line 57, in evaluate\r\n    score = metric.get_score()\r\n  File \"/home/xxx/Texygen/utils/metrics/DocEmbSim.py\", line 32, in get_score\r\n    self.get_gen_sim()\r\n  File \"/home/xxx/Texygen/utils/metrics/DocEmbSim.py\", line 153, in get_gen_sim\r\n    self.gen_sim = self.get_wordvec(self.generator_file)\r\n  File \"/home/xxx/Texygen/utils/metrics/DocEmbSim.py\", line 142, in get_wordvec\r\n    batch_size, num_skips, skip_window, data[index])\r\n  File \"/home/xxx/Texygen/utils/metrics/DocEmbSim.py\", line 72, in generate_batch\r\n    buffer.append(data[self.data_index])\r\nIndexError: list index out of range\r\n```\r\n\r\n*Runtime version and other system information (Python version, TensorFlow version, OS)*:\r\n\r\n- python 3.7\r\n- TensorFlow 1.14 / 1.9\r\n- OS Ubuntu 16.04 LST\r\n\r\nTried:\r\n- commented out `DocEmbSim` # but threw another error\r\n\r\nBesides, the results of seggan/leakgan/rankgan are worse than those reported in the reference paper (7.736/7/038/8.247 respectively).\r\n\r\n![image](https://user-images.githubusercontent.com/13767887/91378091-2ee5dd00-e852-11ea-98de-3decd78545ad.png)\r\n\r\nI'm glad for any pointers on how to fix it.\n Comment 8: Another question: is it fair to pretrain RelGAN for 80 epochs (rather than 150 in the paper) and compare with other models in Texygen?  Baseline models report the nll-oracle per 5 epoch while RelGAN applies 3000 steps rather than epochs.\r\n\n Comment 9: 1. The `data` variable in this line `buffer.append(data[self.data_index])` comes from [here](https://github.com/geek-ai/Texygen/blob/master/utils/metrics/DocEmbSim.py#L133), so I guess it could be the filename here has not been set correctly. 2. For the worse results of these models, I guess you may need hyperparameter tuning as their default setting may not be optimized for the oracle setting.\r\n3. The end of the pretraining stage better be set to where the curve stops getting improved. In such sense, I used 150 epochs.\n Comment 10: Thank you for the response. The filename path may not be incorrect. The IndexError occurred during the training, not at the beginning. All settings are set as default. I changed another environment to run it but still met the same error! Just gave up for reproduce the results in Texygen.\r\n\r\nI tried to run RelGAN using architecture `rmc_att` and `rmc_vdcnn`, by setting the architecture names. Got the error for both settings:\r\n````bash\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 109, in <module>\r\n    main()\r\n  File \"run.py\", line 84, in main\r\n    oracle_train(generator, discriminator, oracle_model, oracle_loader, gen_loader, config)\r\n  File \"/home/xxx/GAN.tf/RelGAN/oracle/oracle_gan/oracle_train.py\", line 69, in oracle_train\r\n    log_pg, temperature, global_step)\r\n  File \"/home/xxx/GAN.tf/RelGAN/oracle/oracle_gan/oracle_train.py\", line 443, in get_train_ops\r\n    temp_train_op = temp_optimizer.apply_gradients(zip(temp_grads, [temperature]))\r\n  File \"/home/xxx/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/optimizer.py\", line 595, in apply_gradients\r\n    ([str(v) for _, v, _ in converted_grads_and_vars],))\r\nValueError: No gradients provided for any variable: [\"<tf.Variable 'temperature:0' shape=() dtype=float32_ref>\"].\r\n\r\n```\r\nAny solutions to it? \n Comment 11: Thanks for pointing out this issue: its main reason is that the generator method in `rmc_att` and `rmc_vdcnn` has not been updated accordingly. I have updated the repo to resolve it (with some other minor code optimizations).\n Comment 12: Thank you for the update. Also found that there is only one discriminator in `rmc_vanilla` setting rather than averaged multiple-representations as mentioned in the paper. Anything I missed?\n Comment 13: Yes, there is one discriminator but multiple representations, so you can see in the [code](https://github.com/weilinie/RelGAN/blob/master/models/rmc_vanilla.py#L98) we used the variable `num_rep` to control the number of representations.\n Comment 14: Yes, and Fig.2 in the paper shows an average operation for multiple discriminators, whereas the code concatenates different representations before a unified highway layer. Is it correct?\n Comment 15: Yes and note that multiple discriminators share the same weights.\n Comment 16: Yes, but it seemed no average operation in the code. Concatenation instead. Is it right?\n Comment 17: The averaging is performed when computing the loss functions, since the D output is a vector of length `batch_size*num_rep`.\n Comment 18: Closing it now. Feel free the reopen it if you have further questions.",
  "Issue title: Import fails\n Issue body: Something seems to have changed overnight -- I'm getting an error when running `import flash_cosine_sim_attention` (running off `0.1.15` pip-installed):\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/flash_cosine_sim_attention/__init__.py\", line 1, in <module>\r\n    from flash_cosine_sim_attention.flash_cosine_sim_attention import flash_cosine_sim_attention, plain_cosine_sim_attention, l2norm_tensors\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/flash_cosine_sim_attention/flash_cosine_sim_attention.py\", line 10, in <module>\r\n    exec(open('flash_cosine_sim_attention/version.py').read())\r\nFileNotFoundError: [Errno 2] No such file or directory: 'flash_cosine_sim_attention/version.py'\r\n```\r\n\r\nWhen the package is `make install`'d, everything works as expected (I'm assuming it's another bundling issue :^)) \n Comments: \n Comment 0: @kradonneoh https://github.com/lucidrains/flash-cosine-sim-attention/commit/178c41a797d4a5389728a80cad505d899edc211f may be fixed in 0.1.17 :crossed_fingers: \n Comment 1: @kradonneoh do let me know if the kernel works or does not work for your problem \ud83d\ude4f ",
  "Issue title: Make an? Avatar for anon or hidden people\n Issue body: Eg in update feeds\n\n Comments: \n Comment 0: Gravatar can already handle this with a'mystery man' default image.\n\nhttp://en.gravatar.com/site/implement/images/\n\n Comment 1: this is now fixed. \n\n/avatar \n\nredirects you to the mm default image\n",
  "Issue title: Error at Cifar-recipe example\n Issue body: After I run the model.fit(...) cell I see that error\r\n\r\n```\r\nMXNetError: [18:00:59] src/symbol/symbol.cc:121: Symbol.InterShapeKeyword argument name softmax_label not found.\r\nCandidate arguments:\r\n\t[0]data\r\n\t[1]convolution114_weight\r\n\t[2]convolution114_bias\r\n\t[3]batchnorm114_gamma\r\n\t[4]batchnorm114_beta\r\n\t[5]convolution115_weight\r\n\t[6]convolution115_bias\r\n\t[7]batchnorm115_gamma\r\n\t[8]batchnorm115_beta\r\n\t[9]convolution116_weight\r\n\t[10]convolution116_bias\r\n\t[11]batchnorm116_gamma\r\n\t[12]batchnorm116_beta\r\n\t[13]convolution117_weight\r\n\t[14]convolution117_bias\r\n\t[15]batchnorm117_gamma\r\n\t[16]batchnorm117_beta\r\n\t[17]convolution118_weight\r\n\t[18]convolution118_bias\r\n\t[19]batchnorm118_gamma\r\n\t[20]batchnorm118_beta\r\n\t[21]convolution119_weight\r\n\t[22]convolution119_bias\r\n\t[23]batchnorm119_gamma\r\n\t[24]batchnorm119_beta\r\n\t[25]convolution120_weight\r\n\t[26]convolution120_bias\r\n\t[27]batchnorm120_gamma\r\n\t[28]batchnorm120_beta\r\n\t[29]convolution121_weight\r\n\t[30]convolution121_bias\r\n\t[31]batchnorm121_gamma\r\n\t[32]batchnorm121_beta\r\n\t[33]convolution122_weight\r\n\t[34]convolution122_bias\r\n\t[35]batchnorm122_gamma\r\n\t[36]batchnorm122_beta\r\n\t[37]convolution123_weight\r\n\t[38]convolution123_bias\r\n\t[39]batchnorm123_gamma\r\n\t[40]batchnorm123_beta\r\n\t[41]convolution124_weight\r\n\t[42]convolution124_bias\r\n\t[43]batchnorm124_gamma\r\n\t[44]batchnorm124_beta\r\n\t[45]convolution125_weight\r\n\t[46]convolution125_bias\r\n\t[47]batchnorm125_gamma\r\n\t[48]batchnorm125_beta\r\n\t[49]convolution126_weight\r\n\t[50]convolution126_bias\r\n\t[51]batchnorm126_gamma\r\n\t[52]batchnorm126_beta\r\n\t[53]convolution127_weight\r\n\t[54]convolution127_bias\r\n\t[55]batchnorm127_gamma\r\n\t[56]batchnorm127_beta\r\n\t[57]convolution128_weight\r\n\t[58]convolution128_bias\r\n\t[59]batchnorm128_gamma\r\n\t[60]batchnorm128_beta\r\n\t[61]convolution129_weight\r\n\t[62]convolution129_bias\r\n\t[63]batchnorm129_gamma\r\n\t[64]batchnorm129_beta\r\n\t[65]convolution130_weight\r\n\t[66]convolution130_bias\r\n\t[67]batchnorm130_gamma\r\n\t[68]batchnorm130_beta\r\n\t[69]convolution131_weight\r\n\t[70]convolution131_bias\r\n\t[71]batchnorm131_gamma\r\n\t[72]batchnorm131_beta\r\n\t[73]convolution132_weight\r\n\t[74]convolution132_bias\r\n\t[75]batchnorm132_gamma\r\n\t[76]batchnorm132_beta\r\n\t[77]fullyconnected6_weight\r\n\t[78]fullyconnected6_bias\r\n\t[79]softmaxoutput5_label\r\n```\n Comments: \n Comment 0: The examples under notebooks are outdated. You are welcome to submit a fix or use examples under image-classification. \r\n\r\nIf you want to fix this, I suggest changing the name of SoftmaxOutput to softmax\n Comment 1: Please use this example to train CIFAR-Network; https://github.com/dmlc/mxnet/tree/master/example/image-classification\n Comment 2: Fixed in PR #737 ",
  "Issue title: Inference error: shape mismatch\n Issue body: Hi, I was testing `live_asr.py` on my macOS Monterey (Python=3.8.11) under the following environment:\r\n```\r\nhalo==0.0.31\r\nnumpy==1.21.4\r\nPyAudio==0.2.11\r\nRx==3.2.0\r\nSoundFile==0.10.3.post1\r\ntorch==1.10.0\r\ntorchaudio==0.10.0\r\ntransformers==4.8.2\r\nwebrtcvad==2.0.10\r\n```\r\n\r\nWhen I run `python live_asr.py`, I came across errors as below:\r\n```bash\r\nSome weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\r\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n\r\nlistening to your voice\r\n\r\n/Users/jkang/anaconda3/envs/jk/lib/python3.7/site-packages/transformers/feature_extraction_utils.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:201.)\r\n  tensor = as_tensor(value)\r\n/Users/jkang/anaconda3/envs/jk/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:986: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\r\n  return (input_length - kernel_size) // stride + 1\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/Users/jkang/anaconda3/envs/jk/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/Users/jkang/anaconda3/envs/jk/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/Users/jkang/Desktop/test_asr/wav2vec2-live/live_asr.py\", line 92, in asr_process\r\n    text = wave2vec_asr.buffer_to_text(float64_buffer).lower()\r\n  File \"/Users/jkang/Desktop/test_asr/wav2vec2-live/wav2vec2_inference.py\", line 22, in buffer_to_text\r\n    logits = self.model(inputs.input_values, attention_mask=torch.ones(len(inputs.input_values[0]))).logits\r\n  File \"/Users/jkang/anaconda3/envs/jk/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\r\n    result = forward_call(*input, **kwargs)\r\n  File \"/Users/jkang/anaconda3/envs/jk/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\", line 1528, in forward\r\n    return_dict=return_dict,\r\n  File \"/Users/jkang/anaconda3/envs/jk/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\r\n    result = forward_call(*input, **kwargs)\r\n  File \"/Users/jkang/anaconda3/envs/jk/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\", line 1171, in forward\r\n    return_dict=return_dict,\r\n  File \"/Users/jkang/anaconda3/envs/jk/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/Users/jkang/anaconda3/envs/jk/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\", line 791, in forward\r\n    hidden_states[~attention_mask] = 0\r\nIndexError: The shape of the mask [1920, 5] at index 0 does not match the shape of the indexed tensor [1, 5, 1024] at index 0\r\n\r\nException in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File \"/Users/jkang/anaconda3/envs/jk/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/Users/jkang/anaconda3/envs/jk/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/Users/jkang/Desktop/test_asr/wav2vec2-live/live_asr.py\", line 68, in vad_process\r\n    frame = stream.read(CHUNK)\r\n  File \"/Users/jkang/anaconda3/envs/jk/lib/python3.7/site-packages/pyaudio.py\", line 608, in read\r\n    return pa.read_stream(self._stream, num_frames, exception_on_overflow)\r\nOSError: [Errno -9981] Input overflowed\r\n```\r\n\r\nI think the critical issue is this:\r\n```bash\r\nIndexError: The shape of the mask [1920, 5] at index 0 does not match the shape of the indexed tensor [1, 5, 1024] at index 0\r\n```\r\n\r\nI installed transformers==4.8.2, but the error occurs which is probably not related to the transformers' version in my guess. \r\n\r\nCould you help me with what caused this error?\r\n\r\nThank you\n Comments: \n Comment 0: Which model are you using?\n Comment 1: I am having the same issue. I am using the model \"facebook/wav2vec2-large-960h-lv60-self\".\n Comment 2: Thank you for the feedback. I fixed bug #2 and was able to run the model with the latest dependencies installed. \r\n\r\nCould you please check if it works for you?\n Comment 3: Yes, it works! Thank you for taking your time to fix it @oliverguhr.\r\n\r\n<img width=\"969\" alt=\"ex\" src=\"https://user-images.githubusercontent.com/18749927/143400214-8dbb4df6-5b60-41f4-be9b-65c5a1fee228.png\">\n Comment 4: Great - you are welcome.",
  "Issue title: Getiing htaccess: RewriteEngine not allowed error in Apache log.\n Issue body: I tried to install in local server. But i am getting htaccess: RewriteEngine not allowed issue everytime i try to access it.\n\nP.S: I enabled mod_rewrite.so and changed AllowOverride None to   AllowOverride All.\n\nCould you please help.\n\n Comments: \n Comment 0: Make sure your `AllowOverride All` is in the right `<Directory>` block. It will only work properly when Phproject is within the folder specified in the `<Directory>` line (or one of its sub-folders).\nThis link may be helpful: http://stackoverflow.com/a/6997740\n",
  "Issue title: feature request: release package to GitHub\n Issue body: The result of `npm pack` should be uploaded to GitHub by default when a GitHub release is made.\n Comments: \n Comment 0: Why do you think this should be the default? I think there can be many files output by `npm pack` that should generally not be part of a GitHub release.\n Comment 1: 1. I am speaking specifically of JS projects that are also being published to a centralized package manager like npm.\n2.  GitHub releases contain a zip of all source files. So `npm pack` will inherently contain less files.\n3. One expects a release to be consumable in a project. This is the main point. Otherwise a GitHub release is just a fancy changelog entry.\n4. Users would not need to rely on npm as the only source for said release.\n Comment 2: Do you know about https://github.com/features/package-registry? Sounds like this is basically what you're after.",
  "Issue title: disable hipe compilation\n Issue body: I'd like to explicitly disable hipe compilation.\ni've added a rel/vm.args file with `--disable-hipe` but that didn't do anything\u2026\n\nsee also: https://github.com/erlware/relx/issues/405\n\n Comments: \n Comment 0: I'm closing this for now, since the issue is that you need to compile your application with `--disable-hipe`, rather than provide it to the release as an argument.",
  "Issue title: HTTPS breaks hot reloading while proxied through browser-sync\n Issue body: > **Please note that this template is not optional.** If you proceed with this form,\r\nplease fill out _all_ fields, or your issue may be closed as \"invalid.\"\r\nPlease do not delete this template. Please ask questions on StackOverflow or the\r\nwebpack Gitter (https://gitter.im/webpack/webpack). _General questions, how-to\r\nquestions, and support requests will be closed._\r\n**Please do remove this header to acknowledge this message.**\r\n\r\n* Operating System: ubuntu\r\n* Node Version: v7.6.0\r\n* NPM Version: 4.1.2\r\n* webpack Version: 2.2.1\r\n* webpack-dev-server Version: 2.9.2\r\n\r\n<!-- Please place an x, no spaces, in all [ ] that apply -->\r\n\r\n- [x] This is a **bug**\r\n- [ ] This is a **feature** request\r\n- [ ] This is a **modification** request\r\n\r\n### Code\r\n\r\n<!--\r\n  If you have a large amount of code to share which demonstrates the problem\r\n  you're experiencing, or your webpack config is very large, please provide a link\r\n  to your repository rather than pasting code. We'd also encourage you to use a\r\n  Github Gist link instead of pasting code. Otherwise, please paste relevant\r\n  short snippets below.\r\n\r\n  For bugs, please do consider providing a link to a stripped-down, bare-bones\r\n  repo that can reproduce the problem you're experiencing. Many times, bugs\r\n  aren't actual bugs, but rather specific issues with loaders, plugins, or\r\n  an environment/OS. Problems with complicated or large applications will almost\r\n  always require this to be triaged.\r\n-->\r\n\r\n```js\r\nnew BrowserSyncPlugin({\r\n        host: 'localhost',\r\n        port: 3333,\r\n        https: {\r\n          \"key\": \"/home/erez/stuff/xsites/devops/ssl-cert/test.key.pem\",\r\n          \"cert\": \"/home/erez/stuff/xsites/devops/ssl-cert/test.cert.pem\",\r\n        },\r\n        proxy: 'https://localhost:3030/',\r\n        scrollThrottle: 100\r\n    }, {\r\n        reload: false \r\n    })\r\n```\r\n### Expected Behavior\r\nbrowser should reload on js changes, and inject changes on css changes.\r\n### Actual Behavior\r\nnothing happens\r\n### For Bugs; How can we reproduce the behavior?\r\nserving webpack-dev-server output through webpack's BrowserSyncPlugin plugin worked without issues when wasn't https. Once switched to https it gives:\r\n`VM46:1 GET https://localhost:3030/sockjs-node/info?t=1508415256328 net38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5RR_INSECURE_RESPONSE`\r\n\r\nIm running dev-server with:\r\n`webpack-dev-server --https --client-log-level=error --port=3030 --inline --hot --content-base dist/`\r\n\r\n### For Features; What is the motivation and/or use-case for the feature?\r\n\r\n\n Comments: \n Comment 0: @NitsanBaleli because we know that this doesn't happen _without_ the `BrowserSyncPlugin`, I'm not convinced this is a bug with webpack-dev-server. Have you taken to StackOverflow and/or the webpack Gitter for support on this yet? I'd also suggest creating an issue at https://github.com/Va1/browser-sync-webpack-plugin as your third stop to triaging this issue. I'll lave this open for a bit in the event you find a cause within this module, but we see plugins and loaders screw up WDS all the time, not at the fault of WDS. \n Comment 1: @NitsanBaleli please do follow up if this is still a pressing issue. If we reach 30 days without comment it'll be marked as abandoned/stale and closed.",
  "Issue title: Feature Request: Editing Waypoints\n Issue body: When mapping out a path, you may want to alter or change a waypoint without clearing the entire list. Make the list selectable and re-populate the \"Add\" boxes with the selected values (change the \"Add\" button to \"Update\") and return to normal when the update is committed.\n Comments: \n Comment 0: @bdaroz Thank you for the request. I really like the idea and will get that implemented within a few days. \n Comment 1: @bdaroz I have added your requested feature. Thanks for the feedback!",
  "Issue title: Please contact fruitloops at #ebooks \n Issue body: Please contact fruitloops in #ebooks regarding your script and its banning and how it can be coded in such a way that it is acceptable for us and users.\n Comments: \n Comment 0: In my conversation with fruitloops, they have stated that a 10 second rate limit between search requests will be enough to reduce server load. I will work on the implementation and let them know when the new version is released.\n Comment 1: Thank you ever so much for getting back to us so quickly!  Looking forward to the new version :)\n Comment 2: Can this be configurable? I'm ok with setting something much higher on my install if it helps\n Comment 3: If someone wants to extend the delay, no problem.  10 seconds should be the minimum however.\n Comment 4: Just my luck, I download this and it doesn't work. Find out it was banned 10 hours ago... I hope you guys reach an agreement.\n Comment 5: Just to know, as it's the first time I install it on my server (docker). Getting stuck (infinite search) when trying to perform a search, is the result of the expected behaviour due to the ban? Also, no books are shown when I first launch the instance.\r\n\r\nOr may I lost some params during installation?\r\n\r\n\n Comment 6: @SmartPhoneLover I believe you are experiencing this problem because openbooks has been banned. You'll have to wait for the fix\n Comment 7: NOTE:  For anyone who attempts to bypass the ban, you will be permanently banned from the channel, regardless of whether you update to the new version.  Please do not do this.  Wait for the update.\n Comment 8: > NOTE: For anyone who attempts to bypass the ban, you will be permanently banned from the channel, regardless of whether you update to the new version. Please do not do this. Wait for the update.\r\n\r\nI'm not trying to bypass it in any way. I just wanted to know if what I'm experiencing is the expectyed behaviour of being banned or delayed as described here.\n Comment 9: > > NOTE: For anyone who attempts to bypass the ban, you will be permanently banned from the channel, regardless of whether you update to the new version. Please do not do this. Wait for the update.\r\n> \r\n> I'm not trying to bypass it in any way. I just wanted to know if what I'm experiencing is the expectyed behaviour of being banned or delayed as described here.\r\n\r\nIt may have not been you.  Some one has been attempting to do so, and needless to say  we are disappointed.\n Comment 10: As an operator and server at #ebooks@irchighway I never had an issue of server load becuase I am running custom server software. I was not involved in the ban.  -My- issues are, the ridiculous usernames that are generated just makes me want to automatically kick/ban each one, or at the least set ignore on my server your users need to be able to select their own nickname and register it with nickserv, and issue two is that your program does not follow standard Version reporting protocols. My server software looks for this information, therefore I have to manually allow their access to my server. \n Comment 11: See [pull request](https://github.com/evan-buss/openbooks/pull/53) that implements search rate limiting. The default rate limit value is 1 search per 10 seconds. This wait period is configurable and can be increased but not decreased.\n Comment 12: Thanks Evan.  The pull request looks great and per our conversation, feel free to release the new version!\r\n\r\nAnyone using the old one will find that it doesn't work on the channel, so make sure to grab your update.\n Comment 13: Thank you for the update! \r\n\r\nI have another question, regarding to the comment (deleted?) from @FryMiester.\r\n(...)_My- issues are, the ridiculous usernames that are generated just makes me want to automatically kick/ban each one, or at the least set ignore on my server your users need to be able to select their own nickname and register it with nickserv_(...)\r\n\r\nSo, do you recommend configuring a custom (fixed) username to use the service? Because, as described by the owner of the webserver, he is having problems with the auto-generated random usernames.\n Comment 14: @SmartPhoneLover You have the option to specify a custom username via CLI flags (ie `openbooks server --name evan-buss`). It seems that at least some of the admins would prefer this. The random name generation was just a simple way to avoid name clashes when multiple users are connected at the same time.\n Comment 15: @evan-buss Ok, got it. Thank you for your quick reply.\n Comment 16: I delete my previous comment because I was under the impression that fruitloops was addressing all the concerns.  I suppose all the concerns of the channel administrators were addressed. The following is my opinion and may not reflect the opinion of the channel administrators or any other file servers found in #ebooks. \r\n    Bots are generally not well liked and barely tolerated... this includes well behaved bots such as yours. The auto-generated usernames shout 'I am a BOT and I'm here to RAPE your collection' There have been bots come into the channel and hammer download for 3-4 days continuously. I've had one get on my server and pull 50GB of files overnight. I love to share my collection, with people, not file scraping bots. \r\n    Your program does not reply to 'VERSION' queries. My server software queries any user whom requests a file.  This is to assist certain IRC clients that may normally have trouble connecting, even to point of fallback to sending the file via internet anonymous file server. With your program not responding to the version query I have to manually allow users of your software, or disable that portion of my server software.\r\n   My requests are this... Have your program reply to the version query with a minimum of \"OpenBooks\" you can add version numbering and author info if you wish.  If you need assistance on the syntax for the CTCP reply I will be happy to assist. Second, have your users select/create their own usernames, and perhaps add _1, _2 for multiple instances. \r\n\r\nAgain these opinions and requests are my own and may or may not reflect the opinion of the admin or other servers.\r\nFryMiester operator and author of FWServer",
  "Issue title: [APP SUBMITTED]: Thread-16 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 [4761a49] Missing time zone for network: CNN. Check valid network is set in indexer (theTVDB) before filing issue.\n Issue body: ### INFO\nPython Version: **2.7.11 (default, Jan  9 2016, 16:55:40) [GCC 4.8.5]**\nOperating System: **Linux-3.12.6-x86_64-with-glibc2.2.5**\nLocale: None\nBranch: **master**\nCommit: SickRage/SickRage@4761a49a93e532ddf59b8aed8cdba69eee519d33\nNo Log available with ERRORS:\n### ERROR\n```\nThread-16 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 [4761a49] Missing time zone for network: CNN. Check valid network is set in indexer (theTVDB) before filing issue.\n```\n---\n_STAFF NOTIFIED_: @SickRage/owners @SickRage/moderators\n Comments: \n Comment 0: Thanks for the issue report! Before a real human comes by, please make sure your report has all the below criteria checked\n\n- [ ] Include basic information: Branch/Commit, OS, What you did, What happened, What you expected\n- [ ] Enable debug logging (be sure to disable after the bug is fixed)\n- [ ] Post debug logs, either inline (for smaller logs) or using gist\n\nPlease make sure you also read [how to create an issue](https://github.com/SickRage/sickrage-issues/blob/master/README.md) and followed all of the steps. \n\nThe title should describe your issue. Having \"SR not working\" or \"I get this bug\" for 100 issues, isn't really helpful. We will close issues if there isn't enough information.\n\nSometimes the devs may seem like grunts and respond with short answers. This isn't (always) because the dev hates you, but because he's on mobile or busy fixing bugs. If something isn't clear, please let us know, and this bot may get updated to automatically answer you.\n\nThanks!",
  "Issue title: Null pointer exception: setReconnectCallback on a null object reference -- Should we just implement the reconnect ourselves?\n Issue body: Please fill out the form below before submitting, thank you!\r\n\r\n- [x ] Bug exists Release Version 1.1.1 (Java Repository Master Branch)\r\n- [x ] Bug exists in Snapshot Version 1.1.2-SNAPSHOT (Android Service Repository Master Branch)\r\n- [ ] Bug is just in the Sample Application.\r\n\r\n__Android API Version Bug Seen on:__22\r\n\r\n__Android Version Bug Seen on:__5.1\r\n\r\n## Description of Bug:\r\nWhen there is no internet connection. I set \r\n\r\n`            conOpt.isAutomaticReconnect = true\r\n`\r\nBut because this doesn't really work, I have implemented auto-reconnect myself:\r\n```\r\noverride fun connectionLost(cause: Throwable) {\r\n        LOG.e(\"Connection Lost 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 $cause\")\r\n        connect()    \r\n}\r\n```\r\n## Console Log output (if available):\r\n\r\n\r\n``` \r\nFailed to connect to <url> 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 java.lang.Exception: MqttException (0) - java.net.UnknownHostException: Host is unresolved: <url>\r\n\r\n java.lang.NullPointerException: Attempt to invoke virtual method 'void org.eclipse.paho.client.mqttv3.internal.CommsCallback.setReconnectCallback(org.eclipse.paho.client.mqttv3.MqttCallbackExtended)' on a null object reference\r\n\tat org.eclipse.paho.client.mqttv3.internal.ClientComms.setReconnectCallback(ClientComms.java:603)\r\n\tat org.eclipse.paho.client.mqttv3.MqttAsyncClient.connect(MqttAsyncClient.java:625)\r\n\tat org.eclipse.paho.client.mqttv3.MqttAsyncClient.attemptReconnect(MqttAsyncClient.java:1304)\r\n\tat org.eclipse.paho.client.mqttv3.MqttAsyncClient.access$2(MqttAsyncClient.java:1299)\r\n\tat org.eclipse.paho.client.mqttv3.MqttAsyncClient$ReconnectTask.run(MqttAsyncClient.java:1343)\r\n\tat java.util.Timer$TimerImpl.run(Timer.java:284)\r\n \r\n ```\r\n\r\n\n Comments: \n Comment 0: fixed by implementing reconnect by myself. ",
  "Issue title: Crop Griefing \n Issue body: On our server running FE Server Complete #244 I was able to destroy others' crops by clicking a lot of crops rapidly. I did not get the drops from the crops like I normally would have, but still its a griefing method. Some crops were preserved, while others were destroyed.\n\n Comments: \n Comment 0: FE is limited to what events forge has. Right now we use ASM to hack in PlayerBreak, PlayerPlace, and PlayerUse events...  if it is such a bug, there isn't much we can do about it asside from put it down to an inadequate event. \n\nI hear that the Forge team is working on some proper events.. so all we acn do is wait.\n\n Comment 1: This should only be client side as the block doesn't even get broken on the server. Jumping on the crops does grief them however.\n\n Comment 2: Filed under #301.\n",
  "Issue title: 8muses : Illegal escape. at 47 [character 48 line 1]\n Issue body: * Ripme version: 1.7.94\r\n* Java version: <!-- (output of `java -version`) -->\r\n* Operating system: Windows\r\n<!-- Please do not link to content featuring underage characters even if the characters are drawn.\r\n These works are still illegal in many places including much of America -->\r\n* Exact URL you were trying to rip when the problem occurred: https://comics.8muses.com/comics/album/Various-Authors/Chessire88\r\n* Please include any additional information about how to reproduce the problem:\r\n\r\n## Expected Behavior\r\n\r\nalbums should download\r\n\r\n## Actual Behavior\r\n\r\nError \"Illegal escape. at 47 [character 48 line 1]\" when downloading 8muses albums\r\n\n Comments: \n Comment 0: can you pls try newest version from https://github.com/ripmeapp2/ripme/releases (main)?\n Comment 1: I used the latest compiled version from this fork and also the latest release here and same issues.\r\n\n Comment 2: closing, if no version is specified in the bug report, difficult to trace.\n Comment 3: > closing, if no version is specified in the bug report, difficult to trace.\r\n\r\nIt's easy, it's the last version compiled with the code from this repositery.\r\n\r\nTried right now with \"ripme-1.7.96-1-c7af5c50\" (compiled myself)\r\n\r\nAnd no error illegal.escape but no files downloaded.\r\n\r\nNow i get \" Non-retriable status code 400 while downloading\"",
  "Issue title: \u7ffb\u5899 ip\u4ee3\u7406\n Issue body: \u7528\u60a8\u8bf4\u7684\u90a3\u4e2aip\u6c60\u7684ip\uff0c\u518d\u6302\u4e0a\u672c\u5730\u7684v2ray\u7ffb\u5899\u4ee3\u7406\uff0c\u90a3\u6700\u7ec8\u8d70\u7684\u4ee3\u7406\u4f1a\u662f\u4ec0\u4e48\uff1f\u5982\u679cip\u88ab\u5c01\u4e86\uff0c\u662f\u4f1a\u5c01ip\u6c60\u7684ip\u8fd8\u662f\u7ffb\u5899\u7684ip\u9e2d\uff0c\u8c22\u8c22\uff01\n Comments: \n Comment 0: \u7ffb\u5899\u7684ip",
  "Issue title: Reorganize issue/PR labels\n Issue body: This repo currently has the following [labels](https://github.com/WordPress-Coding-Standards/WordPress-Coding-Standards/labels) available: \r\n* `Component: Docs`\r\n* `Component: Extras`\r\n* `Component: Templates`\r\n* `Component: Upstream`\r\n* `Component: VIP Blocker`\r\n* `Component: VIP Caution`\r\n* `Project: auto-fix WP Core / trac-41057`\r\n* `Requirement: phpcs 3.x`\r\n* `Status: Awaiting Feedback`\r\n* `Status: Duplicate`\r\n* `Status: Invalid`\r\n* `Status: Investigation`\r\n* `Status: Maybe Later`\r\n* `Status: PR Exists`\r\n* `Status: PR Required`\r\n* `Status: Review Ready`\r\n* `Status: Wontfix`\r\n* `Type: Bug`\r\n* `Type: Chores`\r\n* `Type: Cleanup`\r\n* `Type: Documentation`\r\n* `Type: Enhancement`\r\n* `Type: Modern PHP`\r\n* `Type: Question`\r\n\r\nI'd like to propose to make the following changes:\r\n\r\n### Add labels\r\n* `Component: Core` - While the other rulesets each have a Component label, the `Core` ruleset does not, so this label should be added.\r\n* `Meta` or `Repo: meta` - questions about the repo strategy, repo structure, release schedule, dependency minimum version changes, and for instance, this issue itself, are more \"meta\" questions and there's currently not a good label available to tag these with.\r\n* `Status: help wanted`, `Status: good first issue` - both of these (without the `Status:` prefix) are standard labels which are created by default nowadays for new repositories. They are widely recognized and help new contributors find issues which could be a good fit for them.\r\n\r\n### Rename labels\r\n* `Component: Upstream` - PHPCS upstream is not a component of this repo, so I'd like to propose renaming this label to `PHPCS: upstream`.\r\n* `Requirement: phpcs 3.x` should probably be changed to `Requirement: higher phpcs version` or `Requirement: dependency change` - as that way the same label can continue to be used, even when it would become `phpcs 3.3.x` or `phpcs 4.x` in the future or if more dependencies are added, it can be (re-)used for those too.\r\n    The label basically involves anything for which the minimum supported version of a dependency would need to be raised.\r\n\r\n### Remove labels\r\n* `Component: Templates` - No idea why this label was ever added.\r\n* `Component: VIP Blocker` - as the VIP sniffs are slated for removal and the VIP CS checks are now contained in their own dedicated repo, this label is superfluous.\r\n* `Component: VIP Caution` - same as above.\r\n* `Project: auto-fix WP Core / trac-41057 ` - The label is a bit of an odd one out and has been superseded by the initial trac ticket being closed now. To still keep an overview of everything what happened because of this, we should probably add a GH project (feature didn't exist at the time) and add that project to the issues tagged with that label instead.\r\n* `Status: Investigation` - Basically, if something is being investigated, someone should be (self-)assigned to the issue, so it is clear that someone has taken ownership of the ticket. If nobody is assigned, who is doing the investigating?\r\n     Alternatively, the label could be renamed to `Status: Needs investigation` which would more clearly indicate that the issue is up for grabs.\r\n* `Status: PR Required` - basically any issue which is open and not awaiting feedback/invalid, requires a PR, so this label seems superfluous to me.\r\n* `Type: Cleanup ` - the issues here are typically also `Chores`, so I would suggest relabeling them to `Type: Chores` if they don't already have that label. `Chores` covers more than just `Cleanup` which is why I think that's the better label to keep.\r\n\r\n### Potential new label category:\r\n* `Priority` with label `Priority: High` - High priority issues should be fixed in the very next release. Any issue which doesn't have this label has \"normal\" priority.\r\n* Potentially a `Priority: Low` label could also be added to indicate that those issues can be ignored until further notice. In that case, the `Maybe later` label should probably be renamed to `Priority: Low`.\r\n\r\n### Actions needed\r\n\r\nOnce agreement has been reached on this, the following actions need to be taken:\r\n- [x] Add the new labels and rename labels.\r\n- [x] Where relevant, re-tag issues currently labeled with tags which will be removed. For the (closed) VIP related issues, these can be re-tagged to the ruleset a sniff is still currently in or the tag removed if the sniff will be removed.\r\n- [x] Remove labels slated for removal.\r\n\r\nIf someone feels so inclined, going through the all (open) issues/PRs to verify labels would be a bonus as that just makes issues easier to find.\r\nA good culling of open issues would also not be a bad thing :wink: \r\n\r\nAnd while we're at it: IMO, the `Awaiting feedback`, `Maybe later`, `PR exists` and `Review ready` labels should be removed from issues/PRs when they are being closed.\r\nAnd if the `Investigation`/`Needs investigation` label would remain, that label should be removed from issues when they are closed as well.\n Comments: \n Comment 0: > `Component: Upstream` - PHPCS upstream is not a component of this repo, so I'd like to propose renaming this label to `PHPCS: upstream`.\r\n\r\nI'd suggest `Upstream: PHPCS`, since `Upstream` seems more like the category here.\r\n\r\n\r\n\r\n> `Requirement: phpcs 3.x` should probably be changed to `Requirement: higher phpcs version` or `Requirement: dependency change` - as that way the same label can continue to be used, even when it would become phpcs 3.3.x or phpcs 4.x in the future or if more dependencies are added, it can be (re-)used for those too.\r\n\r\nOther than in code comments, I don't think we have anywhere else centralised that keeps track of what compatibility code could be removed when the minimum PHPCS version is bumped (there may be some individual tickets, but that takes time to pull together). Instead of generalising, I think these comments could be copied into Issues at the time of the PR being merged, and the labels could be added/changed to `Requirement: PHPCS 3.0`, `Requirement: PHPCS 3.1`, `Requirement: PHPCS 3.2`, `Requirement: PHPCS 3.3`, `Requirement: PHP 5.4` etc.\r\n\r\n> `Component: VIP Blocker` - as the VIP sniffs are slated for removal and the VIP CS checks are now contained in their own dedicated repo, this label is superfluous.\r\n> `Component: VIP Caution` - same as above.\r\n\r\nI think these could be consolidated into `Component: VIP`, but kept until the VIP sniffs have actually be removed. I started going through the remaining VIP-tagged tickets on our repo, to see if they were still valid for _someone_, and opened a few in the Automattic VIP CS repo. I'd like to get that task finished off before yanking the labels from those issues. Or I can open an Issue with a list of VIP-tagged tickets, to make them easier to find.\r\n\r\n> Alternatively, the label could be renamed to `Status: Needs investigation` which would more clearly indicate that the issue is up for grabs.\r\n\r\n+1\r\n\r\n> `Type: Chores` if they don't already have that label. `Chores` covers more than just `Cleanup` which is why I think that's the better label to keep.\r\n\r\n-0.5. Fixing a typo in an error message would be a cleanup, but I wouldn't count it as a chore.\r\n\r\nI'm in favour of all the other suggestions.\n Comment 1: > I'd suggest `Upstream: PHPCS`, since Upstream seems more like the category here.\r\n\r\nYeah, I was struggling a bit with the name for this one, but calling it `Upstream: PHPCS` would sort it to the very bottom of the label list, while context -wise, it felt more logical to have it near the `Component` labels, which is why I proposed `PHPCS: upstream`.\r\n\r\nIf we can come up with an better name which would sort the label to still be above the `Status` and `Type` labels, that would be my preference.\r\n\r\n> Other than in code comments, I don't think we have anywhere else centralised that keeps track",
  "Issue title: Make \"Dev\" Default Environment When Creating/Pulling/Pushing a Site\n Issue body: Feature/Enhancement Request\r\n===========================\r\n\r\n**User Story**\r\n\r\nAs a Kalabox user who creates sites often and doesn't always read the form, it'd save me time for the default environment to be \"Dev\", since many of my sites I create (or push to) don't have multi-dev environments.\r\n\r\n**Solution**\r\n\r\nMake \"Dev\" the default environment on these forms.\n Comments: \n Comment 0: \ud83d\udc4d ",
  "Issue title: Idea: Shift Register Implementation by inheritance\n Issue body: Hi Dean,\r\n\r\ni'm very fond of your library. It's great.\r\nHowever when using the Display lots of port are getting blocked (12)\r\n\r\nUsing a Shift Register is moving the issue to external shift registers.\r\nwith this only 3! ports are used by this display.\r\n\r\nI've created an child class from your parent,\r\nwith least possible intrusion and maximum possible re-usage of your code.\r\n\r\nWhat do you think?\r\nCould this be integrated into your library?\r\n\r\nJens\n Comments: \n Comment 0: i'll keep the changes in the fork...",
  "Issue title: Problem with installation using pipenv on Windows\n Issue body: `\r\n    ERROR: Command errored out with exit status 1:\r\n     command: 'd:\\patryk\\repo\\awizacja\\api\\.venv\\scripts\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\patryk\\\\AppData\\\\Local\\\\Temp\\\\pip-install-6431xtl_\\\\amqpstorm_0b6c83c09a564998891af71d3e0395f6\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\patryk\\\\AppData\\\\Local\\\\Temp\\\\pip-install-6431xtl_\\\\amqpstorm_0b6c83c09a564998891af71d3\r\ne0395f6\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\patryk\\AppData\\Local\\Temp\\pip-pip-egg-info-lq1mw9hg'\r\n         cwd: C:\\Users\\patryk\\AppData\\Local\\Temp\\pip-install-6431xtl_\\amqpstorm_0b6c83c09a564998891af71d3e0395f6\\\r\n    Complete output (7 lines):\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"C:\\Users\\patryk\\AppData\\Local\\Temp\\pip-install-6431xtl_\\amqpstorm_0b6c83c09a564998891af71d3e0395f6\\setup.py\", line 28, in <module>\r\n        long_description=open('README.rst').read(),\r\n      File \"d:\\patryk\\repo\\awizacja\\api\\.venv\\lib\\encodings\\cp1250.py\", line 23, in decode\r\n        return codecs.charmap_decode(input,self.errors,decoding_table)[0]\r\n    UnicodeDecodeError: 'charmap' codec can't decode byte 0x88 in position 2091: character maps to <undefined>\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\r\n`\r\n\r\nNames of contributors with native letters break the installation on windows with cp1250 (Polish) encoding.\n Comments: \n Comment 0: Pull request: https://github.com/eandersson/amqpstorm/pull/113\n Comment 1: pull request: https://github.com/eandersson/amqpstorm/pull/113\n Comment 2: Thanks!",
  "Issue title: Package-Dependencies\n Issue body: Dear all,\n\nFirst of all, thank you for sharing this great package. It is really helpful!!\n\nJust a minor comment:\n\nThe first time I loaded Taro, it gave me the following error message: \n\n\"ERROR: StoredArray not defined\"\n\nSo, I Installed \"DataArrays\" package and everything worked fine.\n\nMy question is: Would it be possible to analyze this kind of dependencies automatically? Just like happens with Debian packages: If I ask for the installation of a package A that depends on other packages B, C, and D, julia would be sure that B, C, and D are installed before proceeding with the installation of A. \n\nIs it a Julia limitation? Or a choice of package admin? Or just an accident?\n\nBest,\n\nCharles\n\n Comments: \n Comment 0: Thanks for the report. I am surprised that DataArrays is not installed, since Taro declares a dependency on DataFrames. And DataFrames declares a depdency on DataArrays. \n\nCan you tell us the result of running `versioninfo(true)` on the REPL?\n\n Comment 1: Dear Avik,\n\nThank you for your answer!\n\nI don't know if I understood correctly, but here is the output of running versioninfo(true) in my Julia console:\njulia> versioninfo(true)\nJulia Version 0.3.0-prerelease+3841\nCommit b6ebf91 (2014-06-22 11:24 UTC)\nPlatform Info:\n  System: Linux (x86_64-linux-gnu)\n  CPU: Intel(R) Core(TM) i7-3537U CPU @ 2.00GHz\n  WORD_SIZE: 64\n           Debian GNU/Linux testing (jessie)\n  uname: Linux 3.10-3-amd64 #1 SMP Debian 3.10.11-1 (2013-09-10) x86_64 unknown\nMemory: 7.399562835693359 GB (5945.94921875 MB free)\nUptime: 23292.0 sec\nLoad Avg:  0.529296875  0.3046875  0.438.400.6107\nIntel(R) Core(TM) i7-3537U CPU @ 2.00GHz:\n       speed         user         nice          sys         idle          irq\n#1  3075 MHz      13028 s         20 s       3895 s    1132704 s          0 s\n#2  2875 MHz      14592 s         22 s       4549 s      50691 s          0 s\n#3  3075 MHz      12447 s          9 s       4176 s      50779 s          0 s\n#4  2900 MHz      10670 s          4 s       2910 s      51512 s          0 s\n\n  BLAS: libopenblas (USE64BITINT NO_AFFINITY)\n  LAPACK: libopenblas\n  LIBM: libopenlibm\nEnvironment:\n  TERM = xterm\n  PATH = /usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n  HOME = /home/charles\n  WINDOWPATH = 7\n\nPackage Directory: /home/charles/.julia\n12 required packages:\n- DataArrays                    0.1.3\n- DataFrames                    0.5.3\n- Debug                         0.0.0\n- Distance                      0.3.1\n- Gadfly                        0.2.5\n- Graphs                        0.4.1\n- NHST                          0.0.2\n- NetCDF                        0.1.0\n- PyPlot                        1.2.2\n- SortingAlgorithms             0.0.1\n- Taro                          0.1.1\n- Winston                       0.9.0\n  24 additional packages:\n- ArrayViews                    0.4.1\n- BinDeps                       0.2.12\n- Blocks                        0.0.2\n- Cairo                         0.2.12\n- Codecs                        0.1.0\n- Color                         0.2.8\n- Compose                       0.1.26\n- DataStructures                0.2.10\n- Datetime                      0.1.2\n- Distributions                 0.4.2\n- GZip                          0.2.12\n- Hexagons                      0.0.1\n- IniFile                       0.2.2\n- Iterators                     0.1.2\n- JSON                          0.3.3\n- JavaCall                      0.1.2\n- Loess                         0.0.2\n- Memoize                       0.0.0\n- NumericExtensions             0.5.6\n- PDMats                        0.1.1\n- PyCall                        0.4.2\n- StatsBase                     0.3.9\n- Tk                            0.2.11\n- URIParser                     0.0.1\n\nTonight I will try to use Taro.jl again. I will let you know if everything goes fine!\n\nBest,\n\nCharles\n\n---\n\nFrom: Avik Sengupta [linda24@example.org]\nSent: Friday, June 27, 2014 6:18 PM\nTo: aviks/Taro.jl\nCc: De Santana, Charles\nSubject: Re: [Taro.jl] Package-Dependencies (#4)\n\nThanks for the report. I am surprised that DataArrays is not installed, since Taro declares a dependency on DataFrames. And DataFrames declares a depdency on DataArrays.\n\nCan you tell us the result of running versioninfo(true) on the REPL?\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/aviks/Taro.jl/issues/4#issuecomment-47368875.\n\n Comment 2: This should all be fine now. Please reopen if you still have issues",
  "Issue title: Facebook: \"session expired\"\n Issue body: My user suffers from a message \"Error. Session has expired at unix time 131401800. The current unix time is /current UNIX time/.\"\nHe see this UIAlertView any time he's trying to share something with a Facebook, but I can't reproduce this issue on my own.\n\n Comments: \n Comment 0: This may seem strange but ask him if the time and date are set correctly on his device. If he has an iPod Touch, I've seen the time on those get out of sync, and Facebook will reject SSL requests from a device that has an invalid timestamp on it.\n\n Comment 1: I asked him and he said that time is valid.\nI got another issue: when I removed my Test application from my profile on facebook.com (I had to confirm it's access one more time on iPhone) I got an error 102: \"The session has been invalidated because the user has changed the password.\".\nAnd if I logout from Facebook.com (on my PC) I get an error 102 \"The session is invalid because the user logged out.\"\n\nI'm trying to handle theses errors (codes 400 - 499 and 102, - (void)request:(FBRequest_)aRequest didFailWithError:(NSError_)error in SHKFacebook.m) but they appear event after I call [SHKFacebook logout] - I had to relogin in application but looks like the session key remains the same...\n\nI'm not very familiar with facebook API and ShareKit yet; may be I'm just doing something wrong?\n\nSorry for my english;)\n\n Comment 2: Looks like I found a solution, but how should I share it? Looks like the main working tree is a bit abandoned, and I'm still not sure that my problem is a common problem\n\n Comment 3: i have the same problem mentioned by alexander can someone help for this issue\ni am getting error in ipad 1 device\n\nerror  \"The session is invalid because the user logged out.\"\n\n Comment 4: I fixed that bug in ShareKit code, but I'm not sure how I should share my solution with everyone. This repo looks abandoned\n\n Comment 5: @s-alexander check out https://github.com/ShareKit/ShareKit\n",
  "Issue title: Zeroconf filter `nam*` causes test `zeroconf/test_init.py38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5test_setup` to fail\n Issue body: ### The problem\r\n\r\nI'm working on a new integration that uses `zeroconf` for device discovery. The devices use the names `NAM-<serial number>` so I used the `nam*` filter in `manifest.json` file:\r\n```json\r\n\"zeroconf\": [{\"type\": \"_http._tcp.local.\", \"name\": \"nam*\"}],\r\n```\r\nThis causes the test `tests/components/zeroconf/test_init.py38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5test_setup` to fail with `AssertionError` https://github.com/home-assistant/core/pull/49099/checks?check_run_id=(817)709-6510\r\n```\r\nFAILED tests/components/zeroconf/test_init.py38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5test_setup - AssertionError: assert 26 == 25\r\n```\r\n\r\nBut when I change `zeroconf` filter to this:\r\n```json\r\n\"zeroconf\": [{\"type\": \"_http._tcp.local.\", \"name\": \"nam-*\"}],\r\n```\r\nthe test will pass.\r\n\r\n### What is version of Home Assistant Core has the issue?\r\n\r\ncore-2021.5.0.dev0\r\n\r\n### What was the last working version of Home Assistant Core?\r\n\r\n_No response_\r\n\r\n### What type of installation are you running?\r\n\r\nHome Assistant Core\r\n\r\n### Integration causing the issue\r\n\r\nzeroconf\r\n\r\n### Link to integration documentation on our website\r\n\r\nhttps://www.home-assistant.io/integrations/zeroconf\r\n\r\n### Example YAML snippet\r\n\r\n_No response_\r\n\r\n### Anything in the logs that might be useful for us?\r\n\r\n_No response_\r\n\r\n### Additional information\r\n\r\n_No response_\n Comments: \n Comment 0: Hey there @bdraco, mind taking a look at this issue as its been labeled with an integration (`zeroconf`) you are listed as a [codeowner](https://github.com/home-assistant/core/blob/dev/CODEOWNERS#L558) for? Thanks!\n<sub><sup>(message by CodeOwnersMention)</sup></sub>",
  "Issue title: ijkplayer\u64ad\u653e\u672c\u5730\u89c6\u9891\u7f13\u5b58\u59cb\u7ec8\u4e3a0\u7684\u95ee\u9898\n Issue body: \u95ee\u9898\u63cf\u8ff0\uff1a\r\n\u4f7f\u7528ijkplayer\u786c\u89e3\u64ad\u653e\u672c\u5730U\u76d8\u89c6\u9891\u7684\u65f6\u5019,\u5728\u81ea\u5b9a\u4e49VideoView\u4e2d\u7684setProgressAndTime\u6253\u5370\u5982\u4e0b\u65e5\u5fd7:\r\n`System.out.println(\"BufferedPercentage=\" + getGSYVideoManager().getBufferedPercentage());`\r\n`getGSYVideoManager().getBufferedPercentage()`\u59cb\u7ec8\u8f93\u51fa\u662f0, \u8bd5\u8fc7`ExoPlayerCacheManager`\u6216\u8005\u9ed8\u8ba4\u7684`ProxyCacheManager`\u90fd\u8f93\u51fa\u4e3a0, \u5e73\u65f6\u6b63\u5e38\u64ad\u653e\u90fd\u6ca1\u6709\u4efb\u4f55\u95ee\u9898, \u4f46\u662f\u6d4b\u8bd5\u559c\u6b22\u64ad\u653e\u7684\u65f6\u5019\u76f4\u63a5\u62d4\u51faU\u76d8,\u5bfc\u81f4app\u76f4\u63a5\u95ea\u9000\r\n \r\n\u5982\u679c\u6362\u6210exoplayer\u7684\u8bdd\u5c31\u6ca1\u6709\u8fd9\u4e2a\u95ee\u9898, \u6211\u8bd5\u8fc7\u5728setProgressAndTime\u6253\u5370getGSYVideoManager().getBufferedPercentage(), \u53d1\u73b0\u89c6\u9891\u4f1a\u88ab\u7f13\u51b2\u4e00\u6bb5\u65f6\u95f4,\u5c31\u4e0d\u4f1a\u5bfc\u81f4\u8fd9\u4e2a\u95ee\u9898, \u8bf7\u95ee\u8fd9\u4e2a\u95ee\u9898\u5982\u679c\u975e\u8981\u4f7f\u7528ijk\u6765\u64ad\u653e\u5e94\u8be5\u600e\u4e48\u5904\u7406\u5462?\r\n\r\n\u51fa\u73b0\u95ee\u9898\u7684\u89c6\u9891\u6d41:\r\n\u4efb\u4f55\u89c6\u9891\r\n\r\nGSY\u4f9d\u8d56\u7248\u672c\r\nimplementation 'com.github.CarGuo.GSYVideoPlayer:gsyVideoPlayer-java:v8.3.2-release-jitpack'\r\nimplementation 'com.github.CarGuo.GSYVideoPlayer:GSYVideoPlayer-exo2:v8.3.2-release-jitpack'\r\nimplementation 'com.github.CarGuo.GSYVideoPlayer:gsyVideoPlayer-ex_so:v8.3.2-release-jitpack'\r\n\r\n\n Comments: \n Comment 0: ijk \u6a21\u5f0f\u6682\u65f6\u65e0\u6cd5\u89e3\u51b3\u8fd9\u4e2a\u6d41\u7a81\u53d1\u5f02\u5e38\u7684\u60c5\u51b5\uff0c\u4ece so \u5904 crash \u4f60\u5728 java \u5c42\u83b7\u53d6\u6ca1\u7528\n Comment 1: > ijk \u6a21\u5f0f\u6682\u65f6\u65e0\u6cd5\u89e3\u51b3\u8fd9\u4e2a\u6d41\u7a81\u53d1\u5f02\u5e38\u7684\u60c5\u51b5\uff0c\u4ece so \u5904 crash \u4f60\u5728 java \u5c42\u83b7\u53d6\u6ca1\u7528\r\n\r\nijk\u6a21\u5f0f\u652f\u6301\u7f13\u51b2\u4e00\u6bb5\u89c6\u9891\u5417,  \u600e\u4e48\u8bbe\u7f6e\u5462\n Comment 2: \u7f13\u51b2\u53ea\u6709\u6309\u7167\u5757\u7f13\u51b2\uff0c\u8981\u662f\u7f13\u51b2\u592a\u5927\uff0c\u5185\u5b58\u4f1a\u53d7\u4e0d\u4e86\n Comment 3: \r\n\r\n\r\n> \r\n\r\n\u9700\u8981\u600e\u4e48\u8bbe\u7f6e\u5462  \u6211\u60f3\u8bd5\u4e00\u8bd5\n Comment 4: \u4f60\u5728\u95ee\u9898\u96c6\u9526\u91cc\u641c\u7d22 buffer_size\n Comment 5: \ud83d\udc4c\n Comment 6: \u8bbe\u7f6eijk\u7f13\u51b2\u4e4b\u540e\u4e5f\u6ca1\u6709\u4ec0\u4e48\u7528, \u62d4\u51faU\u76d8\u8fd8\u662f\u7acb\u9a6c\u95ea\u9000\n Comment 7: \u6211\u6ca1\u6709\u8bf4\u8bbe\u7f6e\u80fd\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u524d\u9762\u6211\u90fd\u8bf4\u4e86\u8fd9\u4e2a\u4e0d\u652f\u6301\n Comment 8: > \r\n\r\n\u597d\u7684 \u8c22\u8c22",
  "Issue title: Error compiling 3proxy with SSLPlugin on entware\n Issue body: Hello, I wanted to compile 3proxy on tomato-by-shibby firmware on top of entware tooling.\r\n\r\nI've got this error:\r\nerrno@@GLIBC_PRIVATE: TLS definition in /opt/lib/gcc/arm-openwrt-linux-gnueabi/6.3.0/libc.so.6 section.tbss mismatches non-TLS definition in /lib/libc.so.0 section.bss\r\n\r\nDetails:\r\ngcc -o../bin/3proxy -O2 -fno-strict-aliasing -pthread   3proxy.o mainfunc.o auth.o authradius.o conf.o datatypes.o srvproxy.o srvpop3p.o srvsmtpp.o srvftppr.o srvsocks.o srvtcppm.o srvudppm.o sockmap.o sockgetchar.o myalloc.o common.o mycrypt.o md5.o md4.o base64.o ftp.o smbdes.o ntlm.o stringtable.o srvwebadmin.o srvdnspr.o plugins.o  -lcrypto -lssl -ldl \r\n/opt/bin/ld: warning: libdl.so.0, needed by /usr/lib/libcrypto.so, may conflict with libdl.so.2\r\n/opt/bin/ld: warning: libc.so.0, needed by /usr/lib/libcrypto.so, may conflict with libc.so.6\r\n/opt/bin/ld: errno@@GLIBC_PRIVATE: TLS definition in /opt/lib/gcc/arm-openwrt-linux-gnueabi/6.3.0/libc.so.6 section.tbss mismatches non-TLS definition in /lib/libc.so.0 section.bss\r\n/lib/libc.so.0: error adding symbols: Bad value\r\ncollect2: error: ld returned 1 exit status\r\nmake[1]: *** [Makefile.inc:147:../bin/3proxy] Error 1\r\nmake[1]: Leaving directory '/tmp/home/root/3proxy/src'\r\nmake: *** [Makefile.inc:7: all] Error 2\n Comments: \n Comment 0: It should mean errno is defined in a different way in 2 different libraries (/opt/lib/gcc/arm-openwrt-linux-gnueabi/6.3.0/libc.so.6 and /lib/libc.so.0) so you have conflict in your linking environment and it's probably not 3proxy specific.\n Comment 1: It looks like you are building 3proxy with different libc from one used to build libcrypto.\n Comment 2: Yes you are right. \r\nI was hoping that some had the simmilar problem. \r\nI don't know how to bypass linking to /lib/libc.so.\n Comment 3: Actually, you can remove  -lcrypto -lssl for building 3proxy itself, these libraries are only required to build SSLPlugin. It doesn't resolve the issue itself and I can't guarantee this will build something working, but there is a chance.\n Comment 4: The correct solution should be to rebuild crypto libraries to match the libc\n Comment 5: Thank you for advice. I will try to build crypto libs later today. \r\nFYI, I can succesfully build 3proxy without SSLPlugin, which is commented by default in Makefile.\n Comment 6: Hello, I've compiled the SSLPlugin finally, but I'm getting runtime error `SSLPlugin.ld.so: undefined symbol: CRYPTO_num_locks`.\r\nIt's the same error like in #227. \r\nIn https://github.com/openssl/openssl/issues/8573, i found that the CRYPTO_num_locks is not used anymore in later version then 1.0.2.\n Comment 7: duplicates https://github.com/z3APA3A/3proxy/issues/298",
  "Issue title: Admin can hide archived Projects, or they are always hidden\n Issue body: ## User story \r\nAs a Collective admin, I want to be able to archive no longer active Projects so they don't take up space on my page and people aren't confused by seeing them.\r\n\r\n## Best solution for this problem\r\nEither a per-Project setting to optionally hide it that activates when a Project archived, or a default global choice to hide all archived Projects for non-admins.\r\n\r\n## MVP\r\nBeing able to request the dev team to hide specific archived Projects from view at the request of users via support.\n Comments: \n Comment 0: Related to #4640 - if we implement hiding them all then we don't need to worry about sending them to the end of the order.\n Comment 1: I decided to contact some creators or archived Projects and ask them if they would prefer them to be hidden or not. I'll update the results of this informal survey here.\n Comment 2: I've heard back from a few users and so far they all prefer archived projects are always hidden from non-admins. This also seems like a simpler solution to implement since we don't need a setting for it.\r\n\r\nTo me it really makes sense because if for some reason someone wants to deactivate a project without it disappearing, they can simply remove all contribution tiers and leave it un-archived.\n Comment 3: We have consensus from everyone asked that admins want archived projects to be hidden. Is there any way this could be done soon, as @Betree said it would be simple? This is blocking people from promoting their Projects page because there's stuff on there that is inactive and confusing.\n Comment 4: @alanna Since https://github.com/opencollective/opencollective-frontend/pull/7058, archived projects are normally displayed only to admins. Everyone else only sees the active ones (as per the specifications in https://github.com/opencollective/opencollective/issues/4836#issuecomment-945208792). Was there anything more to do to complete this issue?\n Comment 5: Ah ok, I didn't know. Is this documented? Can we add a tooltip for admins somehow? They are unlikely to figure this out because to them they look visible.",
  "Issue title: Bower dependency list must be a dictionary...\n Issue body:![image](https://cloud.githubusercontent.com/assets/12753650/8010671/18f366ac-0b80-11e5-96c1-dfb5e075ab70.png)\n\nSo I'm attempting to build the application in Ubuntu 14.04. I've got all the right dependencies as far as I can tell. However, I'm getting this error, I'm not quite sure what it means.\n\nThe contents of my bower.json are:\n![image](https://cloud.githubusercontent.com/assets/12753650/8010738/bcfeb0f8-0b80-11e5-839c-a867708a00c4.png)\n\nand those of my bower_components/perfect-scrollbar/bower.json are:\n![image](https://cloud.githubusercontent.com/assets/12753650/8010752/da6db594-0b80-11e5-930f-c9cbfb0fcad2.png)\n\nThanks for your time\n\n Comments: \n Comment 0: This seems to be a problem with https://github.com/mquandalle/meteor-bower, but I'm not sure what is causing it. Maybe you have any additional indication to help me reproduce it?\n Comment 1: I had the same problem when I tried to build the app, after I deleted the build directory (which already had an older version) it worked fine. Not really sure why.\r\nTo which directory are you trying to build? Or are you trying to run it using `meteor run`?\n Comment 2: I've deleted and re-built the directory with git clone directly from this repo. I get the same problem every time when I cd into the libreboard directory and run meteor\n Comment 3: Can you show me the full command you are trying to run please?\n\n Comment 4: `meteor` ;)\n Comment 5: It sounds like you have built the app inside the source directory, as per [this](http://stackoverflow.com/questions/26524346/meteor-fails-to-run-after-building-a-meteor-app) Stackoverflow answer:\n\n> Meteor picks up all javascript files in your project's folder including nested folders. By saving your bundle in the same directory as your project, you just duplicated a lot of files and now Meteor is going to pick them up as \"new source files\". To avoid this, output your bundles to a separate directory from your project or to a hidden folder that is ignored by Meteor build tool (any folder name starting with a dot).\n\n(I've just tried out and built the app to a folder inside the app sources, to confirm that this causes the issue, and have exactly the same errors as you have. Note that the built tool will even warn about this.)\n\nUse the following command to built to a specific directory:\n\n```\nmeteor build./build --directory\n```\n\nNote that you do not have to do this in order to execute `meteor`. The build command is intended to create a production build of the app, to run it on your server.\n\nIf you are still experiencing problems, even choosing a build directory outside the meteor app sources, I can write a short guide how to get it up and running.\n\n Comment 6: BTW, I guess there isn't anything specific to LibreBoard with this bug, but it is instead a problem with https://github.com/mquandalle/meteor-bower.\n Comment 7: @mquandalle I don't think it has anything to do specifically with it, it's just that meteor will try to build files that are already built, resulting in a lot of errors.\n Comment 8: So we are talking about `meteor build` here, right?\n Comment 9: Whatever the problem was, it's not happening now. My guess is something was wrong with the bower package manager or it wasn't installed properly, because I updated all my packages, rebuilt libreboard/ again and was able to run it. I really appreciate your help, guys. Been trying to get this working on a private server for a few days now. \n Comment 10: Note that, for production use you should use the package created with `meteor build` not just run `meteor`\n Comment 11: Okay, thanks for the advice. I'm pretty new to meteor, but so far I'm really liking it\n\n Comment 12: I'm sorry you had an hard time installing Libreboard. Note that you are dealing with in flux software, once v0.9 is released, docker images will be a reasonably easy way to install Libreboard on your own server.\n\n Comment 13: Of course, I understand. You guys have done an awesome job so far, and I'm looking forward to contributing in the near future, once I get my feet wet",
  "Issue title: Stop on point\n Issue body: I'm trying to stop an object on a point or percentage of the length of a path. I was wondering if there is a feedback loop for object's current position or simpler way to do this using your plugin. \n\n Comments: \n Comment 0: i don't think is easy.  u'll have to create a separate path :s as far as I know. unless jQuery has some new functionality to abort animations.\n\n Comment 1: Well, there is the step function of the method. I've been playing around with it. Although, I haven't exactly figure it out. I think it has the potential to function this way. \n\nHowever, when applying it to your plugin, the step function does not seem to return any values.\n\nWhat do you mean create a separate path?\n\n Comment 2: Bah.. I didn't mean to hit Comment and Close...\n\n Comment 3: could u use stop (http://api.jquery.com/stop/) within the step function perhaps? \n\n Comment 4: Well, I haven't quite figured out how to call stop() from within the step function if you even can, but you can do some neat things with it. I have some code, but I don't know how to post it in there.\n\nOn the other hand, I can't get the step function to work while using your Path plugin. Perhaps I'm missing something?\n\n Comment 5: Ok, just figured out how to call stop() from step, but it doesn't work with your Paths plugin. The same data isn't being accessed when being pushed through Paths.\n\n Comment 6: Check it out.. \nChange\nvar css = fx.end.css(1 - fx.pos)\n\nto \nvar css = fx.end.css(fx.pos/2)\n\nCould change the code to accept a param there maybe. \n\n Comment 7: Alright, so I'm still hacking shelby53@example.org. I brought the divisor in as a param, not sure that's the way to go though. Playing around with some loops now to see if I can make the divisor work...\n\n Comment 8: try \n\nvar css = fx.end.css(1 - fx.pos*param)  \n\nwhere param is between 0 and 1\n\n Comment 9: I was able to get an animation to stop at an arbitrary point along the curve by using step and stop()\n\n$(\"#mover2\").animate({path : new $.path.bezier(bezier_params)},\n    {step: function(now, fx) {\n        if (fx.pos >.5) {$(this).stop(true, false)}; //when the position param of fx gets bigger than.5, stop the animation\n        }\n        }                                       \n",
  "Issue title: deprecate unary slice (error prone)\n Issue body: ## proposal\r\ndeprecate unary slice\r\nhttps://nim-lang.github.io/Nim/system.html#..%2CsinkT\r\n\r\n## rationale\r\nit seems error prone eg:\r\n```nim\r\nwhen true:\r\n  var b: array[-3..3, float]\r\n  echo b[.. 2] == b[0.. 2]\r\n  echo b[b.low.. 2] == b[0.. 2]\r\n```\r\nprints:\r\ntrue\r\nfalse\r\n\r\nit'd be useful if `b[.. 2]` would be syntax sugar for `b[b.low.. 2]` (analog to `b[3..^1`) but it seems that all it does is being equal to `default(int)`, ie `0`.\r\n\r\nI don't see the point of avoiding to type `0`.\n Comments: \n Comment 0: Another argument in favor of deprecating: As far as I know only `b[.. 2]` but not `b[2..]` is a thing. This asymmetry feels a bit awkward, because in other languages slice boundaries are typically either mandatory or optional in both positions.\n Comment 1: It only feels \"awkwardly\" asymmetric when you look at it from an ignorant angle though. Nim simply doesn't have postfix operators so why would ``2..`` be a thing? Perfectly senseful design.\n Comment 2: It's ugly either way, information like a start index shouldn't be hidden, `b[0..2]` should just be syntax sugar for `b.slice(0, 2)` IMO.\n Comment 3: > It only feels \"awkwardly\" asymmetric when you look at it from an ignorant angle though. Nim simply doesn't have postfix operators so why would 2.. be a thing? Perfectly senseful design.\r\n\r\nNo need to insult anyone. It is still a matter of expectation coming from other languages, no matter how sensible it is.\n Comment 4: Sorry, no insult implied.\n Comment 5: Nuke it from orbit.\r\n\n Comment 6: Again, \"Accepted RFC\" here means, \"let's see what it breaks\".\n Comment 7: I might be using this, I don't really like it but why remove it and whats the alternative?\n Comment 8: Fine. 0..x is easy to write as well.",
  "Issue title: [Security Solution] URL includes the old nomenclature for the advanced tab: 'Custom'\n Issue body: **Describe the feature**\r\nURL includes the old nomenclature for the advanced tab: 'Custom'\r\n\r\n**Build Details:**\r\n```\r\nVERSION: 7.14.0-SNAPSHOT\r\nBUILD: 41434\r\nCOMMIT: 88615e49f65668b3f8ea707c0bb580580189c297\r\nARTIFACT: https://artifacts-api.elastic.co/v1/search/7.14.0-SNAPSHOT\r\n```\r\n\r\n**Preconditions**\r\n1. Elastic 7.13.0 environment should be deployed.\r\n\r\n**Steps to Reproduce**\r\n1. Navigate to the Integrations Tab under the Fleet\r\n2. Select the Endpoint Security Integration\r\n3. Navigate to the Advanced tab\r\n4. Oberve that the URL is not matched with the Tab name\r\n\r\n**Test data**\r\nN/A\r\n\r\n**Impacted Test case(s)**\r\nN/A\r\n\r\n**Actual Result**\r\nURL includes the old nomenclature for the advanced tab: 'Custom'\r\n\r\n**Expected Result**\r\nURL should be updated for the advanced tab.\r\n\r\n**What's Working**\r\nN/A\r\n\r\n**What's Not Working**\r\nN/A\r\n\r\n**Screenshot**\r\n![WrongURLNaming](https://user-images.githubusercontent.com/60252716/120800112-3498ed80-c55d-11eb-9277-090f0eac21ab.JPG)\r\n\r\n**Logs**:\r\nN/A\n Comments: \n Comment 0: Pinging @elastic/security-solution (Team: SecuritySolution)\n Comment 1: Pinging @elastic/security-onboarding-and-lifecycle-mgt (Team:Onboarding and Lifecycle Mgt)\n Comment 2: @manishgupta-qasource please review!!\n Comment 3: Reviewed & Assigned to @kevinlog ",
  "Issue title: Problem with rendering \\Omega for SI-unit Ohm\n Issue body: Hey everbody! :-)\r\n\r\nI am trying to use Jupyter-Notebooks for creating engineering calculation sheets.\r\nTherefore i found handcalcs and forallpeople packages for SI-uinit support.\r\n\r\nWorks quite nice, but I have trouble with rendering \\Omega for Ohm:\r\n![Screenshot from 2021-01-30 17-32-38](https://user-images.githubusercontent.com/63588234/106362262-25413380-6322-11eb-8be6-c3da7e68d949.png)\r\n\r\nWhats the matter here? Any Ideas?\r\n\r\nCheers!\n Comments: \n Comment 0: Hi @tmrgr,\n\nThanks for posting the issue! I have an idea about what's going on here. Will try to get this patched ASAP. I think it's related to another problem.\n\nWill let you know when it is\n Comment 1: I'm also seeing this where the omega is a derived unit:\r\n\r\n![image](https://user-images.githubusercontent.com/82988/120563235-fdf99080-c3ff-11eb-94b7-b32cb81b920e.png)\r\n\n Comment 2: Hi all (@tmrgr, @psychemedia),\r\n\r\nI have just patched this in a new version of `forallpeople` (that's where the problem was). You can upgrade to v. 2.0.1 of forallpeople as of now and it should be fixed.\r\n\r\nThanks for your patience!",
  "Issue title: @delon\\cli\\application\\other-files\\layout\\default\\header\\components\\i18n.component.ts\u5185\u5bb9\u4e0d\u540c\u6b65\n Issue body: https://github.com/cipchk/ng-alain/blob/0b18923ca7e4d6cf5c251ba07a5662971ce46667/src/app/layout/default/header/components/i18n.component.ts#L38\r\n\r\n@delon\\cli\\application\\other-files\\layout\\default\\header\\components\\i18n.component.ts\r\n\u6587\u4ef6\u548c\u8fd9\u91cc\u7684\u5185\u5bb9\u4e0d\u540c\u6b65\uff0c\u6240\u4f9d\u5bfc\u81f4ng new -c=@delon/cli my-app\u521b\u5efa\u7684\u9879\u76ee\u8fd9\u90e8\u5206\u4ee3\u7801\u6709\u95ee\u9898\n Comments: \n Comment 0: thanks",
  "Issue title: Inline conditionals\n Issue body: ### Describe the problem\n\nThe following is the code to conditionally show a single element:\r\n\r\n```svelte\r\n{#if show}\r\n  <div>...</div>\r\n{/if}\r\n```\n\n### Describe the proposed solution\n\nSyntactical sugar suggestion:\r\n\r\n**Proposal 1** \u2014 After opening tag with a space and a `?` character.\r\n```svelte\r\n<!-- using the variable name -->\r\n<div?show>...</div>\r\n\r\n<!-- using a JS expression -->\r\n<div?{show === true}>...</div>\r\n\r\n<!-- use with components -->\r\n<SomeComponent?show />\r\n<SomeComponent?{show === true} />\r\n```\r\n\r\n**Proposal 2** \u2014 After opening tag without a space and with a `:` character.\r\n```svelte\r\n<!-- using the variable name -->\r\n<div:show>...</div>\r\n\r\n<!-- using a JS expression -->\r\n<div:{show === true}>...</div>\r\n\r\n<!-- use with components -->\r\n<SomeComponent:show />\r\n<SomeComponent:{show === true} />\r\n```\r\n\r\nCommon example I encounter:\r\n```svelte\r\n<!-- before -->\r\n{#if subtitle}\r\n  <p>{subtitle}</p>\r\n{/if}\r\n\r\n<!-- proposed solution -->\r\n<p?subtitle>{subtitle}</p>\r\n\r\n<!-- too much sugar...? (variable is used as the default <slot>, if it exists) -->\r\n<p?subtitle />\r\n<p:subtitle />\r\n<Subtitle?subtitle />\r\n<Subtitle:subtitle />\r\n```\n\n### Alternatives considered\n\nThe following is done in a single line but I prefer to keep `{#}` expressions on their own line.\r\n\r\n```svelte\r\n{#if show}<div>...</div>{/if}\r\n```\n\n### Importance\n\nnice to have\n Comments: \n Comment 0: There have been a number of other similar issues requesting various bits of syntactical sugar, and the general answer to these has been \"no\", both because there shouldn't be multiple ways to do something, and because code is read many more times than it is written. Somewhere someone down the line is going to appreciate having the word `if` in the code rather than some opaque punctuation.\n Comment 1: Additional proposal (somewhere down the linedown the line...):\r\n\r\nWith an `if` directive:\r\n```svelte\r\n```",
  "Issue title: UI unable to render actuator responses\n Issue body: I am using SBA 2.0.1. The UI is unable to render data due to malformed JSON for certain actuator endpoints. The client applications are secured, and the admin server is properly configured to pass required headers to access the actuator endpoints. For example, SBA is able to successfully get response for `loggers` endpoint (please see attached loggers_response_actual.json). You will see in the json, a new object  is introduced as below:\r\n```\r\n{\"error\":\"invalid_token\",\"error_description\":\"G48y3EOMflfRwmvODgs65oizT7sP\"}\r\n```\r\nI am sure this object is not coming from SBA, but there still seems something is not correct as the screenshot suggests that the API call was successful (status 200). Also i have attached the actual response for `loggers` endpoint when hitting it from postman.\r\n\r\n\r\n![loggers_tab](https://user-images.githubusercontent.com/16265134/42389231-a318c8f0-8165-11e8-9746-a112ea99655e.JPG)\r\n\r\n[loggers_response_postman.txt](https://github.com/codecentric/spring-boot-admin/files/2171181/loggers_response_postman.txt)\r\n[loggers_response_actual.txt](https://github.com/codecentric/spring-boot-admin/files/2171182/loggers_response_actual.txt)\r\n\r\n\r\n\n Comments: \n Comment 0: I guess the extra bit at the end is from some kind of middleware/firewall. The HTTP response status may be 200 but the returned content is not compliant to the JSON spec so the ui can't parse the content - there is nothing we can do about it - you need to fix your setup.\r\nMay be you should take some tcp dumps on your client and spring boot admin machine to figure out if there is something in between messing with the response\n Comment 1: I did some investigation and found that the extra JSON element was added by our internal security library. I was able to get UI working by excluding calls from admin UI to admin server using below configuration:\r\n```\r\n   /**\r\n     * Ignoring all self-APIs/SBA server APIs which are called by SBA-UI internally.\r\n     */\r\n    @Override\r\n    public void configure(final WebSecurity web) throws Exception {\r\n        web.ignoring()\r\n          .antMatchers(HttpMethod.OPTIONS)\r\n          .antMatchers(HttpMethod.GET, \"/**/applications\", \"/**/applications/*\", \"/**/notifications/*\", \"/**/instances/**\");\r\n    }\r\n```\r\nHowever, it would be good to call these endpoints securely too. I will raise a feature request for the same.",
  "Issue title:  EMQTT cluster with k8s\n Issue body: #### Environment\r\n\r\n- OS: centos7\r\n- Erlang/OTP: \r\n- EMQ: v3.0.1\r\n\r\n#### Description\r\nI used k8s to set up the MQTT cluster, and when my pod was down, all my client connections were down as well. Is there any way to keep the connection up\r\n\r\n\n Comments: \n Comment 0: In addition to the above environmental information\r\nThe k8s version is v1.13.4\n Comment 1: only one pod down, but bring down all connections to the service? from what you mentioned, it isn't enough clear to me.  Are you using LB? \n Comment 2: The MQTT protocol is based on TCP long connections, so it is normal for the client to disconnect when the pod is closed.\n Comment 3: Yeah, if the client connected to one pod via service/LB, that client connection got disconnected when pod done, that is understandable. But it seems to me that ysyh15 said one pod done, all client connections disconnected. that is very weird. \n Comment 4: That is unclear, and would be extremely unusual. EMQX behaves relatively reasonably when losing members from its cluster.\n Comment 5: thx a lot,",
  "Issue title: `generate_function` should not generate files on storage automatically\n Issue body: **Is your feature request related to a problem? Please describe.**\r\nCould `generate_function` instead of creating files just return their source code? It feels strange that the files on storage are generated, since if a user needs a file, he can easily save it himself.\r\n\r\n**Describe the solution you'd like**\r\n1. a property for accessing sources. Made of objects of `GeneratedSource` class, each one contains the properties\r\n* `path` of `PurePath` with a path of the file rel to the output dir\r\n* `warnings` - an array of warjings\r\n* `source` - source code\r\n2. `generated_files` lazily take `source` of corresponding fikes qnd write them to disk. Usage of `generated_files` causes a deprecation warning to be emitted.\r\n\r\n**Describe alternatives you've considered**\r\nNo.\r\n\n Comments: \n Comment 0: Yeah I think this is a good idea - probably wouldn't deprecate the option of having symforce write to disk but would be good to have the option not to.  One question would be whether all other tools we call out to are ok or can be made to work with this (e.g. autoformatters, skymarshal).\r\n\r\nWhat are some examples of warnings to include in point 1 bullet 2?  Not sure what you mean there (or if there are some warnings we currently emit in other forms that this would be replacing)\n Comment 1: >What are some examples of warnings to include in point 1 bullet 2? Not sure what you mean there (or if there are some warnings we currently emit in other forms that this would be replacing)\r\n\r\nI guess no for now, but in future it may make sense to wind up an own DSL (probably DAG-of-`dict`s-based (can be serialized/parsed into/from many formats (s.a. CBOR, terraform tf2, json, NEON and so on), but YAML is usually used), as lot of projects do). Some projects doing that have a model that 1 input file corresponds to 1 output file. Then for 1 input compiler generates 1 output + bunch of warnings, if any, or, in the case of an error, just `null` output + bunch of errors. Then it can be either written to disk using the attached path, or just used disklessly, for example by showing to a user, or just disklessly compiling and executing.",
  "Issue title: Import CSS file to renderer as static styles\n Issue body: <!------------------------------------------\r\n  Thanks for contributing!\r\n  Please read the guide-lines at the bottom.\r\n------------------------------------------->\r\n\r\n<!--\r\n  FEATURE REQUEST ONLY\r\n  ====================\r\n-->\r\n#### Proposal\r\n\r\nI would very much like a way to be able to dynamically import third party styles into my fela renderer as static styles.\r\n\r\nI'm not sure if this is already possible, but from reading the `renderStatic` docs it seems perhaps not:\r\n\r\n\"It accepts either a valid CSS string or a basic style object with a custom selector to be rendered into.\"\r\n\r\nI see you can pass a css string, but this could be problematic if you rely on third party styles which change from time to time, for example a library might require you to import the styles so the component renders correctly:\r\n\r\n`import'react-aspect-ratio/aspect-ratio.css'`\r\n\r\nBut if we statically add the string from that file into fela, upon update of that library those styles will be stale.\r\n\r\nIs there any current recommended way to deal with this use case?\r\n\r\n<!---------------------\r\n  =====================\r\n  REPORTING GUIDE-LINES\r\n  =====================\r\n\r\n  FEATURE REQUEST:\r\n  If you have a feature request please fill out the form\r\n  to describe is as detailed as possible including code examples, use-cases\r\n  and perhaps pro/contra implementing it\r\n  TODO: Remove the BUG REPORT ONLY part\r\n\r\n  BUG REPPORT:\r\n  If you found a bug please fill out the template below.\r\n  Remove some parts if not needed, but try to be as detailed as possible.\r\n  If it is not reproductible, please note that.\r\n  TODO: Remove the FEATURE REQUEST ONLY part.\r\n--------------------->\r\n\n Comments: \n Comment 0: It's super easy to do in webpack, that's actually what `css-loader` does by default &ndash; bundles css files into js files and provides a simple wrapper. To get a css source string there a method `toString()`, you can use it like this:\r\n\r\n```js\r\nimport styles from'react-aspect-ratio/aspect-ratio.css';\r\n\r\n//...\r\n\r\nrenderer.renderStatic(styles.toString())\r\n```\n Comment 1: Let's go and add this to the docs somewhere :) Sounds like a great recipe again.\n Comment 2: @vlad-zhukov, @rofrischmann, doesn't renderStatic override the previous styles injected as static?\n Comment 3: @aga5tya Nop it doesn't! Should it? No I guess right?\n Comment 4: @rofrischmann I think it logically should not. So it's fine as it is now. Generally static styles are added at the beginning of renderer creation.\r\n\r\nI could see an issue arising if you dynamically insert static styles. For example, a dynamic import similar to the one I used above:\r\n\r\n```\r\nconst styles = await import('react-aspect-ratio/aspect-ratio.css');\r\nrenderer.renderStatic(styles.toString());\r\n```\r\n\r\nWhat would happen if this ran in a `componentDidMount()` of a component which is mounted multiple times? The import will be imported once and cached, but I'm guessing the styles be added multiple times to the renderer? Potentially bloating the CSS?\r\n\r\nPerhaps this is outside of the scope of fela though.\n Comment 5: > @aga5tya Nop it doesn't! Should it? No I guess right?\r\n\r\n@rofrischmann My bad,, It was something wrong with my set up that caused the renderer to override static. Works as expected now.\n Comment 6: @lostpebble if it\u2019s the same CSS string it will only be added once and cached \ud83d\udc4c you can add as many static styles as possible",
  "Issue title: [EN][Quest][Ghostlands][Night Elf Plans]\n Issue body: Night Elf Plans: An'owyn cant be picked up.\n Comments: \n Comment 0: add wowhead link\n Comment 1: I completed this quest yesterday without problems.\n Comment 2: yea quest is working it just has long spown time",
  "Issue title: Messages from python calls get truncated\n Issue body: - NVIM 0.2.0-dev\r\n- Ubuntu-Gnome 16.10\r\n- gnome-terminal\r\n- xterm-256color\r\n\r\n### Actual behaviour\r\n\r\nMessages from python calls get truncated. \r\n\r\n```\r\n...\r\nFile \"/usr/local/lib/python3.5/dist-packages/tasklib/backends.py\", line 281, in execute_command                                                                         \r\n    raise TaskWarriorException(error_msg)                                                                                                                                 \r\ntasklib.backends.TaskWarriorException: Using alternate.taskrc file /home/someone/.taskrc                                                                                  \r\nConfigu\r\n```\r\n### Expected behaviour\r\n\r\nMessage continues after `Configu`\r\n\r\n\r\n\r\n\n Comments: \n Comment 0: I see `...` so I'm guessing this is a bug with the `:!` throttling. Can you list the steps you took?\n Comment 1: I inserted the `...`...\r\n\r\nIt happens when I commit changes with the [taskwiki plugin](https://github.com/tbabej/taskwiki/issues/121). Something goes wrong there and I can not debug it, because of the truncated message.\r\n\r\n\r\n![screenshot from 2017-01-21 18-16-41](https://cloud.githubusercontent.com/assets/3330855/22176287/20a371aa-e007-11e6-987e-bc21c7cf2074.png)\r\n\r\n`:message` does not produce the output either. \r\n\r\n\n Comment 2: > :message does not produce the output either.\r\n\r\nOk, that confirms that \"shell output throttling\" is not the issue.\r\n\r\n> Can I simulate somehow an error with the python provider to check if the message gets truncated too?\r\n\r\nYes, just do something python doesn't like:\r\n\r\n```\r\n:py3 print(foo)\r\n\r\nError detected while processing function provider#python3#Call:                                                  \r\nline   18:                                                                                                       \r\nTraceback (most recent call last):                                                                               \r\n  File \"<string>\", line 1, in <module>                                                                           \r\nNameError: name 'foo' is not defined\r\n```\n Comment 3: I can reproduce it:\r\n`nvim -u NORC` and then `:py3 print(foo)` works fine, but when \"foo\" is replaced by a very long string the message gets truncated.\n Comment 4: @BonarBeavis How long? I tried a 2674 character string with `:py3 print()`, no output was truncated. What version of python 3 client does `:CheckHealth provider` report?\n Comment 5: It works with 2674 characters in single line. Try this:\r\nCopy this line following line:\r\nNeque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit...\r\nPlace the cursor on foo in `:py3 print(foo)` and paste the line about 20 times and the press `<CR>`\n Comment 6: Output `:CheckHealth provider`\r\n\r\n```markdown\r\nhealth#provider#check\r\n========================================================================\r\n## Clipboard\r\n  - SUCCESS: Clipboard tool found: xclip\r\n\r\n## Python 2 provider\r\n  - INFO: `g:python_host_prog` is not set.  Searching for python2 in the environment.\r\n  - INFO: Executable: /usr/bin/python2\r\n  - INFO: Python2 version: 2.7.12\r\n  - INFO: python2-neovim version: 0.1.13\r\n  - SUCCESS: Latest python2-neovim is installed: 0.1.13\r\n\r\n## Python 3 provider\r\n  - INFO: `g:python3_host_prog` is not set.  Searching for python3 in the environment.\r\n  - INFO: Executable: /usr/bin/python3\r\n  - INFO: Python3 version: 3.5.2\r\n  - INFO: python3-neovim version: 0.1.13\r\n  - SUCCESS: Latest python3-neovim is installed: 0.1.13\r\n```\n Comment 7: I wanted to report this behaviour some time ago, but then I found the following pull request in `python-client`\r\n\r\nhttps://github.com/neovim/python-client/pull/221\r\n\r\nmaybe this is root of the problem? (I performed no testing, I just put this off until the pull gets merged :))\n Comment 8: I don't see how that PR would fix this issue. @tbabej do you have a better way to reproduce the reported issue here?\n Comment 9: > nvim -u NORC and then :py3 print(foo) works fine, but when \"foo\" is replaced by a very long string the message gets truncated.\r\n\r\nThat actually happens in the python REPL as well, the limit of 200 for the NameError comes from python itself.",
  "Issue title: Implement termux-wakelock using unix socket\n Issue body: <!--\r\nIMPORTANT:\r\n\r\n1. Support of Android 5.x - 6.x is finished.\r\n2. Fill the template AFTER comments.\r\n-->\r\n\r\n**Feature description**\r\n<!--\r\nDescribe the feature and why you want it.\r\n-->\r\nCurrent the wakelock mechanism is implemented as `am startservice` which is too heavy weighted and cause a lot of latency. As we now have unix socket, wakelock/unlock could be much more responsive.\r\n\r\n**Reference implementation**\r\n\r\nHave you checked if the feature is accessible through the Android API?\r\nDo you know of other open-source apps that has a similar feature as the one you want? (Provide links)\r\n\n Comments: \n Comment 0: If you use the Github action build of Termux, you can try replacing the `am` in the scripts with `termux-am`. It uses a unix socket to connect to the main app and should be about 10 times faster (or was it 100? I can't remember, I ran the tests a long time ago). Emulating `am` is easier than changing all APIs to unix sockets.\n Comment 1: @tareksander I'm using f-droid build of termux with every thing up to date, but when I replace am with termux-am, it give the error `Could not connect to socket: No such file or directory`.\r\n\r\n```\r\nTermux Variables:                    \r\nTERMUX_APP_PACKAGE_MANAGER=apt                                                                                             \r\nTERMUX_MAIN_PACKAGE_FORMAT=debian                                                                                          \r\nTERMUX_VERSION=0.118.0                                                                                                     \r\nPackages CPU architecture:                                                                                                 \r\naarch64                                                                                                                    \r\nSubscribed repositories:                                                                                                   \r\n# sources.list        \r\ndeb https://mirror.iscas.ac.cn/termux/apt/termux-main stable main\r\n# root-repo (sources.list.d/root.list)                                                                                     \r\ndeb https://grimler.se/termux/termux-root root stable\r\n# x11-repo (sources.list.d/x11.list)\r\ndeb https://grimler.se/termux/termux-x11 x11 main\r\nUpdatable packages:\r\nAll packages up to date\r\ntermux-tools version:\r\n1.27.0\r\nAndroid version:\r\n11\r\nKernel build information:\r\nLinux localhost 4.14.180-perf-gf5e9e9c #2 SMP PREEMPT Tue Jul 27 21:52:42 CST 2021 aarch64 Android\r\n```\r\nWhat should I do to make it work?\n Comment 2: > If you use the Github action build of Termux\n\nI said that for a reason, that feature isn't in the fdroid releases yet. Also iirc Termux:API doesn't provide the wakelock, but the main app, so the only thing to do is to wait for the next fdroid release or switch to Github action builds for Termux and all plugins.",
  "Issue title: Tenant level control on/off switch shows it will be removed by May 2018, but it's still there. \n Issue body: Is there an updated date for when the tenant level control on/off switch will be removed? \n\n---\n#### Document Details\n\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\n\n* ID: cccdd91a-7f05-abd5-ed94-e82152b86914\n* Version Independent ID: 3532d0a8-119c-f7d0-0d4f-a865ad32570f\n* Content: [Manage user access to Microsoft Teams](https://docs.microsoft.com/en-us/MicrosoftTeams/user-access)\n* Content Source: [Teams/user-access.md](https://github.com/MicrosoftDocs/OfficeDocs-SkypeForBusiness/blob/live/Teams/user-access.md)\n* Service: **msteams**\n* GitHub Login: @LolaJacobsen\n* Microsoft Alias: **lolaj**\n Comments: \n Comment 0: @islubin - this doc states the below as @soyalejolopez  noted. Should I update this document?\r\n\r\n**Note**\r\nTenant-level control of the on/off status for Teams is temporary and **will be removed by May 2018.** At that time, access to Teams will be controlled via user-level licensing only. To learn more, see Manage user access to Microsoft Teams.\n Comment 1: @soyalejolopez - confirmed the date is moved to through July. I updated article to say it will be removed beginning of August. It should be live shortly. Thanks for catch and the feedback on this!",
  "Issue title: Add window title to the launchers hover tooltip\n Issue body: The window list extension places the window title of a chrome app with the current website title. This is a very desirable feature to me, especially for the purpose of webapps like slimtimer.com/client, which update the title with useful information in real time.\n\n Comments: \n Comment 0: Hi,\n\nIt's not clear to me what you are asking for. Could you elaborate?\nOn 24 Sep 2015 6:12 pm, \"Bryce Schober\" carljackson@example.org wrote:\n\n> The window list extension places the window title of a chrome app with the\n> current website title. This is a very desirable feature to me, especially\n> for the purpose of webapps like slimtimer.com/client, which update the\n> title with useful information in real time.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/micheleg/dash-to-dock/issues/225.\n\n Comment 1: With the dash-to-dock extension, it is hard to access the title of web browser tabs. With the [window-list extension](https://extensions.gnome.org/extension/25/window-list/), the title of the top-most browser tab is displayed on the list.\r\n\r\nIt would be really helpful to my use-case if the mouse-over of a running application displayed current window title next to the application name. As it is, I have to press and hold the application for a bit before I can expose the current window titles.\n Comment 2: So, you would like to replace the small tooltip which appears on hover with the windows title - the website address in the case of a browser, which already appears in the right menu, which, by the way, is accessible with the right click not only with press and hold.\n\nOne problem is the launcher might be link to multiple instances of the application/browser, in which case it is not clear what should be shown on hover. If it were the title of the topmost window it would be confusing. There is a remote possibility that I'll integrate windows thumbnails in the dock on hover, similar to windows 7 and a few shell extensions. In such case the title would appear below the windows thumbnail and it would do the job for you.\n",
  "Issue title: What does the port firewall coming from GCM server?\n Issue body: I have a problem with port firewall for receiving notification from GCM server.\r\nMy network use allow policy for configurated firewall, so I try to config follow this \r\nhttp://esupport.trendmicro.com/solution/en-US/1060693.aspx.\r\nI hope it worked but it not.\r\n\r\nI search in many way to solve, but I couldn\u2019t make head or tail of it.\r\n\n Comments: \n Comment 0: The GCM needs the following connections:\r\n- port: 5228, host: mtalk.google.com\r\n- port: 443, host: android.googleapis.com \n Comment 1: Great thank, Finally I got it. > <\n Comment 2: UPDATE: GCM is also using:\r\n- port: 443, host: android.client.google.com\n Comment 3: this is about devices receiving push notifications.. My server is blocking attempt to initiate push request to GCM server...What ip/port I should open to send push notification request to GCM? ",
  "Issue title: Segfault when cancel print dialog.\n Issue body: Segfault when cancel print dialog.\r\n\r\nOpen print dialog (:hardcopy) and then cancel by pressing \"Cancel\" button or press ESC key on keyboard.\r\n\r\nVieb 7.1.2\r\nDebian 11\r\n\r\nTested both\r\nvieb_7.1.2_amd64.deb\r\nVieb-7.1.2.AppImage\n Comments: \n Comment 0: Seems like this will be fixed if we upgrade electron, it's a know issue that's been fixed there: https://github.com/electron/electron/pull/33015 I'll try to find the time in the next weeks to update electron and Vieb.\n Comment 1: Fixed in 7.2.0!",
  "Issue title: \u8fd9\u4e2a\u63d2\u4ef6\u592a\u597d\u7528\u4e86\uff0c\u89e3\u51b3\u4e86linux\u4e0a\u6ca1\u6709QQ\u7684\u7a98\u5883 \uff0c\u5982\u679c\u80fd\u52a0\u5165\u6587\u4ef6\u4f20\u8f93\u5c31\u5b8c\u7f8e\u4e86\uff01\n Issue body: \u5982\u679c\u80fd\u52a0\u5165\u6587\u4ef6\u4f20\u8f93\u5c31\u5b8c\u7f8e\u4e86\uff01  \u4f8b\u5982 \u7fa4\u6587\u4ef6 \n Comments: \n Comment 0: \u786e\u5b9e, linuxqq\u7b80\u76f4\u65e0\u6cd5\u4f7f\u7528\n Comment 1: \u6682\u65f6\u4e0d\u8003\u8651\u6587\u4ef6\u4e86",
  "Issue title: [amp-story-interactive] Allow for not displaying results\n Issue body: ## Describe the new feature or change to an existing feature you'd like to see\r\n\r\nThere are some cases for polls or quizes where the story publisher might not want to show the results. A simple case would be one of polling for customer satisfaction. If customers are not satisfied, the publisher might not want to show the results or make them public. \r\n\r\nI think simply removing the response percentage text should do the trick, and having the visualisation similar to just one person having responded (100% for the selected option, 0% for all others)\n Comments: \n Comment 0: @mszylkowski I know if no backend is specified, we (obviously) don't aggregate the results; is it possible to trigger that state while still sending data to the backend?\n Comment 1: On our v1 launch we designed components to always show the responses but I think this is a completely valid use-case.\r\n\r\nCurrently the way I see this working in this way would be to have the backend return an invalid JSON (but still record the vote), so the percentages don't show but they get recorded in the backend. This requires some development from the backend owner but I think is the more robust/secure solution (and the format can gracefully catch this error, but it should currently work as you detailed).\r\n\r\nWe can also introduce an attribute to hide the results in the component, but anyone would be able to know the customer responses with the right HTTP request. It should be relatively easy to make this change and we can add it to our roadmap.\n Comment 2: Good point about changing the endpoint's response.  Sounds reasonable to launch an attribute to disable the result state and provide documentation on the shape of the JSON response in that case.\r\n\r\n/cc @raovs @hongcatlover to ensure this sounds reasonable to them\n Comment 3: LGTM from my side",
  "Issue title: computed key marked duplicate\n Issue body: ```js\r\nvar x = \"y\";\r\nvar z = {\r\n  x: x,\r\n  [x]: x\r\n};\r\n```\r\n\r\n```\r\n  2:8  error  Duplicate key 'x'  no-dupe-keys\r\n\r\n\u2716 1 problem\r\n```\r\n\r\nis this by design?\n Comments: \n Comment 0: In this context it's a bug, because you're creating a property called \"y\", so it's not a duplicate. If you did this it would be a valid error:\n\n``` js\nvar z = {\n    x: x,\n   [\"x\"]: x\n}\n```\n\n Comment 1: Working on this.",
  "Issue title: Remove retry policies section for state\n Issue body: As we removed retry policies, this section from the docs should be removed:\r\n\r\nhttps://v1-rc3.docs.dapr.io/developing-applications/building-blocks/state-management/state-management-overview/#retry-policies\n Comments: \n Comment 0: I am in the overview anyway, so picking up this issue.\n Comment 1: Closed with #1206 ",
  "Issue title: Minor Install Packages to Add to Ubuntu Apt \n Issue body: qemu-utils (to get qemu-img) and xtightvncviewer should be apt prereqs. \n Comments: \n Comment 0: Hi, \r\n\r\nThanks for message.\r\n\r\n* xtightvncviewer is not require because by default you should have vinagre\r\n* qemu-utils: It's not mandatory to use GNS3 even if usefull. But most user will not use it.",
  "Issue title: Give hint how to change the repo URL\n Issue body: Since the repo was moved, it might be a good idea to give a hint how to change the URL (using **git remote set-url**; see https://docs.github.com/en/github/using-git/changing-a-remotes-url)\r\n```\r\n% git remote -v\r\norigin\thttps://github.com/biologist79/Tonuino-ESP32-I2S.git (fetch)\r\norigin\thttps://github.com/biologist79/Tonuino-ESP32-I2S.git (push)\r\n% git remote set-url origin https://github.com/biologist79/ESPuino.git\r\n% git remote -v                                                       \r\norigin\thttps://github.com/biologist79/ESPuino.git (fetch)\r\norigin\thttps://github.com/biologist79/ESPuino.git (push)\r\n```\n Comments: \n Comment 0: Well done! Already mentioned it.\r\nThanks for your support.",
  "Issue title: Deprecate `neko.Web` and `php.Web`\n Issue body: Let's deprecate them for 4.1 and move to hx3compat in 4.2\n Comments: \n Comment 0: What is the rationale?\r\n\r\n_(and let's no kid ourselves: code goes to hx3compat to die)_\n Comment 1: It's out-of-scope for a standard library. At least one of our, uhm, size.\n Comment 2: Out of scope and it has very inefficient API to implement for PHP.\n Comment 3: > Let's deprecate them for 4.1 and move to hx3compat in 4.2\r\n\r\nShould it not technically go to `hx4compat`\n Comment 4: Yes, probably\n Comment 5: Deprecated.\r\nNext step: move to hx4compat\n Comment 6: `neko.Web` should not be derpecated as there's no alternative.",
  "Issue title: \u53bb\u6389 xml \u4e2d Class \u6807\u7b7e\u4e2d\u7684 value, \u76f4\u63a5\u5b9a\u4e49\u5c5e\u6027\n Issue body: <!-- \u5728\u63d0\u4ea4\u8fd9\u4e2a\u53cd\u9988\u524d\u8bf7\u786e\u4fdd\u5f53\u524d issue \u4e2d\u6ca1\u6709\u76f8\u540c\u7684\u95ee\u9898 -->\r\n\r\n<!-- \u63cf\u8ff0\u4f60\u60f3\u8981\u7684\u529f\u80fd -->\r\n\u53bb\u6389 class \u6807\u7b7e\u4e2d\u7684 value\uff0c\u76f4\u63a5\u5b9a\u4e49\u5c5e\u6027\uff0c\u8fd9\u6837\u7701\u4e86\u5f88\u591a \u201c&quot;\u201d\uff0c\u770b\u8d77\u6765\u4e5f\u4f1a\u6e05\u6670\u5f88\u591a\u3002\n Comments: \n Comment 0: \u8fd9\u4e2a\u5efa\u8bae\u5f88\u597d \ud83d\udc4d \n Comment 1: \u6211\u5df2\u7ecf\u63d0\u4ea4\u4e86PR, \u770b\u770b\u4f5c\u8005\u662f\u5426\u63a5\u6536 :)\n Comment 2: > \u53bb\u6389 class \u6807\u7b7e\u4e2d\u7684 value\uff0c\u76f4\u63a5\u5b9a\u4e49\u5c5e\u6027\uff0c\u8fd9\u6837\u7701\u4e86\u5f88\u591a \u201c\"\u201d\uff0c\u770b\u8d77\u6765\u4e5f\u4f1a\u6e05\u6670\u5f88\u591a\u3002\r\n\r\n\u8fd9\u91cc\u7684 \"\"\" \u662f <&quot;>\n Comment 3: &quot;&quot;&quot;\n Comment 4: > &quot;\n Comment 5: > \u53bb\u6389 class \u6807\u7b7e\u4e2d\u7684 value\uff0c\u76f4\u63a5\u5b9a\u4e49\u5c5e\u6027\uff0c\u8fd9\u6837\u7701\u4e86\u5f88\u591a \u201c\"\u201d\uff0c\u770b\u8d77\u6765\u4e5f\u4f1a\u6e05\u6670\u5f88\u591a\u3002\r\n\r\n\u201c\u201d\u201c \u662f &quot\n Comment 6: \u8981\u8bbe\u7f6e\u7684\u8bdd \u6700\u597d\u517c\u5bb9\u5904\u7406\n Comment 7: Commit:https://github.com/netease-im/NIM_Duilib_Framework/commit/e817180f3c57dc6ab41bcdac44416f4b0d177154",
  "Issue title: Not recursive?\n Issue body: If we have a scenario where\n\nFile 1:\n\n``` javascript\n//= require myfile.js\n//= require someotherfile.js\n//= require../somemodule/main.js\n```\n\nsomemodule/main.js:\n\n``` javascript\n//= require something.js\n//= require blah.js\n```\n\nWe're not going to get all the files from `somemodule/main.js` are we?\n\n Comments: \n Comment 0: +1\ncan't use such relative paths\n\n Comment 1: +1 I'm looking for a gulp version of this : https://github.com/vanetix/grunt-includes and recursivity is the only thing missing for me\n\n Comment 2: For those looking for this kind of functionality, you might want to look into [Mincer](https://github.com/nodeca/mincer)\n\n Comment 3: :+1: for this. Not a fan of `//= require_tree`, so being able to do some sort of selective recursion would be nice.\n\n Comment 4: Just submitted a pull request that supports this, and globbing.\n\n Comment 5: @scottmas :100: \n\n Comment 6: @scottmas Nice! Hope your PR will be merged soon! :+1: \n\n Comment 7: I can see that this has been merged, but for me this isn't working. I am using Gulp 3.9 and the latest version of gulp-include available. I just get `//=include../components/setUtils.js` in the source code after compile.\r\n\r\nMy path through:\r\n\r\n`index.js -> [require]../utils/pluginExists.js -> [require]../components/setUtils.js`\r\n\r\nAm I doing something wrong here?",
  "Issue title: Crash during logfile re-play\n Issue body: QGS crashes when stopping, rewinding a logfile re-play and on the end of the file.\n\n Comments: \n Comment 0: flyingk, can you provide more info here? I am not able to reproduce this on mac OSX using the latest QGC2 build from here:\nhttp://www.inf.ethz.ch/personal/lomeier/downloads/qgroundcontrol-mac-64-v2.0.0-beta-build01.dmg\n\n Comment 1: Hi Tom,\n\nwith the latest build it seems to work now on the mac. Must have been fixed recently.\nCheers!\nKai\n",
  "Issue title: Can't Install Lottie with Carthage\n Issue body: <!--\r\n## Lottie-iOS Issue\r\nHello! Sorry, you're having an Issue! Please help us make Lottie better by filling everything below out with as much information as you can, so we can try to reproduce and fix the issue!\r\n-->\r\n\r\n## Check these before submitting:\r\n- [] The issue doesn't involve an [Unsupported Feature](https://github.com/airbnb/lottie-ios/blob/master/README.md#supported-after-effects-features)\r\n- [] This issue isn't related to another open issue\r\n\r\n## This issue is a:\r\n- [] Non-Crashing Bug (Visual or otherwise)\r\n- \r\n## Which Version of Lottie are you using?\r\n\r\nLottie 3.0\r\n\r\n## What Platform are you on? \r\n<!-- (Specify Platform Version) -->\r\n- [] iOS\r\n\r\n## What Language are you in?\r\n- [] Swift\r\n\r\n## Expected B\r\nCan be installed with Carthage\r\n<!-- Screenshots encouraged -->\r\n\r\n## Actual Behavior\r\n<img width=\"577\" alt=\"Screen Shot 2021-12-13 at 12 06 58\" src=\"https://user-images.githubusercontent.com/95082093/145755602-0e6bbae3-3b09-4626-8487-eba7e3bc2cd5.png\">\r\nehavior \r\n<!-- Screenshots encouraged -->\r\nCannot install lottie library with carthage\r\n\r\n## Code Example\r\n<img width=\"365\" alt=\"Screen Shot 2021-12-13 at 12 08 06\" src=\"https://user-images.githubusercontent.com/95082093/145755672-bcf6387e-8be8-4869-acf5-f299df1fedf7.png\">\r\n\r\n\r\n## Animation JSON\r\n<!-- Adding the animation JSON helps us debug the issue faster!  If you don't want to publicly share the Animation, please email me amanda48@example.net -->\r\n\n Comments: \n Comment 0: https://github.com/airbnb/lottie-ios/issues/1448#issuecomment-996612284\n Comment 1: @jliussuweno25, does the fix discussed in https://github.com/airbnb/lottie-ios/issues/1448#issuecomment-998960232 work for you?",
  "Issue title: Failure in \"make check\" unit test: \"double free or corruption\" \n Issue body: [test-suite.log](https://github.com/wolfSSL/wolfssl/files/(819)300-7671/test-suite.log)\r\nMemory freeing error occurs in unit test during \"make check\".   The error occurs using the zip files on the website and doing a clone from github.   The test-suite.log file is attached.\r\n\r\nCompilation done using Linux Mint distribution 18.2. \n Comments: \n Comment 0: On a hunch, I moved --enable-all to the end of the configure run and rebuilt.   With no other changes, it was able to run the unit tests.\n Comment 1: Hello @RMartinDielectron \r\n\r\nIt sounds like you were able to resolve the issue by changing the configuration. Are you able to reproduce the original issue? If so could you please share the configuration settings you used?\r\n\r\nBest regards,\r\n\r\nEric Blankenhorn\r\nwolfSSL Support\n Comment 2: Hello @RMartinDielectron\r\n\r\nSince we never heard back from you I will go ahead and close out this support inquiry. Should any other questions come up please do not hesitate to open a new issue anytime by emailing stephanielambert@example.net or through the zendesk portal at https://wolfssl.zendesk.com. We are always happy to help out in any way we can.\r\n\r\nThank you for using wolfSSL support. We look forward to hearing from you in the future if you have any other questions.\r\n\r\nWarmest regards,\r\n\r\nEric Blankenhorn\r\nwolfSSL Support\n Comment 3: My apologies.  I have been trying to systematically reproduce what was\nhappening but on a clean Ubuntu system.\n\nRob Martin\nstephanielambert@example.net\n(819)300-7671\n\nOn Tue, Apr 30, 2019, 15:37 Eric Blankenhorn <stephanielambert@example.net>\nwrote:\n\n> Hello @RMartinDielectron <https://github.com/RMartinDielectron>\n>\n> Since we never heard back from you I will go ahead and close out this\n> support inquiry. Should any other questions come up please do not hesitate\n> to open a new issue anytime by emailing stephanielambert@example.net or through\n> the zendesk portal at https://wolfssl.zendesk.com. We are always happy to\n> help out in any way we can.\n>\n> Thank you for using wolfSSL support. We look forward to hearing from you\n> in the future if you have any other questions.\n>\n> Warmest regards,\n>\n> Eric Blankenhorn\n> wolfSSL Support\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/wolfSSL/wolfssl/issues/2214#issuecomment-488140748>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ALPBYWZBWEEXRXACFZNEK33PTDC4JANCNFSM4HHUNDXA>\n>.\n>\n",
  "Issue title: Named _* can be used only for last argument\n Issue body: ## Minimized code\r\n\r\n```Scala\r\nStarting scala3 REPL...\r\nscala> def f(i: Int, j: Int*) = i + j.sum\r\ndef f(i: Int, j: Int*): Int\r\n\r\nscala> f(j = List(2, 3, 4): _*, i = 42)\r\n1 |f(j = List(2, 3, 4): _*, i = 42)\r\n  |                     ^\r\n  |                     _* can be used only for last argument\r\n\r\nscala> f(List(2, 3, 4): _*)\r\n1 |f(List(2, 3, 4): _*)\r\n  |  ^^^^^^^^^^^^^^^^^\r\n  |Sequence argument type annotation `: _*` cannot be used here: the corresponding parameter has type Int which is not a repeated parameter type\r\n\r\nscala> f(j = List(2, 3, 4): _*)\r\n1 |f(j = List(2, 3, 4): _*)\r\n  |^^^^^^^^^^^^^^^^^^^^^^^^\r\n  |missing argument for parameter i of method f: (i: Int, j: Int*): Int\r\n```\r\n\r\n## Output\r\n\r\n```scala\r\nscala> f(j = List(2, 3, 4): _*, i = 42)\r\n1 |f(j = List(2, 3, 4): _*, i = 42)\r\n  |                     ^\r\n  |                     _* can be used only for last argument\r\n```\r\n\r\n## Expectation\r\n\r\n```\r\nscala 2.13.3> f(j = List(2, 3, 4): _*, i = 42)\r\nval res3: Int = 51\r\n```\r\nDotty fumbles a varargs \"swap job\", as it's known in the default args business.\r\n\r\nObserved at https://github.com/scala/bug/issues/12219\r\n\r\nWould be nice to enclose `_*` in backticks in the message.\r\n\n Comments: \n Comment 0: I think dotty's behavior is reasonable here. I don't think this warrants a fix, unless someone wants to work on it. In that case, please re-open.\r\n\r\n",
  "Issue title: New Chrome version results in annoying translations\n Issue body: Nach den letzten Chrome-Updates schl\u00e4gt der Browser immer automatisch vor, die Seite von EN nach DE zu \u00fcbersetzen. Das ist recht nervig und wenn man dann versehentlich den Auto-\u00dcbersetzer scharf hat, kann das zu uncoolen \u00dcbersetzungseffekten f\u00fchren  \r\n\r\nDas Problem hatten wir auch im CONF... weil im ganz urspr\u00fcnglichen HTML-Quelltext das lang-Attribut mit EN gesetzt war. Den lang-Attribut haben wir einfach entfernt. Das wird dann ja dynamisch erzeugt. Das w\u00fcrde ich auch f\u00fcr PF empfehlen.\n Comments: \n Comment 0: 92be09651859cfb987bc672bdefde9897a27cf64",
  "Issue title: SWIFT_VERSION\n Issue body:  - `flutter_udid` does not specify a Swift version and none of the targets (`Runner`) integrating it have the `SWIFT_VERSION` attribute set. Please contact the author or\r\n    set the `SWIFT_VERSION` attribute in at least one of the targets that integrate this pod.\n Comments: \n Comment 0: `export SWIFT_VERSION=4.0`\r\nhelp me\n Comment 1: I added a swift file to my project to solve the problem.\n Comment 2: Hi @Gorniv do you mind to give more details about how did you solve this problem? Export the `SWIFT_VERSION ` variable didn't didn't work for me. \r\n\r\nThanks\n Comment 3: @lohanbodevan I added a swift file to my project.\n Comment 4: @Gorniv Yes, i saw you have said it before, but i didn't understand what you meant by `I added a swift file to my project.`\r\n\r\nAnyway i solved adding `config.build_settings['SWIFT_VERSION'] = '4.0'` to `post_install` instruction in the `ios/Podfile`.\r\n\r\nLike this:\r\n```\r\npost_install do |installer|\r\n  installer.pods_project.targets.each do |target|\r\n    target.build_configurations.each do |config|\r\n      config.build_settings['ENABLE_BITCODE'] = 'NO'\r\n      config.build_settings['SWIFT_VERSION'] = '4.0'  # <-- this thing did the trick\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nIf someone knows a better way to solve feel free to comment.\r\nThanks!\r\n\n Comment 5: @lohanbodevan If you add the swift file in XCode - XCode change settings XCode project automatic\r\n\r\n`ios/Runner.xcodeproj/project.pbxproj`\r\n![image](https://user-images.githubusercontent.com/963316/59012346-ef436780-883f-11e9-8d17-47c5b06c1ac7.png)\r\n",
  "Issue title: \u8bf7\u95eearia2\u7684rpc\u7aef\u53e3\u662f8080\u5417\uff1f\n Issue body: \u6211\u5df2\u5f00\u653e\u6240\u6709\u7aef\u53e3\uff0c\u4f46\u6211\u60f3\u7528ariang\u8fde\u63a5aria2\u65f6\uff0c\u53d1\u73b0\u65e0\u8bba\u662f\u9ed8\u8ba4\u76846800\u7aef\u53e3\u8fd8\u662f\u5728start.sh\u4e2d\u53d1\u73b0\u8bbe\u7f6e\u76848080\u7aef\u53e3\u90fd\u65e0\u6cd5\u8fde\u63a5\uff0c\u5bc6\u7801\u5df2\u6b63\u786e\u586b\u5199\uff0c\u6240\u4ee5\u60f3\u8bf7\u95ee\u4e00\u4e0b\u8001\u54e5\u8be5\u65b9\u9762\u7684\u4e8b\u5b9c\uff0c\u5341\u5206\u611f\u8c22\u8001\u54e5\u7684\u9879\u76ee\n Comments: \n Comment 0: > \u6211\u5df2\u5f00\u653e\u6240\u6709\u7aef\u53e3\uff0c\u4f46\u6211\u60f3\u7528ariang\u8fde\u63a5aria2\u65f6\uff0c\u53d1\u73b0\u65e0\u8bba\u662f\u9ed8\u8ba4\u76846800\u7aef\u53e3\u8fd8\u662f\u5728start.sh\u4e2d\u53d1\u73b0\u8bbe\u7f6e\u76848080\u7aef\u53e3\u90fd\u65e0\u6cd5\u8fde\u63a5\uff0c\u5bc6\u7801\u5df2\u6b63\u786e\u586b\u5199\uff0c\u6240\u4ee5\u60f3\u8bf7\u95ee\u4e00\u4e0b\u8001\u54e5\u8be5\u65b9\u9762\u7684\u4e8b\u5b9c\uff0c\u5341\u5206\u611f\u8c22\u8001\u54e5\u7684\u9879\u76ee\r\n\r\n\u6211\u77e5\u9053\u4e86\uff0c\u5c45\u7136\u662f8868",
  "Issue title: Desenvolvedor(a) Android S\u00eanior\n Issue body: \r\n## Descri\u00e7\u00e3o da vaga\r\n\r\nProjeto inovador, com grandes desafios t\u00e9cnicos envolvendo IoT e Big Data - Empresa multinacional de grande porte.\r\n\r\n## Local\r\n\r\nCampinas-sp\r\n\r\n## Benef\u00edcios\r\n\r\n- F\u00e9rias remuneradas\r\n- Participa\u00e7\u00e3o nos lucros da empresa\r\n\r\n## Requisitos\r\n\r\nObrigat\u00f3rios\r\nDesenvolvedor Android com mais de 3 anos de experi\u00eancia em desenvolvimento Android nativo. Com experi\u00eancia em Java/Kotlin. Conhecimento de padr\u00f5es de arquitetura como MVP e MVVM. \r\nConhecimento de Testes Unit\u00e1rios e Testes Instrumentados. \r\nExperi\u00eancia com a API RESTful e sockets.\r\nBoa experi\u00eancia de trabalho em equipe.\r\nSiga boas pr\u00e1ticas de desenvolvimento Agile - Scrum\r\nBons conhecimentos de Git e butbucket.\r\n\r\nDiferenciais\r\n- Ter trabalhado com sistemas de coleta de dados em tempo real.\r\n\r\n## Contrata\u00e7\u00e3o\r\n\r\nPJ \r\n\r\n## Nossa empresa\r\n\r\nEmpresa referencia em aplicativos m\u00f3veis\r\n\r\n## Como se candidatar\r\n\r\nPor favor envie um email para michael10@example.com com seu CV anexado - enviar no assunto: Vaga Android\r\n\n Comments: \n Comment 0: @Anatalent Conforme as regras deste mural de vagas, \u00e9 obrigat\u00f3ria a divulga\u00e7\u00e3o do nome da empresa contratante. Encerraremos esta issue at\u00e9 que a mesma seja editada com o nome da empresa.",
  "Issue title: Downloader\u7684Cookie\u65e0\u6cd5\u6e05\u7a7a\n Issue body: \u722c\u53d6\u4e00\u4e2a\u7f51\u9875\uff0c\u5728Cookie\u88ab\u5c01\u540e\u9700\u8981\u6e05\u7a7a\u73b0\u6709\u7684Cookie\uff0c\u518d\u8bf7\u6c42\u4e00\u4e2a\u7ec4\u7684Cookie\u7ee7\u7eed\u722c\u53d6\u3002\u4f46\u662f\u5bf9Spider\u7c7b\u4e2dsite\u64cd\u4f5c\u662f\u6ca1\u6709\u7528\u7684\u3002\u770b\u6765\u9700\u8981\u4fee\u6539\u4e00\u4e0bDownloader\u90e8\u5206\u6e90\u7801\u6765\u5b9e\u73b0\u4e86\u3002\n Comments: \n Comment 0: \u770b\u4e86\u4e00\u4e0b\u6e90\u7801\uff0c\u76f4\u63a5\u8bbe\u7f6erequest\u5bf9\u8c61\uff0c\u4f7f\u7528.addCookie(\"\", \"\")\u65b9\u6cd5\u5c31\u53ef\u4ee5\u4f7f\u672c\u6b21\u8bf7\u6c42\u7684Cookie\u4e3a\u7a7a\u4e86\uff0c\u670d\u52a1\u5668\u8fd4\u56de\u7684\u65b0Cookie\uff0c\u7531\u4e8eCookieManagement\u7684\u4f5c\u7528\u4f1a\u88ab\u91cd\u65b0\u8bb0\u5f55\u4e0b\u6765\u3002",
  "Issue title: 6.1.0.rc1 Strict loading assocations doesn't work with ActiveStorage\n Issue body: I don't know if there is already a tracker for this, or this is planned in a more future release but I'll just leave it here.\r\n\r\n### Steps to reproduce\r\n```ruby\r\n# app/models/supplier.rb\r\nclass Supplier < ApplicationRecord\r\n  has_one_attached :logo, strict_loading: true\r\nend\r\n\r\n# app/controllers/suppliers_controller.rb\r\nclass SuppliersController < ApplicationController\r\n  def index\r\n    suppliers = Supplier.all\r\n    # suppliers = Supplier.includes(:logo_attachment) # When eager loaded\r\n\r\n    render json: suppliers.as_json(include: :logo)\r\n  end\r\nend\r\n```\r\n\r\n### Expected behavior\r\nIt should raise `ActiveRecor38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5StrictLoadingViolationError` error when not eager loaded.\r\n\r\n### Actual behavior\r\nI got `unknown keyword: :strict_loading` error instead.\r\n\r\n### System configuration\r\n**Rails version**:\r\n```ruby\r\ngem 'rails', '~> 6.1.0.rc1'\r\n```\r\n\r\n**Ruby version**:\r\n```\r\nruby 2.7.2p137 (2020-10-01 revision 5445e04352) [x86_64-darwin19]\r\n```\r\n\n Comments: \n Comment 0: After this change, writing\r\n```ruby\r\nhas_one_attached :logo\r\n```\r\nis equal to \r\n```ruby\r\nhas_one_attached :logo, strict_loading: false\r\n```\r\nwhich doesnt always represent user's intent.\r\n\r\nThe problem was introduced by setting the default value [here](https://github.com/dcangulo/rails/blob/1db02b3896501ab4925e017538ee69f65acbc0ba/activestorage/lib/active_storage/attached/model.rb#L50) when user does not provide one, and doesn't taking into account the `strict_loading_by_default` setting in such case.\r\n\r\nConsider this example\r\n\r\n```ruby\r\nclass Avatar\r\n  has_one_attached :logo\r\nend\r\n\r\nclass AvatarTest < ActiveSupport38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5TestCase\r\n  test \"n+1 queries\" do\r\n    Avatar.strict_loading_by_default = true\r\n    # N+1 query doesn't raise ActiveRecor38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5StrictLoadingViolationError error\r\n  end\r\nend\r\n```\r\n\r\nThis is counterintuitive and doesn't match `has_one` behaviour.\r\n`strict_loading` option should be appended [here](https://github.com/dcangulo/rails/blob/1db02b3896501ab4925e017538ee69f65acbc0ba/activestorage/lib/active_storage/attached/model.rb#L70) only when user explicitly specify one.\r\n",
  "Issue title: Apply Git workflow: GitFlow\n Issue body: This task discusses Git workflow that is aimed to be applied before releasing next SOCI, either bugfix release for 3.1.0, or new features release SOCI 4.0.0.\n\nAt the moment, SOCI development history is flat and there is no easy way to apply bug fixes to existing releases, thus no easy way to issue bug fix releases.\n\nThere are two popular Git workflows:\n- git-flow proposed as [A successful Git branching model](http://nvie.com/posts/a-successful-git-branching-model/).\n- [GitHub Flow](http://scottchacon.com/2011/08/31/github-flow.html) as answer to [What is a good Git workflow?](https://help.github.com/articles/what-is-a-good-git-workflow)\n\nIn GitHub Flow article, Scott Chacon says:\n\n> For teams that have to do formal releases on a longer term interval (a few weeks to a few\n> months between releases), and be able to do hot-fixes and maintenance branches and\n> other things that arise from shipping so infrequently, git-flow makes sense and I would \n> highly advocate it\u2019s use.\n> \n> For teams that have set up a culture of shipping, who push to production every day, who are constantly\n> testing and deploying, I would advocate picking something simpler like GitHub Flow.\n\nI think, git-flow is the right choice for SOCI. It is simple and based on use of two branches only: master and develop, where in fact, on daily basis, only develop branch is used.\n\n---\n\nWhat I look for is a dead simple, clear, safe,well structured Git workflow with the following features:\n1. Easy for continuous development and integration of features, patches, pull request\n2. Easy to mark every major release (tags)\n3. Easy to mark every bugfix release (tags)\n4. Easy to maintain what has been released (branches)\n   - apply bug fixes\n   - issue bugfix release\n5. mgay@example.org/SOCI/soci\n   - is the only upstream repository with SOCI source code\n   - is a complete history of SOCI  (commits, and all milestones and snapshots too)\n   - has clear structure of public only stuff, no private branches, no feature brunches\n   - must provide access to every release of SOCI, as there were no mgay@example.org\n\nI also requested for comments on soci-users in [Apply Git branching model](https://sourceforge.net/mailarchive/message.php?msg_id=30107525) thread.\n\nPlease, feel encouraged to post your comments on this topic.\n\n Comments: \n Comment 0: Conclusion post sent to soci-users under [RFC Apply Git branching model](https://sourceforge.net/mailarchive/message.php?msg_id=30107525) thread:\n\nOn 3 March 2013 01:40, Mateusz Loskot mgay@example.org wrote:\n\n> It's not a problem to rename the git-flow's branches\n> -'master' is the current development line, corresponds to git-flow's 'develop'\n> -'release' is the current stable (deployable, production-ready)\n>   branch, corresponds to git-flow's'master'\n\nAfter reading Pro Git book and Git manual, followed by kernel Git workflow\nI stand corrected about the principle behind the master branch:\nmaster tracks the commits that should go into the next release;\nIn most scenarios based on releases, it is production-read deployable state of work.\n\nThe actual development happens in topic branches.\nThe **develop** (or 'next') are integration branches.\n\nThings can potentially get broken in the integration branch, but mustn't in the **master** branch.\n\n**I aim to follow this well-known, well-tested and common approach: the [GitFlow](https://github.com/nvie/gitflow/)**\n\n> If we decide to rename the original git-flow branches, then it will\n> look this way:\n> - `master` - dark blue line, current development work\n> - `release` - light blue line, reserved for release tags only\n> - `release/v.X.Y.Z` - orange line, release integration branch\n\nThis naming is not possible as once we add'release' branch,\nGit won't allow to add the one with subtoken, `release/X.Y.Z`\n\n Comment 1: [Using GitFlow With GitHub](http://datasift.github.com/gitflow/GitFlowForGitHub.html) is a really good introduction to GitFlow for GitHub users with [The Poster](http://datasift.github.com/gitflow/GitFlowWorkflowNoFork.png) where all the basics are displayed.\n\nIf you use SourceTree, check [Smart branching with SourceTree and Git-flow](http://blog.sourcetreeapp.com/2012/08/01/smart-branching-with-sourcetree-and-git-flow/)\n\n Comment 2: I've just made first step and applied the GitFlow scheme to the repository:\n- **master** branch - represents the latest released codebase\n- created **develop** branch -  main development branch (i.e. branch from here if you want to work on SOCI 4.0.0 features)\n- published **release/3.2.0** - branched from `develop` for preparation for 3.2.0 release, once released will be merged back to both, `master` and `develop`.\n\nHere are the three basic rules:\n- If you want to work on new features or more elaborate issues that won't be included in SOCI 3.2.0, branch off of **develop** (if you will use GitFlow localy, new branch will happen in **features/new1**)\n- If you want to test the upcoming release and apply necessary fixes, work in **release/3.2.0**.\n- Do **not** branch off of **master** to start new work.\n\nIf you like it, use gitflow software as it really makes the process simple.\nIf you don't like it, you can still use plain git and expect no problems.\nJust remember: branch **develop** for new, keep **master** stable.\n\nThere is lots of good readings about GitFlow as it has become de facto a standard for software rolling cycles of traditional releases. However, I will wrap up basic info on the [Flow](https://github.com/SOCI/soci/wiki/Flow), so contributors will be displayed with name of GitFlow and at least know they should branch off from **develop**.\n\n Comment 3: I consider it's happened. Should any new issues be discussed, either reopen this or open new issue or post to the mailing lists.\n",
  "Issue title: File manager context menu -> compress does nothing\n Issue body: Clicking on a file and choosing \"Compress\" does nothing.\r\n\r\nUsing Arch Anywhere.\n Comments: \n Comment 0: Did you install file-roller? It is an opt-depend.\n Comment 1: Actually it's not optional if you want the compress function to work @felixonmars \n Comment 2: Had to install file roller myself but then it worked!\r\nMaybe should be taken as dependency when installing dde-desktop?\n Comment 3: @hualet It's an opt-depend of the whole package. Opt-depends do not exist for a specific function.\n Comment 4: I don't know the packaging rules of Arch, maybe you can make it recommended or similar role? since dde-file-manager hard coded fill-roller to do compress. @felixonmars \n Comment 5: There's no recommended or similar role, sadly. Usually we write these as optdepends and let the user to decide whether to install themselves. I can make it a hard dependency, though.\n Comment 6: You should leave out the menu entry then if it is not installed. That way it would not look buggy ;)\n Comment 7: Arch users are expected to read the optdepends notices during installation. But if upstream really want to see it as a hard dependency, we can do it of course...\n Comment 8: It's already a hard dependency now.\n Comment 9: Confirmed. Works now out-of-the-box",
  "Issue title: Support for protobuf binary format\n Issue body: **Is your feature request related to a problem? Please describe.**\r\nI would like ARC to support protobuf binary format. Basically, don't want to see binary data on screen but convert body to protobuf binary format body and do the same on response. \r\n\r\n**Describe the solution you'd like**\r\nUser will enter normal json data in request, ARC should convert json into protobuf format and send the request and vice-versa when request gets received.\r\n\r\n**Additional context**\r\nhttps://developers.google.com/protocol-buffers/docs/proto3\r\nhttps://developers.google.com/protocol-buffers/docs/encoding\r\n\n Comments: \n Comment 0: This issue has been automatically marked as stale because it has not had recent activity and is not currently prioritized. It will be closed in a week if no further activity occurs :)\n",
  "Issue title: Filter by text syntax\n Issue body: **Check for existing issue**\r\nAsked on discord\r\n\r\n**Describe the solution you'd like**\r\n\r\n- [ ] Using the search/filter bar with scripting like syntax with several shortcuts:\r\n   - [ ] `&&` operator that only matches if left and right are true\r\n   - [ ] `||` operator that matches if either left or right are true\r\n   - [ ] `()` to enclose multiple statements\r\n   - [ ] `!<statement>` to reverse output\r\n   - [ ] syntax for all possible filters (ex: `ReleaseYear:2019`, `tag:(VR || VR Support)`) or similar if you got a better way [maybe arrays? or just comma separated :thinking:]\r\n- [ ] Search history\r\n- [ ] Ability to save/favorite searches\r\n\n Comments: \n Comment 0: About the history/favorites; maybe just a combobox there?\r\n\r\n![image](https://user-images.githubusercontent.com/3318223/79836837-f79d8600-83b0-11ea-8f58-160107e9085e.png)\r\n",
  "Issue title: Article on Google Cloud End Points and HTML5\n Issue body: I guess it would be good to have a full article on the subject.\nSomething similar to my post: http://greenido.wordpress.com/2012/07/07/html5-modern-web-app-and-google-cloud-endpoints/\n\n Comments: \n Comment 0: Too specific :)\n",
  "Issue title: Fastly not working.\n Issue body: Hello all\r\n\r\nWe installed and configured the extention plus the fastly options. In stat page, on fastly website, no requests are shown, and when sometimes they are, they are all pass. \r\n\r\nNote that our server have also varnish, plus we use ssl. \r\n\r\nAny advice?\n Comments: \n Comment 0: Hi @ethelserth \r\n\r\nWe will need more details on what the issue is. Can you open up a ticket with our support with full details e.g. URLs affected, what version of Magento etc.\r\n",
  "Issue title: UI Enhancement Proposal: Make use of the windows accent color in UI\n Issue body: I have code staged in a branch ready to be pushed and a pull request made if you like the sound of the idea.\r\n\r\nHow about giving it a little life through using the user's accent color? Currently I'm only proposing the Windows Logo button, as I'm not sure how tastefully it could be implemented otherwise at the moment. It's really as simple as a few extra lines in TaskbarWindow.xaml (adding the name parameter to the glyph) and TaskbarWindow.xaml.cs (adding some lines to set the coloring and then detect the changes in coloring).\r\n\r\nI'm not entirely sure how to add a XAML animation similar to what Microsoft does with the hover animation on the start button so my current code simply colors the logo button at all times.\r\n\r\nAs stated, I have working code that can be merged in if you like the sound of the idea. As for adding the accent color to other elements, it's as simple as changing their fill property to equal `SystemParameters.WindowGlassBrush`.\n Comments: \n Comment 0: About the accent color and dark/light theme is planned (with acrylic, which is already implemented).\r\nThere will be a settings (it will be based on UWP) for MobileShell to handle/remember all of these.\r\n\r\nThese days I can't do much because of ongoing university exams, but ASAP I'll implement more.\n Comment 1: Was playing around with your Acrylic code, and it works great. I'm not finding a good way to implement the dark/light themes without implementing the color schemes from scratch and simply applying it/replacing it depending on the AppsUseLightTheme registry key, then again, this is honestly the most I've ever done with WPF, so I might just be missing something.\r\n\r\nI'd assume that once Microsoft/microsoft-ui-xaml reaches WinUI 3.0 with XAML Islands (and access to more of the UWP API space) this would become easier, but for now it looks like Light/Dark theme may need to be implemented and approximated from scratch.\r\n\r\nThat said, your acrylic code works fine with a transparent background for the Bar Window itself, and bottom layer grid object used for coloring and opacity.\n Comment 2: To illustrate the acrylics, I pushed the changes to my \"customized\" branch and wanted to share this screenshot. It does require some changes to the TaskbarWindow xaml and source to facilitate, and since we don't have access to the WinUI toolkit, it's more of a dirty hack to enable acrylics.\r\n\r\n![mobileshell-acrylic taskbar](https://user-images.githubusercontent.com/1423520/59175884-2d34da00-8b25-11e9-981d-4793d8c11749.png)\r\n\r\n\r\nI think I approximated the opacity needed for the taskbar quite well, I might be slightly off.\r\n\r\nThe changes are the following, for the function changes, you can see them in my 'customized' branch, it's mainly code to set up the acrylic coloring and an extra WM event to listen for DWM color changes:\r\n\r\n```\r\nTaskbarWindow.xaml Line 39:\r\n <Grid x:Name=\"gridAcrylicBackground\" Background=\"Black\" Opacity=\"1\" PreviewTouchDown=\"Grid_PreviewTouchDown\" />\r\n\r\nTaskbarWindow.xaml Function Window_Loaded\r\nTaskbarWindow.xaml Function WndProc (WM_DWMCOLORIZATIONCHANGED)\r\n```\r\n\r\nI had to create a new grid object behind the taskbar, made the taskbar itself transparent, and then use this new grid object to handle colorization events and the opacity changes needed to facilitate Acrylics.\r\n\r\nThis is a wonderful learning experience, I've never delved into the UWP side of Windows before this, but this is actually quite something!\r\n\r\nI can perform a pull request from that branch if you want. \ud83d\ude01\n Comment 3: Dark/Light theme implemented.\r\nNow looking further with Accents and Acrylic.\n Comment 4: I've been tweaking this for my SO's tablet (yup, I've still been quietly hacking on it), he wanted tablet mode to feel more like a tablet but still feel personalized. So I ended up figuring out how to re-add my previous changes, if you're looking into it, about 65-75% opacity on the surface hosting the acrylic surface seems to provide the best Acrylic transparency.\r\n\r\nOf course, as before, since WinUI 3.0 is still in preview and we don't yet have real XAML Island support for acrylics, it's a rather hacky implementation, but seemed to get the accent color quite nicely. I can check to see if that source is still here (I reset my machine since then), and if it is, push it to my repo so you can see what I changed!\n Comment 5: dear devs please update the app!! tired of waiting for thingmuch long\n Comment 6: Then fork it and continue it yourself. This is a project the developer does in his free time and does not get paid for this work. He's not our lackey.\n Comment 7: Once again, **NO ONE** is being paid for this project, nor does ANYONE have the obligation to continue it. This isn't a constructive comment, nor is it something that should be done to ANY developer of the FOSS community at all! ETAs and asking for updates, or even acting as though **you're entitled** to an update to a free and open source project done in a developer's hobby time is absurd and rude.\r\n\r\nAnd again, Either fork it and continue it yourself, or look for an alternative, or OR, sit back and wait for ADeltaX to have free time to work on it. Hobby devs aren't employees, and the dev may have a life, this work is done **IN THEIR FREE TIME**\n Comment 8: Is there any way to ban toxic people? Just wondering... \n Comment 9: I am sorry if i have offended anyone.. I wasn't being a jerk. I just wanted\nDEV to know that how much people are passionate about his work. I my self\nam not a dev so i cant continue this project. I Just wanted him to know\nthat people want this project to be updated... I used the windows store app\nothis project and was feeling so hopeful!\n\nAnyway :) goodluck\n\nOn Thu, Sep 12, 2019 at 11:42 PM ShadowEO <cmarks@example.com> wrote:\n\n> @SuperJMN <https://github.com/SuperJMN> Not that I'm aware of, then\n> again, none of my own projects are big enough to warrant the type of ETA\n> questions that this one is likely to get. Sadly it's the problem that comes\n> with gaining project notoriety, Android ROM devs and Game Console\n> Homebrewers deal with it everyday though I can't imagine how.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/ADeltaX/MobileShell/issues/6?email_source=notifications&email_token=AIRXJSADRMLWQ24XCYBVOSLQJKEQPA5CNFSM4HP6UDG2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD6S3POQ#issuecomment-530954170>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AIRXJSAFSO4FAQUBPD7QFJTQJKEQPANCNFSM4HP6UDGQ>\n>.\n>\n",
  "Issue title: 07e96-Kaisho.svg has strokes 4 and 5 swapped\n Issue body:![07e96-Kaisho](https://user-images.githubusercontent.com/102005/163094397-e06818ce-76d3-4179-b9cb-32277d83bd31.png)\r\n\r\nAlso the type on stroke 12 is \u31d2 which is inconsistent with all the other \u97ed elements, which use a vertical for this, and the final stroke has no number.\r\n\n Comments: \n Comment 0: [This website](https://kakijun.jp/page/sen23200.html) gives the order of the bottom strokes from left to right.\n Comment 1: Here's a visual for a quick check:\r\n\r\n![7e96-after](https://user-images.githubusercontent.com/102005/163281526-60ca8fe0-bd78-44cb-b0f3-7df1a94de916.png)\r\n",
  "Issue title: no option for background in osx\n Issue body: hello,\nI have telegram dekstop from the mac app store.\nI wanted to add a picture for the background in the chats like on mobile, but I see that I can't do that on telegram desktop.\nIs it normal? Or maybe it's a feature that is not live yet?\n\n Comments: \n Comment 0: It's possible in the settings\n\n Comment 1: @auchri could you send me a screenshot please?\r\nI looked again but I don't see anything... :(\n Comment 2:![image](https://cloud.githubusercontent.com/assets/5092164/9138952/4de06dfa-3d27-11e5-9c39-3bb3380f4c02.png)\n\n Comment 3: I can't find it in the settings... which version was it added or which submenu is it in?\n Comment 4: @NicoKnoll just open settings and scroll down\n Comment 5: I think there is a misunderstanding here. Is it possible that @ploctaux has Telegram for MacOS and @nicoknoll has Telegram Desktop for MacOS? The two clients are confusing. One is only for OS X and is also available over the Mac App Store, the other one is the all-platform client, only available over the website.\r\n\r\n- Telegram for MacOS (available on the web site and Mac App store, an app optimized for Mac OS) does not have a setting for the background, which is very annoying as it is bright white. This is what I guess is meant in this issue.\r\n- Telegram Desktop (available on the web site for all Operating Systems) is greyish in color and has an option to change the background to something easier for my eyes, is not meant with this issue.\r\n\r\nAm I correct?\n Comment 6: @jbfriedrich Telegram Desktop is available on the MacAppStore as well. This issue tracker is only about Telegram Desktop and it does have the background option.\n Comment 7: Oh I did not know that Telegram Desktop was also available in the Mac App Store. But otherwise exactly the point I meant. Issue in the wrong project \ud83d\ude03. Do you know why there is an additional client for MacOS? Two clients is a bit confusing.\n Comment 8: Why has it to be on both platforms web download and the Mac app store? And why have it show backgrounds on mobile (iOS) and not on Mac?\n Comment 9: for use background on Mac, you should:\r\n\r\n- open settings\r\n- go to appearence\r\n- change \"chat view\" from \"Minimalist\" to \"Bubbles\", this will make appears bellow \"chat preview\" on this page the option \"Chat Background\"\r\n\r\nchoose yours.... enjoy!\r\n\r\n![image](https://user-images.githubusercontent.com/38701792/39205813-24717c76-47d2-11e8-9871-fb61dd7cd540.png)\r\n\n Comment 10: I also don't find the option in the `4.5.1` version\r\n\r\n<img width=\"1057\" alt=\"not option\" src=\"https://user-images.githubusercontent.com/770971/48160359-674fac00-e2b6-11e8-86d9-d152db5b9870.png\">\r\n\n Comment 11: @margge set chat mode to bubbles\n Comment 12: This issue has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.",
  "Issue title: Error on /premium and /cracked\n Issue body: `[21:55:26] [Server thread/ERROR]: null\r\norg.bukkit.command.CommandException: Unhandled exception executing command 'cracked' in plugin FastLogin v1.9\r\n\tat org.bukkit.command.PluginCommand.execute(PluginCommand.java:46) ~[spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat org.bukkit.command.SimpleCommandMap.dispatch(SimpleCommandMap.java:141) ~[spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat org.bukkit.craftbukkit.v1_11_R1.CraftServer.dispatchCommand(CraftServer.java:650) ~[spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat net.minecraft.server.v1_11_R1.PlayerConnection.handleCommand(PlayerConnection.java:1353) [spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat net.minecraft.server.v1_11_R1.PlayerConnection.a(PlayerConnection.java:1188) [spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat net.minecraft.server.v1_11_R1.PacketPlayInChat.a(PacketPlayInChat.java:45) [spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat net.minecraft.server.v1_11_R1.PacketPlayInChat.a(PacketPlayInChat.java:1) [spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat net.minecraft.server.v1_11_R1.PlayerConnectionUtils$1.run(SourceFile:13) [spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:1.8.0_91]\r\n\tat java.util.concurrent.FutureTask.run(Unknown Source) [?:1.8.0_91]\r\n\tat net.minecraft.server.v1_11_R1.SystemUtils.a(SourceFile:46) [spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat net.minecraft.server.v1_11_R1.MinecraftServer.D(MinecraftServer.java:747) [spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat net.minecraft.server.v1_11_R1.DedicatedServer.D(DedicatedServer.java:399) [spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat net.minecraft.server.v1_11_R1.MinecraftServer.C(MinecraftServer.java:678) [spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat net.minecraft.server.v1_11_R1.MinecraftServer.run(MinecraftServer.java:576) [spigot.jar:git-Spigot-d276ab1-d219213]\r\n\tat java.lang.Thread.run(Unknown Source) [?:1.8.0_91]\r\nCaused by: java.lang.NullPointerException\r\n\tat com.github.games647.fastlogin.bukkit.commands.CrackedCommand.onCommand(CrackedCommand.java:38) ~[?:?]\r\n\tat org.bukkit.command.PluginCommand.execute(PluginCommand.java:44) ~[spigot.jar:git-Spigot-d276ab1-d219213]\r\n\t... 15 more`\r\n\r\n\n Comments: \n Comment 0: Duplicate #141",
  "Issue title: [EH] Getting unknown parameter value from data\n Issue body: Hi, here: https://github.com/symplify/easy-hydrator/blob/master/src/ClassConstructorValuesResolver.php#L50 is getting parameter from data.\r\n\r\nFor our needs, we want to change this behavior to cover these cases:\r\n- If parameter has default value on object and is not present in data, use default value\r\n- If parameter has NO default value and is missing in data, either pass NULL or throw exception bcoz passing null to not nullable will end up with type error anyways\r\n\r\nI can see some problems with current implementation:\r\n- If property is not string, and empty string is provided, it can end up with type error for non-string parameters (this could be maybe covered in specific type caster)\r\n- It overwrites default value form object if nothing is provided\r\n- It is not extendable/overwritable for users\r\n\r\nMy proposal is to decouple method `getParameterValue()` into `ParameterValueGetter` class (and creating interface for it), which would be public in DI container, allowing easy extending for 3rd party users.\r\n\r\nThis way, i wanted to open some discussion, as i believe we are not the only users of easy hydrator, but i have no idea how others uses it and for what purposes.\n Comments: \n Comment 0: Hi,\r\n\r\nthis is hard for me undestands. Maybe some simple PHP code to show the problem?\n Comment 1: I believe https://github.com/symplify/symplify/pull/2416/files#diff-ca431e0a608da3d93f168dfbc683ef800a3fc8aae44eb2cb85d83bc0fe5f8ce6R26 is great example:\r\n```php\r\n$data = [\r\n     'bar' => 'bar',\r\n];\r\n\r\n   public function __construct(\r\n        ?string $foo = null,\r\n         string $bar = 'bar',\r\n        ?Person $person = null\r\n     ) {\r\n         $this->foo = $foo;\r\n         $this->bar = $bar;\r\n         $this->person = $person;\r\n     }\r\n```\r\n\r\nWe are using easy hydrator as in rest api to translate json -> request body objects and it is somehow often that some parameters are optionable with default value.\n Comment 2: I see :+1: ",
  "Issue title: Unable to login using Android client and CAS plugin\n Issue body: Your Rocket.Chat version: 0.29\r\nWhen trying to login via CAS using the Android app, the login page is correctly shown but after providing username and password a blank page is shown (see attached screenshot).\r\n\r\nEverything works correctly when using a browser.\r\n![cas_login_attempt](https://cloud.githubusercontent.com/assets/1647955/15181259/8485a598-1786-11e6-97eb-1b324f50ea45.png)\r\n\n Comments: \n Comment 0: Does this only effect the mobile application or does this happen when doing mobile web also?\n Comment 1: The issue affects the mobile application only. No issues while using Chrome or Firefox for Android.\n Comment 2: Can confirm. I have the same issue.\n Comment 3: Pull request created. Anyone that can test, please do so!\n Comment 4: Updated to 0.33.0 and the CAS login works again, thank you!",
  "Issue title: Fix drawing of plots in statistics box.\n Issue body: The plot in the statistics box has some glithces to be worked out.\n\n Comments: \n Comment 0: http://www.youtube.com/watch?v=99a0cdZOj38&feature=youtu.be\n\n Comment 1: very good, i have hope that you make new windows build, today\n",
  "Issue title: Auto-clean history of favourites/hidden threads\n Issue body: From #657\nAn option to exclude from the history of dollchan, the favourited/created thread/hidden thread would do good for security of the user and good for management issues. Periods of 1 day, 5 days 15 days etc. to autoclean all the history of saved threads could be a good improvement.\n\nThanks.\n\ncc: @personalpersonal\n\n Comments: \n Comment 0: \u041d\u0438\u0444\u0438\u0433\u0430 \u043d\u0435 \u043f\u043e\u043d\u044f\u043b. \u0427\u0442\u043e \u044d\u0442\u043e \u0431\u044b\u043b \u0437\u0430 \u0441\u0442\u0440\u0430\u043d\u043d\u044b\u0439 \u043f\u0443\u043b\u043b-\u0440\u0435\u043a\u0432\u0435\u0441\u0442? \u0413\u0434\u0435 \u043a\u043e\u043c\u043c\u0438\u0442\u044b? Wtf \u0432\u043e\u043e\u0431\u0449\u0435 \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442?\n\n Comment 1: \u0418\u0437 \u0432\u0435\u0442\u043a\u0438 `master` \u0432 \u0432\u0435\u0442\u043a\u0443 `stable`. \u042f \u0443\u0434\u0430\u043b\u0438\u043b \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u044e\u044e, \u0438\u0431\u043e \u043d\u0438\u043d\u0443\u0436\u043d\u0430.\n\n Comment 2: \u0410 \u0433\u0434\u0435 \u0441\u043e\u0431\u0441\u043d\u043e \u0435\u0433\u043e \u043a\u043e\u043c\u043c\u0438\u0442? \u0418\u043b\u0438 \u044d\u0442\u043e \u0431\u044b\u043b \u0442\u0430\u043a\u043e\u0439 \u0445\u0438\u0442\u0440\u044b\u0439 issue, \u043e\u0444\u043e\u0440\u043c\u043b\u0435\u043d\u043d\u044b\u0439 \u043a\u0430\u043a \u043f\u0443\u043b\u043b-\u0440\u0435\u043a\u0432\u0435\u0441\u0442?\n\n Comment 3: > \u0442\u0430\u043a\u043e\u0439 \u0445\u0438\u0442\u0440\u044b\u0439 issue, \u043e\u0444\u043e\u0440\u043c\u043b\u0435\u043d\u043d\u044b\u0439 \u043a\u0430\u043a \u043f\u0443\u043b\u043b-\u0440\u0435\u043a\u0432\u0435\u0441\u0442\n\n\u042d\u0442\u043e.\n\n Comment 4: \u041a\u0430\u0441\u0430\u0435\u043c\u043e \u0432\u043e\u043f\u0440\u043e\u0441\u0430 - \u043e \u0447\u0435\u043c \u043e\u043d \u0432\u043e\u043e\u0431\u0449\u0435?\n\u042f \u0442\u0430\u043a \u043f\u043e\u043d\u044f\u043b \u043f\u0440\u043e `\u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 -> \u041e\u0431\u0449\u0435\u0435`?\n\n```\n\u0422\u0440\u0435\u0434\u043e\u0432 \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u0435\u043d\u043e:\n\u0422\u0440\u0435\u0434\u043e\u0432 \u0441\u043e\u0437\u0434\u0430\u043d\u043e:\n\u0422\u0440\u0435\u0434\u043e\u0432 \u0441\u043a\u0440\u044b\u0442\u043e:\n```\n\n Comment 5: \u0418\u043b\u0438 \u043f\u0440\u043e \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0443\u044e \u043e\u0447\u0438\u0441\u0442\u043a\u0443 \u0438\u0437\u0431\u0440\u0430\u043d\u043d\u043e\u0433\u043e?\n\n Comment 6: \u041e\u0447\u0438\u0449\u0430\u0442\u044c \u0441\u043a\u0440\u044b\u0442\u043e\u0435/\u0438\u0437\u0431\u0440\u0430\u043d\u043d\u043e\u0435 \u0447\u0435\u0440\u0435\u0437 x \u0434\u043d\u0435\u0439 \u043f\u043e\u0441\u043b\u0435 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u044f/\u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u0430.\n\n Comment 7: \u0422\u043e \u0435\u0441\u0442\u044c, \u043f\u0440\u0438\u0434\u0435\u0442\u0441\u044f \u0445\u0440\u0430\u043d\u0438\u0442\u044c \u0430\u0449\u0435 \u0438 \u0434\u0430\u0442\u0443 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u0442\u0440\u0435\u0434\u043e\u0432...\n\n Comment 8: \u041a\u0430\u043a \u0441 \u0441\u043a\u0440\u044b\u0442\u044b\u043c\u0438 \u044e\u0437\u0435\u0440\u043e\u043c \u043f\u043e\u0441\u0442\u0430\u043c\u0438, \u0442\u043e\u043b\u044c\u043a\u043e \u0442\u0430\u043c 5 \u0434\u043d\u0435\u0439: https://github.com/SthephanShinkufag/Dollchan-Extension-Tools/blob/eb270bff53d8b7de945a54e8224f176e3a4f2030/Dollchan_Extension_Tools.user.js#L1115\n",
  "Issue title: links where the event target is a child of the <a> tag causes full page reload\n Issue body: If you have children inside an anchor, then they get taken as the event.target and therefor the link hijacking this library does fails.\r\n\r\ne.g.\r\n\r\n```svelte\r\n<a href=\"/my/route\">\r\n  <p>Some Text</p>\r\n  <p>Some more text</p>\r\n</a>\r\n```\r\n\r\nThe event.target use in the click handler code in this example will often be the p tags\r\nhttps://github.com/jorgegorka/svelte-router/blob/0f72f85d5601e06cd13c87406aca2cbcc122644e/src/spa_router.js#L113\r\n\r\n\r\nI wonder if its worth 'borrowing' the code from either sapper\r\nhttps://github.com/sveltejs/sapper/blob/5757a85d195f9ceb2e329caa5e3e38abd5a1123d/runtime/src/app/router/index.ts#L126-L168\r\n\r\nor page.js\r\nhttps://github.com/visionmedia/page.js/blob/4f9991658f9b9e3de9b6059bade93693af24d6bd/page.js#L745-L826\r\n\r\nas I assume they will have come across most weird issues like this (certainly page.js)\r\n\r\nEither way they both have code along the lines of\r\n```js\r\n    // el.nodeName for svg links are 'a' instead of 'A'\r\n    while (el && 'A'!== el.nodeName.toUpperCase()) el = el.parentNode;\r\n```\n Comments: \n Comment 0: I have exactly the same problem... ;(\n Comment 1: yep. any link without plain text inside will do this... I found out with an `<img>`. \r\n\r\nUsing the `<Navigate></Navigate>` element doesn't seem to do this, but it doesn't update the \"active\" state either. \r\n\r\nI have worked around this for my use case by setting `class:active={currentRoute?.name === '/my-page'}` on the child element as indicated in https://github.com/jorgegorka/svelte-router/issues/113#issuecomment-908839891\r\n\r\n`<Navigate to=\"/my-page\" styles=\"ml-24\"><img src=\"/icon.png\" class=\"inline-block\" class:active={currentRoute?.name === '/my-page'}></Navigate>`\r\n\r\n\n Comment 2: I cannot believe this is still a problem.\r\n\r\nIn theory, this is my favorite router for svelte. But actually using it has been quite the disappointment when the most simplest things are failing. Regular `a` tags do not work if they include anything but plaintext, and the `Navigate` component fails to update the active class unless you have a full page refresh (https://github.com/jorgegorka/svelte-router/issues/113). So literally none of those implementations work for me. The solution above should not have to be used in order to get this to work, and also messes with existing styling of nav bars (especially if styles were meant for a tags).\r\n\r\nCome on, let's get this fixed already! You have a fantastic router here, please don't abandon it!",
  "Issue title: Dependency check fails if build WAR/JAR is failed\n Issue body: Hi Jeremy,\r\nWe've noticed if the maven build for building war/jar is failed and not success, we can manage to run dependency check after that but it gives an empty report with 0 components/vulnerabilities, it is dependent on the success of build to display accurate report. \r\n\r\nIs there a way we can test so we don\u2019t publish data in failure scenarios?\r\nIf that were so, we could always try and run the dependency check rather than just in success cases.\r\n\r\nRegards,\r\nAejaz\n Comments: \n Comment 0: yes, but please show your configuration, pom and commands used so we can help\n Comment 1: If the build fails as you have pointed out dependency-check runs successfully and reports zero findings. Works as expected. This is not an ODC issue rather an issue with calling ODC after you already know the build failed.",
  "Issue title: [feature request]: allow disabling screenshot sound\n Issue body: Example commits from spark os:\r\nhttps://github.com/Spark-Rom/frameworks_base/commit/b12faaab3f0057b152d15e659ace5d1d0839ba7b\r\nhttps://github.com/Spark-Rom/packages_apps_Settings/commit/77a143ecf1693aef4a9c3aa64b613fbdfc8a8fef\r\n\n Comments: \n Comment 0: WIP in https://github.com/crdroidandroid/android_frameworks_base/pull/868",
  "Issue title: Install IIS service on Visual Studio 2019 image\n Issue body: Original issue: https://help.appveyor.com/discussions/problems/24344-vs-2019-build-cant-find-iis-service\n Comments: \n Comment 0: Cheers for raising and for the workaround. Any rough ideas when this'll reach prod?\n Comment 1: @wozzo 1-2 weeks, but cannot give a specific promises\n Comment 2: Any movement on this?\n Comment 3: @FeodorFitsner @IlyaFinkelshteyn is this any closer to being done?\n Comment 4: We plan to update `Visual Studio 2019`  image this week.\n Comment 5: @IlyaFinkelshteyn I saw the milestone was dated yesterday, has this gone out yet?\n Comment 6: We will switch image today tonight, sorry for those delays.\n Comment 7: Thanks.",
  "Issue title: tomcat\u4e0a\u90e8\u7f72dubbox\u6d88\u8d39\u8005jar\u5305\u51b2\u7a81\u95ee\u9898\n Issue body: dubbox 2.8.4 \u4f9d\u8d56 spring-web\uff08\u7248\u672c \uff1a3.2.9.RELEASE\uff09 \u4f1a\u548ctomcat\u4e2d\u7684jar\u5305\u51b2\u7a81\u3002\r\n\u5bfc\u81f4\u6d88\u8d39\u8005\u65e0\u6cd5\u8dd1\u5728tomcat\u4e0a\uff0c\u5927\u5bb6\u662f\u5982\u4f55\u89e3\u51b3\u7684\r\n\r\n\u9519\u8bef\u5185\u5bb9\uff1a\r\nCannot cast org.springframework.web.SpringServletContainerInitializer to javax.servlet.ServletContainerInitializer\r\n\r\n\u8be6\u7ec6\u5185\u5bb9\r\n\u4e25\u91cd: Failed to detect ServletContainerInitializers for context with name []\r\njava.io.IOException: java.lang.ClassCastException: Cannot cast org.springframework.web.SpringServletContainerInitializer to javax.servlet.ServletContainerInitializer\r\n\tat org.apache.catalina.startup.WebappServiceLoader.loadServices(WebappServiceLoader.java:205)\r\n\tat org.apache.catalina.startup.WebappServiceLoader.load(WebappServiceLoader.java:157)\r\n\tat org.apache.catalina.startup.ContextConfig.processServletContainerInitializers(ContextConfig.java:1575)\r\n\tat org.apache.catalina.startup.ContextConfig.webConfig(ContextConfig.java:1281)\r\n\tat org.apache.catalina.startup.ContextConfig.configureStart(ContextConfig.java:889)\r\n\tat org.apache.catalina.startup.ContextConfig.lifecycleEvent(ContextConfig.java:386)\r\n\tat org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:117)\r\n\tat org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:90)\r\n\tat org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5479)\r\n\tat org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)\r\n\tat org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1574)\r\n\tat org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1564)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.lang.ClassCastException: Cannot cast org.springframework.web.SpringServletContainerInitializer to javax.servlet.ServletContainerInitializer\r\n\tat java.lang.Class.cast(Class.java:3176)\r\n\tat org.apache.catalina.startup.WebappServiceLoader.loadServices(WebappServiceLoader.java:197)\r\n\t... 15 more\r\n\n Comments: \n Comment 0: pom\u6587\u4ef6\u4f9d\u8d56\u5217\u8868\r\n  <dependencies>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.pursuit</groupId>\r\n\t\t\t<artifactId>auth-rbac-common</artifactId>\r\n\t\t\t<version>0.0.1-SNAPSHOT</version>\r\n\t\t</dependency>\r\n\t\t \r\n\t\t<!-- Spring \u8865\u5145-->\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.springframework</groupId>\r\n\t\t\t<artifactId>spring-webmvc</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.springframework</groupId>\r\n\t\t\t<artifactId>spring-beans</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.springframework</groupId>\r\n\t\t\t<artifactId>spring-context</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.springframework</groupId>\r\n\t\t\t<artifactId>spring-context-support</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.springframework</groupId>\r\n\t\t\t<artifactId>spring-aspects</artifactId>\r\n\t\t</dependency>\r\n\t\t<!-- \u6587\u4ef6\u4e0a\u4f20\u7ec4\u4ef6 -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>commons-fileupload</groupId>\r\n\t\t\t<artifactId>commons-fileupload</artifactId>\r\n\t\t</dependency>\r\n\t\t<!-- Apache\u5de5\u5177\u7ec4\u4ef6 -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.apache.commons</groupId>\r\n\t\t\t<artifactId>commons-lang3</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.apache.commons</groupId>\r\n\t\t\t<artifactId>commons-io</artifactId>\r\n\t\t</dependency>\r\n\t\t<!-- \u5355\u5143\u6d4b\u8bd5 -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>junit</groupId>\r\n\t\t\t<artifactId>junit</artifactId>\r\n\t\t</dependency>\r\n\t\t<!-- JSP\u76f8\u5173 -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>jstl</groupId>\r\n\t\t\t<artifactId>jstl</artifactId>\r\n\t\t\t<scope>provided</scope>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>javax.servlet</groupId>\r\n\t\t\t<artifactId>servlet-api</artifactId>\r\n\t\t\t<scope>provided</scope>\r\n\t\t</dependency>\r\n\t\t<!-- \u65e5\u5fd7\u5904\u7406 -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.slf4j</groupId>\r\n\t\t\t<artifactId>slf4j-log4j12</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t    <groupId>com.alibaba</groupId>\r\n\t\t    <artifactId>fastjson</artifactId>\r\n\t\t    <version>1.2.4</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.apache.zookeeper</groupId>\r\n\t\t\t<artifactId>zookeeper</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t    <groupId>com.101tec</groupId>\r\n\t\t    <artifactId>zkclient</artifactId>\r\n\t\t</dependency>\r\n\t\t<!-- dubbo -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.alibaba</groupId>\r\n\t\t\t<artifactId>dubbo</artifactId>\r\n\t\t</dependency>\r\n\t</dependencies>\n Comment 1: \u7531\u4e8e dubbox 2.8.4 \u4f9d\u8d56 javax.servlet-api \u4e0etomcat \u51b2\u7a81\r\n\u53d8\u66f4  javax.servlet-api \u4f5c\u7528\u57df  <scope>provided</scope>\r\n\t\t<dependency>\r\n\t\t    <groupId>javax.servlet</groupId>\r\n\t\t    <artifactId>javax.servlet-api</artifactId>\r\n\t\t    <version>3.1.0</version>\r\n\t\t    <scope>provided</scope>\r\n\t\t</dependency>\r\n\r\n\u6ce8\u610f\uff1a\u4e4b\u524d\u9519\u8bef\u627e\u4e0d\u5230\u539f\u56e0\uff0c\u4e3b\u8981\u662f\u56e0\u4e3adubbo\u4f9d\u8d56\u7684\u662f javax.servlet-api  \u800c\u4e0d\u662f servlet-api\r\n\t\t<dependency>\r\n\t\t\t<groupId>javax.servlet</groupId>\r\n\t\t\t<artifactId>servlet-api</artifactId>\r\n\t\t\t<scope>provided</scope>\r\n\t\t</dependency>\r\n",
  "Issue title: Storybook on @nrwl/next:app\n Issue body: ## Description\r\nAs far as i know, if we try to add storybook configuration, via @nrwl/react, to @nrwl/next:app in Nx 13.1.4, we receive an error at build time on storybook target because it seems that Storybook needs babel config like @nrwl/react:lib to build successfully but @nrwl/react:lib babel config is incompatible with @nrwl/next:app babel config.\r\n\r\n## Motivation\r\nIntegration of Storybook workflow on @nrwl/next:app, for example, to run isolated pages.\r\n\r\n## Suggested Implementation\r\nSame process that runs @nrwl/react:storybook-configuration in @nrwl/next.\r\n\n Comments: \n Comment 0: I'm trying to integrate `@nrwl/next` and Storybook too. Here is a repo.\r\nhttps://github.com/puku0x/nx-nextjs-storybook-sample\r\n\r\nIt seems it works for me but the best solution is to make `@nrwl/next` support Storybook, indeed. \n Comment 1: This issue has been automatically marked as stale because it hasn't had any recent activity. It will be closed in 14 days if no further activity occurs.\nIf we missed this issue please reply to keep it active.\nThanks for being a part of the Nx community! \ud83d\ude4f",
  "Issue title: Site accesses every profile picture on startup\n Issue body: Windows 7, Chrome and Firefox.\n\nI see a plethora of warnings like these in the JavaScript console whenever I log in:\n\n![screenclip](https://f.cloud.github.com/assets/4501321/905907/3f28c66c-fc5c-11e2-88c0-676228cf3a66.png)\n\nThis seems unnecessary/a bad idea...\n- It slows down loading of the site.\n- It could provide a route in for a DOS or malware attack.\n- The likelihood of the user actually needing to view most of these images is very low.\n\nSuggestion: Don't try to fetch these images until needed, i.e., when you actually pull up somebody's profile to piercesara@example.com.\n\n Comments: \n Comment 0: Thanks for pointing this out! This a known issue, and is part of the reason Habit takes so long to load before you can click anything meaningful (see https://github.com/lefnire/habitrpg/issues/840#issuecomment-20908741). Realistically, this will be a part of the angular rewrite to be released soon, or fixed shortly thereafter.\n\n Comment 1: Hi! The site has been totally rewritten from the ground up, I'm closing the issue since it's probably fixed. Check if it's still happening and in case reopen the bug, thanks!\n",
  "Issue title: Selective checkout of a file from a commit\n Issue body: **Topic**\r\nRestoring a chunk of code from a file in a past commit\r\n\r\n**Your thoughts**\r\nSay I have a _piece of code_ in `a.py` I want to restore from a past commit (let's call it `commit_X`). Also, `a.py` was not changed in `commit_X`, so it doesn't appear in the commit file window. Is there a way to see all files in that commit (not just changed ones), and select a piece of code from one of them and restore it?\r\n\r\nThanks a lot for this awesome project! I feel sorry that it took me so long to find it :)\n Comments: \n Comment 0: @felixkreuk this sounds like a good feature. I'm currently working on a way to render a tree of files (compared to the flat file structure you see currently) so this feature would be blocked until that work is done. But once that work is done I think this feature should be fairly straightforward to implement\n Comment 1: Awesome, thanks!",
  "Issue title: Set-AzureRmDiagnosticSetting failing for data factory in West Europe\n Issue body: ### Cmdlet(s)\r\nSet-AzureRmDiagnosticSetting\r\n\r\n### PowerShell Version\r\n5.1.16299.19\r\n\r\n### Module Version\r\n4.0.0\r\n\r\n### OS Version\r\n10.0.16299.19\r\n\r\n### Description\r\nWhen I try to set the diagnostics for a data factory in West Europe with a corresponding storage account in West Europe, I keep getting an error saying \"Set-AzureRmDiagnosticSetting : Exception type: CloudException, Message: Null/Empty, Code: InternalServerError, Status code:InternalServerError, Reason \r\nphrase: Internal Server Error\". But, when I try to execute the same command for a data factory in East US, it works fine.\r\n\r\n### Debug Output\r\nSet-AzureRmDiagnosticSetting -ResourceId \"/subscriptions/8d6baaa6-0ec4-49fd-acfa-55c3194e32dd/resourceGroups/datafactory/providers/Microsoft.DataFactory/factories/datfac\" -Enabled $true -Timegrains \"PT1M\" -StorageAccountId \"/subscriptions/8d6baaa6-0ec4-49fd-acfa-55c3194e32dd/resourceGroups/datafactory/providers/Microsoft.Storage/storageAccounts/datfac\" -Categories \"ActivityRuns\" -Debug\r\nDEBUG: 2:25:46 PM - SetAzureRmDiagnosticSettingCommand begin processing with ParameterSet '__AllParameterSets'.\r\nDEBUG: 2:25:48 PM - using account id 'riverastephanie@example.org'...\r\nDEBUG: [Common.Authentication]: Authenticating using Account: 'riverastephanie@example.org', environment: 'AzureCloud', tenant: '5ed1d584-3cdd-4f8b-87b5-515a23\r\ne7e65e'\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Information: 2 : \r\nDEBUG: 11/15/2017 08:55:48: 0a8355f1-a764-4503-aeb9-78eae881cd04 - AcquireTokenHandlerBase: === Token Acquisition started:\r\n\tAuthority: https://login.microsoftonline.com/5ed1d584-3cdd-4f8b-87b5-515a23e7e65e/\r\n\tResource: https://management.core.windows.net/\r\n\tClientId: 1950a258-227b-4e31-a9cf-717495945fc2\r\n\tCacheType: Microsoft.Azure.Commands.Common.Authentication.AuthenticationStoreTokenCache (6 items)\r\n\tAuthentication Target: User\r\n\t\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Verbose: 1 : \r\nDEBUG: 11/15/2017 08:55:48: 0a8355f1-a764-4503-aeb9-78eae881cd04 - TokenCache: Looking up cache for a token...\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Information: 2 : \r\nDEBUG: 11/15/2017 08:55:48: 0a8355f1-a764-4503-aeb9-78eae881cd04 - TokenCache: An item matching the requested resource was found in the cache\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Verbose: 1 : \r\nDEBUG: 11/15/2017 08:55:48: 0a8355f1-a764-4503-aeb9-78eae881cd04 - TokenCache: 57.21151438 minutes left until token in cache expires\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Information: 2 : \r\nDEBUG: 11/15/2017 08:55:48: 0a8355f1-a764-4503-aeb9-78eae881cd04 - TokenCache: A matching item (access token or refresh token or both) was found in the c\r\nache\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Information: 2 : \r\nDEBUG: 11/15/2017 08:55:48: 0a8355f1-a764-4503-aeb9-78eae881cd04 - AcquireTokenHandlerBase: === Token Acquisition finished successfully. An access token \r\nwas retuned:\r\n\tAccess Token Hash: rocPxtPtwxzDjF9V5v7BwnZV2jg6kbjjwH6aQu4sc+o=\r\n\tRefresh Token Hash: Ppl19v4Mb0NMlf1brAYCDyozle9nEXtS4QJ9uPH5Mfw=\r\n\tExpiration Time: 11/15/2017 09:53:01 +00:00\r\n\tUser Hash: 4uMjdux6PlbHohqQSPfTCHKRPTSuusBeoflGpyYQ1ps=\r\n\t\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Information: 2 : \r\nDEBUG: 11/15/2017 08:55:48:  - TokenCache: Serializing token cache with 6 items.\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Information: 2 : \r\nDEBUG: 11/15/2017 08:55:48: 32b37e12-ee8c-4e1b-86c6-dafc266930c9 - AcquireTokenHandlerBase: === Token Acquisition started:\r\n\tAuthority: https://login.microsoftonline.com/5ed1d584-3cdd-4f8b-87b5-515a23e7e65e/\r\n\tResource: https://management.core.windows.net/\r\n\tClientId: 1950a258-227b-4e31-a9cf-717495945fc2\r\n\tCacheType: Microsoft.Azure.Commands.Common.Authentication.AuthenticationStoreTokenCache (6 items)\r\n\tAuthentication Target: User\r\n\t\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Verbose: 1 : \r\nDEBUG: 11/15/2017 08:55:48: 32b37e12-ee8c-4e1b-86c6-dafc266930c9 - TokenCache: Looking up cache for a token...\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Information: 2 : \r\nDEBUG: 11/15/2017 08:55:48: 32b37e12-ee8c-4e1b-86c6-dafc266930c9 - TokenCache: An item matching the requested resource was found in the cache\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Verbose: 1 : \r\nDEBUG: 11/15/2017 08:55:48: 32b37e12-ee8c-4e1b-86c6-dafc266930c9 - TokenCache: 57.2112224033333 minutes left until token in cache expires\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Information: 2 : \r\nDEBUG: 11/15/2017 08:55:48: 32b37e12-ee8c-4e1b-86c6-dafc266930c9 - TokenCache: A matching item (access token or refresh token or both) was found in the c\r\nache\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Information: 2 : \r\nDEBUG: 11/15/2017 08:55:48: 32b37e12-ee8c-4e1b-86c6-dafc266930c9 - AcquireTokenHandlerBase: === Token Acquisition finished successfully. An access token \r\nwas retuned:\r\n\tAccess Token Hash: rocPxtPtwxzDjF9V5v7BwnZV2jg6kbjjwH6aQu4sc+o=\r\n\tRefresh Token Hash: Ppl19v4Mb0NMlf1brAYCDyozle9nEXtS4QJ9uPH5Mfw=\r\n\tExpiration Time: 11/15/2017 09:53:01 +00:00\r\n\tUser Hash: 4uMjdux6PlbHohqQSPfTCHKRPTSuusBeoflGpyYQ1ps=\r\n\t\r\n\r\nDEBUG: Microsoft.IdentityModel.Clients.ActiveDirectory Information: 2 : \r\nDEBUG: 11/15/2017 08:55:48:  - TokenCache: Serializing token cache with 6 items.\r\n\r\nDEBUG: ============================ HTTP REQUEST ============================\r\n\r\nHTTP Method:\r\nGET\r\n\r\nAbsolute Uri:\r\nhttps://management.azure.com/%2Fsubscriptions%2F8d6baaa6-0ec4-49fd-acfa-55c3194e32dd%2FresourceGroups%2Fdatafactory%2Fproviders%2FMicrosoft.DataFactory%2\r\nFfactories%2Fdatfac/providers/",
  "Issue title: How to hide New button in grid based on value of grid\n Issue body: Hi;\r\n\r\nI need your help in how to conditionally check if a grid column has a specific value and if so then hide the New button in the grid.\r\n![image](https://user-images.githubusercontent.com/20435849/86539552-ac583580-bf12-11ea-950a-0b3238d0ccb2.png)\r\n\r\nThank you\n Comments: \n Comment 0: @ms4hafiz,\r\n\r\ncan you give us an example as to when this button should be hidden (or maybe just disabled) and what would be the purpose for this?\r\n\r\n(if I understand your request correctly, then - for example - when there is a category name with **seafood**, this button should disappear until this category is renamed or deleted, correct?)\r\n\r\nWith kind regards,\r\n\r\nJohn\n Comment 1: @JohnRanger \r\nThank you for the response\r\nBasically in my project, I have one column DateTo which will not filled at the time of entry and will be filled at a later date.\r\nWhat I want is to be table to if the DateTo for an existing record in the grid is null, the add button is disabled or hidden. And want this button to be enabled if there DateTo is not blank.\r\n\r\nFor the above example, we could go for seafood to check if seafood exist then the add button is disabled.\r\n\n Comment 2: @ms4hafiz \r\n\r\n\r\nIf you know the value of of the field - for example you could do this in afterLoadEntity() or by subscribing to the event of rows added.\r\n\r\nI see you are using DateTo - so the code below will need to be modified to fit your purpose - but it should do the trick.\r\n\r\n**If you choose In your afterLoadEntity** \r\n```\r\n        protected afterLoadEntity() {\r\n            super.afterLoadEntity();\r\n\r\n                for (var k of this.getItems()) {\r\n                    // you could also use match here instead of IndexOf -1 means no match \r\n                    if (k.CategoryName.indexOf(\"myValue\")!= -1) {\r\n                       toggleNewVisibility(true);\r\n                     // exit your for statement here as there is no reason to continue.. \r\n                       break;\r\n                    }\r\n   }\r\n```\r\n**In your Constructor subscribing to the event of rows added - perhaps when add row is available they add the thing you don't allow **\r\n```\r\n            (this.view as any).onRowCountChanged.subscribe(() => {                \r\n                for (var k of this.getItems()) {\r\n                    // you could also use match here instead of IndexOf -1 means no match \r\n                    if (k.CategoryName.indexOf(\"myValue\")!= -1) {\r\n                       toggleNewVisibility(true);\r\n                     // exit your for statement here as there is no reason to continue.. \r\n                       break;\r\n                    }\r\n              }\r\n```\r\n**In your XYZ dialog**\r\n```\r\n        public toggleNewVisibility(SetHidden: boolean) {\r\n// var b only used to allow a look see into the object found.\r\n          //  var b = this.toolbar.findButton('add-button');\r\n            this.toolbar.findButton('add-button').toggleClass('disabled', SetHidden);\r\n        }\r\n```",
  "Issue title: Test issue\n Issue body: Please ignore\n Comments: \n Comment 0: Ok, ignored.",
  "Issue title: Template not working Maybe - Functions.php\n Issue body: I believe there is a current problem with the functions.php.in the latest version of WordPress. Activating the template you are greeted with a blank page. Emptying the contents of functions renders the page but of course breaks everything too.\n\n Comments: \n Comment 0: I'm having same issue. This is my first experience with Reverie and I'm not an expert WP developer, so may well be user error.\nI've just downloaded the zip from themefortress.com, uploaded to WP and activated, which then creates a blank screen. Have I missed a crucial step?\n",
  "Issue title: [LMLayer] Enhanced Levenshtein-like algorithm for predictive corrections\n Issue body: **Is your feature request related to a problem? Please describe.**\r\nAt present, communication between KMW and the LMLayer only provide limited corrective ability - only variations based on the last keystroke are considered for correction.\r\n\r\n**Describe the solution you'd like**\r\nIt would be better if we can have keystroke-based correction that considers the keystroke input that generated the current context.  Swapping out keystrokes (and applying their underlying keyboard rules) would provide a much more natural predictive experience.\r\n\r\nOf course, wisdom in implementation is necessary; keyboard rules can permit a wide, wide range of variation in outputs and the resulting time complexity of a complete, exact algorithm is likely to be computationally expensive if not restrained or scope-limited in some manner.\r\n\r\n**Existing work**\r\n#1869 features work that could be used to support such an algorithm, though said work is in need of further refinement.  The algorithm itself was never completed, as it was necessary to cut its development for 12.0's release.\n Comments: \n Comment 0: Enough enhancements are in place to consider this fulfilled for now.  Sure, more improvements may be possible in the future... but that's much further down the roadmap.",
  "Issue title: Dasshio wifi problem\n Issue body: I have dasshio on 2 raspberry 3 b+\r\n\r\nFirst master have a Lan connection and working good with dasshio 0.3.6 and HA 0.91.4\r\n\r\nSecond have a wifi connection to the same lan and never see any button it's all the time \r\n2019-04-18 10:20:34,530 | INFO | Reading config file: /data/options.json\r\n2019-04-18 10:20:34,536 | INFO | Starting...\r\n2019-04-18 10:20:34,537 | INFO | Starting sniffing...\r\nbut never see any button, while with 0.3.1 see when it pushed.\r\n\r\nIt's a bug on new version? \r\n\r\nSame config for both dasshio, try different button, nothing change.\r\ntry to set timeout more then 20, since to 40 nothing, don't see when they are pushed.\n Comments: \n Comment 0: I have exactly the same problem dasshio v 0.3.6 and HA v 0.94.1 on a raspi 3B+.\r\nButton presses are not being detected for different timeout settings.",
  "Issue title: Provide support for @addNLConstraints\n Issue body: Currently we can add groups of (affine) constraints through the `@addConstraints` macro, e.g.\n\n``` julia\n@addConstraints m begin\n  x >= 1\n  y - w <= 2\n  sum_to_one[i=1:3], z[i] + y == 1\nend\n```\n\nIt will be great to extend it to nonlinear constraints, by introducing a `@addNLConstraints` macro. This will be useful for problem instances such as the [MINLP example in KNITRO](https://github.com/JuliaOpt/KNITRO.jl/blob/minlp/examples/jump_minlp.jl).\n\n Comments: \n Comment 0: This would be nice to have. `@addConstraints` works as a simple wrapper around `@addConstraint`, and I'm guessing `@addNLConstraints` could be implemented with pretty much the exact same strategy (and code).\n\n Comment 1: Yeah, should be a copy-paste job.\n",
  "Issue title: How to find remote file?\n Issue body: It seems we can not find the remote files.\n Comments: \n Comment 0: I had this issue when I first started with remote-ftp. for me it was because a slash is required at the end of the remote path in my **.ftpconfig**\r\nI changed from:\r\n\r\n    \"remote\": \"/home/user1/domains/domain.com/private_html\",\r\n\r\nTo \r\n\r\n    \"remote\": \"/home/user1/domains/domain.com/private_html/\",\r\n\r\nAnd it worked!\n Comment 1: @cronoklee \r\nThanks, but my question was how to find files in the Remote when I select \"Find<Find File\" from the Atom top menu.\r\nThe local files only could be found.",
  "Issue title: Window frame icons are missing\n Issue body: This is what happens when I set one of the Yaru color theme (Yaru-Aqua here). The maximize, minimize, close icons with some more are missing\r\n\r\n![image](https://user-images.githubusercontent.com/1885909/88454011-fedf9e80-ce8d-11ea-932a-d157e4ef5d4f.png)\r\n\r\nThis is when I change back the icon to Yaru (from canonical)\r\n\r\n![image](https://user-images.githubusercontent.com/1885909/88454022-1159d800-ce8e-11ea-9501-418ab80bb140.png)\r\n\n Comments: \n Comment 0: Does this happen in every application and what app is that in your screenshots?\n Comment 1: That is evince, the default pdf viewer for GNOME\n Comment 2: No. I don't see this in other applications such as terminal, gedit or image viewer (eog). Only on evince \n Comment 3: Okay, I've tried it on both, my running system and a freshly installed VM with the latest release.\r\nI din't have this issue and absolutely can't relate and reproduce. \r\nDo you use the version 3.36.0 of evince?\r\nHere's screenshot of my titlebar:\r\n![Bildschirmfoto von 2020-07-27 18-45-53](https://user-images.githubusercontent.com/31586674/88568790-ca104a80-d039-11ea-9524-67a24ece226c.png)\r\n\r\nIt seems that there's something broken with your theme installation because those icons are missing. Did you install the latest release?\n Comment 4: I'm using Debian and Yaru icon theme was there. This doesn't happen with\nthe original Yaru icon theme. Only with Yaru-colors icons. I installed the\nlatest release of your icon theme.\n\nOn Mon, Jul 27, 2020 at 10:52 PM Jan Schr\u00f6der <walkerjennifer@example.net>\nwrote:\n\n> Okay, I've tried it on both, my running system and a freshly installed VM\n> with the latest release.\n> I din't have this issue and absolutely can't relate and reproduce.\n> Do you use the version 3.36.0 of evince?\n> Here's screenshot of my titlebar:\n> [image: Bildschirmfoto von 2020-07-27 18-45-53]\n> <https://user-images.githubusercontent.com/31586674/88568790-ca104a80-d039-11ea-9524-67a24ece226c.png>\n>\n> It seems that there's something broken with your theme installation\n> because those icons are missing. Did you install the latest release?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/Jannomag/Yaru-Colors/issues/47#issuecomment-664513229>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAOMNVIDY2HLDNIDBRHCMLLR5WWDFANCNFSM4PHMB3GA>\n>.\n>\n\n Comment 5: Okay. Even with Yaru there's something wrong with your icons. The icons in the title bar are NOT from Yaru, when you set your theme to it.\r\nThey're \"Humanity\", the stock icon set. You can see this if you compare your Yaru screenshot with my Yaru-Colors screenshot.\r\nYaru-Colors doesn't contain those scalable icons because they're not changed. Instead Yaru-Colors inherits to Yaru, Humanity, hicolor - in this order (this is what stock Yaru/Suru does).\r\nSo, somehow Evince won't inherit it's icons.\r\n\r\nDo you have Yaru icons even installed? If not, try this first. If so, then try to set Adwaita as first inherit theme in index.theme in your Yaru-Colors icon directory.\n Comment 6: I had yaru installed on a place and then linked to `~/.local/share/icons` dir. Looks like for some unknown reason it was not working with your theme (idk why?!). I re-installed yaru icon theme in system directory (/usr/share/icons) and removed the link, now it's working!\r\n\r\nI'm now trying to feature out what might have gone wrong? since the icon theme itself working with the linking. \r\n\n Comment 7: It can be that some programs don't use Inherits when looking for icons. I really don't know how gnome / gtk works with icons.\r\nI tried linking themes and icons as well and noticed similar and other issues. So linking is not a good idea.\n Comment 8: The problem was with evince's apparmor profile. Apparomor profile for evince was blocking the read access for the icon theme. This is weird. I've fixed it anyway. Thanks",
  "Issue title: DirAsDisk corrupts file.\n Issue body: Using Trilotracker a file keeps getting corrupt when using DirAsDisk to overwrite. On other emulators (Emulicious), real HW or saving in openMSX using HDD image the file saves correctly.\r\n\r\nWhen overwriting a the ALESTEGG.TMU file the file gets corrupted. If saved under another filename there is no corruption. \r\nIn the corrupt file old and new data is visible :\r\n$0000-$07FF = New data\r\n$0800-$1FFF = Old data 2,5kb?\r\n$2000- einde = New data\r\n\r\nUsing MSX-DOS2 functions:\r\n```\r\n3.48 CREATE FILE HANDLE (44H)\r\n     Parameters:    C = 44H (_CREATE) \r\n                        DE = Drive/path/file ASCIIZ string\r\n                    A = Open mode. b0 set => no write\r\n                                   b1 set => no read\r\n                                   b2 set => inheritable   \r\n                                 b3..b7   -  must be clear\r\n                    B = b0..b6 = Required attributes\r\n                            b7 = Create new flag\r\n     Results:       A = Error\r\n                    B = New file handle\r\nA = $00\r\nB = $00\r\nHL = F:\\ALESTEGG.TMU + $00\r\n```\r\n\r\n```\r\n3.53 WRITE TO FILE HANDLE (49H)\r\n     Parameters:    C = 49H (_WRITE) \r\n                    B = File handle\r\n                   DE = Buffer address\r\n                   HL = Number of bytes to write\r\n     Results:       A = Error\r\n                   HL = Number of bytes actually written\r\n\r\n```\r\n\r\n\r\nReproduction method:\r\n- Start openMSX with attached files in a DirAsDisk folder.\r\n- DOS prompt type 'TTFM' + enter\r\n- F5 (opens file menu)\r\n- select 'Load Song'\r\n- select file 'ALESTEGG.TMU' + enter\r\n- F5\r\n- select 'Save Song'\r\n- select file 'ALESTEGG.TMU' + enter\r\n- now try to load the file 'ALESTEGG.TMU' again. A mesage will indicate the file is corrupted\r\n[TTdir.zip](https://github.com/openMSX/openMSX/files/7809845/TTdir.zip)\r\n.\n Comments: \n Comment 0: Thanks a lot for the bug report!   Unfortunately I cannot reproduce the problem :-(\r\n\r\nThough maybe because I couldn't exactly follow the steps you gave:\r\n- You didn't specify a specific MSX machine. So I randomly picked a turbor machine. (I was guessing I needed a machine with MSX-MUSIC? Any other configuration that might be relevant?)\r\n- Your TTdir.zip didn't contain MSXDOS2.SYS and COMMAND2.COM. Because of this I first booted using another disk.\r\n- More specifically I started openmsx like this:   openmsx ~/msx/disks/dos2.dsk -machine turbor\r\n- After the machine booted and showed the DOS prompt, I opened the openmsx console and gave the command:  diska TTdir/\r\n- Then close the openMSX console and type the command   TTFM<enter>\r\n- Load the song:  <f5><enter><enter>\r\n- Save the song:  <f5><cursor-down><enter><enter>\r\n- Load again: <cursor-up><enter><enter>\r\nThis doesn't show any error message. And playing the song (<F1>) seems to work fine.\r\n\r\nDo you see any (differences in the steps that you executed and the steps that I described?\r\n\r\nWhich openMSX version are you using? I tried to reproduce with\r\n- The latest development snapshot.\r\n- The version right before a bugfix in dir-as-disk (https://github.com/openMSX/openMSX/commit/0d342a9d17eff9451561928463e3dc47d015b2af)\r\n- The 17.0 release.\r\nBut with all 3 versions the above scenario worked just fine for me.\r\n\r\nCould you maybe try to simplify the scenario (e.g. include the DOS2 files in the zip). And maybe try to make a replay file (see the \"reverse savereplay\" openmsx command).\r\n\r\nThough one annoying thing with dir-as-disk is that it's not 100% deterministic across host machines. E.g. internally openMSX asks the OS (linux, windows,..) for the list of files in the directory, and these files are not always returned in the same order. And thus they also and up in different sectors in the virtual dir-as-disk.\r\n\r\nWouter\n Comment 1: Your steps seem OK to me.\r\n\r\n[TTdir 2.zip](https://github.com/openMSX/openMSX/files/7810218/TTdir.2.zip)\r\n[openmsx0001.zip](https://github.com/openMSX/openMSX/files/7810244/openmsx0001.zip)\r\nAdded :\r\n- attachment including the MSX-DOS files. \r\n- replay file.\r\n\r\nMy config:\r\nopenMSX 17.0 + Catapult\r\nMSX turbo-R GT + ram1mb\r\nAll running on Windows10\r\n\r\nI hope this helps\r\n\r\n.\n Comment 2: @cornelisser Can you test with the latest development build? As @m9710797 said, there was a bug fix after the 17.0 release.\n Comment 3: Where can I download the latest version? Can only see 17.0 release for download.\n Comment 4: @cornelisser 17.0 is the latest release, development builds can be downloaded from the link on the website under \"Development builds\" at the bottom of the download box.\n Comment 5: With the latest development build the issues is gone. YES!\n Comment 6: OK, thanks for confirming, I'll close this issue then.",
  "Issue title: Walkthrough Step 9: Component Configuration Documentation is missing index.js\n Issue body: OpenUI5 version: 1.61.2\r\n\r\nBrowser/version (+device/version): Chrome/72.0.3626.81 (macOS 10.13.6 (17G4015))\r\n\r\nAny other tested browsers/devices(OK/FAIL):\r\nFAIL Firefox 62.0b20 (64 bits)\r\n\r\nURL (minimal example if possible): [Step 9: Component Configuration](https://openui5.hana.ondemand.com/#/topic/4cfa60872dca462cb87148ccd0d948ee)\r\n\r\nUser/password (if required and possible - do not post any confidential information here):\r\n\r\nSteps to reproduce the problem:\r\n1. Open Step 9\r\n2. Download step files and decompress\r\n3. Adjust bootstrapping code inside index.html if needed\r\n3. Open webserver in webapp folder (I am using python -m http.server NNNN for this example)\r\n3. Load app in browser: localhost:NNNN\r\n\r\nWhat is the expected result?\r\nLoad index.js\r\nDocumented step in walk-through detailing changes in index.js\r\n\r\nWhat happens instead?\r\nError while trying to load index.js (browser's console)\r\nindex.js from previous step does not work\r\n\r\nAny other information? (attach screenshot if possible)\r\n\r\nProbably related to #2338\r\n\r\nThe tutorial says the index.js file is not needed any more:\r\n\r\n> Since the Component.js now handles everything, we no longer need our index.js.\r\n\r\nHowever, there is no connection between the html file and the application. That means the html still references to index.js when loading the bootstrap:\r\n\r\n`data-sap-ui-oninit=\"module:sap/ui/demo/walkthrough/index\"`\r\n\r\nMoreover, when reviewing the [app code](https://openui5.hana.ondemand.com/test-resources/sap/m/demokit/tutorial/walkthrough/09/webapp/index.html), index.js was properly updated to reflect the changes from the XMLView to the ComponentContainer.\r\n\r\n```\r\nsap.ui.define([\r\n\t\"sap/ui/core/ComponentContainer\"\r\n], function (ComponentContainer) {\r\n\t\"use strict\";\r\n\tnew ComponentContainer({\r\n\t\tname: \"sap.ui.demo.walkthrough\",\r\n\t\tsettings : {\r\n\t\t\tid : \"walkthrough\"\r\n\t\t}\r\n\t}).placeAt(\"content\");\r\n});\r\n```\r\n\r\n![capture d ecran 2019-02-07 a 19 02 49](https://user-images.githubusercontent.com/1663486/52450897-fca74a00-2b0a-11e9-8162-607df2d5afca.png)\n Comments: \n Comment 0: Hello @arguapacha,\r\n\r\nthank you for reporting this, we missed out to add the index.js file to the documentaiton, it was only available in the code. We updated the documentation accordingly:\r\nhttps://openui5nightly.hana.ondemand.com/#/topic/4cfa60872dca462cb87148ccd0d948ee\r\n\r\nAll the best,\r\nMichael",
  "Issue title: Create a home page for the project\n Issue body: Suggest gh-pages and http://okfnlabs.org/dataconverters/\n\nThis would be a:\n- Brief intro the project\n- Link to main python docs (if we have them, at pypi)\n- Instructions that people can easily contribute\n- Call for people to help us host nodes?\n- History / Background (?)\n\n Comments: \n Comment 0: FIXED.\n",
  "Issue title: FlywayAutoConfiguration & QuartzAutoConfiguration process order issue\n Issue body: I am trying to use flyway handling the quartz schema initialization, but it seems QuartzAutoConfiguration is always processed ahead of FlywayAutoConfiguration, which will raise the [org.quartz.JobPersistenceException: Couldn't retrieve job: ORA-00942] exception, because the quartz schema is not initializd yet\uff08I am using jdbc as the quartz job store type, spring.quartz.job-store-type=jdbc\uff09.\r\n\r\nSo, am i got something wrong, or maybe should put @AutoConfigurationAfter(FlywayAutoConfiguration.class) on the QuartzAutoConfiguration?\r\n\r\n\r\n      THX!!\n Comments: \n Comment 0: Using spring-boot-2.1.6.RELEASE\n Comment 1: Closing in favour of #17539.",
  "Issue title: how to switch connect info\n Issue body: 1. Which driver are you using and version of it (Ex: PostgreSQL 10.0):\r\nMYSQL\r\n2. Which TablePlus build number are you using (the number on the welcome screen, Ex: build 81):\r\n2.9.1(264)\r\n3. The steps to reproduce this issue:\r\nHow to connect other database addresses under the current connection? (I have 2 connection addresses for dev)\r\nNoted: If the bug is related to data, please attach an example SQL data.\r\n\n Comments: \n Comment 0: You can do it by pressing Command + P or Command + K.",
  "Issue title: Pipe non-existent file to stdin freezes fish\n Issue body: <!--\r\nPlease tell us which fish version you are using by executing the following:\r\n\r\n  fish --version\r\n  echo $version\r\n\r\nPlease tell us which operating system and terminal you are using. The output of `uname -a` and `echo $TERM` may be helpful in this regard although other commands might be relevant in your specific situation.\r\n\r\nPlease tell us if you tried fish without third-party customizations by executing this command and whether it affected the behavior you are reporting:\r\n\r\n  sh -c 'env HOME=$(mktemp -d) fish'\r\n\r\nTell us how to reproduce the problem. Including an asciinema.org recording is useful for problems that involve the visual display of fish output such as its prompt.\r\n-->\r\n\r\n```sh\r\ncat | echo < a\r\n```\r\nThis freezes the fish shell and CPU usage goes to 100%.\r\nIf I use a terminal emulator(Alacritty), simply it exits.\r\nOn the bash shell, Behavior is the same as `cat | echo`.\r\nOS: Arch Linux(Fish installed using Pacman, no other shell customization)\r\n\r\n`fish --version`:\r\n```\r\nfish, version 3.1.2\r\n```\r\n\r\n`echo $version`:\r\n```\r\n3.1.2\r\n```\r\n\r\n`uname -a`:\r\n```\r\nLinux Kuro 5.8.8-zen1-1-zen #1 ZEN SMP PREEMPT Wed, 09 Sep 2020 19:01:48 +0000 x86_64 GNU/Linux\r\n```\r\n\r\n`echo $TERM`:\r\n```\r\nalacritty\r\n```\r\n\r\n> Please tell us if you tried fish without third-party customizations\r\nYes\n Comments: \n Comment 0: Duplicate of #7038",
  "Issue title: Input Invariant Violation\n Issue body: ### Description\r\n\r\n1. Updated from beta2 to beta3\r\n2. Input doesn't crush the app\r\n3. Got console error\r\n\r\n```\r\nInvariant Violation: Element type is invalid: expected a string (for built-in components) or a class/function (for composite components) but got: undefined. You likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports\r\n```\r\n\r\n### Reproduction Steps and Sample Code\r\nImport `Input` as in docs.\r\n\r\n\n Comments: \n Comment 0: Hey @bohdanbirdie, you're right this is a bug, we also set the background to the default blue primary color. The problem is [this line](https://github.com/react-native-training/react-native-elements/blob/master/src/buttons/ButtonGroup.js#L97) if someone wants to tackle this \ud83d\udcaa \n Comment 1: I would like to work on this. Will make a pr as soon as I can\n Comment 2: @k3ithl1m If you hadn't had a chance to work on this issue, like to fix it.\n Comment 3: Hey @dincozdemir Sure thing. I forgot about this issue entirely as I was traveling. Go at it and have fun! :)\n Comment 4: While i was fixing the issue, I also noticed that this usage gives an error when the given style is defined using ``\r\nStyleSheet.create``:\r\n\r\n``borderRightColor:\r\n                  (innerBorderStyle && innerBorderStyle.color) || colors.grey4,``\r\n\r\nThat's because in such case, innerBorderStyle is a style id, not the style itself.\r\nIt should be ``StyleSheet.flatten(innerBorderStyle)`` to avoid crashes.\r\n\r\nI see this usage pattern through all the components. I wonder if this is a known issue.\n Comment 5: @dincozdemir As you can see [in the docs](https://react-native-training.github.io/react-native-elements/docs/button_group.html#buttongroup-props), the `innerBorderStyle` has the type `object { width, color }`, it cannot be a Stylesheet object, it's basically a simple object that allows you to override these two border props. Other styles has the type `object (style)`, which can be an object OR a Stylesheet object. The name is a bit confusing tho",
  "Issue title: Extend the list of supported languages in AIR\n Issue body: https://help.adobe.com/en_US/air/build/WSB2927578-20D8-4065-99F3-00ACE6511EEE.html\r\n\r\nThe AppStore and PlayStore support many more languages.\n Comments: \n Comment 0: I think those are mainly related to desktop AIR installer\r\n\r\nfor the app itself you have the [flash.globalization](https://help.adobe.com/en_US/FlashPlatform/reference/actionscript/3/flash/globalization/package-detail.html) package\r\n\r\nalso see [Choosing a locale](https://help.adobe.com/en_US/as3/dev/WS9b644acd4ebe59993a5b57f812214f2074b-8000.html#WS9b644acd4ebe59993a5b57f812214f2074b-7ffd)\r\n\r\n",
  "Issue title: iOS 7 Simulator Session Ends With Error But exit(EXIT_SUCCESS) Called Since Error is Nil\n Issue body: I created an app to run with the sole purpose of crashing. I achieved this by calling NSAssert(NO,@\"Force Crash\") in the AppDelegate. \n\nI then forked a copy of ios-sim and added my broken app as a launch argument. \n\n![screen shot 2013-10-22 at 12 01 29 pm](https://f.cloud.github.com/assets/857247/1382807/37bc37fe-3b33-11e3-947f-74cf65752d00.png)\n\nI then set a breakpoint at line 82:iPhoneSimulator.m and in the lldb typed\n\n``` lldb\npo error\n```\n\n![screen shot 2013-10-22 at 12 03 28 pm](https://f.cloud.github.com/assets/857247/1382828/917f4c72-3b33-11e3-9b38-c18e604a7670.png)\n\nI then executed the lldb next command.\n\n![screen shot 2013-10-22 at 12 05 31 pm](https://f.cloud.github.com/assets/857247/1382847/c7895fe2-3b33-11e3-92f3-42095a8a2182.png)\n\nAs you can see since the error is nil exit(EXIT_FAILURE); is never called, and hence   exit(EXIT_SUCCESS) is called. \n\nI also ran ios-sim through this process_events.py script and here were the results.\n\n![screen shot 2013-10-22 at 12 19 08 pm](https://f.cloud.github.com/assets/857247/1382978/f1f9c94a-3b35-11e3-973a-e5f7c30ccd7e.png)\n![screen shot 2013-10-22 at 12 19 47 pm](https://f.cloud.github.com/assets/857247/1382982/ff43b944-3b35-11e3-8cdf-88b7ac45f84e.png)\n\nSource: http://www.opensource.apple.com/source/lldb/lldb-179.1/examples/python/process_events.py\n\n``` python\n#!/usr/bin/python\n\n#----------------------------------------------------------------------\n# Be sure to add the python path that points to the LLDB shared library.\n# On MacOSX csh, tcsh:\n#   setenv PYTHONPATH /Applications/Xcode.app/Contents/SharedFrameworks/LLDB.framework/Resources/Python\n# On MacOSX sh, bash:\n#   export PYTHONPATH=/Applications/Xcode.app/Contents/SharedFrameworks/LLDB.framework/Resources/Python\n#----------------------------------------------------------------------\n\nimport commands\nimport optparse\nimport os\nimport platform\nimport sys\n\n#----------------------------------------------------------------------\n# Code that auto imports LLDB\n#----------------------------------------------------------------------\ntry: \n    # Just try for LLDB in case PYTHONPATH is already correctly setup\n    import lldb\nexcept ImportError:\n    lldb_python_dirs = list()\n    # lldb is not in the PYTHONPATH, try some defaults for the current platform\n    platform_system = platform.system()\n    if platform_system == 'Darwin':\n        # On Darwin, try the currently selected Xcode directory\n        xcode_dir = commands.getoutput(\"xcode-select --print-path\")\n        if xcode_dir:\n            lldb_python_dirs.append(os.path.realpath(xcode_dir + '/../SharedFrameworks/LLDB.framework/Resources/Python'))\n            lldb_python_dirs.append(xcode_dir + '/Library/PrivateFrameworks/LLDB.framework/Resources/Python')\n        lldb_python_dirs.append('/System/Library/PrivateFrameworks/LLDB.framework/Resources/Python')\n    success = False\n    for lldb_python_dir in lldb_python_dirs:\n        if os.path.exists(lldb_python_dir):\n            if not (sys.path.__contains__(lldb_python_dir)):\n                sys.path.append(lldb_python_dir)\n                try: \n                    import lldb\n                except ImportError:\n                    pass\n                else:\n                    print 'imported lldb from: \"%s\"' % (lldb_python_dir)\n                    success = True\n                    break\n    if not success:\n        print \"error: couldn't locate the 'lldb' module, please set PYTHONPATH correctly\"\n        sys.exit(1)\n\ndef print_threads(process, options):\n    if options.show_threads:\n        for thread in process:\n            print '%s %s' % (thread, thread.GetFrameAtIndex(0))\n\ndef run_commands(command_interpreter, commands):\n    return_obj = lldb.SBCommandReturnObject()\n    for command in commands:\n        command_interpreter.HandleCommand( command, return_obj )\n        if return_obj.Succeeded():\n            print return_obj.GetOutput()\n        else:\n            print return_obj\n            if options.stop_on_error:\n                break\n\ndef main(argv):\n    description='''Debugs a program using the LLDB python API and uses asynchronous broadcast events to watch for process state changes.'''\n    epilog='''Examples:\n\n#----------------------------------------------------------------------\n# Run \"/bin/ls\" with the arguments \"-lAF /tmp/\", and set a breakpoint \n# at \"malloc\" and backtrace and read all registers each time we stop\n#----------------------------------------------------------------------\n%./process_events.py --breakpoint malloc --stop-command bt --stop-command'register read' -- /bin/ls -lAF /tmp/\n\n'''\n    optparse.OptionParser.format_epilog = lambda self, formatter: self.epilog\n    parser = optparse.OptionParser(description=description, prog='process_events',usage='usage: process_events [options] program [arg1 arg2]', epilog=epilog)\n    parser.add_option('-v', '--verbose', action='store_true', dest='verbose', help=\"Enable verbose logging.\", default=False)\n    parser.add_option('-b', '--breakpoint', action='append', type='string', metavar='BPEXPR', dest='breakpoints', help='Breakpoint commands to create after the target has been created, the values will be sent to the \"_regexp-break\" command which supports breakpoints by name, file:line, and address.')\n    parser.add_option('-a', '--arch', type='string', dest='arch', help='The architecture to use when creating the debug target.', default=None)\n    parser.add_option('--platform', type='string', metavar='platform', dest='platform', help='Specify the platform to use when creating the debug target. Valid values include \"localhost\", \"darwin-kernel\", \"ios-simulator\", \"remote-freebsd\", \"remote-macosx\", \"remote-ios\", \"remote-linux\".', default=None)\n    parser.add_option('-l', '--launch-command', action='append', type='string', metavar='CMD', dest='launch_commands', help='LLDB command interpreter commands to run once after the process has launched. This option can be specified more than once.', default=[])\n    parser.add_option('-s', '--stop-command', action='append', type='string', metavar='CMD', dest='stop_commands', help='LLDB command interpreter commands to run each time the process stops. This option can be specified more than once.', default=[])\n    parser.add_option('-c', '--crash-command', action='append', type='string', metavar='CMD', dest='crash_commands', help='LLDB command interpreter commands to run in case the process crashes. This option can be specified more than once.', default=[])\n    parser.add_option('-x', '--exit-command', action='append', type='string', metavar='CMD', dest='exit_commands', help='LLDB command interpreter commands to run once after the process has exited. This option can be specified more than once.', default=[])\n    parser.add_option('-T', '--no-threads', action='store_false', dest='show_threads', help=\"Don't show threads when process stops.\", default=True)\n    parser.add_option('--ignore-errors', action='store_false', dest='stop_on_error', help=\"Don't stop executing LLDB commands if the command returns an error. This applies",
  "Issue title: Replace httpie for curl\n Issue body: httpie is not consistent across all Linux distributions. Some customers might not be willing to install it either.\n Comments: \n Comment 0: Really?\r\nWho would not install httpie for their training environment? And why is \"curl\" better?\n Comment 1: I love httpie, and would definitely encourage anybody to install it - both in training and production environments.\r\n\r\nBut certainly if the customer has a strict policy on their testing machines, and for example deploy standard server VMs to do the training on, it can certainly be a problem. But if it's packaged in EPEL (which I think it is? Thoug not sure?), I'm not sure if it's a bigger problem than installing Varnish itself?\n Comment 2: The training requires local root.\r\nIf they can't install httpie in their training environment they figure out how to use curl on their own. \r\n\r\nThere is absolutely no need to suboptimize the book just because someone has a lame security policy.\n Comment 3: I think a reasonable compromise would perhaps be to use httpie in the examples and such, but then include a small section of \"here's how you do the most common things in curl as well\" - for those that are stuck with it. But using httpie \"inline\".\n\n Comment 4: We leave httpie in.\r\nIf somebody cares enough about this to contribute a little appendix on curl usage I'm sure pull requests would be pulled with a smile and a nice pat on the back. :-)\n Comment 5: I'll wait until Dridi is back from vacation to comment on this issue. It is my understanding that he faced many problems with httpie while teaching at a customer's site.\n Comment 6: In the Varnish 3 series of the Varnish Book, I used to get negative feedback on the `GET` command, because unlike `curl` they couldn't figure what the flags would mean.\n\nFor my first Varnish 4 training, the customer had decided to host the VMs used for training, and they use RHEL 6. Httpie couldn't be installed via EPEL and they eventually tried with `pip` but in the end it didn't work.\n\nFallback to curl, but looking at `http` commands they did not understand what was going on, especially the developers (it was a 3 days training including both courses). And there's a terrible UI decision in httpie that leads to confusion.\n\n`http -p hH --proxy=http:http://localhost sport.example.com/index.html`\n\nThe `--proxy` option is confusion because:\n- of the http:http: double scheme\n- the very name \"proxy\"\n- the impedance mismatch with HTTP\n\nThey first thought that they had to specify this to bypass their corporate proxy. Then they thought that doubling `http:` was a typo. And then they didn't understand the relationship between this and a `Host:` header.\n\nIf we keep httpie, we should for instance get rid of all `--proxy` options and simply follow the principle of lest astonishment.\n\n`http -p hH localhost/index.html Host:sport.example.com`\n\nSame result, a lot closer to reality. That is important during training to not confuse trainees, they already have a hard time with VCL.\n\nNow why `curl`?\n\nIt doesn't pretty print the output, it doesn't have colors. But really when a trainee is on a windows laptop using putty, they have bad UX anyway. And it's not that hard to read one key:value per line.\n\nIt is more verbose:\n\n``` bash\nhttp -p hH localhost/index.html Host:sport.example.com\n# vs\ncurl --verbose --header Host:sport.example.com localhost/index.html\n# vs\ncurl -v -H Host:sport.example.com localhost/index.html\n```\n\nAnd you don't get to pick what's printed, that one thing httpie does way better. But during the training, you only access to small files so it doesn't really hurt. Only the chapters _HTTP_ and _Content Composition_ contain large (for a terminal) files, but you look at them through a browser, and we use the developer tools to look at the HTTP bits.\n\nAnd the main reason for using `curl` is not that I'm used to it and sysadmins are usually too as described above. The main reason is stability and consistency. Curl is mature, and available on all the platforms we support. Differences in feature (if any) between one shipped in RHEL 5 or 7 doesn't change anything for the training and is thus reliable.\n\nWe want to waste the least possible time and neurons during a training, because Varnish is disruptive, and therefore we need the most stable and comfortable environment possible.\n\nMy $0.02\n\n Comment 7: Those are valid objections. Probably worth a tad bit more than $.02, maybe as much as $.5. :-)\n\nI'll see if I can find the time to rewrite some of the httpie statements to be more in line with best practices. The use of --proxy is probably a bit distracting and should be placed.\n\nI suggest we move along with the current toolset and at a later point, when we're happy with the rest of the content we can add curl examples alongside the httpie ones. As you say, curl is omnipresent and a well known tool. However, my personal option is that httpie is a lot more powerful (the native JSON support is very nice).\nYou might scoff at the color support in httpie, but for me it makes a bit of a difference. I've abandoned curl quite a bit of time ago. \n\n Comment 8: @perbu I use httpie when I want to look at the payload itself, because color support becomes very useful there!\n\nI still use curl for both interactive commands and scripting, so unless I'm interested in looking at the response body, I stick to it.\n\nDuring the training, we rarely look at the body, and AFAIK there's no json involved. When we do care about the body, we use a proper browser.\n\n Comment 9: Closed because this issue is a bit subjective and we better use our resources in more meaningful improvements for the book.\n",
  "Issue title: Feature Request: UI element indicating version\n Issue body: Not really a issue more of a Feature Request\r\n\r\nWould be a nice little addition to have somewhere in the browser home page, or perhaps settings, the current version that is running. \r\nIdeally it would also include another UI element that indicates the status of if they are actually running the latest available verion or not, this would help users stay as up to date as possible with out requiring they monitor slack or github for new version announcements. \r\n\r\nTy\n Comments: \n Comment 0: @larrysalibra @yknl It would be nice to add an initial splash screen upon startup of the Blockstack Browser.\n Comment 1: I'd like to see this too!",
  "Issue title: Cant use the software\n Issue body: Hey im trying to run the example qcdm fuzzer but its not able to import the modules cuz the names arnt the same i tried fixing it by renaming and moving stuff but cant get it working\n Comments: \n Comment 0: Ok i got everything renamed and had to install pyusb and scapy but now get this error\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\PC2\\Desktop\\usb-device-fuzzing-master\\USBFuzz\\qcdm_fuzzer.py\", line 10, in <module>\r\n    arg = sys.argv[1].split(':')\r\nIndexError: list index out of range",
  "Issue title: CDEC historical data does not retrieve today's data for hourly data\n Issue body: This is due to the _download_raw only using the date and not the full datetime with hours and minutes in the url.  I'm working on a solution now. \n Comments: \n Comment 0: Nice to see some interest in this. ",
  "Issue title: Custom error message\n Issue body: Hi, i love this lib.\r\nBut i cannot custom error message.\r\nMy input is number, and errorMessage=\"Invalid name\", but when i type `-`, input always shows default message: This field is invalid\r\nSo Could you tell me how do i custom that message. Thank you.\r\nHere is my code https://codesandbox.io/s/damp-snow-w9dxu?file=/src/App.js\r\n![image](https://user-images.githubusercontent.com/12009276/95286750-5cc93300-088e-11eb-843e-7c8036d26b12.png)\r\n\n Comments: \n Comment 0: Hi there! The reason you're seeing `This field is invalid` instead of your custom error message has to do with line 15 where you have `type=\"number\"`. The HTML Number type has some [built in validation](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/input/number#Validation) that won't allow normal characters to be typed, so in your screenshot the `value` of the component is `\"\"`.\r\n\r\nChanging line 15 to be `type=\"text\"` will allow these values and your custom error message will show up based on based on your `pattern`, `minLength`, and `maxLength` validation.\n Comment 1: @chrishavekost  but i just want to allow input number\n Comment 2: Part of this is because of how the browser handles `type=\"number\"` inputs which are invalid. The browser's validation is actually what is running in this case, not this library's validation. The browser never gives value to the library (at least in chrome), even when trying to get the input's value directly, it's an empty string (so we cannot run our own validation). In these cases we have to depend on `target.validity.badInput` to determine if the input is invalid. When that is invalid we don't know which one of our validations would correlate and cannot show specific error messages.\r\n\r\nhttps://github.com/Availity/availity-reactstrap-validation/blob/3d44e388208438134879a30d414fff835a0f4c71/src/AvBaseInput.js#L126",
  "Issue title: Deploy Checklist: New Expensify 2021-09-28\n Issue body: **Release Version:** `1.1.2-9`\r\n**Compare Changes:** https://github.com/Expensify/App/compare/production...staging\r\n\r\n**This release contains changes from the following pull requests:**\r\n- [ ] https://github.com/Expensify/App/pull/5255\r\n- [ ] https://github.com/Expensify/App/pull/5302\r\n- [ ] https://github.com/Expensify/App/pull/5417\r\n- [ ] https://github.com/Expensify/App/pull/5473\r\n- [ ] https://github.com/Expensify/App/pull/5485\r\n- [ ] https://github.com/Expensify/App/pull/5495\r\n- [ ] https://github.com/Expensify/App/pull/5501\r\n- [ ] https://github.com/Expensify/App/pull/5513\r\n- [ ] https://github.com/Expensify/App/pull/5515\r\n- [ ] https://github.com/Expensify/App/pull/5517\r\n- [ ] https://github.com/Expensify/App/pull/5524\r\n- [ ] https://github.com/Expensify/App/pull/5535\r\n- [ ] https://github.com/Expensify/App/pull/5540\r\n- [ ] https://github.com/Expensify/App/pull/5558\r\n\r\ncc @Expensify/applauseleads\r\n\n Comments: \n Comment 0: Starting QA\n Comment 1: **Regression** is finished! \r\nIssues found: \r\n1. https://github.com/Expensify/App/issues/5580\r\n2. https://github.com/Expensify/App/issues/5577\r\n3. https://github.com/Expensify/App/issues/5579 \r\n\r\n**PRs** are finished too. \r\n1. https://github.com/Expensify/App/issues/5580 is failing https://github.com/Expensify/App/pull/5255\r\n\r\nThanks! \n Comment 2: Retest of https://github.com/Expensify/App/issues/5580 is a pass! \r\nChecking off: \r\n1. https://github.com/Expensify/App/issues/5580\r\n2. https://github.com/Expensify/App/pull/5584\r\n3. https://github.com/Expensify/App/pull/5255\n Comment 3: Nice! Closing this to trigger the deploy.\n Comment 4: This issue either has unchecked QA steps or has not yet been marked with the `:shipit:` emoji of approval.\nReopening!\n Comment 5: :shipit: ",
  "Issue title: Feature suggestion: exporting data directly to AWS S3\n Issue body: Not sure if it's possible or already available. Please let me know!\n Comments: \n Comment 0: Again, quite a delayed reply, but TCAT will not support this on the short-term.\r\n\r\nHowever, you could play around with FUSE. Mount an S3 backed partition under /var/www/dmi-tcat/analysis/cache and your CSV files should be directly stored in the Amazon cloud. Never tried it, but it should work.",
  "Issue title: Ability to render custom tags\n Issue body: So basically, I am using mistune to store my blog posts. And sometimes I have some images or iframes or other tags that I only use in that article. So I want to be able to render customly, using some syntax like : `~img-href\"link\"alt\"image\"~` and it would be parsed as `<img href=\"link\" alt=\"image\"`. It is not just for that tag but any custom tag we want to make, like `~anytag~` render as `<anytag>`. \n Comments: \n Comment 0: You can always use HTML in Markdown.",
  "Issue title: Sharing to group chats not possible\n Issue body: *Sent by 76672 (nelsonwhitney@example.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\nHello, thank you for working on this app.  \nOn the new update, you van only share via DM to accounts and not group chats. Could you please implement this feature? Thank you.  \n  \n  \n\n\n Comments: \n Comment 0: yes you can?",
  "Issue title: Enumerable.Single and Enumerable.SingleOrDefault overloaded implementations are inconsistent\n Issue body: There is an inconsistency between the implementations of [Enumerable.Single()][1] and [Enumerable.Single(predicate)][2]. Similarly there is another similar inconsistency between the implementations of [Enumerable.SingleOrDefault()][3] and [Enumerable.SingleOrDefault(predicate)][4]\r\n\r\nThe overloads which accept a predicate enumerate the whole sequence before eventually throwing, even if more than one matching elements were already found:\r\n\r\nFor consistency and performance reasons, it may be a good idea to make [Enumerable.Single(predicate)][2] and [Enumerable.SingleOrDefault(predicate)][4] methods able to fail fast and to throw an `InvalidOperationException` as soon as a second matching element is found.\r\n\r\nIf that seems like a reasonable change, I would gladly submit a pull request.\r\n\r\n  [1]: https://github.com/dotnet/corefx/blob/master/src/System.Linq/src/System/Linq/Enumerable.cs#L1260\r\n  [2]: https://github.com/dotnet/corefx/blob/master/src/System.Linq/src/System/Linq/Enumerable.cs#L1284\r\n  [3]: https://github.com/dotnet/corefx/blob/master/src/System.Linq/src/System/Linq/Enumerable.cs#L1306\r\n  [4]: https://github.com/dotnet/corefx/blob/master/src/System.Linq/src/System/Linq/Enumerable.cs#L1330\n Comments: \n Comment 0: There is a really old Connect report about that by Jon Skeet that was *Won't Fix*ed: https://connect.microsoft.com/VisualStudio/feedback/details/639955\n Comment 1: Hello Marcin,\r\n\r\nI found that Connect issue, as well as this one:\r\n\r\nhttps://connect.microsoft.com/VisualStudio/feedback/details/810457\r\n\r\nIn the issue you mention, the reason why it was marked as \"Won't fix\" seems to be related to bug triage/schedule/priority. The answer even states (in 2011) that this issue will be re-opened for a future release. So I thought that in 2015, given the context \u2013 i.e. CoreFx being open-source, Microsoft accepting pull requests, etc. \u2013 it could be a good thing to fix this minor issue.\n Comment 2: @AlekseyTs fixing this to early out seems reasonable, what do you think?\n Comment 3: :+1:\n Comment 4: This is a subset of #2349, and as such was fixed by #2350.",
  "Issue title: ERROR    ReferenceError: Can't find variable: r\n Issue body: Whenever I run my React Native project (after removing node_modules,.gradle,.idea, android/app/build, android/build)\r\nI get the following error in my metro server:\r\n\r\n```\r\ninfo Reloading app...\r\n[Fri Jun 11 2021 14:46:49.120]  BUNDLE ./index.js \r\n\r\n[Fri Jun 11 2021 14:46:50.778]  ERROR    ReferenceError: Can't find variable: r\r\n[Fri Jun 11 2021 14:46:50.780]  ERROR    Invariant Violation: Module AppRegistry is not a registered callable module (calling runApplication)\r\n[Fri Jun 11 2021 14:46:50.782]  ERROR    Invariant Violation: Module AppRegistry is not a registered callable module (calling runApplication)\r\n```\r\n\r\nexported = true is in all my activity entries in manifest:\r\n\r\n```\r\n<activity android:name=\"com.facebook.react.devsupport.DevSettingsActivity\" \r\n      android:exported=\"true\"/>\r\n```\r\n\r\nThis is my package.json:\r\n\r\n```{\r\n  \"name\": \"HeraMedica\",\r\n  \"version\": \"0.0.1\",\r\n  \"private\": true,\r\n  \"scripts\": {\r\n    \"android\": \"react-native run-android\",\r\n    \"ios\": \"react-native run-ios\",\r\n    \"start\": \"react-native start --reset-cache\",\r\n    \"test\": \"jest\",\r\n    \"lint\": \"eslint.\",\r\n    \"postinstall\": \"patch-package\"\r\n  },\r\n  \"dependencies\": {\r\n    \"@react-native-async-storage/async-storage\": \"^1.15.4\",\r\n    \"@react-native-community/clipboard\": \"^1.5.1\",\r\n    \"@react-native-community/datetimepicker\": \"^2.6.2\",\r\n    \"@react-native-community/masked-view\": \"^0.1.10\",\r\n    \"@react-native-community/netinfo\": \"^6.0.0\",\r\n    \"@react-native-google-signin/google-signin\": \"^6.0.0\",\r\n    \"@react-native-picker/picker\": \"^1.15.0\",\r\n    \"@react-navigation/drawer\": \"^5.12.5\",\r\n    \"@react-navigation/material-top-tabs\": \"^5.3.15\",\r\n    \"@react-navigation/native\": \"^5.9.3\",\r\n    \"@react-navigation/stack\": \"^5.14.3\",\r\n    \"moment\": \"^2.29.1\",\r\n    \"patch-package\": \"^6.4.7\",\r\n    \"postinstall-postinstall\": \"^2.1.0\",\r\n    \"react\": \"16.13.1\",\r\n    \"react-native\": \"0.63.4\",\r\n    \"react-native-crypto-js\": \"^1.0.0\",\r\n    \"react-native-fbsdk\": \"^3.0.0\",\r\n    \"react-native-gesture-handler\": \"^1.10.3\",\r\n    \"react-native-keyboard-aware-scroll-view\": \"^0.9.4\",\r\n    \"react-native-linear-gradient\": \"^2.5.6\",\r\n    \"react-native-localize\": \"^2.1.0\",\r\n    \"react-native-material-dropdown\": \"^0.11.1\",\r\n    \"react-native-material-textfield\": \"^0.16.1\",\r\n    \"react-native-modal-datetime-picker\": \"^9.2.3\",\r\n    \"react-native-pager-view\": \"^5.1.10\",\r\n    \"react-native-picker-select\": \"^8.0.4\",\r\n    \"react-native-reanimated\": \"^2.1.0\",\r\n    \"react-native-safe-area-context\": \"^3.2.0\",\r\n    \"react-native-screens\": \"^2.18.1\",\r\n    \"react-native-switch\": \"^2.0.0\",\r\n    \"react-native-tab-view\": \"^3.0.1\",\r\n    \"react-native-table-component\": \"^1.2.1\",\r\n    \"react-redux\": \"^7.2.2\",\r\n    \"redux\": \"^4.0.5\",\r\n    \"redux-persist\": \"^6.0.0\",\r\n    \"redux-thunk\": \"^2.3.0\"\r\n  },\r\n  \"devDependencies\": {\r\n    \"@babel/core\": \"^7.8.4\",\r\n    \"@babel/runtime\": \"^7.8.4\",\r\n    \"@react-native-community/eslint-config\": \"^1.1.0\",\r\n    \"babel-jest\": \"^25.1.0\",\r\n    \"eslint\": \"^6.5.1\",\r\n    \"jest\": \"^25.1.0\",\r\n    \"metro-react-native-babel-preset\": \"^0.59.0\",\r\n    \"react-test-renderer\": \"16.13.1\"\r\n  },\r\n  \"jest\": {\r\n    \"preset\": \"react-native\"\r\n  }\r\n}\r\n```\r\nI don't have a clue where this error is coming from.\n Comments: \n Comment 0: Seeing to AppRegistry.js, there are lots of errors because typeScript support is not there. Is this the reason of the error?\n Comment 1: For type-script support, this is a mandate that file should have.tsx extension.\r\nWhen I tried it with AppRegistry.js => AppRegistry.tsx, certain import, type errors were still there, then I thought type-script support is not needed. ReactNative handles it easily. I have seen certain AweSomeProject examples that use action script but ReactNative compiles it easily.",
  "Issue title: Feature Request - HomeKit/Siri to control Alexa\n Issue body: Amazing plugin!  But, I am wondering if there is any way to do the reverse of the communication and allow HomeKit/Siri to control Alexa-enabled devices?  Thoughts?\n Comments: \n Comment 0: This is totally unfeasible as Alexa controlled devices are using the vendors cloud to talk to Alexa, and it isn\u2019t something I have systemic acces to. There may be one off devices where someone reverse engineers the api\u2019s Like Tuya, but it is not something where could do wholesale.",
  "Issue title: LinkageError \"Make sure you're not using this jar for multiple server instances!\"\n Issue body: [ProtocolLib] Encountered a LinkageError. Make sure you're not using this jar for multiple server instances!\r\n- Server is using latest dev build of ProtocolLib (4.2.1)\r\n- Minigame server will sometimes be unjoin-able for [Proxy] Lost connection to server\r\nError Log:\r\nhttps://puu.sh/vqPtT/7be38a0dda.txt\r\n\r\nProtocol Dump:\r\nhttps://puu.sh/vqQ46/0c435fe81e.txt\n Comments: \n Comment 0: I suppose the first question is are you using it for multiple server instances?\n Comment 1: No, each server uses its own protocolLib jar\n Comment 2: Hmm well this is new. Unfortunately, linkage errors are notoriously difficult to pin down. My first guess is that it has to do with \"MineHeroesSpigot\". Could you try using regular Spigot and see if the problem persists?\n Comment 3: Any more info on this?\n Comment 4: got the same issue, it happen only with my factions server in rare case (i am using 1.8.8 + viaversion) using 4.2.0\r\nhttps://hastebin.com/zowusigobu.md\n Comment 5: Hello,\r\ni have the same problem\n Comment 6: Same issue with us.\n Comment 7: This issue is still not fixed. \n Comment 8: Issue is not fixed, happen more often with factions server and rarely in other server",
  "Issue title: New-BTText with style adds characters to the content\n Issue body: Hello,\r\n\r\nIf you run the following code you end up with an initial { before the text you specify:\r\nNew-BTText -Text 'My Text' -Style Title\r\n\r\nWhich style i use does not seem to matter but i didnt try them all.\r\n\r\nI am using:\r\nWindows 10 1803 with latest CU\r\nWindowsPowershell 5.1\r\nBurntToast 0.6.2\n Comments: \n Comment 0: Hmm, after an update of the UWP toolkit a long time ago it started adding curly braces to text, and I had to add some code to strip them out. However, looks like specifying a style adds more braces than I was expecting...\r\n\r\nI'll look at a fix, I also need to check to see that these styles have actually been implemented correctly, as they don't appear to have any effect on the style of the text.\r\n\r\nGiven they don't seems to have much effect anyway, other than adding that stray brace, workaround for now is to not specific a laceyjones@example.org.\n Comment 1: It's amazing what 20/20 hindsight will get you. Those curly braces were coming from \"bindable\" strings which is the backbone for updating toasts.\r\n\r\nI'm now properly supporting this bindable text (rather than just brute-forcing the curly braces away), and styles are no longer resulting in what you were seeing.\r\n\r\nThis is all wrapped up in the next release (0.7.0), so keep an eye out for that!\r\n\r\nn.b. Styles still don't seem to *do* anything, but I've left them in so as to not break things is people have specified them.\n Comment 2: I'm still getting curly brackets around my title and my text, even with the simplest notification.\r\n\r\n`New-BurntToastNotification -SuppressPopup -UniqueIdentifier'skyline' -AppLogo D:\\XAMPP\\htdocs\\root\\skyline\\favicon.ico -Text 'Skyline Notifier', '%retVar%'`",
  "Issue title: Using the API in other software?\n Issue body: Hi, not sure if this is the right place to ask, but I just wanted to make sure it was ok to use the site's API for a feature in the Elm extension for VSCode [sbrink/vscode-elm](https://github.com/sbrink/vscode-elm/). It would basically mean downloading http://package.elm-lang.org/all-packages.\n\nThanks :)\n\n Comments: \n Comment 0: I think that is okay. Thanks for asking, and try to treat our servers nice!\n",
  "Issue title: Particle Editor - New particles are not rendered correctly\n Issue body: When you create a new particle emitter, the setting for Soft Distance is set to 1000. This causes the particle to render as if it's behind most or all objects in your scene. If anything is in front of it besides sky, which there usually is, the particles do not render.\n\nExpected: The default settings for a new emitter are set so the emitter is visible.\n\nSteps to reproduce:\n1. Open the World editor.\n2. Open the particle editor.\n3. Create a new particle emitter.\n4. Observe the particles draw behind everything but the skybox.\n\n Comments: \n Comment 0: Resolved with pr #489 \n",
  "Issue title: Implement transactions\n Issue body: tx_select\r\ntx_commit\r\ntx_rollback\r\n\n Comments: \n Comment 0: Requires #81 ",
  "Issue title: SEC-1166: Provide strategy interface for AclImpl isGranted() method. \n Issue body: [Luke Taylor](https://jira.spring.io/secure/ViewProfile.jspa?name=luke) (Migrated from [SEC-1166](https://jira.spring.io/browse/SEC-1166?redirect=false)) said:\n\nThis will allow more flexibility in the way the permission bitmasks are evaluated. The existing auditLogger should be moved to the default implementation, as this is the only place logging occurs in AclImpl.\n\n Comments: \n Comment 0: [Luke Taylor](https://jira.spring.io/secure/ViewProfile.jspa?name=luke) said:\n\nDone. See \"source\" tab for information.\n\n Comment 1: [Bojan Tomic](https://jira.spring.io/secure/ViewProfile.jspa?name=veggen) said:\n\nDoes this mean providing a bitwise comparing strategy is a safe thing to do?\n\n Comment 2: [Peter Rietzler](https://jira.spring.io/secure/ViewProfile.jspa?name=prietzler) said:\n\nIt would be nice if DefaultPermissionGrantingStrategy would contain a template method in order to decide if a permission is contained in the given mask - see \nhttps://gist.github.com/oliverfernandez/36846fcdc03696a7b829\nwhich is a copy with a new method containsPermission. If DefaultPermissionGrantingStrategy would adopt this with a protected version of containsPermission it would be easier to add stuff like bit-wise permission checking etc.\n\n Comment 3: \n\nThis issue supersedes #740",
  "Issue title: GUI for header filters\n Issue body: Currently JSON and Avro filters can be added via Hermes-console. Thanks to #753 we can also add Header filters via REST API. Unfortunately, Header filters aren\u2019t supported via GUI. It would be nice to have this support in Hermes-console. Furthermore, it should be enabled/disabled by configuration as not all environments have to support Headers filters.\n Comments: \n Comment 0: Hi, can I take this one?\n Comment 1: @qrman sure, you can\n Comment 2: @druminski Can you explain what do you mean by saying: `it should be enabled/disabled by configuration as not all environments have to support Headers filters`?\r\n\r\nShould filtering section be visible only when some flag in configuration is set? Does Hermes (`SubscriptionEndpoint`) throw any exception when headers filters are set and environment doesn't support filtering?",
  "Issue title: Doubts regarding the library\n Issue body: Hi,\r\n\r\nWe are trying to use this library and would like to know if it will be easy to modify the library to do the following:\r\n\r\n1) We run a FORTH script, but only partially.\r\n2) We store the VM in memory.\r\n3) We restore the VM from memory\r\n3) We resume the script at the point we previously finished, using the return stacks, the latest instruction we were running, the latest word, etc,...\r\n\r\nAfter our tests, it seems that the library resets the stacks each time we execute an script we can not execute partial scripts or limit the amount of instructions we execute each time.\r\n\r\nThanks,\r\n\n Comments: \n Comment 0: Hi Richard, thanks for you quick answer. I detail below what we are trying to achieve.\r\n\r\n1) We are using libforth inside another program.\r\n2) We use the features it has to save/load from memory.\r\n3) We work on Linux/Ubuntu.\r\n4) We already noticed that there are issues with the return stack :-(, seems not saved and the VM, when resumed does not take into account it and reads directly the next input script instead of executing first the pending instructions and then move to parsing new text (this is the main feature we are interested in).\r\n5) Our logic does the following:\r\n- Reads an input script\r\n- Loads VM from memory (or creates a new one if none) and executes it.\r\n- We want to limit the number of instructions that are executed each cycle, so after N instructions, we save everything and resume later. Here is where it is important to save correctly the return stack and then when resumed, execute first the pending instructions (taken from return stack) before moving to next text token.\r\n5) There is no problem controlling the number of instructions we execute in each cycle, we can control it adding small tweaks to the code, I think that even we are able to save the return stack just not initializing the RSTK register, the problem we are facing now is at the resume step, the VM should go first to the RSTK and execute any pending call stored in the return stack before moving into the READ instruction.\r\n\r\nHope this helps to understand our issue:\r\n1) We need to save the return stack when VM is saved into memory.\r\n2) We need to continue at the return stack when resumed, and execute any pending instruction before moving ahead to READ (parse more text).\r\n\r\nThanks a lot\r\nCarlos\n Comment 1: I still do not quite understand what you are trying to do. The functions 'forth_save_core_memory' and 'forth_load_core_memory' are just analogues to 'forth_save_core_file' and 'forth_load_core_file', they are for the serialization to disk (for the file functions, or to other mediums for the memory functions),  you shouldn't be calling them inbetween halting and resuming execution for 'N' cycles.  'forth_run' does not reset the return stack between calls, so the logic should be:\r\n\r\n      /* Error checking omitted */\r\n      forth_t *f = forth_load_core_file(\"your.core\");\r\n      FILE *my_script = fopen(\"script.fth\", \"rb\");\r\n      forth_set_file_input(f, script);\r\n      while(true) {\r\n           forth_run(f); /* Modified version of forth_run() to only run for, say 1000 cycles */\r\n           do_some_other_stuff();\r\n      }\r\n\r\nThe position in the script (a FILE*) and the return stack (held in m[RSTK]) should not change between calls. So do not need modifying.\r\n\r\nOr do you mean you need to resume execution at the same point after saving to disk?\r\n\r\nThe code to exit after a 1000 cycles in the main loop will have to look like this:\r\n\r\n      for(;(pc = m[ck(I++)]);) {\r\n           if(cycle_count++ > N) {\r\n                    I--;\r\n                    o->m[INSTRUCTION] = I;\r\n                    goto end;\r\n           }\r\n           /*... The rest of the interpreter... */\r\n      }\r\n\r\nDoes this help? Or have I misunderstood what you are trying to do? It would help if I could see the code? (it would not need to be public).\r\n\r\n\n Comment 2: Hi Richard.   Just to give you a little more background, Carlos and I are developing a multiplayer space game that teaches players to code using FORTH.   You're welcome to take at our GitHub project here: https://github.com/Darwin-River/Ex-Machinis \r\n\r\nOur goal is to have players develop increasingly complex dictionaries to control fleets of remotely piloted drones on the edges of the solar system.  As such, we need a compact FORTH interpreter that can rapidly cycle between each of the in-game spacecraft as they execute the contents of their own VMs.\r\n\r\nWe started using your libforth and ran into problems when we tried to pause and return to a VM that was in the middle of executing a user-supplied script.  The problem occurs when we try to switch between paused VMs that are stored in an SQL DB when not being processed by the interpreter.\r\n\r\nYou suggest above that we consider using a16-bit FORTH interpreter that you\u2019re also developing.  This sounds like it might actually be a better solution since it\u2019s compact and already contains a functioning stack.  \r\n\r\nI\u2019m just wondering, before we decide to switch over to embed, what are the primary differences between libforth and embed? Would embed work better with our system of shuffling paused VMs in and out of DB?\r\n\r\nThanks for helping us work through this problem!\r\n\r\nDave\r\n\n Comment 3: Hello!\r\n\r\nOk, this makes more sense, it would make a lot more sense to use the embed project, at https://github.com/howerj/embed, for multiple reasons.\r\n\r\n1) It's smaller and easier for you to understand, it's also much more like a traditional Forth.\r\n2) If you look at 'libforth', the virtual machine has instructions like 'SYSTEM', which would allow the user\r\nto run arbitrary commands on your server, but that's not the only security issue. The embed project wasn't designed for security either - but given how simple it is, it would be much easier to modify to suite your requirements. If I understand the games architecture many people would submit\r\ncommands/scripts via email to an instance of the server which hosts the game, if that's right security is going to be one of your concerns.\r\n3) Users could provide their own images and target the Virtual Machine if they are not happy\r\nwith the Forth interpreter it provides. As you can see, the entire program is only 200 LOC, and\r\ncould be your games version of https://en.wikipedia.org/wiki/0x10c.\r\n\r\n'embed' would work better, but it still needs modifications (although they would be minor). \r\n1). Remove the 'assert(!(sp & 0x8000) &&!(rp & 0x8000))' in the 'embed_forth()' main loop. This won't stop the variable stack (sp) and return stack pointer (rp) from going where they shouldn't but it will stop it from taking down the interpreter.\r\n2). Move and modify the definition of 'forth_t' to the 'embed.h' header:\r\n\r\n      typedef struct forth_t { uw_t pc, t, rp, sp, core[CORE/sizeof(uw_t)]; } forth_t;\r\n\r\nbecomes:\r\n\r\n      typedef struct forth_t { uw_t pc, t, rp, sp, core[CORE]; } forth_t;\r\n\r\nThis (should) prevent the virtual machine from accessing out of bounds memory.\r\n\r\n3) You'll want to comment out the 22 VM instruction, which saves to disk (but do not reuse this\r\ninstruction!).\r\n\r\n4) After the for loop you will need to add a 'goto finished' after your cycle timer has run out.\r\n\r\n5) You'll need to make similar modifications to the input/output functions that you made to 'libforth', although there should be only two VM instructions which you need to modify, 'fputc' and 'fgetc', which should be easier.\r\n\r\nTo run this you will need both the virtual machine, and the provided image, 'eforth.blk', if you want\r\nto add VM instructions the process is more complicated than it would be with 'libforth', and would require a lit bit of an understanding of how to generate new images with the metacompiler in'meta.fth', which would be the biggest complication. I can help you out with that, but as you know my time is limited at the moment due to a new job/move (I'll have more free time in a couple of weeks!).\r\n\r\nIf you do want to continue using 'libforth', I can make some more recommendations, it does not look like you have added the code that I suggested though? Did it work or not?\r\n\r\nThanks,\r\nRichard Howe\n Comment 4: Hi Carlos,\n\nYes it would be possible, if you make the changes I've suggested, which\nI can check. You'll need to write your own serialization routines to\nsave the state",
  "Issue title: Proposal: Add \"lock\" or \"no delete\" flag to container\n Issue body: Sometimes you have really important containers, like data only containers, that you don't want accidentally deleted.  `docker rm -f $(docker ps -qa)` is just too easy to type sometimes and then, \"oh!@#!\", it's all gone.  (Well not really because you can find your data in `/var/lib/docker/vfs`).  Anyhow, I propose we add the following:\r\n\r\n`docker run/create --lock=true...`\r\n`docker lock CID`\r\n`docker unlock CID`\r\n\r\nIf one was to do `docker rm CID` and CID was locked it wouldn't delete and exit with an error code.  Start/stop/restart should still work.  This flag is the equivalent of EC2's `DisableApiTermination` flag.  In order to delete a locked container you must first run `docker unlock CID`.\n Comments: \n Comment 0: A PR for this was created some time ago, but voted against by Solomon; https://github.com/docker/docker/pull/7523#issuecomment-59592874 not sure if he's still against it?\n Comment 1: Thanks @thaJeztah, you're an encyclopedia of Docker PRs.\n Comment 2: @shykes You already said no to this in https://github.com/docker/docker/pull/7523#issuecomment-59592874, but I'd like you to reconsider.  We could use a special label for this, but just as you said you don't like \"pin\" as it seem very specific, along the some lines, I don't really like magic label names.  Labels should really be used for things above/outside of Docker engine.\r\n\r\nI usually look at AWS for a good litmus test as whether a specific piece of API functionality is a good idea.  While AWS isn't perfect, they have a very good track records of making extremely thoughtful changes to their API.  EC2 has this similar concept with DisableApiTermination but I think we can make this a bit more generic with \"lock\".  With \"lock\" meta data of any kind (nothing is really all that changeable at the moment) should not be modifiable.  This is really no different than when you do `chmod 400` on a file.  As the owner, you could change the file, but you want to put a little bit of a safety net around modifications.\n Comment 3: This is definitely a big one for clean up. There is otherwise no way to do clean up operations when you are running multiple things on the same host and too much cruft builds up quickly when continuously deploying things. \n Comment 4: +1\n Comment 5: +1\n Comment 6: This would be *really* nice for swarm clusters so that users/operators don't accidentally delete the `swarm` daemons.\n Comment 7: :+1: @rgbkrk \n Comment 8: :+1: \r\n\r\nThis is something that's necessary to avoid the dreaded [Fat Finger Error](https://en.wikipedia.org/wiki/Fat-finger_error).\n Comment 9: +1\n Comment 10: *USER POLL*\n\n*The best way to get notified when there are changes in this discussion is by clicking the Subscribe button in the top right.*\n\nThe people listed below have appreciated your meaningfull discussion with a random +1:\n\n@cecitorres\n@flaccid\n@alanfung\n Comment 11: Definitely a way to protect volumes from deletion is a feature that I personally need before using volumes to host production data. Otherwise the risk of accidentally deleting them while removing a container is too high.\r\n\r\nTLDR: :+1:\n Comment 12: @nivox Deleting a container does not delete its volumes unless you do so explicitly `docker rm -v`.\n Comment 13: @cpuguy83 I'm aware of that, but when you have a production servers with tens of container, some of which have unimportant volumes associated with them while others have volumes hosting production data, using the `-v` flag on the wrong container is not an unthinkable occurrence.\r\n\r\nFurthermore the current  approach doesn't work all that well in case you have a Dockerfile extending a third party image defining a bunch of volumes that, for whatever reason, you don't really care about. In your Dockerfile however you define a volume that will hold production data.\r\n\r\nYou create a container off of the image you obtain ending up with:\r\n\r\n- *baseVolume1,..., baseVolumeN*: you might not care about them\r\n- *dataVolume*: you REALLY want this NOT to be deleted\r\n\r\nNow when it's time to update the container (new image version), you would like to cleanup all the *baseVolume* while keeping *dataVolume*. Right now you have to manually delete volumes (i.e. `docker volume rm baseVolume`) and then remove the container without the `-v` flag.\r\n\r\nAn explicit way of marking a volume as protected (i.e. `docker volume pin <volume-id>`) would prevent accidental deletion due to distraction (i.e. `docker rm -v <wrong-container>`) as well as making life easier in cleaning up unimportant volumes.\n Comment 14: +1\n Comment 15: Where are we now with this proposal?\r\n\r\nI'm also in favour of having a lock mechanism, despite this seems controversial. I disagree with the fact that further level of classification (multiple security levels) might be required, since removal is a binary operation (possible/not possible).\r\n\r\nAnother permission-managed operation could be `read` vs. `write` but I'm not sure it makes sense regarding docker, so for now the `deletable` seems to do the trick.\n Comment 16: Yes, I [support a more explicit lock mechanism](https://github.com/docker/docker/issues/17907#issuecomment-163703811). However, an implicit mechanism was added in #19568 so that `--rm` will not remove named volumes. A [note was added to the docs to explain](https://github.com/docker/docker/blob/master/docs/reference/run.md#clean-up---rm), but it's still a confusing/surprising and sometimes dastardly behavior to have volumes (even inherited ones) destroyed unexpectedly.\r\n\r\nAs a result, newcomers to docker must understand more of the counterintuitive intricacies of docker volumes and docker data containers. From what I've seen, this behavior may have been part of the reason for the rise of data containers -- an additional abstraction around volumes -- when volumes with an explicit lock would have been sufficient. \r\n\r\ntl;dr: use names for your volumes.\n Comment 17: LOL, got a email notification about somebody talking about \"locking\" containers and was like, \"I'm totally going to plus 1 that issues/PR.\"  Come to find out, it's mine from 2 years ago :(\n Comment 18: Following this discussion, and others (w.r.t. `docker system prune`), perhaps it should be looked at in a wider scope; being able to lock other objects (volumes, networks, secrets, containers, images)\n Comment 19: test\n Comment 20: :+1: \n Comment 21: +1, this is a major problem with using `docker system prune` to clean up. It removes any volumes not attached to a container, so if for some reason your container happens to have stopped when you prune, your data is gone. I've already lost data to this more than once. A feature to mark volumes as important, so they aren't removed during normal cleanup, would solve this problem.\n Comment 22: @ryannoblett `docker system prune` will no longer automatically prune volumes (you have to specify it with a flag). You can also provide filters to the prune command. You can specify a default set of filters in your CLI config.\r\n\r\nNot a 100% perfect solution, but should be ok for most scenarios.\n Comment 23: +1 I use Docker for development purposes in my computer and I do a lot of testing (a hell lot of testing) with containers. BUT I keep a few untouched, like databases and libraries. Sometimes I do some cleaning but it's a PITA to cherry pick the ones that should not be touched. This feature would really save some time among dev teams.\n Comment 24: +1 I use Docker for development purposes in my computer and I do a lot of testing (a hell lot of testing) with containers. BUT I keep a few untouched, like databases and libraries. Sometimes I do some cleaning but it's a PITA to cherry pick the ones that should not be touched. This feature would really save some time among dev teams.\n Comment 25: @pepBR \r\n\r\n> You can also provide filters to the prune command. You can specify a default set of filters in your CLI config.\n Comment 26: @cpuguy83 Couldn't find an example of how to prevent deleting containers using prune filters and using CLI config. Can you point me to the right direction?\n Comment 27: `docker container prune --filter label!=foo=bar` -- This would filter out containers that have a label where `foo=bar`\r\nYou can also do `label!=foo` (no value) and it would filter out any container that has a `foo` label regardless of the value.\r\n\r\nYou can also add",
  "Issue title: Function name `scatter` conflics\n Issue body: The function name `scatter` in DistributedArrays conflicts with the `scatter` function in, say, 80% of all julia's plotting packages (for making scatter plots). Would it be possible to rename to something unambiguous, such as `distribute`?\n Comments: \n Comment 0: It's a pretty standard parallel computing concept/function though. I think a solution could be not to export the `SPMD` functions from the `DistributedArrays` module. Then this will only become an issue when people use `DistributedArrays.SPMD`.\n Comment 1: Yes I think the SPMD code might actually be a good example for a separate package, (but still in the same repository.)",
  "Issue title: Example 2.12 Comparison operators, line 8, shows extraneous markup\n Issue body: I think that line 8 in example 2.12:\n\n```\nfoo == baz;   <span class=\"bold\"><strong>// returns true; careful!</strong></span>\n```\n\nshould read:\n\n```\nfoo == baz;   // returns true; careful!\n```\n\n(Maybe the word \"careful!\" is meant to be highlighted?)\n\n Comments: \n Comment 0: I think this is only an issue when this content was in jqfundamentals with syntaxhighlighter. Once/if this chapter is switched to markdown, we will be all good.\n\n Comment 1: Issue is still present, should probably be changed for professionalism :)\n\n Comment 2: Fixed: https://github.com/jquery/web-learn-jquery-com/commit/888eec012e631187f090937f88ea73f50dc096d9\n\nPlease remember that as per @gjohnson's last message, we're going to be moving to only having markdown based files in these folders with compiled versions being available in the built version of the site at some point. Right now theres a combination of precompiled older chapters and separated onces that have been since updated hanging. We should aim to do a clean-up at some point.\n",
  "Issue title: Cant get fin init to work, ERROR: network ebs_default id ### has active endpoints\n Issue body: **Description**\r\n\r\nI cant get passed `fin init` or `fin project remove` due to error. It happens only in one project.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n1. Started VM with `fin vm start`\r\n2. Typed `fin init` or `fin project remove`\r\n3. Error happen\r\n\r\n**Describe the results you received:**\r\n\r\n``` alex@alexs-mbp \ue0b0 ~/projects/ffw/ebs \ue0b0 \ue0a0 master \ue0b0 fin init\r\n Step 1  Initializing local project configuration...\r\n/Users/alex/projects/ebs/docroot/sites/default/settings.local.php already in place.\r\n Step 2  Recreating services...\r\nRemoving containers...\r\nRemoving ebs_web_1    ... done\r\nRemoving ebs_cli_1    ... done\r\nRemoving ebs_varnish_1... done\r\nRemoving ebs_db_1     ... done\r\nRemoving network ebs_default\r\nERROR: network ebs_default id de61849dbc2b1bc0c224a5a458e0367b2ad6a2c52b79925e833ea7c0019cac23 has active endpoints\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\nI expected my `fin init` command to pass like ususal.\r\n\r\n**Output of `fin config`:**\r\n\r\n<details>\r\n  <summary>fin config output</summary>\r\n\r\n```\r\n---------------------\r\nCOMPOSE_PROJECT_NAME_SAFE: ebs\r\nCOMPOSE_FILE:\r\n/Users/alex/.docksal/stacks/volumes-bind.yml\r\n/Users/alex/projects/ebs/.docksal/docksal.yml\r\nENV_FILE:\r\n/Users/alex/projects/ebs/.docksal/docksal.env\r\n/Users/alex/projects/ebs/.docksal/docksal-local.env\r\n\r\nPROJECT_ROOT: /Users/alex/projects/ebs\r\nDOCROOT: docroot\r\nVIRTUAL_HOST: ebs.docksal\r\nVIRTUAL_HOST_ALIASES: *.ebs.docksal\r\nIP: 116.69.203.115\r\nMYSQL:\r\n\r\nDocker Compose configuration\r\n---------------------\r\nservices:\r\n  cli:\r\n    environment:\r\n      XDEBUG_ENABLED: '1'\r\n    hostname: cli\r\n    image: docksal/cli:1.3-php7\r\n    volumes:\r\n    - docksal_ssh_agent:/.ssh-agent:ro\r\n    - project_root:/var/www:rw\r\n  db:\r\n    environment:\r\n      MYSQL_DATABASE: ebs\r\n      MYSQL_PASSWORD: '123'\r\n      MYSQL_ROOT_PASSWORD: admin123\r\n      MYSQL_USER: drupal\r\n    hostname: db\r\n    image: docksal/db:1.0-mysql-5.5\r\n    ports:\r\n    - 0:3306/tcp\r\n    volumes:\r\n    - project_root:/var/www:ro\r\n  varnish:\r\n    environment:\r\n      VARNISH_BACKEND_HOST: web\r\n    hostname: varnish\r\n    image: docksal/varnish:1.0-varnish4\r\n    labels:\r\n      io.docksal.virtual-host: varnish.ebs.docksal\r\n    volumes:\r\n    - /Users/alex/projects/ebs/.docksal/etc/varnish/default.vcl:/opt/default.vcl:ro\r\n  web:\r\n    depends_on:\r\n      cli:\r\n        condition: service_started\r\n    environment:\r\n      APACHE_DOCUMENTROOT: /var/www/docroot\r\n      VIRTUAL_HOST: ebs.docksal\r\n    hostname: web\r\n    image: docksal/web:1.0-apache2.2\r\n    labels:\r\n      io.docksal.project-root: /Users/alex/projects/ebs\r\n      io.docksal.virtual-host: ebs.docksal\r\n    volumes:\r\n    - project_root:/var/www:ro\r\nversion: '2.1'\r\nvolumes:\r\n  docksal_ssh_agent:\r\n    external: true\r\n    name: docksal_ssh_agent\r\n  project_root:\r\n    driver: local\r\n    driver_opts:\r\n      device: /Users/alex/projects/ebs\r\n      o: bind\r\n      type: none\r\n\r\n---------------------\r\n\r\n```\r\n\r\n</details>\r\n\r\n<br>\r\n\r\n**Output of `fin sysinfo`:**\r\n\r\n<details>\r\n  <summary>fin sysinfo output</summary>\r\n\r\n  ```\r\n   alex@alexs-mbp \ue0b0 ~/projects/eastern-bank-micro-site \ue0b0 \ue0a0 master \ue0b0 fin sysinfo\r\n\u2588\u2588\u2588  OS\r\nDarwin Mac OS X 10.13.4\r\nDarwin alexs-mbp 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\nMode: VirtualBox VM\r\n\r\n\u2588\u2588\u2588  FIN\r\nfin version: 1.60.2\r\n\r\n\u2588\u2588\u2588  ENVIRONMENT\r\nDOCKER_HOST\t\t| tcp://116.69.203.115:2376\r\n------------------------------------------------------------\r\nDOCKSAL_NFS_PATH\t| \r\n\r\n\u2588\u2588\u2588  DOCKER\r\nEXPECTED VERSION: 18.03.1-ce\r\n\r\nClient:\r\n Version:      18.03.1-ce\r\n API version:  1.37\r\n Go version:   go1.9.5\r\n Git commit:   9ee9f40\r\n Built:        Thu Apr 26 07:13:02 2018\r\n OS/Arch:      darwin/amd64\r\n Experimental: false\r\n Orchestrator: swarm\r\n\r\nServer:\r\n Engine:\r\n  Version:      18.06.0-ce-rc1\r\n  API version:  1.38 (minimum version 1.12)\r\n  Go version:   go1.10.3\r\n  Git commit:   20580f1\r\n  Built:        Thu Jun 28 06:25:00 2018\r\n  OS/Arch:      linux/amd64\r\n  Experimental: false\r\n\r\n\u2588\u2588\u2588  DOCKER INFO\r\nContainers: 46\r\n Running: 6\r\n Paused: 0\r\n Stopped: 40\r\nImages: 19\r\nServer Version: 18.06.0-ce-rc1\r\nStorage Driver: aufs\r\n Root Dir: /mnt/sda1/var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 396\r\n Dirperm1 Supported: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: cbef57047e900aeb2bafe7a634919bec13f4a2a5\r\nrunc version: 69663f0bd4b60df09991c08812a60108003fa340\r\ninit version: fec3683\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\nKernel Version: 4.9.93-boot2docker\r\nOperating System: Boot2Docker 18.06.0-ce-rc1 (TCL 8.2.1); HEAD : 17a6556 - Mon Jul  2 17:23:14 UTC 2018\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 1\r\nTotal Memory: 3.764GiB\r\nName: docksal\r\nID: ZL7Q:ZB3D:6LNI:VLQI:RFHG:J576:KBAL:QJW4:RWPD:DYUE:HHFU:VDXH\r\nDocker Root Dir: /mnt/sda1/var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nLabels:\r\n provider=virtualbox\r\nExperimental: false\r\nInsecure Registries:\r\n 917.461.8284\r\nLive Restore Enabled: false\r\n\r\n\u2588\u2588\u2588  DOCKER COMPOSE",
  "Issue title: Thought not re-rendered after attributes load\n Issue body: ## Steps to Reproduce\r\n\r\n```\r\n- a\n- b\n  - =bullet\n    - None\n  - =pin\n    - true\n  - =styleContainer\n    - color\n      - pink\n  - c\n```\n\nImport and refresh the page. \r\n\r\n## Current Behavior\r\n\r\n`b` has a bullet and is not pink. \n\r\n## Expected Behavior\r\n\r\n`b` should not have a bullet and should be pink. \n\nThoughts should be re-rendered when `=bullet` or `=styleContainer` are loaded.\n Comments: \n Comment 0: Fixed in abeded016b, a71d8e9604, and 809978f05a",
  "Issue title: Showing the differentiating property of an event in Funells Insights\n Issue body: ## Is your feature request related to a problem?\r\n\r\nWhen creating a conversion chart with events of the same type (like `$screen`) with different parameters (like the screen name) only the event type is displayed and this makes it very hard to understand where the users are dropping off.\r\n\r\n![image](https://user-images.githubusercontent.com/6215122/141483112-8bca1b73-4ebf-4707-9980-bd992fcbd12c.png)\r\n\r\n\r\n## Describe the solution you'd like\r\n\r\nAmplitude shows the event parameter in parenthesis so that it's easy to see where the user is dropping off.\r\n\r\n![image](https://user-images.githubusercontent.com/6215122/141483679-cd7e430d-c6d7-4e58-9e24-8c53aeed44c3.png)\r\n\r\n#### *Thank you* for your feature request \u2013 we love each and every one!\r\n\n Comments: \n Comment 0: Thanks for this @savy-91! Makes sense to clean this up\n Comment 1: I have been thinking on how best it would be to proceed to improve this (I was thinking of creating a PR for it) and here are a couple of options (not mutually exclusive):\r\n\r\n- Allow users to set a custom name for the step regardless of the event that is being tracked\r\n- Display all filters (if there are) in the step either as a popover or text\r\n- Only display filters if there is just a WHERE clause (like the Amplitude example)\n Comment 2: Oh that's awesome, thanks for the interest!\r\n\r\nTagging @alexkim205 who did some similar work to provide more guidance\n Comment 3: Hi @savy-91 glad you asked! There is a new feature that we're rolling out that allows you to give filters/steps custom names which I think will solve your use case here. \r\n\r\nWe can add you to our beta testers if you'd like to try it out? If so, just let me know what your email address is so that I can add you. \n Comment 4: > Hi @savy-91 glad you asked! There is a new feature that we're rolling out that allows you to give filters/steps custom names which I think will solve your use case here.\r\n> \r\n> <img alt=\"Screen Shot 2021-11-15 at 8 18 15 AM\" width=\"468\" src=\"https://user-images.githubusercontent.com/13460330/141816510-183dc62d-8c5b-4229-837e-bc51614a9889.png\">\r\n> \r\n> <img alt=\"Screen Shot 2021-11-15 at 8 17 52 AM\" width=\"969\" src=\"https://user-images.githubusercontent.com/13460330/141816454-701ba576-056d-4ecc-93c1-f36e96e731b3.png\">\r\n> \r\n> We can add you to our beta testers if you'd like to try it out? If so, just let me know what your email address is so that I can add you.\r\n\r\nThis is exactly what I had in mind! I'd be glad to test it out. My account on Posthog-cloud is areyes@example.com\n Comment 5: Awesome! I've added you to our beta list and you should be able to see this feature on your end :) ",
  "Issue title: `Tinder ++` not working on iOS 11.3.1\n Issue body: ```\r\n{\r\n  \"packageId\": \"com.unlimapps.autotinder\",\r\n  \"action\": \"notworking\",\r\n  \"userInfo\": {\r\n    \"arch32\": false,\r\n    \"packageId\": \"com.unlimapps.autotinder\",\r\n    \"deviceId\": \"iPhone9,4\",\r\n    \"url\": \"http://cydia.saurik.com/package/com.unlimapps.autotinder/\",\r\n    \"iOSVersion\": \"11.3.1\",\r\n    \"packageVersionIndexed\": true,\r\n    \"packageName\": \"Tinder ++\",\r\n    \"category\": \"Tweaks\",\r\n    \"repository\": \"BigBoss\",\r\n    \"name\": \"Tinder ++\",\r\n    \"packageIndexed\": true,\r\n    \"packageStatusExplaination\": \"This package version has been marked as Not working based on feedback from users in the community. The current positive rating is 0% with 0 working reports.\",\r\n    \"id\": \"com.unlimapps.autotinder\",\r\n    \"commercial\": false,\r\n    \"packageInstalled\": true,\r\n    \"tweakCompatVersion\": \"0.0.7\",\r\n    \"shortDescription\": \"auto-swipe for Tinder profiles\",\r\n    \"latest\": \"0.0.3-1\",\r\n    \"author\": \"UnlimApps Inc.\",\r\n    \"packageStatus\": \"Not working\"\r\n  },\r\n  \"base64\": \"eyJhcmNoMzIiOmZhbHNlLCJwYWNrYWdlSWQiOiJjb20udW5saW1hcHBzLmF1dG90aW5kZXIiLCJkZXZpY2VJZCI6ImlQaG9uZTksNCIsInVybCI6Imh0dHA6XC9cL2N5ZGlhLnNhdXJpay5jb21cL3BhY2thZ2VcL2NvbS51bmxpbWFwcHMuYXV0b3RpbmRlclwvIiwiaU9TVmVyc2lvbiI6IjExLjMuMSIsInBhY2thZ2VWZXJzaW9uSW5kZXhlZCI6dHJ1ZSwicGFja2FnZU5hbWUiOiJUaW5kZXIgKysiLCJjYXRlZ29yeSI6IlR3ZWFrcyIsInJlcG9zaXRvcnkiOiJCaWdCb3NzIiwibmFtZSI6IlRpbmRlciArKyIsInBhY2thZ2VJbmRleGVkIjp0cnVlLCJwYWNrYWdlU3RhdHVzRXhwbGFpbmF0aW9uIjoiVGhpcyBwYWNrYWdlIHZlcnNpb24gaGFzIGJlZW4gbWFya2VkIGFzIE5vdCB3b3JraW5nIGJhc2VkIG9uIGZlZWRiYWNrIGZyb20gdXNlcnMgaW4gdGhlIGNvbW11bml0eS4gVGhlIGN1cnJlbnQgcG9zaXRpdmUgcmF0aW5nIGlzIDAlIHdpdGggMCB3b3JraW5nIHJlcG9ydHMuIiwiaWQiOiJjb20udW5saW1hcHBzLmF1dG90aW5kZXIiLCJjb21tZXJjaWFsIjpmYWxzZSwicGFja2FnZUluc3RhbGxlZCI6dHJ1ZSwidHdlYWtDb21wYXRWZXJzaW9uIjoiMC4wLjciLCJzaG9ydERlc2NyaXB0aW9uIjoiYXV0by1zd2lwZSBmb3IgVGluZGVyIHByb2ZpbGVzIiwibGF0ZXN0IjoiMC4wLjMtMSIsImF1dGhvciI6IlVubGltQXBwcyBJbmMuIiwicGFja2FnZVN0YXR1cyI6Ik5vdCB3b3JraW5nIn0=\",\r\n  \"chosenStatus\": \"not working\",\r\n  \"notes\": \"\"\r\n}\r\n```\n Comments: \n Comment 0: This issue is being closed because your review was accepted into the tweakCompatible website. \nTweak developers do not monitor or fix issues submitted via this repo.\nIf you have an issue with a tweak, contact the developer via another method.",
  "Issue title: You can receive conflicting missions on the spaceport and be forced to lose one\n Issue body: The first time I got a mission from the spaceport, I got TWO missions instead, this left me very confused, also the missions were to completely opposite sides of the galaxy (one in the northernmost star and the other to the southernmost star).\r\n\r\nI had to cancel one of them, but now I can't see how the mission story went (I cancelled the one about hauling a dragon-like creature)\n Comments: \n Comment 0: I agree that it is confusing to have multiple missions pop up. But, as you get further on in the game, there are situations where you can have multiple mission threads going at the same time, and it's necessary for the next step in both of them to be offered on the same planet at the same time. So, I can't make it a general rule that the game never offers two tcoleman@example.net.\r\n\r\nRight now there's the capability for marking a mission as \"high priority,\" meaning, \"if this mission is being offered, do not simultaneously offer any missions with a lower priority.\" I suppose I could extend that to also have \"low priority\" missions, so that the \"flavor\" missions like the courier ones would only be offered if nothing else is available.\n Comment 1: Commit 6a328fd should fix this: it makes it so that missions marked as \"minor\" are only offered if no other missions are being offered (minor or otherwise). There will still be cases where multiple higher-priority missions are offered simultaneously, but at least there won't be any minor missions competing with them.",
  "Issue title: Normative statements for the vocabulary association mechanism?\n Issue body: The [\u00a711 Vocabulary Association Mechanism](https://w3c.github.io/epub-specs/epub33/rs/#sec-vocab-assoc) section is altogether a _MAY_; it starts with:\r\n\r\n> [Reading systems](https://www.w3.org/TR/epub-33/#dfn-epub-reading-system) MAY support [vocabulary association mechanisms](https://www.w3.org/TR/epub-33/#sec-vocab-assoc) [[epub-33](https://w3c.github.io/epub-specs/epub33/rs/#bib-epub-33)] in [EPUB content documents](https://www.w3.org/TR/epub-33/#dfn-epub-content-document).\r\n\r\nWe actually know that RS-s almost never implement this. It is therefore a bit disturbing to see the section full of _MUST_ statements (which all would also require tests). It all sounds very \"aspirational\" to me. Wouldn't it be better to rephrase this section? Maybe a simple solution to replace all the _MUST_ statements by plain, lower case \"must\"-s?\r\n\r\nWe had a similar situation with, e.g., MOL, which is also an optional feature, but the section contains lots of _MUST_-s. But this section is not optional in terms of _SHOULD_, but in terms of _MAY_. Also, we know that MOL is implemented by RS-s (although not by all).\r\n\n Comments: \n Comment 0: Not sure how this would make sense? If you have nothing but informative statements, then why not let reading systems make up their own processing of optional features? Interop is out the window anyway.\r\n\r\n> which all would also require tests\r\n\r\nWhy do we need to test the requirements of optional features? That's making the atomic statements more important than their overall support statement.\n Comment 1: > Why do we need to test the requirements of optional features? That's making the atomic statements more important than their overall support statement.\r\n\r\nThat is actually the problem: if we have _MUST_ statements, we are supposed to provide tests to see if they are properly implemented by a RS that does Voc. Associations. In theory, a _MUST_ statement without a test is a no-no...\n Comment 2: > we are supposed to provide tests to see if they are properly implemented by a RS that does Voc. Associations\r\n\r\nYa, but the problem with lowercasing all the requirements is that we're turning an optional feature into an informative description. That can't be any better, can it?\r\n\r\nThat means you don't actually have to respect prefix declarations, for example, since it would no longer be a real requirement.\n Comment 3: This is a lot like the pub manifest proof problem. We seem to require our own implementation to show that you can do these things, since there isn't a verifiable result you can check for in reading systems.\n Comment 4: What if we rewrite the whole section as a set of steps for calculating an expanded property. It would probably be a lot clearer. Could we then get away with making it more of a function rather than a series of MUSTs, so introduce it like:\r\n\r\n> To obtain an expanded `property` value... apply the following steps:\r\n\r\nWould that dodge the testing requirements?\n Comment 5: When authors override reserved prefixes, do existing RSes use predefined URLs for reserved prefixes anyway?\n Comment 6: > When authors override reserved prefixes, do existing RSes use predefined URLs for reserved prefixes anyway?\r\n\r\nI think that is the case, yes. \n Comment 7: According to the spec, the author declaration takes precedence:\r\n\r\n> Reading systems MUST use the URLs defined for locally overridden prefixes (using the prefix attribute) when encountered.\r\n\r\nThere were complaints a long time back that we could clobber someone's legitimate use of a prefix by reserving it for own purposes in the future.\n Comment 8: The issue was discussed in a [meeting](https://www.w3.org/publishing/groups/epub-wg/Meetings/Minutes/2022-08-04-epub#section2) on 2022-08-04\n\nList of resolutions:\n\n- ***[Resolution No. 1](https://www.w3.org/publishing/groups/epub-wg/Meetings/Minutes/2022-08-04-epub#resolution1):  The WG supports merging #2379 pending approval from the assigned reviewers..***\n\n<details><summary><i>View the transcript</i></summary>\n\n### 2. Re-implement vocabulary association mechanisms as an algorithm (pr epub-specs#2379)\n\n_See github pull request [epub-specs#2379](https://github.com/w3c/epub-specs/pull/2379)._\n\n\n\n\n_See github issue [epub-specs#2378](https://github.com/w3c/epub-specs/issues/2378)._\n\n\n\n\n_See github issue [epub-specs#2382](https://github.com/w3c/epub-specs/issues/2382)._\n\n\n\n\n**Dave Cramer:** there are a couple issues associated with this (#2378, #2382).  \n\u2026 this is very technical, I wish mgarrish were here to explain.  \n\u2026 doesn't really seems to change how the spec works, more an editorial change.  \n\u2026 seems like they were just looking for WG approval before merging, even though most of us probably won't have strong opinions on this.  \n\u2026 i'm generally in favor of explaining things in an algorithmic fashion rather than hard to understand paragraphs.  \n\u2026 maybe we just say that we don't have objection to merging this pending github reviews?.  \n\n> **Proposed resolution: The WG supports merging #2379 pending approval from the assigned reviewers..** *(Dave Cramer)*\n\n> *Dave Cramer:* +1.\n\n> *Matthew Chan:* +1.\n\n> *Brady Duga:* +1.\n\n> *Toshiaki Koike:* +1.\n\n> *Shinya Takami (\u9ad8\u898b\u771f\u4e5f):* +1.\n\n> ***Resolution #1: The WG supports merging #2379 pending approval from the assigned reviewers..***\n\n</details>",
  "Issue title: \u5982\u4f55\u4e0d\u663e\u793atimeout\n Issue body: \u5728\u5927\u6279\u91cf\u4f7f\u7528get_tick_data\u65f6\uff0c\u4f1a\u5728\u7ec8\u7aef\u663e\u793a\u51fa\u5927\u91cf\u7684timeout\uff0c\u5404\u4f4d\u6709\u6ca1\u6709\u65b9\u6cd5\u53ef\u4ee5\u4e0d\u663e\u793atimeout\u4fe1\u606f\u5462\uff1f\n Comments: \n Comment 0: \u9047\u5230\u540c\u6837\u7684\u95ee\u9898\uff0c\u89e3\u51b3\u4e86\u5417\uff1f",
  "Issue title: Patterns in extern fns either ICE or aren't type-checked\n Issue body: The following compiles fine, but uncommenting any of the currently-commented `extern` functions makes the compiler ICE.\n\n``` rust\nstruct Foo { x: int }\nextern {\n    // fn foo(1: ());\n    // fn bar((): int);\n    // fn baz(Foo { x }: int);\n    fn qux((x,y): ());\n}\nfn main() {}\n```\n\nFor `foo` the ICE message is \n\n```\nerror: internal compiler error: node_id_to_type: no type for node `expr 1 (id=12)`\n```\n\nand the others are similar.\n\n Comments: \n Comment 0: I'm inclined to say that the correct behavior is to deny all patterns other than `ident` (give a parser error perhaps).\n\n Comment 1: Nominating.\n\n Comment 2: @alexcrichton I agree\n\n Comment 3: Accepted for 1.0, P-backcompat-lang.\n\n Comment 4: Good newbie bug.\n\n Comment 5: Being a good newbie, I'll have a crack at this one. :)\n\n Comment 6: Might have aimed a little too high by trying this issue.. but from what i understand, the type checking is working as people would like, but the message is incorrect and should be a actual syntax error and not an ICE... so the below is some thing like how it should work?\n\n``` rust\nstruct Foo { x: int }\n\nextern {\n    // This one should fail because you've supplied a literal as a fn arg with\n    // no type\n    fn foo(1: ());\n    // This one should fail because you've specified '()' as a variable name for\n    // the fn args\n    fn bar((): int);\n    // This one should pass because you've declared a deconstructed variable name\n    // for the input parm 'x' and you've declared a type. This still should trigger\n    // the warning for not using a 'li38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5c_int'.\n    fn baz(Foo {x}: int);\n    // This should pass because you've specified input parameters and rust will \n    // infer the type?\n    fn qux((x,y): ());\n}\n```\n\nSorry if I've completely misunderstood, still pretty nubbins with Rust. :\\\n\n Comment 7: @mankyKitty my reading of [acrichto's comment](#issuecomment-30111618) is that all of your examples should fail; ideally only an identfier should pass.\n\n Comment 8: They should all fail, the only thing that should pass is `fn foo(some_ident: int);`, nothing involving destructuring or pattern matching.\n\nOne way to implement this would be to make it an actual syntax error. You can find a starting place for this change by grepping for `ForeignItemFn` in `src/libsyntax/parse/parser.rs`. (I personally would recommend implementing this by threading a `require_ident_patterns_only` argument through `parse_fn_decl`, `parse_fn_args` to `parse_arg_general` where you chose between the existing `parse_pat` call and calling `parse_pat_ident` directly based on that boolean.)\n\n> ```\n> // This should pass because you've specified input parameters and rust will \n> // infer the type?\n> fn qux((x,y): ());\n> ```\n\nNo inference; this is always incorrect because you're trying to match a 2-tuple pattern (i.e. type `(T, U)`) in a slot of type `()` (i.e. nil, void, 0-tuple).\n\n Comment 9: @pnkfelix @huonw \n\nAhhh okay, that makes more sense. Thanks for that. I'll see what I can make happen. \n",
  "Issue title: socket_select accepts only integers\n Issue body: https://www.php.net/manual/en/function.fmod\r\n\r\n```php\r\n        $usec = $sec === null? null : fmod($sec, 1) * 1e6;\r\n\r\n        $ret = @socket_select($r, $w, $e, (int)$sec, (int)$usec);\r\n```\r\n\r\nWhat do you think about this?\r\n\n Comments: \n Comment 0: @szepeviktor Thanks for spotting :+1: \n Comment 1: You're welcome.\r\nBTW it was @phpstan.\r\n\n Comment 2: https://phpstan.org/r/47de8c45-8636-46d7-8d08-3011f9bbc554 Looks like a minor bug in @phpstan by the way, both timeout arguments also support `null` values. Feel like filing an upstream PR? :+1: \n Comment 3: Yes, socket_select's signature need to be fixed in @phpstan.\r\n\r\nhttps://github.com/phpstan/phpstan-src/blob/3e8ec5f0d4ecf3df531c9f674345508a8e1e51fa/resources/functionMap.php#L10346\n Comment 4: Go for it :+1: \n Comment 5: \ud83c\udfcb\ufe0f\u200d\u2642\ufe0f Done.\r\nhttps://github.com/phpstan/phpstan-src/pull/385",
  "Issue title: qs_ prefix\n Issue body: The qs_ prefix is horrid and by itself, alone, prevents me from ever using this library.  What a truly terrible, non-Objective-C-esque idea!\n\n Comments: \n Comment 0: It\u2019s Apple\u2019s idea. Not mine.\n\nhttps://developer.apple.com/library/ios/documentation/cocoa/conceptual/ProgrammingWithObjectiveC/Conventions/Conventions.html\n\nApple says to prefix category method names:\n\n\u201cIn order to avoid undefined behavior, it\u2019s best practice to add a prefix to method names in categories on framework classes, just like you should add a prefix to the names of your own classes. You might choose to use the same three letters you use for your class prefixes, but lowercase to follow the usual convention for method names, then an underscore, before the rest of the method name.\u201d\n\nApple provides an example:\n\n`+ (id)xyz_sortDescriptorWithKey:(NSString *)key ascending:(BOOL)ascending;`\n\nApple recommends three-letter prefixes, but I use just two. (Having to use three-letter-prefixes is a bit unfair. I'm sticking to two.)\n\n Comment 1: Thanks so much for sharing all of this code. We're using parts of it in Castro already and plan to use more soon. \n\nI wanted to throw in an argument for removing the prefixes in spite of Apples recommendation. Aside from how it looks, it makes autocomplete less useful since we have to constantly remember that the category is a qs_ instead of just starting to type what we would expect the method to be called. \n",
  "Issue title: gather_nd doesnt work for batched slicing,(even for documented examples)\n Issue body: gather_nd function doesn't work for batched slicing\r\nSteps to Reproduce\r\n\r\nRun the following code\r\n```python\r\nimport tensorflow as tf\r\ncons_indices=tf.constant([[[1]], [[0]]])\r\nbatch=tf.constant([['a', 'b'], ['c', 'd']])\r\ngathered=tf.gather_nd(batch,cons_indices)\r\nsess = tf.Session()\r\nresult = sess.run(gathered)\r\nprint(result)\r\nsess.close()\r\n```\r\n\r\n\r\nAlways gives an error regarding incompatible dimensions.\r\n\r\nEither the documentation needs to be updated to indicate proper argument format\n Comments: \n Comment 0: When I run your program I get:\r\n\r\n[[['c' 'd']] [['a' 'b']]]\r\n\r\nwhich I believe is correct.  Could you provide more information on your version and installation, and the exact error message?\n Comment 1: Closing due to lack of response.  We are happy to reopen if more details emerge!\n Comment 2: In TFv1.0 it tf.gather_nd seems to wrok randomly. Checkout [here](http://stackoverflow.com/questions/43007410/tensorflow-unexpected-tf-gather-nd-behaviour-bug) ",
  "Issue title: ORM Auth _login ussing login blocked message\n Issue body: class Kohana_Auth_ORM\r\n\r\nif ($user->has('roles', ORM38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5tory('Role', array('name' => 'login'))) AND $user->password === $password) line: 90\r\nWhen user try to login Auth ORM check password and role in one line so even username and password is correct but login role is remove system can't tell user that that login privilege is remove and they need to contact admin. \n Comments: \n Comment 0: Well, if login role has been removed you wouldn't be able to log in. But there shouldn't be message \"Our admin has messed up the settings, so you can't log in. \"\r\n\r\nYou could make login,admin roles non-removable in your system.\r\nTherefore it is not a bug.\n Comment 1: What if Admin deliberately block user access by removing login role? \n Comment 2: How is that a software issue?\n Comment 3: What do you think what issue it is? user entering correct username and password but getting a standard message \"wrong username or password\", In this case they think password is wrong and attempt to reset password. but in reality Admin has blocked them from website by removing login role. Its functional requirement of Login function. it need to return distinct message why login failed.    \n Comment 4: Can you suggest a PR?\n Comment 5: after a long though I conclusion is not to change login function. as it will be tricky to change function return type.. \r\ncurrent return type bool can only support logged in or not.. so we need some kind of message system or complex return type..\r\nSo I have updated my password reset function. if user account is blocked or not active. it show message that user can't request password reset as account is blocked and they need to contact Admin for help. \r\n\r\n\r\n\n Comment 6: In fact, it's not entirely correct to block users in this way. You must add a new role, or a mark for blocked users. After authorization, it is necessary to check whether the user is blocked and restrict his actions, if necessary.\n Comment 7: Yes there are many ways to approach this issue. Here is what happening to my sites.\r\nUsers signup they get login role assigned.. \r\n\r\nBut some time in future admin remove the login role so user was unable to login.. system worked as it was suppose to work.. but user was confused how they can't login even after resetting password many times.. \r\n\r\nOnce even one admin uncheck the login role from other admin.. so I have done two changes \r\n\r\n1. Updated the user edit code so there is always at least on user with Admin and login role \r\n2.  on password reset screen tell user if their account is blocked or not. ",
  "Issue title: Profile the rocksDB performance in deleting and writing\n Issue body: ### Description\nProfile the rocksDB performance in deleting and writing. What happens when we start deleting or writing a large number of transactions?\n\n### Motivation\nExplain why this feature is needed.\n\n### Requirements\nCreate a list of what you want this feature request to fulfill.\n\n### Open Questions (optional)\nAnything you want to discuss.\n\n### Am I planning to do it myself with a PR?\nYes/No.\n\n Comments: \n Comment 0: @alon-e and @jakubcech \r\n\r\nI am creating a separate benchmarking project that will be part of tangle tools.\r\n\r\nI think it is better to first do tests on RockDbPersistenceProvider isolated from the node.\r\nThis is so that we know how changes that we make to RocksDbPersistenceProvider affect its performance.\n Comment 1: I decided in the end to implement this as a *unit test* that will not be ran as part of the maven lifecycle.\r\nCurrently the best way to run this directly is by `mvn surefire:test -Dtest=BenchmarkRunner` or if you want to compile first to do `mvn -Dtest=BenchmarkRunner <goals>`.\r\n\r\nIt is very important to run those benchmarks in a clean environment to reduce noise. For example when I run this on my laptop while working I got the following results:\r\n\r\n```\r\nBenchmark                         (numTxsToTest)  Mode  Cnt    Score     Error  Units\r\nRocksDbBenchmark.deleteBatch                  10  avgt   20    8.485 \u00b1   0.038  ms/op\r\nRocksDbBenchmark.deleteBatch                 100  avgt   20    8.696 \u00b1   0.049  ms/op\r\nRocksDbBenchmark.deleteBatch                 500  avgt   20    8.944 \u00b1   0.145  ms/op\r\nRocksDbBenchmark.deleteBatch                1000  avgt   20   11.558 \u00b1   0.639  ms/op\r\nRocksDbBenchmark.deleteBatch                3000  avgt   20   27.561 \u00b1   1.720  ms/op\r\nRocksDbBenchmark.deleteOneByOne               10  avgt   20    0.116 \u00b1   0.017  ms/op\r\nRocksDbBenchmark.deleteOneByOne              100  avgt   20    1.054 \u00b1   0.117  ms/op\r\nRocksDbBenchmark.deleteOneByOne              500  avgt   20    6.717 \u00b1   1.223  ms/op\r\nRocksDbBenchmark.deleteOneByOne             1000  avgt   20   17.201 \u00b1   3.121  ms/op\r\nRocksDbBenchmark.deleteOneByOne             3000  avgt   20   43.366 \u00b1   9.175  ms/op\r\nRocksDbBenchmark.dropAll                      10  avgt   20    0.329 \u00b1   0.080  ms/op\r\nRocksDbBenchmark.dropAll                     100  avgt   20    3.412 \u00b1   0.572  ms/op\r\nRocksDbBenchmark.dropAll                     500  avgt   20   17.000 \u00b1   3.756  ms/op\r\nRocksDbBenchmark.dropAll                    1000  avgt   20   37.898 \u00b1   7.543  ms/op\r\nRocksDbBenchmark.dropAll                    3000  avgt   20   64.127 \u00b1  16.081  ms/op\r\nRocksDbBenchmark.fetchBatch                   10  avgt   20    0.071 \u00b1   0.002  ms/op\r\nRocksDbBenchmark.fetchBatch                  100  avgt   20    1.304 \u00b1   0.978  ms/op\r\nRocksDbBenchmark.fetchBatch                  500  avgt   20    9.997 \u00b1   4.622  ms/op\r\nRocksDbBenchmark.fetchBatch                 1000  avgt   20   25.455 \u00b1   8.109  ms/op\r\nRocksDbBenchmark.fetchBatch                 3000  avgt   20  108.476 \u00b1  15.976  ms/op\r\nRocksDbBenchmark.persistOneByOne              10  avgt   20    0.031 \u00b1   0.001  ms/op\r\nRocksDbBenchmark.persistOneByOne             100  avgt   20    0.480 \u00b1   0.331  ms/op\r\nRocksDbBenchmark.persistOneByOne             500  avgt   20    4.902 \u00b1   3.419  ms/op\r\nRocksDbBenchmark.persistOneByOne            1000  avgt   20   14.489 \u00b1   6.685  ms/op\r\nRocksDbBenchmark.persistOneByOne            3000  avgt   20  131.039 \u00b1 206.119  ms/op\r\n```\r\n\r\nAs you can see in some cases the error is quite unacceptable.\r\nWhen I run the test on Hetzner (cloud) machine that has nothing running on I got better results.\r\n\r\n```\r\nBenchmark                         (numTxsToTest)  Mode  Cnt   Score   Error  Units\r\nRocksDbBenchmark.deleteBatch                3000  avgt   20  14.468? 0.534  ms/op\r\nRocksDbBenchmark.deleteOneByOne             3000  avgt   20  11.412? 0.341  ms/op\r\nRocksDbBenchmark.dropAll                    3000  avgt   20  23.479? 4.598  ms/op\r\nRocksDbBenchmark.fetchBatch                 3000  avgt   20  46.698? 7.336  ms/op\r\nRocksDbBenchmark.persistOneByOne            3000  avgt   20  30.745? 2.609  ms/op\r\n```\r\n\r\nOn the Hetzner you are only seeing the results for 3000 because I skipped the other tests to save time.\r\nThe whole suit can take a very long time to complete. I just need to make it recognize the `\u00b1` character :-P. \r\n\r\n`Cnt` btw is the number of measurement iterations (2 forks X 10 iterations). In #962 I reduced the number of forks to 1 because from experimenting I didn't notice that the forks changed the results too much and the tests are long enough as it is.\n Comment 2: By the way it is very surprising that `deleteOneByOne` is faster than the other deleting methods...\r\nI may have to do more experiments to see how I can get results that I can count on...\n Comment 3: I don't seem to be able to get better results by changing the order of the tests.\r\nBy looking at the implementation of `dropAll` it is not so surprising that it is slow.\r\n\r\nI am surprised that `deleteBatch` is a bit slower though...",
  "Issue title: Gatsby Plugin Create client Paths\n Issue body: In the plugin https://www.gatsbyjs.org/packages/gatsby-plugin-create-client-paths/?=create%20clien\r\nI am not sure how to add multiple clients paths. \r\nFor example I would like app/ and store/ to be client only paths\r\n\r\nI have tried\r\n    {\r\n      resolve: `gatsby-plugin-create-client-paths`,\r\n      options: { prefixes: [`/app/*`, `/store/*`] },\r\n    },\r\n\r\nAnd this does not work for me\n Comments: \n Comment 0: Hi!\r\n\r\nSorry to hear you're running into an issue. To help us best begin debugging the underlying cause, it is incredibly helpful if you're able to create a [minimal reproduction][reproduction]. This is a simplified example of the issue that makes it clear and obvious what the issue is and how we can begin to debug it.\r\n\r\nIf you're up for it, we'd very much appreciate if you could [provide a minimal reproduction][reproduction] and we'll be able to take another look.\r\n\r\nThanks for using Gatsby! \ud83d\udc9c\r\n\r\n[reproduction]: https://gatsby.dev/reproduction\n Comment 1: Hiya!\n\nThis issue has gone quiet. Spooky quiet. \ud83d\udc7b\n\nWe get a lot of issues, so we currently close issues after 30 days of inactivity. It\u2019s been at least 20 days since the last update here.\nIf we missed this issue or if you want to keep it open, please reply here. You can also add the label \"not stale\" to keep this issue open!\nAs a friendly reminder: the best way to see this issue, or any other, fixed is to open a Pull Request. Check out [gatsby.dev/contribute](https://www.gatsbyjs.org/contributing/how-to-contribute/) for more information about opening PRs, triaging issues, and contributing!\n\nThanks for being a part of the Gatsby community! \ud83d\udcaa\ud83d\udc9c\n Comment 2: Hey again!\n\nIt\u2019s been 30 days since anything happened on this issue, so our friendly neighborhood robot (that\u2019s me!) is going to close it.\nPlease keep in mind that I\u2019m only a robot, so if I\u2019ve closed this issue in error, I\u2019m `HUMAN_EMOTION_SORRY`. Please feel free to reopen this issue or create a new one if you need anything else.\nAs a friendly reminder: the best way to see this issue, or any other, fixed is to open a Pull Request. Check out [gatsby.dev/contribute](https://www.gatsbyjs.org/contributing/how-to-contribute/) for more information about opening PRs, triaging issues, and contributing!\n\nThanks again for being part of the Gatsby community! \ud83d\udcaa\ud83d\udc9c\n Comment 3: @arhoy it should work, please create a small reproduction for us that will help us debug this issue.\n Comment 4: Hiya!\n\nThis issue has gone quiet. Spooky quiet. \ud83d\udc7b\n\nWe get a lot of issues, so we currently close issues after 30 days of inactivity. It\u2019s been at least 20 days since the last update here.\nIf we missed this issue or if you want to keep it open, please reply here. You can also add the label \"not stale\" to keep this issue open!\nAs a friendly reminder: the best way to see this issue, or any other, fixed is to open a Pull Request. Check out [gatsby.dev/contribute](https://www.gatsbyjs.org/contributing/how-to-contribute/) for more information about opening PRs, triaging issues, and contributing!\n\nThanks for being a part of the Gatsby community! \ud83d\udcaa\ud83d\udc9c\n Comment 5: Hey again!\n\nIt\u2019s been 30 days since anything happened on this issue, so our friendly neighborhood robot (that\u2019s me!) is going to close it.\nPlease keep in mind that I\u2019m only a robot, so if I\u2019ve closed this issue in error, I\u2019m `HUMAN_EMOTION_SORRY`. Please feel free to reopen this issue or create a new one if you need anything else.\nAs a friendly reminder: the best way to see this issue, or any other, fixed is to open a Pull Request. Check out [gatsby.dev/contribute](https://www.gatsbyjs.org/contributing/how-to-contribute/) for more information about opening PRs, triaging issues, and contributing!\n\nThanks again for being part of the Gatsby community! \ud83d\udcaa\ud83d\udc9c",
  "Issue title: Arquivos Porto Algre\n Issue body: ONde encontro os arquivos de Porto Alegre para dar uma olhada?\n Comments: \n Comment 0: Oi @fagnersutel. \r\n\r\nPodes obter a rede vi\u00e1ria da cidade em [https://export.hotosm.org/en/v3/](https://export.hotosm.org/en/v3/). Basta selecionar a \u00e1rea desejada e baixar em formato pbf.\r\nOs dados de GTFS est\u00e3o dispon\u00edveis em [http://datapoa.com.br/dataset/gtfs](http://datapoa.com.br/dataset/gtfs).\r\n\r\nSe tiveres algum feedback, nos escreva.\r\nObrigado por usar nosso pacote. ",
  "Issue title: Using gas value provided by estimateGas triggers error even though tx succeeds\n Issue body: ### Description <!-- In plain words, what happened -->\r\n\r\nIn 1.2.2, perfect gas throws an error. This problem was introduced in #3123.  It looks like the modified logic is meant to handle pre-byzantium chain behavior where `gasUsed === gasSent` is a signal that the transaction was reverted. [Post-byzantium][2], the `status` field on the receipt is  a more definitive check. There are also gas refunds which may make these estimates less useful overall.\r\n\r\nPerhaps there should be some community discussion about how to address this. Is there agreement that the estimates are imperfect and `estimate + something` should always be provided? If so, perhaps a docs clarification is all that is required.\r\n\r\nConversely, the change could be see as de-facto breaking and reverted on those grounds. \r\n\r\n@gabmontes What is your view of this? Could you provide more background on what execution contexts this gas check is necessary for? \r\n\r\n[2]: https://github.com/ethereum/wiki/wiki/Byzantium-Hard-Fork-changes\r\n\r\n#### Actual behavior\r\n```javascript\r\nvar estimate = await instance\r\n .methods\r\n .setValue('1')\r\n .estimateGas();\r\n\r\nvar receipt = await instance\r\n .methods\r\n .setValue('1')\r\n .send({from: accounts[0], gas: estimate});\r\n\r\n\r\n> Error: Transaction ran out of gas. Please provide more gas:\r\n{\r\n  \"transactionHash\": \"0x5ac5cd5c927fb5fc379ef08ab76d901e04ff39d479c626574cfefe36ba88cbd0\",\r\n  \"transactionIndex\": 0,\r\n  \"blockHash\": \"0x9b7bd2b531e94862ba99ed69771bbe4098f87ca729e1209f9eacef30c6aa3857\",\r\n  \"blockNumber\": 2,\r\n  \"from\": \"0x27ca018a8ab7e7661a596077633e4d5026a571b1\",\r\n  \"to\": \"0xe63685170cd157a1d4dad3e3dd65df9fd44ad6a9\",\r\n  \"gasUsed\": 41728,\r\n  \"cumulativeGasUsed\": 41728,\r\n  \"contractAddress\": null,\r\n  \"status\": true,\r\n  \"logsBloom\": \"0x000..00\",\r\n  \"v\": \"0x1c\",\r\n  \"r\": \"0x23d539bb02df7fbbc99c4ee8901dd6149fd5c812176990fbba868bc2b5e0dfee\",\r\n  \"s\": \"0x7aef125f4f79a66f8253733c306c333bec9fcbe38d1a2623192bf0c702d44674\",\r\n  \"events\": {}\r\n}\r\n```\r\n\r\n### Versions \r\n* web3.js: 1.2.2\r\n* nodejs:\r\n* browser:\r\n* ethereum node:\r\n\n Comments: \n Comment 0: @cgewecke Thanks for opening this issue! The gas check got completely fixed in 2.x and does only slightly differ from the gas check we have in 1.x. \r\n\r\n1.x does throw the ``Transaction ran out of gas`` error if the ``gasProvided`` and ``gasUsed`` value from the ``Method`` class on line 351 is equal and if the ``status`` property is set to``true``. The correct and also implemented logic in 2.x is that it first checks if the ``status`` property is set to ``false`` and if the ``gasProvided`` and ``gasUsed`` property are equals. ([2.x PR](https://github.com/ethereum/web3.js/pull/2511))\r\n\r\nBtw.: I think to cover the gas validation logic would it require some smaller additional test cases.\n Comment 1: @cgewecke @nivida actually #3123 fixes a comparison that had been broken for a long time. As a side-effect, it looks like it also revealed another issue with the gas-checking logic.\r\n\r\nIn order to handle both pre and post-byzantimum fork in a better way, additional checks have to be added. This is what we are currently using in our projects:\r\n\r\n```diff\r\n--- a/node_modules/web3-core-method/src/index.js\r\n+++ b/node_modules/web3-core-method/src/index.js\r\n@@ -203,6 +203,7 @@ Method.prototype._confirmTransaction = function(defer, result, payload) {\r\n         lastBlock = null,\r\n         receiptJSON = '',\r\n         gasProvided = (_.isObject(payload.params[0]) && payload.params[0].gas)? payload.params[0].gas : null,\r\n+        isContractCall = _.isObject(payload.params[0]) &&!!payload.params[0].data,\r\n         isContractDeployment = _.isObject(payload.params[0]) &&\r\n             payload.params[0].data &&\r\n             payload.params[0].from &&\r\n@@ -394,8 +395,8 @@ Method.prototype._confirmTransaction = function(defer, result, payload) {\r\n                .then(function(receipt) {\r\n                     if (!isContractDeployment &&!promiseResolved) {\r\n                         if (!receipt.outOfGas &&\r\n-                            (!gasProvided || gasProvided!== utils.numberToHex(receipt.gasUsed)) &&\r\n-                            (receipt.status === true || receipt.status === '0x1' || typeof receipt.status === 'undefined')) {\r\n+                            (!gasProvided || gasProvided!== utils.numberToHex(receipt.gasUsed) ||!isContractCall || (isContractCall && receipt.events)) &&\r\n+                            (receipt.status === true || receipt.status === '0x1' || receipt.status === null || typeof receipt.status === 'undefined')) {\r\n                             defer.eventEmitter.emit('receipt', receipt);\r\n                             defer.resolve(receipt);\r\n```\r\n\r\nI have not sent a PR with this because it needs to be tested thoroughly. In summary, if you have `status` as `true` or `false`, you are post-byzantinum and should use that. Otherwise, if it is `null` or `undefined` you are pre-byzantinum and can only try to infer if the transaction was successful or was reverted. In order to do that, we added more checks so even when the gas used is equal to the gas price, if it is a contract call and you have logs, you know the transaction was successful.\r\n\r\nIs there a good test suite for this in `2.x`? In that case we can port the tests back and work on fixing this logic properly.\n Comment 2: Thanks @nivida @gabmontes! \n Comment 3: Does anyone know what client or fork actually attaches this field to the receipt? \r\n```javascript\r\nreceipt.outOfGas\r\n```\n Comment 4: @cgewecke \r\n> receipt.outOfGas\r\n\r\nThis property doesn't exist officially only the ganache client does have it.\n Comment 5: > The correct and also implemented logic in 2.x is that it first checks if the status property is set to false and if the gasProvided and gasUsed property are equals.\r\n\r\nThis logic doesn't reject successfully mined transactions who exactly used the provided gas. \r\nWhat the 2.x code is missing is returning of the contract error messages in a human-readable way but this already reported as an issue [here](https://github.com/ethereum/web3.js/issues/1707).\r\n\r\nThe rules behind the status property are:\r\n- If the ``status`` property is ``false`` and ``providedGas!== gasUsed`` then the transaction got reverted because of the logic implemented of the current contract (``require``, ``throw``). \r\n- If the ``status`` property is ``false`` and ``providedGas === gasUsed`` then the transaction got reverted by a non-contract-logic related problem (not enough gas).  \n Comment 6: Well, this was unexpected. It behaved differently in version `v1.2.1`. \r\n\r\nI was not expecting such a change in a patch release. \n Comment 7: Well, this was unexpected. It behaved differently in version v1.2.1. (https://github.com/oceanprotocol/squid-js/pull/331/files#diff-b9cfc7f2cdf78a7f4b91a753d10865a2L62)\r\n\r\nI was not expecting such a change in a patch release.",
  "Issue title: DTU Quantitative results\n Issue body: Hi, I recently ran the training code in **Generic mode** and extract the mesh, then use the scripts\r\n[https://github.com/jzhangbs/DTUeval-python](https://github.com/jzhangbs/DTUeval-python) to evaluate the **Chamfer Distance** for 15 test scenes according to the **Table 1** of your paper.\r\nHowever I found the quantitative results I got are worse than those in **Table 1**, eg:\r\n\r\n- scan24:   2.2(I got)  VS  1.68(Paper)\r\n- scan37:  5.15(I got) VS  3.06(Paper)\r\n- scan50:   3.2(I got)  VS  2.25(Paper) \r\n\r\nI use `--mode val` in command line to extract the mesh. In **conf** file I set the `test_ref_view = [23]`. In your paper I don't find the ref-view settings in experiment. So maybe you use other pairs.txt in Chamfer Distance test? Can you share some details in your experiment? \r\n\r\nThanks a lot.\r\n\n Comments: \n Comment 0: Hello. We use two pairs in each scene to do the evaluation.\r\nBefore calculating the chamfer distance for all the neural-based methods, we use the input image masks to clean the reconstruction results. This is because for all the neural-based methods, there will be many free surfaces in the background parts. Directly calculating the chamfer distance with ground truth point cloud and comparing it with the SOTA methods doesn't make much sense.\r\n\r\nThe evaluation input image pairs we used can be downloaded here: https://connecthkuhk-my.sharepoint.com/:u:/g/personal/xxlong_connect_hku_hk/EU22HEv48nRLnnnliRvJNA0BILozsMLbhsnMQh1WZLY5kg?e=Lh7kWM\r\n\r\nI will upload the full evaluation code this week.\n Comment 1: > Hello. We use two pairs in each scene to do the evaluation. Before calculating the chamfer distance for all the neural-based methods, we use the input image masks to clean the reconstruction results. This is because for all the neural-based methods, there will be many free surfaces in the background parts. Directly calculating the chamfer distance with ground truth point cloud and comparing it with the SOTA methods doesn't make much sense.\r\n> \r\n> The evaluation input image pairs we used can be downloaded here: https://connecthkuhk-my.sharepoint.com/:u:/g/personal/xxlong_connect_hku_hk/EU22HEv48nRLnnnliRvJNA0BILozsMLbhsnMQh1WZLY5kg?e=Lh7kWM\r\n> \r\n> I will upload the full evaluation code this week.\r\n\r\nHi, @flamehaze1115,thanks for your reply.\r\n- I have noticed the [testing dataset](https://connecthkuhk-my.sharepoint.com/:u:/g/personal/xxlong_connect_hku_hk/EU22HEv48nRLnnnliRvJNA0BILozsMLbhsnMQh1WZLY5kg?e=Lh7kWM) has **set0** and **set1**. What's the difference between them? Maybe **set0** _corresp._ **lod0**, **set1** _corresp._ **lod1**? Or just select the best result in **set0 and set1**?\r\n- the image mask files in [testing dataset](https://connecthkuhk-my.sharepoint.com/:u:/g/personal/xxlong_connect_hku_hk/EU22HEv48nRLnnnliRvJNA0BILozsMLbhsnMQh1WZLY5kg?e=Lh7kWM) how to use?  shall we have other evaluation  scripts to utilize the image mask files\uff1f\n Comment 2: @flamehaze1115 \r\n\r\nSorry to bother you, but where is the full evaluation code?\r\n\r\nThanks a lot.\n Comment 3: @jerryxu9905 HI, guys, I meet the same problem. Did you solve it? \r\nThe results of my run is bad, the details can be found in [this](https://github.com/xxlong0/SparseNeuS/issues/23#issuecomment-1264648535). \r\nCan you offer some suggestions?",
  "Issue title: 13.4 beta update crash\n Issue body: HDT crashed shorting after starting up\r\n\r\nI was playing the new brawl at the time.\r\n\r\nhttp://pastebin.com/pq54mp7Q\n Comments: \n Comment 0: Looks the same as #1837, I think\n Comment 1: Definitely the same as #1837, yes.",
  "Issue title: POST /clusterNodes - non of available options for nodeInitScript are working\n Issue body: Hi\r\ni got an problem with setting up BYON nodes, for every script name from https://github.com/Shippable/node/tree/master/scripts i get validation error\r\n\r\nExample request\r\n```\r\n curl --request POST \\\r\n  --url https://api.shippable.com/clusterNodes \\\r\n  --header \"authorization: apiToken <token>\" \\\r\n  --header \"cache-control: no-cache\" \\\r\n  --header \"content-type: application/json\" \\\r\n  --data '{\"subscriptionId\": \"59f08e78a64bbc0700a8aa4d\",\"friendlyName\": \"test\", \"clusterId\": 110758,\"location\": \"<ip>\",\"nodeInitScript\": \"x86_64__Ubuntu__16.04__Docker__17.06.sh\",\"initializeSwap\": false,\"nodeTypeCode\": 7000,\"isShippableInitialized\": false}'\r\n```\r\n```\r\n{\r\n    \"logType\": \"verbose\",\r\n    \"methodName\": \"clusterNodes|post|callerId:59dff12a82a9930700c9b25f|_generateInitSteps\",\r\n    \"id\": 4003,\r\n    \"message\": \"failed to parseScriptName for: x86_64__Ubuntu__16.04__Docker__17.06.shwith error: Error: Invalid script name, cannot parse for Arch and OS\"\r\n}\r\n```\r\nfew weeks ago have used `ubu_16.04_docker_1.13.sh` but it does not work right now\r\ni have tried most of scripts names available in repo but them and all return same message, also node is actually created, just without `Docker Version`\n Comments: \n Comment 0: Since the subscription has been upgraded to node pools, a couple of changes to the API payload are required:\r\n- `nodeInitScript` now refers to the scripts in [`node/initScripts`](https://github.com/Shippable/node/tree/master/initScripts) instead of [`node/scripts`](https://github.com/Shippable/node/tree/master/scripts). In your example this will be\r\n`x86_64/Ubuntu_16.04/Docker_17.06.sh`\r\n- `clusterId` is a required field. You can find this by navigating to the subscription's node pools page and clicking on the edit button on one of the node pools. The number after `nodePools` in the address bar will be the `clusterId`. You can also find this by making a `GET /clusters` call.\r\n\r\nLet us know if this works for you. You might also want to check the [release notes](https://github.com/Shippable/admiral/blob/master/releaseNotes/v6.2.2.md#features) related to this.\r\n\n Comment 1: @shrivara are these changes documented? \n Comment 2: The opt-in button links to the [release notes](https://github.com/Shippable/admiral/blob/master/releaseNotes/v6.2.2.md#features) which document these changes.\n Comment 3: thanks for quick response @shrivara \r\nsomehow i have missed this in release notes, would be nice if documentation could be updated to http://docs.shippable.com/platform/api/api-overview/#!/ClusterNodes/post_clusterNodes\r\n\r\n`x86_64/Ubuntu_16.04/Docker_17.06.sh` work perfectly",
  "Issue title: Automate release process\n Issue body: We should have an `npm` script (e.g.: `release`) that will:\r\n\r\n- [ ] Update the `CHANGELOG.md` (see: #345)\r\n- [ ] Tags a new version and updates the [release](https://github.com/sonarwhal/sonar/releases).\r\n- [ ] Publishes a new version on `npm`.\r\n- [ ] Other?\n Comments: \n Comment 0: - [ ] Triggers a site update.\n Comment 1: * [] publishes a tweet with a link to the changelog?\n Comment 2: > publishes a tweet with a link to the changelog?\r\n\r\nThe whole point of having the release process more automated is to release often, so I haven't implement that as I don't think it's a good idea to tweet about every single version. \r\n\r\nWe could have an option to only tweet about major versions, but yet again, my opinion is that in general we should tweet also about versions that include important changes (e.g.: a new connector was added), plus, tweets should include something unique about the release they are talking about.\r\n\r\n\n Comment 3: OK, there's always time to add it later.",
  "Issue title: Unable to set Files as default File Explorer - Windows 11\n Issue body: ### Description\n\nHello,\r\n\r\nFirst of all, I LOVE the look of your file explore app for Windows. It's so clean.\r\n\r\nSecondly, I was attempting to follow your instructions to set my default file explorer to the Files app (through the experimental tab), but there is no option to set it as default.\r\n\r\nAny thoughts?\n\n### Steps To Reproduce\n\n_No response_\n\n### Expected behavior\n\nI expected there to be an option for me to click on that tells Windows to default to the Files app when opening files.\n\n### Files Version\n\nVersion: 116.69.203.115 OS Version: 10.0.22000.527\n\n### Windows Version\n\nWindows 11 Pro 21H2\n\n### Relevant Assets/Logs\n\n![Screenshot 2022-02-28 133845](https://user-images.githubusercontent.com/100497079/156062986-36dcc2ca-d57a-4e4f-acd7-6774317e54c4.jpg)\r\n\n Comments: \n Comment 0: This option is only available in the sideload version of Files.",
  "Issue title: AW renders armor pieces on the wrong mannequin's body parts if SM is installed\n Issue body: If Smart Moving is installed, AW renders armor pieces on the wrong mannequin's body parts.\r\n\r\nFull body armor:\r\n![2016-05-02_00 05 29](https://cloud.githubusercontent.com/assets/6743303/14946517/9d4f1b20-0ff9-11e6-9665-b66716322cf5.png)\r\n![2016-05-01_23 35 24](https://cloud.githubusercontent.com/assets/6743303/14946516/9d4cae44-0ff9-11e6-9901-f669026a72cf.png)\r\n\r\nOnly pants:\r\n![2016-05-01_22 28 44](https://cloud.githubusercontent.com/assets/6743303/14945967/705f68f2-0ff1-11e6-8145-ce0068b4dbab.png)\r\n![2016-05-01_22 54 49](https://cloud.githubusercontent.com/assets/6743303/14945968/706033f4-0ff1-11e6-9c12-9e145daceac9.png)\r\n\r\nI'm using the latest AW version with latest 1.7.10 SM version.\n Comments: \n Comment 0: Can you try this version and tell me if it works. I think this has maybe been fixed but I never put out the build. http://puu.sh/oDnoK/e946773d65.jar\n\nThis is the current dev version please make a copy of your world before installing. Skins created in this version may not updated to the next version. (although they really should)\n\n Comment 1: > Can you try this version and tell me if it works.\r\n\r\nIt doesn't.\n Comment 2: Did you off the \"Chest armour render\"?\r\n\n Comment 3: Uh @RiskyKen, the version you put here causes my skin to bug out (meaning it looks all pink and black)\n\n Comment 4: @TheChronomancer please make a new issue and post your mod list.\n\n Comment 5: Only when Smart Moving is installed that's strange. What armours are you having issues with?\r\n\r\nSeems to be working for me :S\r\n\r\nhttp://puu.sh/oIcOt/b324442f16.png\n Comment 6: > What armours are you having issues with?\r\n\r\nVanilla armors: leather, diamond, golden...\r\n\r\nIt's a very weird bug. Firstly, the mannequins load right:\r\n\r\n![2016-08-30_00 50 39](https://cloud.githubusercontent.com/assets/6743303/18075551/2a0bc274-6e4c-11e6-94fa-4cf674fd8e35.png)\r\n\r\nThen once I press F5:\r\n\r\n![2016-08-30_00 50 51](https://cloud.githubusercontent.com/assets/6743303/18075555/303030fe-6e4c-11e6-9956-7d4b7f9ccf6f.png)\r\n\r\nAnd as you can see here, my (backup) world is a wreck, since I had removed all mods except:\r\nArmourers-Workshop-1.7.10-0.39.6.jar\r\nOptiFine_1.7.10_HD_U_D6.jar\r\nPlayerAPI-1.7.10-1.4.jar\r\nRenderPlayerAPI-1.7.10-1.4.jar\r\nSmartMoving-1.7.10-15.6.jar\r\nSmartRender-1.7.10-2.1.jar\r\nForge 1614\n Comment 7: Since I managed to solve that issue, I'm posting these leftovers in a separate post.\r\n\r\n1. The leather_layer_2_overlay and leather_layer_1 (torso part) do not follow the model rotation: [GIF 1](https://cloud.githubusercontent.com/assets/6743303/18076506/e3e09cd0-6e54-11e6-8970-15b8dd776522.gif)\r\n\r\n\r\n\r\n\r\n\r\n\n Comment 8: I recorded a video showing how each armor piece (chain mail set) rotates: https://youtu.be/y5cq5c2LKC0\r\n(the video was recorded with the mannequin facing south. The other mannequins are armor stands from other mods)\r\n\r\n**Key points:**\r\n* Head:\r\n  - Head wear: rotates 2x faster\r\n* Torso:\r\n  - Chest:\r\n    - X axis: rotates 2x faster\r\n    - Y and Z axes: don't rotate.\r\n  - Arms: their pivots are at the torso pivot.\r\n* Legs:\r\n  - Limbs: their pivots are at the torso pivot.\r\n* Feet:\r\n  - Limbs: their pivots are at the torso pivot.\r\n\r\nMods:\r\n- Armourers-Workshop-1.7.10-0.45.1.jar\r\n- PlayerAPI-1.7.10-1.4.jar\r\n- RenderPlayerAPI-1.7.10-1.4.jar\r\n- SmartMoving-1.7.10-15.6.jar\r\n- SmartRender-1.7.10-2.1.jar\n Comment 9: Updated title to reflect actual issue.\n Comment 10: > Updated title to reflect actual issue.\r\n\r\n@LordPhrozen, did you? For me it looks the same.\r\n\r\nNormally GitHub would log \"Issue title changed from X to Y on `date`\".\n Comment 11: I did now :D",
  "Issue title: Access API with API-KEY in case of OIDC \n Issue body: **Is your feature request related to a problem? Please describe.**\nWhen OIDC is enabled only the admin user/credential can use the API. In other cases it depends on the IDP or isn't possible as such.\n\n**Describe the solution you'd like**\nHarbor should extend the the \"Robot Accounts\" with READ/WRITE API\n\n Comments: \n Comment 0: Just encoutered that problem while trying to setup replication with Harbor as Provider.\n Comment 1: We're planning to enhance the robot account in the next 2.2 version. Supporting API permission is one of the items. Please stay tuned.\n Comment 2: See also.. where i have it working with Azure AD\r\nhttps://github.com/goharbor/harbor/issues/13683#issuecomment-739036574\n Comment 3: >  planning to enhance the robot account in the next 2.2 version. Supporting API permission is one of the items. Please stay tuned.\r\n\r\nI can see the first harbor 2.2 rc has been released today. Just to clarify: Is it possible in 2.2 to assign arbitrary api permissions to a robot account or only the select 10 permissions that are shown in the GUI? (I\u2019m interested in editing the repo description, which doesn\u2019t work with a regular user when oidc auth is enabled).\n Comment 4: @steven-zou is this delivered in 2.2.1 already?\n Comment 5: @Morriz take a look at https://github.com/goharbor/harbor/issues/14145#issuecomment-781006533 and let us know if that did work for you\r\n\n Comment 6: got that to work! check out https://github.com/redkubes/otomi-tasks/blob/master/src/tasks/harbor/harbor.ts/\n Comment 7: This issue is being marked stale due to a period of inactivity. If this issue is still relevant, please comment or remove the stale label. Otherwise, this issue will close in 30 days.",
  "Issue title: bug: ion-select\n Issue body: I use ion-select of Ionic on my application and I find an error on this.\r\nThis error is random and she's present on <ion-select interface=\"popover\"></ion-select>.\r\nWhen I select a value on my ion-select and I click on an other field, sometimes my value selected to modify alone.\r\nI've test on Ionic's documentation and I reproduct this error...\r\nIf I choose a value in gaming field and I click on an other field, Month for example, the gaming field change without selection of my part.\n Comments: \n Comment 0: Thanks for the issue! It appears that you have not filled out the provided issue template. We use this issue template in order to gather more information and further assist you. Please create a new issue and ensure the template is fully filled out.\n\nThank you for using Ionic!\n",
  "Issue title: Kubernetes pod using all nodes vCPU\n Issue body: I have a 8vcpu/8core box worker node where we are running our nginx pods.  nginx pods are limited to use only 2cores max in\r\n \r\nYAML definition i.e\r\nrequest cpu:- 500m\r\nlimit cpu:- 2\r\n\r\nnginx configuration as below,\r\n\r\nworker_process 2\r\nworker_cpu_affinity auto;\r\n\r\nnginx is using only 1st 2 CPU00, CPU01 of the nodes with 2 child processes and rest of other 6 CPUs are idle.\r\n\r\nwhereas with below nginx configuration\r\n\r\nworker_process auto\r\nworker_cpu_affinity auto;\r\n\r\nit is using all nodes CPU with that much number of processes.\r\n\r\nNow query here is,\r\n1) Why nginx container is not limiting to use 2 cores which is defined in pod definition, why it is using all CPUs?\r\n2) Why only first 2 CPU are utilized in former case where worker process are 2?\r\n3) Can pod use all CPU cores of a node even after limiting it in YAML definition?\r\n\r\n\r\n\r\n\n Comments: \n Comment 0: @Ankur7890: There are no sig labels on this issue. Please add an appropriate label by using one of the following commands:\n- `/sig <group-name>`\n- `/wg <group-name>`\n- `/committee <group-name>`\n\nPlease see the [group list](https://git.k8s.io/community/sig-list.md) for a listing of the SIGs, working groups, and committees available.\n\n\n<details>\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>\n Comment 1: @Ankur7890: This issue is currently awaiting triage.\n\nIf a SIG or subproject determines this is a relevant issue, they will accept it by applying the `triage/accepted` label and provide further guidance.\n\nThe `triage/accepted` label can be added by org members by writing `/triage accepted` in a comment.\n\n\n<details>\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>\n Comment 2: please try the support channels:\r\n\n Comment 3: https://github.com/kubernetes/kubernetes/blob/master/SUPPORT.md\r\n/close\n Comment 4: @neolit123: Closing this issue.\n\n<details>\n\nIn response to [this](https://github.com/kubernetes/kubernetes/issues/95827#issuecomment-716180460):\n\n>https://github.com/kubernetes/kubernetes/blob/master/SUPPORT.md\r\n>/close\n\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>",
  "Issue title: Serenity/JS 3.0 - Migrate WDIO mocha template\n Issue body: Migrate template https://github.com/serenity-js/serenity-js-mocha-webdriverio-template\r\n\u2014\u2014\r\n> migrate templates,\r\n\r\nThis is something I think we could actually start straight away (and, in fact, @gigamac has already started in https://github.com/serenity-js/serenity-js-cucumber-template/pull/209).\r\n\r\nWhat I think we'd need to do is:\r\n- create a branch called `main` in each template (based on the current `master`)\r\n- migrate the code to use `3.0.0-rc`\r\n- when 3.0 is published, swap the default branch in each template to `main` and rename `master` to `2.x`\r\n\r\n\ud83c\udfab It feels like migrating each template is a nice, isolated piece of work that someone could pick up.\r\n\r\n_Originally posted by @jan-molak in https://github.com/serenity-js/serenity-js/issues/805#issuecomment-1073366654_\r\n\r\n> I\u2019d even say, that 3.0 can go without having all the templates migrated, maybe we can prioritise some.\r\n\r\nYes, I think WDIO Cucumber and WDIO Mocha are probably the most important ones\r\n\r\n_Originally posted by @jan-molak  in https://github.com/serenity-js/serenity-js/issues/805#issuecomment-1074303265_\r\n\n Comments: \n Comment 0: @jan-molak, created https://github.com/serenity-js/serenity-js-mocha-webdriverio-template/pull/222 for this.\n Comment 1: merged",
  "Issue title: Drawer cover is not shown\n Issue body: Drawer cover is not shown on Galaxy Nexus(4.2)\r\n```\r\n02-14 13:33:22.202 11551-11551/io.github.droidkaigi.confsched.develop.debug W/OpenGLRenderer: Bitmap too large to be uploaded into a texture (2342x1304, max=2048x2048)\r\n02-14 13:33:22.225 11551-11551/io.github.droidkaigi.confsched.develop.debug W/OpenGLRenderer: Bitmap too large to be uploaded into a texture (2342x1304, max=2048x2048)\r\n02-14 13:33:22.241 11551-11551/io.github.droidkaigi.confsched.develop.debug W/OpenGLRenderer: Bitmap too large to be uploaded into a texture (2342x1304, max=2048x2048)\r\n02-14 13:33:22.256 11551-11551/io.github.droidkaigi.confsched.develop.debug W/OpenGLRenderer: Bitmap too large to be uploaded into a texture (2342x1304, max=2048x2048)\r\n```\r\n![device-2016-02-14-134012](https://cloud.githubusercontent.com/assets/1487505/13031881/91c10086-d320-11e5-86bd-70fba5670c9c.png)\r\nRelated with #54 \n Comments: \n Comment 0: :eyes:  Thanks for your report!!\n Comment 1: First we can try shrink this large image. I didn't do that.\n Comment 2: Close via #232",
  "Issue title: PGP and Uppercase\n Issue body: Hello,\n\nWhen I've generated my PGP key, I put an uppercase at the first letter of my mail address.\nNow, I've got a problem with rainloop because it use lowercase and so, my pgp key isn't recognised...\nCan rainloop be case insensitive when it check for pgp correspondence?\n\n Comments: \n Comment 0: Thanks\n\n Comment 1: I think you will have problems if you try to implement this, and I am not sure what RFC to cite, but domain names are case insensitive and usernames are not!  \n",
  "Issue title: get error for verify the cert-manager installation\n Issue body: Dear all,\r\n\r\nBelow is the error prompt in verification steps.\r\n[root@kubnms21 cert-manager]# kubectl apply -f test-resources.yaml\r\nnamespace/cert-manager-test unchanged\r\nError from server (InternalError): error when creating \"test-resources.yaml\": Internal error occurred: failed calling webhook \"webhook.cert-manager.io\": Post                                         https://cert-manager-webhook.cert-manager.svc:443/mutate?timeout=30s: Service Unavailable\r\nError from server (InternalError): error when creating \"test-resources.yaml\": Internal error occurred: failed calling webhook \"webhook.cert-manager.io\": Post                                         https://cert-manager-webhook.cert-manager.svc:443/mutate?timeout=30s: Service Unavailable\r\n\r\n\r\n[root@kubnms21 cert-manager]# kubectl get pods -n cert-manager\r\nNAME                                      READY   STATUS    RESTARTS   AGE\r\ncert-manager-66c8bc8b67-7hw2x             1/1     Running   0          22m\r\ncert-manager-cainjector-df4dc78cd-fqqjx   1/1     Running   0          22m\r\ncert-manager-webhook-5f78ff89bc-69b7j     1/1     Running   0          22m\r\n\r\n[root@kubnms21 cert-manager]# kubectl logs cert-manager-webhook-5f78ff89bc-69b7j -n cert-manager\r\nI0107 06:45:59.799305       1 main.go:64]  \"level\"=0 \"msg\"=\"enabling TLS as certificate file flags specified\"\r\nI0107 06:45:59.800091       1 server.go:121]  \"level\"=0 \"msg\"=\"listening for insecure healthz connections\"  \"address\"=\":6080\"\r\nI0107 06:45:59.800200       1 server.go:133]  \"level\"=0 \"msg\"=\"listening for secure connections\"  \"address\"=\":10250\"\r\nI0107 06:45:59.800842       1 tls_file_source.go:142]  \"level\"=0 \"msg\"=\"detected private key or certificate data on disk has changed. reloading certificate\" \r\n\r\n[root@kubnms21 cert-manager]# kubectl describe pods cert-manager-webhook-5f78ff89bc-69b7j -n cert-manager\r\nName:           cert-manager-webhook-5f78ff89bc-69b7j\r\nNamespace:      cert-manager\r\nPriority:       0\r\nNode:           kubnnd23/116.69.203.115\r\nStart Time:     Tue, 07 Jan 2020 14:43:43 +0800\r\nLabels:         app=webhook\r\n                app.kubernetes.io/instance=cert-manager\r\n                app.kubernetes.io/managed-by=Tiller\r\n                app.kubernetes.io/name=webhook\r\n                helm.sh/chart=cert-manager-v0.12.0\r\n                pod-template-hash=5f78ff89bc\r\nAnnotations:    <none>\r\nStatus:         Running\r\nIP:             116.69.203.115\r\nControlled By:  ReplicaSet/cert-manager-webhook-5f78ff89bc\r\nContainers:\r\n  cert-manager:\r\n    Container ID:  docker://2bd248711a2eb123e17615f6ea33351f313b7e69f16b7a8fabcce946d6770c5d\r\n    Image:         quay.io/jetstack/cert-manager-webhook:v0.12.0\r\n    Image ID:      docker-pullable://quay.io/jetstack/cert-manager-webhook@sha256:f3b58247c674937deab9ae9603a2f2bf332bdd31a0e4f7928b52f7abfe653f15\r\n    Port:          <none>\r\n    Host Port:     <none>\r\n    Args:\r\n      --v=2\r\n      --secure-port=10250\r\n      --tls-cert-file=/certs/tls.crt\r\n      --tls-private-key-file=/certs/tls.key\r\n    State:          Running\r\n      Started:      Tue, 07 Jan 2020 14:45:59 +0800\r\n    Ready:          True\r\n    Restart Count:  0\r\n    Liveness:       http-get http://:6080/livez delay=0s timeout=1s period=10s #success=1 #failure=3\r\n    Readiness:      http-get http://:6080/healthz delay=0s timeout=1s period=10s #success=1 #failure=3\r\n    Environment:\r\n      POD_NAMESPACE:  cert-manager (v1:metadata.namespace)\r\n    Mounts:\r\n      /certs from certs (rw)\r\n      /var/run/secrets/kubernetes.io/serviceaccount from cert-manager-webhook-token-57bs6 (ro)\r\nConditions:\r\n  Type              Status\r\n  Initialized       True\r\n  Ready             True\r\n  ContainersReady   True\r\n  PodScheduled      True\r\nVolumes:\r\n  certs:\r\n    Type:        Secret (a volume populated by a Secret)\r\n    SecretName:  cert-manager-webhook-tls\r\n    Optional:    false\r\n  cert-manager-webhook-token-57bs6:\r\n    Type:        Secret (a volume populated by a Secret)\r\n    SecretName:  cert-manager-webhook-token-57bs6\r\n    Optional:    false\r\nQoS Class:       BestEffort\r\nNode-Selectors:  <none>\r\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\r\n                 node.kubernetes.io/unreachable:NoExecute for 300s\r\nEvents:\r\n  Type     Reason       Age                From               Message\r\n  ----     ------       ----               ----               -------\r\n  Normal   Scheduled    24m                default-scheduler  Successfully assigned cert-manager/cert-manager-webhook-5f78ff89bc-69b7j to kubnnd23\r\n  Warning  FailedMount  23m (x8 over 24m)  kubelet, kubnnd23  MountVolume.SetUp failed for volume \"certs\" : secret \"cert-manager-webhook-tls\" not found\r\n  Warning  FailedMount  22m                kubelet, kubnnd23  Unable to mount volumes for pod \"cert-manager-webhook-5f78ff89bc-69b7j_cert-manager(4e3559fa-0542-4feb-a54b-aa5508a4d35d)\": timeout expired waiting for volumes to attach or mount for pod \"cert-manager\"/\"cert-manager-webhook-5f78ff89bc-69b7j\". list of unmounted volumes=[certs]. list of unattached volumes=[certs cert-manager-webhook-token-57bs6]\r\n  Normal   Pulled       22m                kubelet, kubnnd23  Container image \"quay.io/jetstack/cert-manager-webhook:v0.12.0\" already present on machine\r\n  Normal   Created      22m                kubelet, kubnnd23  Created container cert-manager\r\n  Normal   Started      22m                kubelet, kubnnd23  Started container cert-manager\r\n[root@kubnms21 cert-manager]#\r\n\r\n[root@kubnms21 cert-manager]# kubectl get nodes -o wide\r\nNAME       STATUS   ROLES    AGE    VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION               CONTAINER-RUNTIME\r\nkubnms21   Ready    master   177d   v1.15.3   116.69.203.115   <none>        CentOS Linux 7 (Core)   3.10.0-1062.9.1.el7.x86_64   docker://19.3.5\r\nkubnms22   Ready    master   177d   v1.15.3   116.69.203.115   <none>        CentOS Linux 7 (Core)   3.10.0-1062.1.2.el7.x86_64   docker://18.9.7\r\nkubnms23   Ready    master   177d   v1.15.3   116.69.203.115   <none>        CentOS Linux 7 (Core)   3",
  "Issue title: Support and respect underlying tool's `--fix` feature\n Issue body: Proposal is to respect, where possible, a tool's underlying fixes. Related ask from a user:\r\n\r\n> I also wouldn't mind a way to apply changes (kind of like python's `2to3` converts files).\n Comments: \n Comment 0: Honestly https://libcst.readthedocs.io is way better than `2to3 ` for enabling this feature. See https://github.com/returntocorp/r2c-authentication-checks/pull/4 for previous work!\n Comment 1: @ulziibay unfortunately libCST only supports python 3.5+ as input, so it couldn't do 2to3 workflow\n Comment 2: User comment:\r\n\r\n> * There were some things that would be nice to fix, but would be a pain to go through and manually fix them. Ex: == vs ===. Would be nice to have something like tslint's tslint --fix.\n Comment 3: Spatch can also implement easily many autofixes.\r\nSee https://github.com/facebookarchive/pfff/wiki/Spatch\r\nI have a version that can work on many languages that is similar to the recent paper\r\nby claire Goues on parser combinators for program transformation.",
  "Issue title: SqlServer Cache Dependency\n Issue body: Hello, \n\nI have a few questions here.\n1. Do we still support SqlServer cache dependency on SQLServer Cache in ASP.NET? If yes how should I configure it? \n2. How can I define DI for SQLCacheDependency and what should I put  in the constructor of Controller ( IDistributedCache?)\n3. I have been using table based cache dependency, is there a solution to manage SQLCacheDependency at record level?\n4. I'm using RedisCache in ASP.NET 4, do you have performance benchmark between RedisCache on Azure cloud and SQL Cache in a local DB? \n\nThanks lot!\nGary\n\n Comments: \n Comment 0: We haven't prioritized this in the past 5 years and I don't expect that to change. This seems like a great distinguishing feature for a third-party SQL Server cache component. Closing as we don't expect this to be something we can prioritize.",
  "Issue title: panic in cascades planner when read from partitioned table\n Issue body: # Bug Report\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n## 1. What did you do?\r\n\r\n```sql\r\ndrop table if exists pt;\r\ncreate table pt(a bigint, b bigint) partition by hash(a) partitions 4;\r\n\r\n-- enable cascades planner\r\nset @@tidb_enable_cascades_planner = 1;\r\ndesc select * from pt;\r\n```\r\n\r\n## 2. What did you expect to see?\r\n\r\nexecuted successfully, no panic.\r\n\r\n## 3. What did you see instead?\r\n\r\npanic log:\r\n\r\n```\r\n[2020/01/05 15:15:42.647 +08:00] [ERROR] [conn.go:622] [\"connection running loop panic\"] [conn=1] [lastSQL=\"desc select * from pt\"] [err=\"runtime error: invalid memory address or nil pointer dereference\"] [stack=\"goroutine 227 [running]:\r\ngithub.com/pingcap/tidb/server.(*clientConn).Run.func1(0x5c0b920, 0xc00091aff0, 0xc0000c0680)\r\n    /Users/zhangjian/Code/tidb/server/conn.go:620 +0xee\r\npanic(0x5621540, 0x6f9d1e0)\r\n    /opt/goroot/src/runtime/panic.go:679 +0x1b2\r\ngithub.com/pingcap/tidb/planner/core.(*DataSource).initStats(0xc0074ce000)\r\n    /Users/zhangjian/Code/tidb/planner/core/stats.go:148 +0x6c\r\ngithub.com/pingcap/tidb/planner/core.(*DataSource).deriveStatsByFilter(0xc0074ce000, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0xc0074c4220)\r\n    /Users/zhangjian/Code/tidb/planner/core/stats.go:162 +0x43\r\ngithub.com/pingcap/tidb/planner/core.(*LogicalTableScan).DeriveStats(0xc0008ac750, 0x7023800, 0x0, 0x0, 0xc0008116b0, 0x7023800, 0x0, 0x0, 0x83858b8, 0x0,...)\r\n    /Users/zhangjian/Code/tidb/planner/core/stats.go:271 +0x137\r\ngithub.com/pingcap/tidb/planner/cascades.(*Optimizer).fillGroupStats(0xc00031be30, 0xc000814c30, 0x1, 0xc00733c230)\r\n    /Users/zhangjian/Code/tidb/planner/cascades/optimize.go:240 +0x24c\r\ngithub.com/pingcap/tidb/planner/cascades.(*Optimizer).fillGroupStats(0xc00031be30, 0xc000814b40, 0xc000832680, 0x18)\r\n    /Users/zhangjian/Code/tidb/planner/cascades/optimize.go:232 +0x14a\r\ngithub.com/pingcap/tidb/planner/cascades.(*Optimizer).implGroup(0xc00031be30, 0xc000814b40, 0xc000814c80, 0x7fefffffffffffff, 0x1, 0xc0074c4160, 0x4016687, 0xc0008ac708)\r\n    /Users/zhangjian/Code/tidb/planner/cascades/optimize.go:279 +0x12e\r\ngithub.com/pingcap/tidb/planner/cascades.(*Optimizer).onPhaseImplementation(0xc00031be30, 0x5c5f620, 0xc00700a400, 0xc000814b40, 0x0, 0x0, 0xc00082cb00, 0x0, 0x0)\r\n    /Users/zhangjian/Code/tidb/planner/cascades/optimize.go:251 +0x109\r\ngithub.com/pingcap/tidb/planner/cascades.(*Optimizer).FindBestPlan(0xc00031be30, 0x5c5f620, 0xc00700a400, 0x5c3d540, 0xc00082cb00, 0x1, 0x1, 0x0, 0x0, 0x0)\r\n    /Users/zhangjian/Code/tidb/planner/cascades/optimize.go:115 +0x10a\r\ngithub.com/pingcap/tidb/planner.optimize(0x5c0b920, 0xc00091aff0, 0x5c5f620, 0xc00700a400, 0x5c0d420, 0xc00083e300, 0x5c342c0, 0xc0070438f0, 0x0, 0x203000,...)\r\n    /Users/zhangjian/Code/tidb/planner/optimize.go:151 +0x45e\r\ngithub.com/pingcap/tidb/planner.Optimize(0x5c0b920, 0xc00091aff0, 0x5c5f620, 0xc00700a400, 0x5c0d420, 0xc00083e300, 0x5c342c0, 0xc0070438f0, 0xc000811110, 0x0,...)\r\n    /Users/zhangjian/Code/tidb/planner/optimize.go:50 +0x254\r\ngithub.com/pingcap/tidb/planner/core.(*PlanBuilder).buildExplain(0xc0008dc500, 0x5c0b920, 0xc00091aff0, 0xc00082a900, 0x20, 0x56c7e60, 0x57de401, 0xc000830a80)\r\n    /Users/zhangjian/Code/tidb/planner/core/planbuilder.go:2682 +0x10b\r\ngithub.com/pingcap/tidb/planner/core.(*PlanBuilder).Build(0xc0008dc500, 0x5c0b920, 0xc00091aff0, 0x5c0c760, 0xc00082a900, 0xc0008dc500, 0xc007340400, 0x83858b8, 0x0)\r\n    /Users/zhangjian/Code/tidb/planner/core/planbuilder.go:387 +0xe8b\r\ngithub.com/pingcap/tidb/planner.optimize(0x5c0b920, 0xc00091aff0, 0x5c5f620, 0xc00700a400, 0x5c0c760, 0xc00082a900, 0x5c342c0, 0xc0070438f0, 0x83858b8, 0x0,...)\r\n    /Users/zhangjian/Code/tidb/planner/optimize.go:115 +0x17f\r\ngithub.com/pingcap/tidb/planner.Optimize(0x5c0b920, 0xc00091aff0, 0x5c5f620, 0xc00700a400, 0x5c0c760, 0xc00082a900, 0x5c342c0, 0xc0070438f0, 0x0, 0x0,...)\r\n    /Users/zhangjian/Code/tidb/planner/optimize.go:50 +0x254\r\ngithub.com/pingcap/tidb/executor.(*Compiler).Compile(0xc0074c4ea8, 0x5c0b920, 0xc00091aff0, 0x5c11ea0, 0xc00082a900, 0x0, 0x0, 0x0)\r\n    /Users/zhangjian/Code/tidb/executor/compiler.go:61 +0x253\r\ngithub.com/pingcap/tidb/session.(*session).execute(0xc00700a400, 0x5c0b920, 0xc00091aff0, 0xc000832621, 0x15, 0x407aa46, 0xc0074c51c0, 0x4030a81, 0x596e9e8, 0xc0074c51d0)\r\n    /Users/zhangjian/Code/tidb/session/session.go:1110 +0x5cf\r\ngithub.com/pingcap/tidb",
  "Issue title: DASHStreams allow a manifest string instead of an url\n Issue body: ## Feature Request\r\n\r\n- [x] This is a feature request and I have read the contribution guidelines.\r\n\r\n\r\n### Description\r\n\r\nsome DASHStreams don't have an URL, they are only provided as a XML String\r\n\r\n**Facebook** as an example uses this method\r\n\r\n- https://github.com/streamlink/streamlink/issues/2133\r\n- https://github.com/streamlink/streamlink/issues/2168\r\n\r\nsome example Video URLs can be found in the other issues,\r\nthis feature is required to solve the other issues.\r\n\r\n---\r\n\r\n`parse_manifest` needs an update\r\n\r\nhttps://github.com/streamlink/streamlink/blob/5db462eb993d659e27d9de4babd14ab33eb4ad8d/src/streamlink/stream/dash.py#L165-L180\r\n\r\nhere is some example, in how it could be done\r\n\r\n```diff\r\ndiff --git a/src/streamlink/stream/dash.py b/src/streamlink/stream/dash.py\r\nindex 7339735c..5859efb5 100644\r\n--- a/src/streamlink/stream/dash.py\r\n+++ b/src/streamlink/stream/dash.py\r\n@@ -5,13 +5,14 @@ import os.path\r\n \r\n import requests\r\n from streamlink import StreamError, PluginError\r\n-from streamlink.compat import urlparse, urlunparse\r\n+from streamlink.compat import urlparse, urlunparse, unquote_plus\r\n from streamlink.stream.http import valid_args, normalize_key\r\n from streamlink.stream.stream import Stream\r\n from streamlink.stream.dash_manifest import MPD, sleeper, sleep_until, utc, freeze_timeline\r\n from streamlink.stream.ffmpegmux import FFMPEGMuxer\r\n from streamlink.stream.segmented import SegmentedStreamReader, SegmentedStreamWorker, SegmentedStreamWriter\r\n from streamlink.utils.l10n import Language\r\n+from streamlink.utils import parse_xml\r\n \r\n log = logging.getLogger(__name__)\r\n \r\n@@ -162,7 +163,7 @@ class DASHStream(Stream):\r\n         return dict(type=type(self).shortname(), url=req.url, headers=headers)\r\n \r\n     @classmethod\r\n-    def parse_manifest(cls, session, url, **args):\r\n+    def parse_manifest(cls, session, url, manifest=None, **args):\r\n         \"\"\"\r\n         Attempt to parse a DASH manifest file and return its streams\r\n \r\n@@ -170,14 +171,26 @@ class DASHStream(Stream):\r\n         :param url: URL of the manifest file\r\n         :return: a dict of name -> DASHStream instances\r\n         \"\"\"\r\n+\r\n         ret = {}\r\n-        res = session.http.get(url, **args)\r\n-        url = res.url\r\n \r\n-        urlp = list(urlparse(url))\r\n-        urlp[2], _ = urlp[2].rsplit(\"/\", 1)\r\n+        # XXX: Test manifest\r\n+        url = None\r\n+        manifest = '\\x3C?xml version=\\\"1.0\\\"?>\\n\\x3CMPD xmlns=\\\"urn:mpeg:dash:schema:mpd:... x3C/AdaptationSet>\\x3C/Period>\\x3C/MPD>\\n'\r\n+\r\n+        if url and not manifest:\r\n+            res = session.http.get(url, **args)\r\n+            url = res.url\r\n+\r\n+            urlp = list(urlparse(url))\r\n+            urlp[2], _ = urlp[2].rsplit(\"/\", 1)\r\n \r\n-        mpd = MPD(session.http.xml(res, ignore_ns=True), base_url=urlunparse(urlp), url=url)\r\n+            mpd = MPD(session.http.xml(res, ignore_ns=True), base_url=urlunparse(urlp), url=url)\r\n+        elif manifest and not url:\r\n+            mpd = MPD(parse_xml(unquote_plus(manifest).replace(\"\\\\\", \"\"), ignore_ns=True))\r\n+            # mpd = MPD(manifest, ignore_ns=True)\r\n+        else:\r\n+            raise StreamError(\"...\")\r\n \r\n         video, audio = [], []\r\n```\r\n\r\n### Expected / Actual behavior\r\n\r\nUse a XML String instead of an URL for DASHStreams.\r\n\r\n\n Comments: \n Comment 0: Could make it a file like (eg. `StringIO`) then it would work for other cases too, dunno which other cases - but it sounds like a good idea. ",
  "Issue title: How does autocontainmode \"relaxed\" work?\n Issue body: Tridactyl version: 1.21.0pre5424-85d7bcbe\r\nFirefox version: Mozilla Firefox 86.0.1\r\nOperating system: linux\r\n\r\n-   Brief description of the problem:\r\n`relaxed` mode doesn't seem to assign tabs to the expected container, neither when opened as a new tab nor from an existing tab. Is this behaviour normal?\r\n\r\n-   Steps to reproduce:\r\n\r\n```\r\nset auconcreatecontainer true\r\nset autocontainmode relaxed\r\nautocontain -s archlinux.org tech\r\n\r\ntabopen archlinux.org\r\nopen archlinux.org\r\n```\n Comments: \n Comment 0: Yeah, it must be broken, thanks for filing the issue! `tabopen archlinux.org` is supposed to be in the `tech` container in your example.\r\n\r\nProbably introduced by ea257f364 or 85129c346, something like that.\r\n\r\nI'm a bit perplexed though because I think https://github.com/tridactyl/tridactyl/blob/ee8bd48d46c1550282d89ec066d9a1808908fcba/src/excmds.ts#L2392 should still work : /",
  "Issue title: ElggMemcache->load reports false negative (ERROR: MEMCACHE: FAILED TO LOAD...) (Trac #3993)\n Issue body: _Original ticket http://trac.elgg.org/ticket/3993 on 41805790-08-18 by trac user janlb, assigned to unknown._\n\nElgg version: 1.7\n\nElggMemcache->load($key) reports a false negative when it returns a value that evaluates to FALSE.\n\nFor example:\n\n$memcache->save('key', array());\n$memcache->load('key');\n\nWill report that it failed to load 'key'\n\nElgg should check for FALSE 'identicalness' via ===\n(see: http://www.php.net/manual/en/memcache.get.php#refsect1-memcache.get-returnvalues)\n\n Comments: \n Comment 0: _trac user janlb wrote on 41825237-10-02_\n\nduplicate of #1995\n",
  "Issue title: Button not showing on tasks in Salesforce integration\n Issue body: #### Relevant integration (if any): Salesforce\r\n\r\n### \ud83d\udc1b Describe the bug\r\n\r\ntoggl button salesforce integration issue - user can see button on some pages (e.g. profile page, attached), but not on the task lists\r\n![image](https://user-images.githubusercontent.com/18132080/59045664-ca231900-8880-11e9-9d84-fd779b13ca22.png)\r\nBut it's not showing on the task lists\r\n![image](https://user-images.githubusercontent.com/18132080/59045698-d909cb80-8880-11e9-9259-c79e30917046.png)\r\nScreenshot from the wiki showing where it should appear:\r\n![image](https://user-images.githubusercontent.com/18132080/59045724-e6bf5100-8880-11e9-80a7-a03af71329d5.png)\r\n\r\n\r\n\r\n### Other details or context\r\nconversations/22174259794\r\n\n Comments: \n Comment 0: [case reference](https://app.intercom.com/a/apps/ayixs927/inbox/inbox/2759100/conversations/26301393618)",
  "Issue title: Don't treat EOF as an error when enable.partition.eof is false\n Issue body: Description\r\n===========\r\nBy setting enable.partition.eof to false, EOF is not emitted to the application, but internally, EOF is still treated as an error. Meanwhile, we have fetch.error.backoff.ms defaults to 500ms. As a result, regardless of enable.partition.eof value, by default, every time consumer hits EOF, it will wait 500 ms before next fetch. It might be what most people want as a default behavior, we are building an application that requires a latency much lower than 500ms.\r\n\r\nThe workaround right now is to assign 0 or a small value to fetch.error.backoff.ms. But this is not ideal because we still want to wait 500ms or even longer should other errors happen, e.g., leader not available. A better solution would be to skip error backoff for EOF when enable.partition.eof is false. Alternatively, we can also have a separate error backoff just for EOF.\r\n\r\ncc @qix\r\n\r\nHow to reproduce\r\n================\r\n\r\nUse high-level consumer to consume from a low volume topic so that it will hit EOF. Note that this is not bug. librdkafka is behaving as designed, but we are proposing an alternative design.\r\n\r\n\r\nChecklist\r\n=========\r\nPlease provide the following information:\r\n\r\n - [x] librdkafka version (release number or git tag): 0.9.2\r\n - [x] Apache Kafka version: 116.69.203.115\r\n - [x] librdkafka client configuration: fetch.error.backoff.ms=500, enable.partition.eof=false\r\n - [x] Operating system: Ubuntu 16.04\r\n - [x] Using the legacy Consumer: No\r\n - [x] Using the high-level KafkaConsumer: Yes\r\n - [ ] Provide logs (with `debug=..` as necessary) from librdkafka\r\n - [ ] Provide broker log excerpts\r\n - [ ] Critical issue\r\n\r\n\n Comments: \n Comment 0: As to not change existing behaviour (which people might depend) I think your second proposal is good: adding a separate configuration property.\r\nBut it might be better to abstract that somewhat and add a higher-level property that defines the application's desired maximum latency and then various parts of the code can use that value automatically to try to adhere to that contract.\r\n\r\nSomething like `latency.max.ms`, which could also be used for the producer.\r\n\r\nWhat do you think?\n Comment 1: That's even better!",
  "Issue title: Comments on workflow\n Issue body: It would be cool if you can add comment tap in the general section\r\nso that we can write a summery or describe the function of the workflow \n Comments: \n Comment 0: Do you mean to add a description to the workflow?\n Comment 1: yes that would be helpful, and to add comments for each step of the workflow as drag and drop box",
  "Issue title: Training Anime like ARCANE (Netflix)\n Issue body: Quick question:\r\nIs it possible to train with new style like from Netflix style animation \"ARCANE\" I really love their rendering of face.\r\n\r\nIf possible, is it hard, does it take a long time using M1?\n Comments: \n Comment 0: It would be cool indeed. I think Face Portrait v2 is close to this.\r\nI will try to train with my own dataset and will let you know if I succeed with ARCANE pictures\n Comment 1: @Greg8978 Have you trained the model on your own dataset and what kind of dataset is it, facial animation? Looking forward for your update.\n Comment 2: Hey there!\r\n\r\nI collect some images directly from the show.\r\nI try to train the model but it took 187 hours on my ubuntu.\r\nI did not take the time to try to make the setup on my windows computer to use GPU for trainning.\r\n\r\n\r\n\n Comment 3: > Hey there!\r\n> \r\n> I collect some images directly from the show. I try to train the model but it took 187 hours on my ubuntu. I did not take the time yet to make the setup on my windows computer to use GPU for trainning.\r\n\r\nWould you mind sharing the dataset? I have enough GPU resources for training.\n Comment 4: Sure, have a look [here](https://we.tl/t-1wPGKRJlUJ)\r\n\n Comment 5: @zhanglonghao1992, if you can share the training output it would make thinks easier for me ;)\n Comment 6: @Greg8978  I failed to train face stylization on the data set you provided. I guess the training style data should contain a large number of clear faces. At present, I plan to collect more face images in Arcane for training.\n Comment 7: Ha ok, thanks for the feedback.\n Comment 8: this dataset might be of interest, not exactly arcane look but artstation has a realistic stylized look https://github.com/onion-liu/aahq-dataset\n Comment 9: I'm training one but the results are not as good so far. will let you know if I get it work. \r\nIn the mean time, here are some super-cherry-picked golden samples:\r\n\r\n![arcane](https://user-images.githubusercontent.com/26464535/144731793-51f73a57-8f36-4243-b515-c83c4db5776c.jpeg)\r\n\r\n\n Comment 10: any chance that you could release the checkpoint? the results look amazing already\n Comment 11: > I'm training one but the results are not as good so far. will let you know if I get it work. In the mean time, here are some super-cherry-picked golden samples:\r\n> \r\n>![arcane](https://user-images.githubusercontent.com/26464535/144731793-51f73a57-8f36-4243-b515-c83c4db5776c.jpeg)\r\n\r\nDid you do face alignment when training face stylization?\n Comment 12: > Face Por\r\n\r\nThanks, your results looks fine enough. Could you please tell me which training code you use? I have another custom dataset and want to train it too. \n Comment 13: I've also given a try to this style. So far I've got results like this on images in the wild. \r\n![image](https://user-images.githubusercontent.com/11751592/144801328-546d2c6c-8abf-4541-941c-ffaae959eb49.png)\r\n\n Comment 14: > I've also given a try to this style. So far I've got results like this on images in the wild.![image](https://user-images.githubusercontent.com/11751592/144801328-546d2c6c-8abf-4541-941c-ffaae959eb49.png)\r\n\r\nThat's cool! Would you mind sharing you training datasets and strategies?\n Comment 15: > I'm training one but the results are not as good so far. will let you know if I get it work. In the mean time, here are some super-cherry-picked golden samples:\r\n> \r\n>![arcane](https://user-images.githubusercontent.com/26464535/144731793-51f73a57-8f36-4243-b515-c83c4db5776c.jpeg)\r\n\r\nThose are awesome! Is that a blend with the same Z or a projection?\n Comment 16: > I'm training one but the results are not as good so far. will let you know if I get it work. In the mean time, here are some super-cherry-picked golden samples:\r\n> \r\n>![arcane](https://user-images.githubusercontent.com/26464535/144731793-51f73a57-8f36-4243-b515-c83c4db5776c.jpeg)\r\n\r\nHi, how many pictures did you use to train stylegan model?\n Comment 17: > \r\n\r\nAmazing work! When I train stylegan model using screenshots in anime, there are always artifacts on the face. I am troubled by the lack of appropriate data sets. I wonder how many pictures did you use to train stylegan model? I would appreciate it if you could let me know. And if it is convenient, I would like to ask if you can release the data set?\n Comment 18: > I'm training one but the results are not as good so far. will let you know if I get it work. In the mean time, here are some super-cherry-picked golden samples:\r\n> \r\n>![arcane](https://user-images.githubusercontent.com/26464535/144731793-51f73a57-8f36-4243-b515-c83c4db5776c.jpeg)\r\nAmazing work! When I train stylegan model using screenshots in anime, there are always artifacts on the face. I am troubled by the lack of appropriate data sets. I wonder how many pictures did you use to train stylegan model? I would appreciate it if you could let me know. And if it is convenient, I would like to ask if you can release the data set?\r\n\n Comment 19: > I'm training one but the results are not as good so far. will let you know if I get it work. In the mean time, here are some super-cherry-picked golden samples:\r\n> \r\n>![arcane](https://user-images.githubusercontent.com/26464535/144731793-51f73a57-8f36-4243-b515-c83c4db5776c.jpeg)\r\n\r\nAwesome! Is this a StyleGAN result then do a animegan training?\n Comment 20: > Sure, have a look [here](https://we.tl/t-1wPGKRJlUJ)\r\n\r\nThe transfer has expired, can you share it again?\n Comment 21: It's easy to reproduce, just collect arcane video(s) (I used youtube trailers), then \r\n`ffmpeg -i Arcanevideo.mp4  fps=0.5 arcane%d.jpg`\n Comment 22: @bilal2vec These are super cherrypicked samples. The model's really fragile at the moment and have obvious normalization related artifacts for most of the images. I'm testing out some other techniques and trying to find a sweet spot between the quality and robustness.\r\n@zhanglonghao1992  I didn't but it should help\r\n@Sxela It's from a distilled pix2pix model\r\n@rainsoulsrx @tinapan-pt  I've used about 500 images but it contains many duplicates cause it was taken from videos with limited characters\r\n@chenhk-chn yup\r\n\r\n\n Comment 23: @bryandlee Do you use pair data for training?\n Comment 24: > @bilal2vec These are super cherrypicked samples. The model's really fragile at the moment and have obvious normalization related artifacts for most of the images. I'm testing out some other techniques and trying to find a sweet spot between the quality and robustness.\r\n> \r\n> @zhanglonghao1992 I didn't but it should help\r\n> \r\n> @Sxela It's from a distilled pix2pix model\r\n> \r\n> @rainsoulsrx @tinapan-pt I've used about 500 images but it contains many duplicates cause it was taken from videos with limited characters\r\n> \r\n> @chenhk-chn yup\r\n\r\nSo besides these super cherrypicked samples, would  you please share some normal examples? \n Comment 25: @zhanglonghao1992 yup\r\n\r\n@rainsoulsrx  https://fragrant-chauffeur-53f.notion.site/Failures-d701a060e52046188b45823f56589093\r\nIt's pix2pixHD network with instance norm and I suspect that the black blobs are something similar to the \"droplet artifact",
  "Issue title: \u624d\u4e70\u4e0d\u4e45\u7684\u4e24\u5e74\u4e13\u4e1a\u7248\u5c31\u7528\u4e0d\u4e86\u4e86\uff0c\u6c42\u89e3\u51b3\n Issue body: \u624d\u4e70\u4e0d\u4e45\u7684\u4e24\u5e74\u4e13\u4e1a\u7248\u5c31\u7528\u4e0d\u4e86\u4e86\uff0c\u6c42\u89e3\u51b3\uff0cmacos\u7cfb\u7edf\u7684\uff0c\u65b0\u7248\u4e5f\u6ca1\u7528\uff0c\u8fd8\u4e0d\u5982\u4ee5\u524d\n Comments: \n Comment 0: \u5e94\u8be5\u662f19\u5927\u52a0\u5f3a\u4e86\u7f51\u7edc\u5c01\u9501\uff0c\u5c34\u5c2c\u554a\uff0c\u6211\u662f\u524d\u4e0d\u4e45\u624d\u7eed\u8d39\u4e00\u5e74\u3002\n Comment 1: \u540c\u521a\u7eed\u8d39\u4e00\u5e74\u3002\u3002\u3002",
  "Issue title: Justifying text in CTkLabel\n Issue body: I am trying to justify text to the left in my program. Here is the label code:\r\n`self.lblUserInfo = CTkLabel(\r\n            self.frameMain,\r\n            width=200,\r\n            text=\"User (Username)\",\r\n            text_font=self.font3,\r\n            text_color=(\"#0969DA\", \"#58A6FF\"),\r\n            justify=\"left\",\r\n            anchor=\"w\",\r\n            fg_color=\"gray30\" # <- temporary, just for highlighting the issue\r\n        )`\r\nand the code for placement (using grid):\r\n`self.lblUserInfo.grid(row=0, column=0, padx=10, pady=10, sticky=\"w\")`\r\n\r\nThis is what the GUI looks like:\r\n![image](https://user-images.githubusercontent.com/80557973/175807865-d8de002e-3684-4d21-bfc4-24ac830654b1.png)\r\nAs shown the label with text \"User (Username)\" still has text that is not justified properly, I'm not sure why the options aren't working, could someone please explain why this is happening and what I could do to fix it?\n Comments: \n Comment 0: Update: It seems the issue only happens for labels with **bold** text and also goes away when they are configured (even if the configure isn't changing the justify attribute).\n Comment 1: **Update:** I believe this may be an issue with the way the CTkLabel is created. While the anchor option is passed to the internal tkinter Label widget through **kwargs in ctk_label.py, the label itself is placed inside the canvas using grid which always places it in the centre of the canvas. This placement renders the anchor value input into the CTkLabel useless.\r\n\r\nIn my own installation of customtkinter I have fixed this issue by adding an anchor option into the __init__ function of with a default value of \"center\". I then pass this anchor value into the internal tkinter Label widget that the CTkLabel class creates. Afterwards I assign the anchor value to a variable called'stickyness' (with \"center\" being mapped to None as \"center\" is not an accepted stickyness value). This stickyness value is then passed into the'sticky' attribute of the grid function to properly align the internal tkinter Label widget according to the anchor specified in the CTkLabel. Here are the images of my changes (Atom IDE with Atom Material theme):\r\n![image](https://user-images.githubusercontent.com/80557973/175811407-4d28a160-e813-4833-851d-14688da7fee5.png)\r\n![image](https://user-images.githubusercontent.com/80557973/175811426-05a9520c-e7ba-4381-959f-1ac85d020231.png)\r\n![image](https://user-images.githubusercontent.com/80557973/175811459-c53d788e-5128-4488-a002-4a9bba14b74a.png)\r\n![image](https://user-images.githubusercontent.com/80557973/175811489-5c622731-47d9-4824-871b-f59362d214e4.png)\r\n\r\nThis fix works for my use case, however I haven't thoroughly tested this. That being said, could a permanent fix like this be implemented to the actual customtkinter library sometime soon?\n Comment 2: I know of this behaviour, I think I will try to do it like you suggested it and move the text to the correct edge when the anchor attribute is passed.\n Comment 3: That's great to hear, hope to see it implemented soon.\n Comment 4: Works now with version 4.5.5.",
  "Issue title: Automatische Korrektur bei Datumseingabe abschalten\n Issue body: bei Eingabe des Datums z.B. im Zinsen-Dialog findet sofort eine Plausibilit\u00e4tspr\u00fcfung statt.\r\nDa wir uns im Monat Februar befinden, kann ich aus diesem Grund bei Tag nicht 30 eingeben. (In Deutschland schreibt man normalerweise erst den Tag, Monat und zum Schlu\u00df das Jahr.\r\n\r\nIch m\u00f6chte 30.09.2002 eingeben, dh. um das zu erreichen muss zuerst den Monat \u00e4ndern,\r\num den gew\u00fcnschten Tag eingeben zu k\u00f6nnen. Ich bin der Meinung die Pr\u00fcfung sollte sp\u00e4ter stattfinden.\r\n\r\n\r\n\n Comments: \n Comment 0: Ehrlich gesagt nervt mich dieses Verhalten ebenfalls... :angry:\r\n\r\nIch verwende f\u00fcr das Datumsfeld ein fertiges Widget von SWT. Und dem Widget kann man nicht beibringen a) kurzfristig mal den 30.2. zu erlauben (erst am Ende muss das Datum stimmen) und b) ein Datum auch zu kopieren (und einzuf\u00fcgen) (das ist ja Dein anderer Issue #431).\r\n\r\nAllerdings hat es mich bisher offensichtlich nicht stark genug genervt um ein eigenes Widget zu bauen. Klar, ich k\u00f6nnte alternativ auf den Kalender verzichten (also dass man per Maus ein Datum ausw\u00e4hlen kann) aber das erscheint mir dann doch etwas zu wenig f\u00fcr ein UI zu sein...\r\n\r\nIch \u00fcberlege mal ob ich zumindest dieses einfache Eingabefeld als Option anbieten kann.\r\n\r\nDen anderen Issue (#431) machen ich mal zu - die geh\u00f6ren mehr oder weniger zusammen.",
  "Issue title: vlcj crashes on win64\n Issue body: I cloned this project and ran it on my pc, it crashed, and below is my log file.\r\n[debug.log](https://github.com/caprica/vlcj/files/1393321/debug.log)\r\nI have found what is wrong. Because vlc only has a 32-bit version, when it is installed on win64, the location of it in the register is \"HKEY_LOCAL_MACHINE->SOFTWARE->WOW6432Node->VideoLAN->VLC\", not \"HKEY_LOCAL_MACHINE->SOFTWARE->VideoLAN->VLC\". So this will fail when the function \"getVlcInstallDir\" in the class uk.co.caprica.vlcj.runtime.windows.WindowsRuntimeUtil runs.\r\n\r\nI know what is wrong, but I don't know how to fixed it, Could you help to solve it?Thanks\r\n\n Comments: \n Comment 0: You could write your own implementation of a vlcj native discovery strategy class that looks for the other registry key.\r\n\r\nEventually the existing code in vlcj will probably be patched to search that additional key I suppose.\n Comment 1: You can also simply not use those vlcj classes, and instead add the LibVLC path manually as described in the tutorial or the JNA documentation.\n Comment 2: Thanks for your reply. I've solved this by install a 64-bit version on my pc.(sorry, the link on the official website only points to a 32-bit version, so I thought there wasn't 64-bit version. Later I found a 64-bit version on this website http://download.videolan.org/pub/videolan/vlc/).\r\n\r\nBut I still advise to patch this to improve the usability. Thanks again for your share. ",
  "Issue title: Title appears more than once only when theme is enabled.\n Issue body:![image](https://cloud.githubusercontent.com/assets/14027493/9561167/a0b7004a-4e7d-11e5-9ca2-4a2836c04b44.png)\r\nTitle tag with another theme\r\n\r\n![screen shot 2015-08-29 at 6 40 26 pm](https://cloud.githubusercontent.com/assets/14027493/9561185/aa81b6a0-4e7e-11e5-99f4-5a247f29310f.png)\r\nTitle tag with theme\n Comments: \n Comment 0: This should now be fixed if you pull down the latest header.php file.",
  "Issue title: problems with install (louvain)\n Issue body: Hi,\r\n\r\nI am trying to install cellOracle on a shared server, which I don't have the sudo permission.\r\nOS: CentOS 7.8. queing system: slurm\r\nI tried first to go through the installation webpage, but failed.\r\n\r\nThen I tried to install in the following steps:\r\nml purge\r\nml load Python/3.6.6-foss-2018b\r\nvirtualenv --system-site-packages /xxx/home/user/cellOracle\r\nsource /xxx/home/user/cellOracle/bin/activate\r\nconda install gcc_linux-64 llvm\r\npip install numpy scipy cython numba matplotlib scikit-learn h5py click pysam \r\n\tpip install velocyto\r\n\tgit clone https://github.com/velocyto-team/velocyto.py.git\r\n\tcd software/velocyto.py/\r\n\tpip install -e. #velocyto --help, check install successfully or not\r\npip install scanpy==1.4.4 umap-learn==0.3.10\r\npip install genomepy==0.5.5 gimmemotifs==0.13.1\r\npip install goatools pyarrow tqdm joblib jupyter\r\nAll above works.\r\n\r\nBut when I come to the final step, which is installed cellOracle, stucked.\r\npip install git+https://github.com/morris-lab/CellOracle.git\r\nIt seems related to louvain, which I also tried to install it before install cellOracle:\r\npip install python-louvain\r\npip install --user --upgrade python-louvain\r\n\r\nThe error log:\r\n  ERROR: Failed building wheel for louvain\r\n  Running setup.py clean for louvain\r\nSuccessfully built celloracle\r\nFailed to build louvain\r\nInstalling collected packages: louvain, fa2, celloracle\r\n    Running setup.py install for louvain... error\r\n\r\nAny ideas on how to fix it? thanks a lot!\r\n\r\n\r\n\n Comments: \n Comment 0: Hi wangmhan, \r\nThank you for trying celloracle!\r\n\r\nAs you said, the problem seems to exist in the louvain package.\r\n\r\nCould you please try to install \"louvain\", instead of \"python-louvain\" using the following command?\r\n`pip install louvain`\r\n\r\n\n Comment 1: Hi wangmhan,\r\n\r\nThank you for sending the log file! But I could not find it. \r\nI think the attached file was automatically removed by the system of GitHub.\r\n\r\nCould you please copy and paste the content of log file to the body of message?\r\n\r\nThank you for help. It helps us to improve celloracle!\r\n\n Comment 2: yes, sure. It is quite long...\n\nCollecting git+https://github.com/morris-lab/CellOracle.git\n  Cloning https://github.com/morris-lab/CellOracle.git to\n/scratch/pip-req-build-7969rtrw\n  Running command git clone -q https://github.com/morris-lab/CellOracle.git\n/scratch/pip-req-build-7969rtrw\nRequirement already satisfied: numpy in\n/scicore/soft/apps/Python/3.6.6-foss-2018b/lib/python3.6/site-packages/numpy-1.15.0-py3.6-linux-x86_64.egg\n(from celloracle==0.3.7) (1.15.0)\nRequirement already satisfied: scipy in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (1.5.0)\nRequirement already satisfied: cython in\n/scicore/soft/apps/Python/3.6.6-foss-2018b/lib/python3.6/site-packages/Cython-0.28.5-py3.6-linux-x86_64.egg\n(from celloracle==0.3.7) (0.28.5)\nRequirement already satisfied: numba in\n./.local/lib/python3.6/site-packages (from celloracle==0.3.7) (0.50.0)\nRequirement already satisfied: matplotlib==3.0.* in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (3.0.3)\nRequirement already satisfied: seaborn in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (0.10.1)\nRequirement already satisfied: scikit-learn in\n./.local/lib/python3.6/site-packages (from celloracle==0.3.7) (0.23.1)\nRequirement already satisfied: h5py in./.local/lib/python3.6/site-packages\n(from celloracle==0.3.7) (2.10.0)\nRequirement already satisfied: pandas==0.25.* in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (0.25.3)\nRequirement already satisfied: velocyto>=0.17 in./software/velocyto.py\n(from celloracle==0.3.7) (0.17.16)\nRequirement already satisfied: umap-learn==0.3.10 in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (0.3.10)\nRequirement already satisfied: pyarrow in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (0.17.1)\nRequirement already satisfied: jupyter in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (1.0.0)\nRequirement already satisfied: tqdm>=4.45 in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (4.46.1)\nRequirement already satisfied: python-igraph in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (0.8.2)\nCollecting louvain==0.6.1\n  Using cached louvain-0.6.1.tar.gz (84 kB)\nRequirement already satisfied: fa2 in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (0.3.5)\nRequirement already satisfied: scanpy==1.4.4 in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (1.4.4)\nRequirement already satisfied: joblib in\n/scicore/soft/apps/Python/3.6.6-foss-2018b/lib/python3.6/site-packages\n(from celloracle==0.3.7) (0.12.2)\nRequirement already satisfied: goatools in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (1.0.6)\nRequirement already satisfied: genomepy==0.5.5 in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (0.5.5)\nRequirement already satisfied: gimmemotifs==0.13.1 in\n./cellOracle/lib/python3.6/site-packages (from celloracle==0.3.7) (0.13.1)\nRequirement already satisfied: llvmlite<0.34,>=0.33.0.dev0 in\n./.local/lib/python3.6/site-packages (from numba->celloracle==0.3.7)\n(0.33.0)\nRequirement already satisfied: setuptools in\n./cellOracle/lib/python3.6/site-packages (from numba->celloracle==0.3.7)\n(47.3.1)\nRequirement already satisfied: python-dateutil>=2.1 in\n/scicore/soft/apps/Python/3.6.6-foss-2018b/lib/python3.6/site-packages/python_dateutil-2.7.3-py3.6.egg\n(from matplotlib==3.0.*->celloracle==0.3.7) (2.7.",
  "Issue title: unused-namespaces linter warns if namespace vars only used inside syntax-quote forms\n Issue body: Example in the README docs for the unused-namespaces linter.\n\n Comments: \n Comment 0: See also issue #25 \n\n Comment 1: There is a TBD in a comment before a test case in cases/testcases/unusednss.clj with an example.\n\n Comment 2: Should be fixed in Eastwood 0.2.5",
  "Issue title: Formating with Prettier: Honor `prettier.requireConfig` (or add equivalent option)\n Issue body: - [x] I have searched through existing issues\r\n- [x] I have read through [docs](https://vuejs.github.io/vetur)\r\n- [x] I have read [FAQ](https://github.com/vuejs/vetur/blob/master/docs/FAQ.md)\r\n\r\n## Info\r\n\r\n- Platform: macOS\r\n- Vetur version: 0.22.3\r\n- VS Code version: 1.38.1\r\n\r\n## Problem\r\n\r\nWith my VS Code setup, there's a pretty common problem I regularly run into:\r\n\r\nI use the [official Prettier extension](https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode) for formatting code with Prettier, but I have enabled its `prettier.requireConfig` option which only runs the Prettier formatter if a `.prettierrc` file is present.\r\n\r\nThis leads to a pretty annoying inconsistency, because if no `.prettierrc` exists, my JS/CSS/... code stays untouched while Vue code still gets formatted.\r\n\r\nI'm aware that Vetur ships with its own instance of the Prettier library and does not generally interact with the Prettier extension, but it would be great if the `prettier.requireConfig` option would be honored by Vetur. Of course this would create a soft dependency on the Prettier extension, but since it's the official extension and the behavior would be a no-op without that extension installed, it should be fine IMO.\r\n\r\nAlternatively, there could be an equivalent Vetur option which does the same.\r\n\r\nWhat do you think?\r\n\r\n## Reproducible Case\r\n\r\n0. Enable \"Format on Save\" in VS Code\r\n1. Install Vetur and the [Prettier extension](https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode)\r\n2. Set the Prettier extension's `prettier.requrieConfig` option to `true`.\r\n3. Create a new project and in it a JS and a Vue file.\r\n4. Fill them with the bare minimum of formattable code (`console.log()` respectively `<script>console.log()</script>` should be sufficient).\r\n5. Save both files.\r\n6. Observation: The JS file will not be formatted while the JS section of the Vue file will.\n Comments: \n Comment 0: Vetur doesn't read any setting from prettier.* scope to avoid confusion (https://vuejs.github.io/vetur/formatting.html). It used to be very confusing whether Vetur is reading config from prettier.* or config files.\r\nIf you don't want to format script sections, try having a workspace setting that sets `vetur.format.defaultFormatter.js` to `none`.\n Comment 1: Alright. Not optimal, but plausible. Thanks for taking care!",
  "Issue title: Ruby19Parser doesn't handle string literals with Unicode escape sequences\n Issue body: test case:\n\n``` ruby\nrequire 'ruby_parser'\n\nsource = '\"Se\\xc3\\xb1or\"'\np eval(source)\np Ruby19Parser.new.parse(source)\n\nsource = '\"Se\\u00F1or\"'\np eval(source)\np Ruby19Parser.new.parse(source)\n\nsource = '\"Se\\u{F1}or\"'\np eval(source)\np Ruby19Parser.new.parse(source)\n```\n\nExpected Output:\n\n```\n\"Se\\xC3\\xB1or\"\ns(:str, \"Se\u00f1or\")\n\"Se\u00f1or\"\ns(:str, \"Se\u00f1or\")\n\"Se\u00f1or\"\ns(:str, \"Se\u00f1or\")\n```\n\nActual Output:\n\n```\n\"Se\\xC3\\xB1or\"\ns(:str, \"Se\u00f1or\")\n\"Se\u00f1or\"\ns(:str, \"Seu00F1or\")\n\"Se\u00f1or\"\ns(:str, \"Seu{F1}or\")\n```\n\n Comments: \n Comment 0: duplicate of #98, #133 \n\n Comment 1: indeed a dupe\n",
  "Issue title: automate more of release process\n Issue body: I'm getting pretty tired of our manually-intensive release process. At a minimum, something ought upload signatures etc. I looked around, and (githubrelease)[https://pypi.org/project/githubrelease/] looks like it might be just the ticket.\n Comments: \n Comment 0: I'm now doing everything up through actual (distro-specific) packaging. That's a pretty good step forward.\r\n\r\nhttps://www.youtube.com/watch?v=8UGtlUMMkOU",
  "Issue title: Visual Studio 2019 Error\n Issue body: ### Installed product versions\r\n- Visual Studio: Visual Studio 2019 Enterprise\r\n- This extension: 2.8.396\r\n\r\n### Description\r\nError when saving js file that should be minfied:\r\nSystem.NullReferenceException: Object reference not set to an instance of an object.\r\n   at BundlerMinifier.BundleFileProcessor.SourceFileChanged(String bundleFile, String sourceFile)\r\n   at BundlerMinifierVsix.BundleService.<>c__DisplayClass11_0.<SourceFileChanged>b__0(Object o) in C:\\projects\\bundlerminifier\\src\\BundlerMinifierVSIX\\BundleService.cs:line 169\r\n\r\n\r\n### Steps to recreate\r\n1.  Create js file\r\n2. Add file to bundleconfig.json\r\n3. Save file\r\n\r\n### Current behavior\r\nNo min file is created and no minification is done\r\n\r\n### Expected behavior\r\nmin file should be created and the js file should be minified.\n Comments: \n Comment 0: Never mind, my stupid error... Missing a comma.\n Comment 1: Same here, got the error when trying to minify the bootstrap.js 5.0. \r\nWhen minify is disabled, it works fine with just bundling. Any solution or fixes?",
  "Issue title: Missing \"up\"/\"down\" icon on \"Stack\" list page.\n Issue body: Server version - v0.38.0-rc1\n\nApplications->Stacks view, \"up\"/\"down\" icon is show as a box character.\n<img width=\"1268\" alt=\"screen shot 2015-09-17 at 1 55 18 pm\" src=\"https://cloud.githubusercontent.com/assets/4266958/9945994/8d63c402-5d45-11e5-87a9-5157ebc3cb51.png\">\n\n Comments: \n Comment 0: Tested with server version - v0.38.0-rc3.\r\n\r\n\"up\"/\"down\" icon on \"Stack\" list page is now available.",
  "Issue title: [vue] \u8bf7\u6c42\u62e6\u622a\u5668\u4e0e\u54cd\u5e94\u62e6\u622a\u5668\u5206\u522b\u6709\u4ec0\u4e48\u5e94\u7528\u573a\u666f\uff1f\n Issue body: \u8bf7\u6c42\u62e6\u622a\u5668\u4e0e\u54cd\u5e94\u62e6\u622a\u5668\u5206\u522b\u6709\u4ec0\u4e48\u5e94\u7528\u573a\u666f\uff1f\n\r[3+1\u5b98\u7f51](http://www.h-camel.com/index.html)\n\r[\u6211\u4e5f\u8981\u51fa\u9898](http://www.h-camel.com/contribution.html)\n Comments: \n Comment 0: - \u5728\u8bf7\u6c42\u524d\u8bbe\u7f6e\u8bf7\u6c42\u5934\uff0c\u8fc7\u6ee4\u91cd\u590d\u8bf7\u6c42\u7b49\r\n- \u5728\u8bf7\u6c42\u540e\u5224\u65ad\u8bf7\u6c42\u662f\u5426\u6210\u529f\uff0c\u8f6c\u6362\u8bf7\u6c42\u6570\u636e\u683c\u5f0f\n Comment 1: \u8bf7\u6c42\u62e6\u622a\n 1.\u5f53\u53d1\u9001\u7f51\u7edc\u8bf7\u6c42\u65f6, \u5728\u9875\u9762\u4e2d\u6dfb\u52a0\u4e00\u4e2aloading\u7ec4\u4ef6, \u4f5c\u4e3a\u52a8\u753b\n 2.\u67d0\u4e9b\u8bf7\u6c42\u8981\u6c42\u7528\u6237\u5fc5\u987b\u767b\u5f55, \u5224\u65ad\u7528\u6237\u662f\u5426\u6709token, \u5982\u679c\u6ca1\u6709token\u8df3\u8f6c\u5230login\u9875\u9762\n 3.\u5bf9\u8bf7\u6c42\u7684\u53c2\u6570\u8fdb\u884c\u5e8f\u5217\u5316(\u770b\u670d\u52a1\u5668\u662f\u5426\u9700\u8981\u5e8f\u5217\u5316)\n\u54cd\u5e94\u62e6\u622a\n 1.\u5bf9\u54cd\u5e94\u7684\u72b6\u6001\uff0c\u53ef\u4ee5\u5148\u505a\u4e00\u5c42\u5224\u65ad\uff0c\u7136\u540e\u629b\u51fa\u9519\u8bef\n 2.\u5bf9\u54cd\u5e94\u7684\u6570\u636e\u5148\u505a\u4e00\u5c42\u5904\u7406",
  "Issue title: onDayPress not workink on Debug JS Remotely\n Issue body: ## Environment\r\n* `\"react-native-calendars\": \"^1.18.2\"`:\r\n* `\"react-native\": \"0.53.0\"`:\r\nAlso specify:\r\n* `Redmi 5A/Android 7.1.2\"`:\r\n\r\n## Reproducible Demo\r\n\r\nAfter updating to `^1.18.2` **onDayPress** not workind on debug mode, just when I turned off debug mode it's working.\r\n\r\nCan you have any ideas? \r\n\n Comments: \n Comment 0: hello, same issue for me.\r\nsometimes it work, sometimes not...\n Comment 1: +1.\r\n\r\nIt works on an emulator for me on latest current version (1.19.3), even with remote debugging selected. It just doesn't work with an external device.\n Comment 2: I figured out the problem for me. The time on the external device and the time on my computer was off.\r\n\r\n1. run this command: `adb shell date && date`\r\n - Mine was only off by 4 milliseconds. But it was still causing the issue.\r\n\r\nTo fix:\r\n1. On your laptop/host computer go to your time and date settings and turn off and on \"Set date and time automatically\"\r\n2. On the device turn off and on \"Automatic date & time\" AND \"Automatic time zone\"\r\nTook a couple tries, and I restarted both devices.\r\nThen just run that command to keep checking until both devices are synced. `adb shell date && date`\r\n\n Comment 3: I figured out the issue for me. I received this error at some point:\r\n```diff\r\n- Attempted to transition from state 'RESPONDER_INACTIVE_PRESS_IN' to 'RESPONDER_ACTIVE_LONG_PRESS_IN', which is not supported. This is most likely due to 'Touchable.longPressDelayTimeout' not being called.\r\n```\r\n\r\nThe problem was that the time on the device and time on my computer were not synced up. If it's off even by 1 millisecond, onDayPress won't fire.\r\nThat's why if I used an emulator it was fine (same clock). And when I would run it on a release build on a physical device, not connected to my computer, it was fine.\r\n\r\nTo check this:\r\n1. Run this command in terminal from anywhere to check if it's synced: `adb shell date && date`\r\n2. on your laptop go to your time and date settings and turn off and on \"Set date and time automatically\"\r\n3. on the device turn off and on \"Automatic date & time\" AND \"Automatic time zone\"\r\n4. repeat until they're synced.\r\n\r\nStill, my clocks aren't always exactly synced. Like right now it's like 1/2 ms off. So sometimes it fires and sometimes it doesn't. Just depends on if the ms are the same or not.",
  "Issue title: Build descriptions in Wiki outdated\n Issue body: The build descriptions in the Wiki are outdated. Please update.\r\n\r\nFor example https://github.com/nextcloud/desktop/wiki/System-requirements-for-compiling-the-desktop-client states that OpenSSL 1.1 is required and that the libs are available on https://indy.fulgan.com/SSL/. That is not the case, there onyl OpenSSL 1.0 is available (how comes that the official version 2.5.2 is linked to OpenSSL 1.0 when the source requires 1.1?)\r\n\r\nIt would be great to have a detailed descripton on how to build with VS2017/VS2019 on Windows.\n Comments: \n Comment 0: * https://github.com/csware/nextcloud-desktop-wiki/commits/windows-outdated (https://github.com/csware/nextcloud-desktop-wiki/compare/master...windows-outdated)\r\n* https://github.com/csware/nextcloud-desktop-wiki/commits/build-linux (https://github.com/csware/nextcloud-desktop-wiki/compare/master...build-linux)\r\n\r\n\n Comment 1: I would also be interested in this. I tried looking into building OpenSSL myself but this seems to be a major endeavour as well, as it requires Perl and apparently some obscure \"dmake\" build tool for which I couldn't find any pre-built binaries...\n Comment 2: If anyone on Windows has trouble fining OpenSSL 1.1.x binaries, since the link on the Wiki leads to 1.0.x, here's some with an installer: [https://slproweb.com/products/Win32OpenSSL.html](https://slproweb.com/products/Win32OpenSSL.html)\n Comment 3: We have been improving build system to better report error when initializing the build tree.\r\nThe wiki page has probably been updated since you reported this issue because it is now up to date.",
  "Issue title: [FR]: Upgrade 2021.12.4\n Issue body: After upgrade to 2021.12.4 \r\n\r\nThe componente have some problem\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/homeassistant/.pyenv/versions/3.9.7/lib/python3.9/site-packages/homeassistant/setup.py\", line 229, in _async_setup_component\r\n    result = await task\r\n  File \"/mnt/dietpi_userdata/homeassistant/custom_components/landroid_cloud/__init__.py\", line 154, in async_setup\r\n    _LOGGER.debug(\"Partymode available: %s\", client[dev].partymode)\r\nAttributeError: 'WorxCloud' object has no attribute 'partymode'\n Comments: \n Comment 0: Turn on the mower - at the moment there is an issue when the mower is offline.\n Comment 1: Same bug for me, not really a problem but I can't turn on the mower since it's winter and the mower is in the garage ;)\n Comment 2: Here also the same problem after update  2021.12.4\r\n\r\nLogger: homeassistant.setup\r\nSource: custom_components/landroid_cloud/__init__.py:154\r\nIntegration: landroid_cloud (documentation, issues)\r\nFirst occurred: 20:32:32 (1 occurrences)\r\nLast logged: 20:32:32\r\n\r\nError during setup of component landroid_cloud\r\nTraceback (most recent call last):\r\n  File \"/usr/src/homeassistant/homeassistant/setup.py\", line 229, in _async_setup_component\r\n    result = await task\r\n  File \"/config/custom_components/landroid_cloud/__init__.py\", line 154, in async_setup\r\n    _LOGGER.debug(\"Partymode available: %s\", client[dev].partymode)\r\nAttributeError: 'WorxCloud' object has no attribute 'partymode'\n Comment 3: The integration are getting a complete overhaul during the winter season - then this will be fixed along with a few other minor bugs.\n Comment 4: Duplicate of #86 \n Comment 5: Same issue here, will not turn on mower until spring. If you need someone to test a new version i am willing to help on short notice.\n Comment 6: Fixed in v1.8.1",
  "Issue title: Suggestion: change the internal name of the generated ROMs so they don't share save files.\n Issue body: The emulator I use, Mupen64Plus, uses the same save file for all ROMs with the same internal name.  This means I can't switch back and forth between playing the original Majora's Mask and a randomized version without completely deleting my saves in between.\r\n\r\nA potential solution would be to rename the generated ROM.  The new name would incorporate the seed used to generated the ROM, as well as a hash of the settings used.  That way each generated ROM could have its own save file as well.\n Comments: \n Comment 0: I believe this would also allow us to install multiple WADs on Wii, because right now if you try installing another seed it will overwrite the old channel & still have your old save.\n Comment 1: If it uses a sep save hd packs won't work",
  "Issue title: Clock Date doesn't work\n Issue body: I cannot get the date on the clock to work. I posted an issue with some details on Launchpad, but now that we're here I figured I'd bring it up and mention that it still doesn't display for me.\n Comments: \n Comment 0: This is you? https://answers.launchpad.net/xibo/+question/260958\r\n\r\nSo in summary, it displays fine in the preview on the CMS, when you find the file in the library, it displays fine when you open it in IE - but it doesn't display fine when in the player.\r\n\r\nI can only imagine this is the \"old IE rendering engine issue\", which is a bit unfortunate. Can you try adding a new DWORD in your registry on the player PC?\r\n\r\n`HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\Microsoft\\Internet Explorer\\MAIN\\FeatureControl\\FEATURE_BROWSER_EMULATION\\XiboClient.exe`\r\n\r\nwith the value:\r\n\r\n`decimal 9999`\r\n\r\nYou'll need to restart the player for it to take effect.\n Comment 1: Yup, I go by Allie now, though I was using an OLD launch pad under my legal name... Yeah. Anyway, that did nothing. Also, switching to CEF did nothing (except make the rendering when it opens really slow and block by block - it takes a few seconds. But still no clock). If I could figure out how to post a ZIP I would post the layout I am using.\n Comment 2: https://www.dropbox.com/s/tkqpt2wtejts7t3/export_default-layout.zip?dl=0\n Comment 3: Fair enough :-)\r\n\r\nI'll try out the file and see\r\n\n Comment 4: The clock is on top of the date\r\n\r\nTry deleting your date region altogether and using the following as the source for your clock region:\r\n\r\n``` html\r\n<p><span style=\"font-size:96px;\"><span style=\"color:#000000;\"><span style=\"font-family:arial,helvetica,sans-serif;\"><strong>[HH:mm]</strong></span></span></span></p>\r\n\r\n<p><span style=\"color: rgb(0, 0, 0); font-family: arial, helvetica, sans-serif; font-size: 48px;\">[YYYY-MM-DD]</span></p>\r\n```\n Comment 5: Okay, I just put it all in one. I didn't think it would matter since other overlapping regions seem to render just fine.\n Comment 6: P.S. I had hoped that when I got this figured out it might fix the exclamation mark on the display status. It didn't. Any ideas?\n Comment 7: Yes - unfortunately I do... there was a small problem with the first MSI I put out... I switched it quickly in the hope nobody would notice... but of course they did.\r\n\r\nIf you re-download, un-install and reinstall it will be fixed.\r\n\r\n\r\nFYI - overlapping regions aren't supported at all in the windows player - they used to be in the Ubuntu player and we will be working to reintroduce them.",
  "Issue title: ClientSidePage Page Header is always centered using PnP Provisioning Engine\n Issue body: #### Category\r\n[x] Bug\r\n[ ] Enhancement\r\n\r\n#### Environment\r\n[x] Office 365 / SharePoint Online\r\n[ ] SharePoint 2016\r\n[ ] SharePoint 2013\r\n\r\n#### Expected or Desired Behavior\r\nWhen exporting and important an PnP Template that would create / update a Client Side Page, the title should stay where it is, meaning left aligned.\r\n\r\n#### Observed Behavior\r\nWhen getting a PnP Template with only the -PageContents handler, the template looks OK. When applying this template to the same site (and even same page), the page header changes and shows a centered Title.\r\n\r\n#### Steps to Reproduce\r\nCreate a page and make it your Welcome Page of your site. Then, generate your PnP Provisioning Template\r\n\r\n`Get-PnPProvisioningTemplate -Out C:\\_\\temp\\TestHome.xml -Handlers PageContents -Force`\r\n\r\nThen Apply the same template to your site\r\n\r\n`Apply-PnPProvisioningTemplate -Path C:\\_\\temp\\TestHome.xml`\r\n\r\nThe title is now centered on the page\r\n\r\n![screenshot-20180921123343](https://user-images.githubusercontent.com/7620955/45893901-c3a84c00-bd9a-11e8-8e5e-380336a5582f.png)\r\n\r\n![screenshot-20180921123429](https://user-images.githubusercontent.com/7620955/45893906-c73bd300-bd9a-11e8-90a4-b2bfe4a106de.png)\r\n\n Comments: \n Comment 0: This was fixed in the latest release. Can you reproduce this with the September 2018 release?\n Comment 1: Closing for now, feel free to re-open if you can't get it to work with the September 2018 version\n Comment 2: Looks all good! Well done!",
  "Issue title: Working settings\n Issue body: These settings worked for me.\r\n\r\nmelissa75@example.com\r\n\r\n## functions\\package.json\r\n\r\n```json\r\n{\r\n  \"name\": \"functions\",\r\n  \"description\": \"Cloud Functions for Firebase\",\r\n  \"scripts\": {\r\n    \"lint\": \"eslint.\",\r\n    \"serve\": \"firebase serve --only functions\",\r\n    \"shell\": \"firebase functions:shell\",\r\n    \"start\": \"npm run shell\",\r\n    \"deploy\": \"firebase deploy --only functions\",\r\n    \"logs\": \"firebase functions:log\",\r\n    \"test\": \"mocha --timeout 10000\",\r\n    \"test_all\": \"mocha test_all.js --timeout 10000\"\r\n  },\r\n  \"engines\": {\r\n    \"node\": \"8\"\r\n  },\r\n  \"dependencies\": {\r\n    \"file-system\": \"2.2.2\",\r\n    \"firebase-admin\": \"8.8.0\",\r\n    \"firebase-functions\": \"3.3.0\"\r\n  },\r\n  \"devDependencies\": {\r\n    \"@firebase/testing\": \"0.16.3\",\r\n    \"eslint\": \"^5.12.0\",\r\n    \"eslint-plugin-promise\": \"^4.0.1\",\r\n    \"firebase-functions-test\": \"0.1.7\",\r\n    \"mocha\": \"6.2.2\"\r\n  },\r\n  \"private\": true\r\n}\r\n```\r\n\r\n## public\\index.html\r\n\r\n```html\r\n<script src=\"/__/firebase/7.6.0/firebase-app.js\"></script>\r\n<script src=\"/__/firebase/7.6.0/firebase-auth.js\"></script>\r\n<script src=\"/__/firebase/7.6.0/firebase-firestore.js\"></script>\r\n<script src=\"/__/firebase/init.js\"></script>\r\n```\r\n\r\n## Links\r\n\r\n### 1. Getting started with the Firebase Local Emulator Suite\r\n\r\nhttps://google.dev/codelabs/firebase-emulator-get-started?playlist-id=firebase-emulators#0\r\n\r\n### 2. Test-drive Firestore Security Rules\r\n\r\nhttps://google.dev/codelabs/firebase-emulator-test-rules#0\r\n\r\n### 3. Test-drive Complex Firebase Functions\r\n\r\nhttps://google.dev/codelabs/firebase-emulators-test-functions#0\r\n\n Comments: \n Comment 0: I found a few problems with this issue:\n  * I couldn't figure out how to label this issue, so I've labeled it for a human to triage. Hang tight.\n  * This issue does not seem to follow the issue template. Make sure you provide all the required information.\n Comment 1: @yuchenshi I am surprised to see this issue given that it's `0.16.3` of the `@firebase/testing` SDK.  Can you check it out?\n Comment 2: I cannot reproduce this. A few things to try though:\r\n\r\n1. Please check node and npm version. Try `npm install -g npm@latest`\r\n1. `rm -r node_modules` in functions and `npm install` again.\r\n1. `npm ls` and attach the output\n Comment 3: Okay I can now reproduce it. It turned out that I just forget to update to the latest master. I'll take a deeper dive.\n Comment 4: I've updated `@firebase/testing` on master. Thanks.\r\n\r\nThe reason was that `@melissa75@example.com` pulls in `melissa75@example.com`, which is one major version less than 7. However, `melissa75@example.com` pulls in `@melissa75@example.com` which only works with `firebase@7`.\r\n\r\n\r\n```\r\n\u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u251c\u2500\u252c melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u2514\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com deduped\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com deduped\r\n\u2502 \u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com deduped\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2514\u2500\u252c @melissa75@example.com\r\n\u251c\u2500\u252c melissa75@example.com\r\n\u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com deduped\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u2502 \u2502 \u2514\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u2500 @melissa75@example.com\r\n\u2502 \u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u2502 \u251c\u2500\u252c @melissa75@example.com\r\n\u251c\u2500\u252c melissa75@example.com\r\n\u251c\u2500\u252c melissa75@example.com\r\n```\r\n",
  "Issue title: Start moving repositories master branch to main\n Issue body: There are a number of repositories that we can migrate to use main right away:\r\n\r\n* cocoon\r\n* recipes\r\n\r\nMigrating those two repos will give us enough information about what will be required to migrate repositories with more traffic like engine. Flutter/flutter has its own challenges and will require its own design doc.\n Comments: \n Comment 0: GoB configurations to keep master and main in sync have already landed.\r\n\r\nhttps://flutter-review.googlesource.com/c/infra/+/18342 to move recipes to use main.\n Comment 1: CL to use main branch in engine builders: https://flutter-review.googlesource.com/c/infra/+/18344\n Comment 2: Start using main branch from cocoon repository: https://flutter-review.googlesource.com/c/recipes/+/18361\n Comment 3: @godofredoc If you want to set up `master`->`main` mirroring for flutter/plugins and flutter/packages, I can start updating scripts and CI jobs as I have time; I would expect that they will be fairly straightforward repos to migrate.\n Comment 4: Thanks @stuartmorgan, I'll send the changes for review during the day.\n Comment 5: I think `plugins` and `packages` are likely ready to flip the mirroring and lock `master`, but I'm not actually sure how to test all the Cirrus jobs on `main`. Is there a playbook for that?\n Comment 6: There is no playbook for cirrus that I'm aware of but it seems like we only need to change this line: https://github.com/flutter/plugins/blob/master/.cirrus.yml#L12\n Comment 7: Please let us know when you would like to finalize the migration to block some time on the engprod calendars to help with anything that may arise.\n Comment 8: > Please let us know when you would like to finalize the migration to block some time on the engprod calendars to help with anything that may arise.\r\n\r\nIf there's enough time next week we could do `packages` at the beginning of the week (so there's time to roll it back if necessary) as a small-scale test of the CI and tooling--most of which is very similar to that of `plugins`. Then if everything goes smoothly we can do `plugins` when everyone is back in January.\r\n\r\nIf not, let's plan on `packages` early in January, followed by `plugins` shortly after.\n Comment 9: Seems like `packages` went smoothly; can we schedule `plugins` for the first week of January?",
  "Issue title: saving intermediate checkpoint\n Issue body: HI, \r\nIs your code saving the intermediate checkpoints? if no how to do I add the code for it?\n Comments: \n Comment 0: @JiteshPshah yes, your can modify this parameter in  [/ctpn/text.yml](https://github.com/eragonruan/text-detection-ctpn/blob/5d091787c9ba2e0c5da919341a9fe11117cceab2/ctpn/text.yml#L17), currently, i save the model every 1k steps\n Comment 1: @eragonruan  Thanks Buddy....",
  "Issue title: [core] Group item can be added into itself\n Issue body: A Group item can be added into itself. Is this supposed to be possible?\r\n\r\ndemo.items\r\n```\r\nGroup gHISTORY \"Persistence\" (gHISTORY)\r\n```\r\n\r\nconsole output\r\n```\r\nopenhab> items list gHISTORY\r\ngHISTORY (Type=GroupItem, Members=0, State=NULL, Label=Persistence, Category=null, Groups=[gHISTORY])\r\n```\r\n\n Comments: \n Comment 0: More generally, you can define a loop in the tree. That is certainly not expected.\n Comment 1: Why isn't it expected? To my knowledge the framework can cope with cycles quite well. So this boils down to the question of whether the framework needs to patronize the user in this case \"just for fun\". Isn't this also kind of a \"s**t in, s**t out\"-situation?",
  "Issue title: [Bug] Windows installer doesn't tell you where to put system roms [sf#343]\n Issue body: **Reported by manuelbi on 2009-05-25 19:22 UTC**\nIn contrast to the old NSIS based Windows installer, the new one doesn't tell you where to put the system roms, at the end. I find this a very important message that should be retained in the new installer.\r\n\r\nOld installer did this:\r\nFunction.onInstSuccess\r\nMessageBox MB\\_OK \"If you want to emulate real MSX systems and not only the free C-BIOS machines, put the system ROMs in the following directory: $\\r$OUTDIR\\share\\systemroms\"\r\n\r\n\n Comments: \n Comment 0: **Commented by mfeingol on 2009-05-30 17:55 UTC**\nCommitted revision 9932.\n Comment 1: **Updated by mfeingol on 2009-05-30 17:55 UTC**\n- **status**: open --> open-fixed\n Comment 2: **Updated by mfeingol on 2009-05-30 17:55 UTC**\n- **status**: open-fixed --> pending-fixed\n Comment 3: **Commented by manuelbi on 2009-05-30 19:58 UTC**\nConfirmed, closing. Thanks.\n Comment 4: **Updated by manuelbi on 2009-05-30 19:58 UTC**\n- **status**: pending-fixed --> closed-fixed",
  "Issue title: Improvement - when middle mouse button pressed, switch temporarily to the Hand function\n Issue body: This would make navigation in the document possible just with the mouse.\r\nThanks.\n Comments: \n Comment 0: Thanks for the report @vrozkovec, this is good idea, we'll keep it in mind for next releases \ud83d\ude09 \n",
  "Issue title: VoIP Pushes on iOS13 with Xcode 11\n Issue body: Dear Telegram team,\r\n\r\n\u001dTelegram 5.12 built with \bXcode 11 has a ton of new features like system dark mode, card presentation... It also means that you can no longer use VoIP pushes for non VoIP messages. ([](https://developer.apple.com/videos/play/wwdc2019/707))\r\n\r\nAfter hours of experiments on the new version, I found that your app can still wake up and receive messages in background. But when I build my own fork with Xcode 11, it's not getting VoIP pprice@example.org.\r\n\r\n**Q:** Are there any possible solutions or work around to enable VoIP notifications for forked apps?\r\n\r\nThanks\r\n\r\n\r\n\n Comments: \n Comment 0: Hey, let's assume it's duplicate of #178 ",
  "Issue title: A problem with \"collection\" when generating bulk\n Issue body: I have a problem when generating my art, it doesn't add the collection data in each JSON file.\r\n\r\nIs there an updated version or a way around this, thanks in advance! \n Comments: \n Comment 0: @LaugeBirchLorup what do you mean by 'collection data'?\n Comment 1: @bolshoytoster There's a URI specifically for the collection to show the overall collection image and name\n Comment 2: @LaugeBirchLorup you could try running `node utils/update_info.js`",
  "Issue title: JS dependencies stale in new project, triggering security alerts\n Issue body: ### Environment\r\n\r\n* Elixir version (elixir -v): _Elixir 1.9.0 (compiled with Erlang/OTP 22)_\r\n* Phoenix version (mix deps): _phoenix 1.4.10 (Hex package) (mix)_\r\n* NodeJS version (node -v): _v12.10.0_\r\n* NPM version (npm -v): _6.11.3_\r\n* Operating system: _Arch Linux_\r\n\r\n### Expected behavior\r\n\r\n1. Creating a new phoenix project and uploading it to github will not show any JS security vulnerabilities from their automated scanner.\r\n2. (Debatable) All `package.json` should be at the latest major version; that is, in the `X.Y.Z` versioning scheme the `X` should be the same as the latest released version. (Or Y, if X=0).\r\n\r\n### Actual behavior\r\n\r\n1. A new phoenix project uploaded to github triggers 3 security alerts from javascript packages.\r\n  -  Two from `js-yaml`, which needs to be >= `3.13.1` to be safe.  (WS-2019-0032, WS-2019-0063)\r\n  - One from `mem`, which needs to be >= `4.0.0` to be safe. ( WS-2018-0236 )\r\n\r\nTwo are severity medium (memory leak, dos) and one is severity high (arbitrary code execution).\r\n\r\nThese aren't specified directly in the package.json, so they have parent projects that need to be upgraded instead.  `mem` is being pulled in by `webpack-cli`.  `js-yaml` is being pulled in by `optimize-css-assets-webpack-plugin`.\r\n\r\n2. These packages are outdated by a major version:\r\n```\r\nPackage                            Current Wanted Latest Package Type    URL                                                       \r\ncopy-webpack-plugin                4.6.0   4.6.0  5.0.4  devDependencies https://github.com/webpack-contrib/copy-webpack-plugin    \r\ncss-loader                         2.1.1   2.1.1  3.2.0  devDependencies https://github.com/webpack-contrib/css-loader             \r\nmini-css-extract-plugin            0.4.5   0.4.5  0.8.0  devDependencies https://github.com/webpack-contrib/mini-css-extract-plugin\r\noptimize-css-assets-webpack-plugin 4.0.3   4.0.3  5.0.3  devDependencies http://github.com/NMFR/optimize-css-assets-webpack-plugin \r\nuglifyjs-webpack-plugin            1.3.0   1.3.0  2.2.0  devDependencies https://github.com/webpack-contrib/uglifyjs-webpack-plugin\r\nwebpack-cli                        2.1.5   2.1.5  3.3.8  devDependencies https://github.com/webpack/webpack-cli#readme             \r\n```\r\nNot a major version, but several minor versions behind:\r\n```\r\nPackage                            Current Wanted Latest Package Type    URL                                                       \r\nwebpack                            +1-312-251-4853 devDependencies https://github.com/webpack/webpack                        \r\n```\r\n\n Comments: \n Comment 0: > These aren't specified directly in the package.json, so they have parent projects that need to be upgraded instead.\r\n\r\nAs this is outside of our control, closing since we need to wait on changes from the affected libraries. However, If you are aware of non-transitive dep updates that will resolve some of the warnings, please send a PR. If minor versions are not available, major version changes will need thoroughly tested to make sure we are still in working states across Mac/windows/linux. Thanks!\r\n\n Comment 1: I don't believe there are any changes from libraries we need to wait for.  The fixes are out there, but we're not getting them due to the versions of libraries phoenix is requesting.  I suppose it's possible for package maintainers to backport security fixes to previous major versions, but I don't think it's often done in JS land.\r\n\r\nI tested, and these changes remove the vulnerabilities:\r\n```\r\n-    \"optimize-css-assets-webpack-plugin\": \"^4.0.0\",\r\n+    \"optimize-css-assets-webpack-plugin\": \"^5.0.3\",\r\n```\r\nUpgrades `js-yaml` from `3.7.0` to `3.13.1`, a version with the vulnerabilities fixed.\r\n\r\n```\r\n-    \"webpack-cli\": \"^2.0.10\"\r\n+    \"webpack-cli\": \"^3.3.8\"\r\n```\r\nUpgrades `mem` from `1.1.0` to `4.3.0`, a version with the vulnerabilities fixed.\r\n\r\nI'll send PRs for each, but I will need help testing, I don't really know how to go about it.\r\n\n Comment 2: I'd love PRs for those! Testing wise, we only need to ensure that the watcher run out of the box by phx.server (`./node_modules/webpack/bin/webpack.js --mode --watch-stdin --display minimal`) works as expected on Mac/osx/linux. So as long as it builds the app.js/app.css bundles we are generally good to go.\r\n \n Comment 3: Holding off on the PR.  It seems to already be fixed on the `master` branch (but not `v1.4`).  It was fixed here: #3430 \n Comment 4: Ah, good catch! @Gazler can you backport  #3430  to v1.4 when you get a chance? Thanks!\n Comment 5: Done. Also backported https://github.com/phoenixframework/phoenix/pull/3189",
  "Issue title: Google fonts?\n Issue body: Hi,\r\nIs this possible to load few google fonts directly in html via <link href=\"\" rel=\"stylesheet\" type=\"text/css\"> and then generate them in mPDF?\r\n\n Comments: \n Comment 0: No.",
  "Issue title: Used Social Buttons in modal box. Cant calculate text width correctly.\n Issue body: when i use in modal. texts looking like this. \n\n![socialbtn](https://cloud.githubusercontent.com/assets/5338985/9002270/a849d6c6-3716-11e5-8d30-dbcbd8925049.jpg)\n\n Comments: \n Comment 0: can you post example code somwehre\n",
  "Issue title: [Feature Request] Global directory for Mailspring plugins\n Issue body: ##### Are there any related issues?\r\nThere are no any related issues\r\n\r\n##### What operating system are you using?\r\nArch Linux\r\n\r\n##### What version of Mailspring are you using?\r\n116.69.203.115a837d0e\r\n\r\n--\r\n\r\n**Bug?**\r\n##### Do you have any third-party plugins installed? If so, which ones?\r\nNo plugins\r\n\r\n##### Is the issue related to a specific email provider (Gmail, Exchange, etc.)?\r\nNo, it concerns installation of Mailspring plugins, not email accounts.\r\n\r\n##### Is the issue reproducible with a particular attachment, message, signature, etc?\r\n...\r\n\r\n--\r\n\r\n**Feature Request?**\r\n##### Does this feature exist in another mail client or tool you use?\r\nIt would be great to have ability to install plugins for all users on your system. \r\nIt could be used for plugins installation as optional dependencies for the Mailspring package.\r\n\n Comments: \n Comment 0: Same here (Ubuntu 16.04, Gmail account, no plugins)\n Comment 1: *bump* :cry: \n Comment 2: While we do have plans of adding a formal Plugins UI in Mailspring itself at some point in the future, we have meantime created a central place in our new Discourse community for sharing plugins: https://community.getmailspring.com/c/plugins/8\r\n\r\nPlease join there, and encourage your favorite plugin developers to post! (As you can see, it's a bit quiet there right now, but only because we've just started.)",
  "Issue title: Diffie Hellman Parameters\n Issue body: I like that this supports generating 4096 bit RSA keys. It would be good if the scripts could be enhanced to also generate new 4096 DH parameters. I'm not sure how to incorporate this into the scripts, but the OpenSSL command would be: `openssl dhparam 4096 -out pki/dh.pem`.\r\n\r\nFor now, my work around is to generate these manually after running `ovpn_copy_server_files` on my private CA box. \r\n\r\nBy the way, thanks for the great image and good documentation!\n Comments: \n Comment 0: Disregard. Just realized this is already handled. ",
  "Issue title: Is there gonna be any change in Server Tick rate for 1.3?\n Issue body: I don't know what is current server tick rate for 1.2. But I assume it's not 60 Hz? So Dying behind cover, Hit register, movements and all gonna be the same or any plans for introducing high tick rate servers..Even Battlefield has 60 Hz servers and assaultcube is much more fast paced than that.\n Comments: \n Comment 0: AC uses a fat client architecture so I think your idea is not applicable.",
  "Issue title: Migrate \"Advanced Parameters > Administration\" page\n Issue body: Part of Symfony migration project\n Comments: \n Comment 0: Fixed by https://github.com/PrestaShop/PrestaShop/pull/8365",
  "Issue title: TypeError: win.matchmedia is not a function\n Issue body: <!--\r\n\r\n\r\n\r\n-->\r\n\r\n- `@testing-library/react` version: 13.2.0 (also tried 13.1.1 - same error)\r\n- Testing Framework and version:\r\n  React Scripts version 5.0.1 using Jest 27.5.1\r\n- DOM Environment:\r\n@testing-library/jest-dom version 5.16.4\r\n\r\n### Relevant code or config:\r\n\r\n```js\r\nconst customRender = (ui: React.ReactElement, options?: RenderOptions) =>\r\n  render(ui, { wrapper: AllProviders,...options });\r\n```\r\n\r\n### What you did:\r\nUpdated to react-scripts 5.0.1 and React 18. \r\n\r\n<!-- What you were doing -->\r\nRan the tests with `npm test`\r\n\r\n### What happened:\r\nGot this error:\r\n`TypeError: win.matchMedia is not a function`\r\n\r\n### Problem description:\r\n\r\nTests calling render won't run.\r\n\r\n\n Comments: \n Comment 0: This looks like an issue with your testing environment. I suggest finding out where this error originates first and then find how who should provide that value. Testing Library is not responsible for polyfilling browser features like `matchMedia`.",
  "Issue title: Introduce Service Worker to improve speed (and help with unreliable, offline connections)\n Issue body: A Service Worker would be good to introduce to help the load times. Even on subsequent loads, the time to first byte (even for the 304 requests with `E-Tag` headers) can add up.\r\n\r\nI'd recommend using https://github.com/GoogleChrome/sw-toolbox or a snippet from https://serviceworke.rs/. I have several handy but I'd recommend starting with `sw-toolbox`.\r\n\r\nCache the common assets first. And, we can look to possibly storing the Uploadcare URLs with the responses using the [Cache API](https://developer.mozilla.org/en-US/docs/Web/API/Cache) (if the files are big, IndexedDB could be used as a last resort).\r\n\n Comments: \n Comment 0: Also could be useful: https://github.com/TalAter/UpUp\n Comment 1: Since users can also save their painting in a local file, the offline option is interesting! \n Comment 2: Example: load a drawing URL once, close the tab, and load it again. On my connection, [this drawing](https://aframe.io/a-painter/?url=https://ucarecdn.com/962b242b-87a9-422c-b730-febdc470f203/) takes over 6 seconds to load on subsequent refreshes (even with all the `304` responses).\r\n\r\nThe [drawing file](https://ucarecdn.com/962b242b-87a9-422c-b730-febdc470f203/) clocks in at `568.303 KB`, which isn't that large.\r\n\r\nBut, it's the whole request/response lifecycle that is eating up the time (even if the responses are already cached by the browser, which they are).\r\n\r\nA simple Service Worker will obliterate these network bottlenecks. It's some low-hanging fruit to get some great improved perf.\r\n\r\nI'd love to tackle this next week.\r\n\n Comment 3: @cvan I'v never worked with Service Worker before, do you mind giving some advices on how to deal with it, or start some wip PR?\n Comment 4: Yep, working on it for Puzzle Rain, so expect a PR for several repos soon.\r\n\n Comment 5: Cool! :)\n Comment 6: FYI: I made a tool for handling a Service Worker that is versioned based on a hash of static assets in a directory:\r\n\r\nhttps://github.com/cvan/sherpy\r\nhttps://gist.github.com/cvan/b0b373442a69b298fc05d4a8a8001d5a\r\n\r\nMight be useful out of the box, though you may have to tweak things slightly - YMMV.",
  "Issue title: Asset folder building problem\n Issue body: npm: 4.0.5v; LinuxMint 17.2 Cinnamon.\r\n\r\nI just installed this generator, and something I was troubled at is that \"npm run build\" command won't work properly if you don't create a subfolder also named \"assets\" inside you \"assets\" folder to put your files there; otherwise what will happen is that all your asset files will be \"built\" on the root folder of the project, and Phaser won't find them when loading.\r\n\r\nThis also happens with the generator game example, which means you can't test it from scratch just by generating and building it.\n Comments: \n Comment 0: I'm a total newbie at npm, but the problem is easily solvable by changing line 13 at \"package.json\" from\r\n`\"copy:assets\": \"ncp assets build/\",`\r\nto\r\n`\"copy:assets\": \"ncp assets build/assets/\",`\r\n\r\nI'm not sure if this is the best solution or I was just mistaken somewhere during the npm built, though.\n Comment 1: Hi  @henriquelalves,\r\n\r\nThanks for reporting this issue and providing the solution, and sorry for the late reply.\r\n\r\n\r\n\r\n\r\n",
  "Issue title: Nebere otazn\u00edk v heslu\n Issue body: Zkou\u0161el jsem zadat p\u0159\u00edstupov\u00e9 \u00fadaje a ftp://user:rhonda74@example.net/directory nefunguje, h\u00e1\u017ee to\r\n\r\nError: syntax error, unexpected '!' in /var/www/html/***/ftp_deploy/deployment.ini on line 2    \n Comments: \n Comment 0: Encode it as `%21`",
  "Issue title: class Observable<Element> non public init\n Issue body: Add the following to RxSwift framework codebase:\r\n```\r\npublic class S<T> : Observable<T> {\r\n   public override init() {\r\n      super.init()\r\n   }\r\n}\r\n```\r\nit compiles. However take the same and place in separate project that links against RxSwift and you get compile error due to init() not being declared public in Observable. Is this by design to stop subclassing of Observable outside of RxSwift.framework or oversight? If by design what is the reasoning?\r\n\r\nThanks Mark\n Comments: \n Comment 0: Hi @mwoollard,\r\n\r\nthis is by design :) This was the end result of trying a lot of things out. If you want to create an `Observable` sequence you do it by invoking `Observable.create` and pass a lambda.\r\n\r\nObservableType:\r\n* implementor says that it is observable\r\n* but you can't have `ObservableType` as a type parameter in Swift because it has associated types\r\n* since anything can implement it, there are no guarantees that sequence grammar is honored - Next * (Completed | Error)?\r\n\r\nObservable:\r\n* anonymous observable sequence\r\n* you can use it to specify type of parameter/property...\r\n* it guarantees that after `Completed` or `Error` is received, observer/sink is closed and thus no new event can be produced\r\n\r\nThat is also a reason why we do `asObservable` before we pass `ObservableType` to operators in our code base. I could actually document this all of this in inline documentation of `Observable`.\r\n\r\nIf you do `asObservable` on `Observable`, it's a no op ;)\r\n\r\nThe reason why it's not final is because although we don't trust external implementors, we do have some internal classes that inherit from Observable for certain reasons.\n Comment 1: Thanks for the explanation!\n Comment 2: I'm supposing we can close this then :)",
  "Issue title: OPA server debug logging should include response body\n Issue body: Title is pretty self-explanatory. The logging handler in OPA's server does not log the response body which is often useful for debugging purposes.\n Comments: \n Comment 0: Fixed in #328 ",
  "Issue title: How does the first proto file import the message in the second file\uff1f\n Issue body: syntax = \"proto3\";\r\npackage com.mobuz;\r\nimport \u201cAddressInfo\u201d\uff1b\r\noption java_package = \"com.proto.user\";\r\noption java_outer_classname = \"UserInfo\";\r\nmessage User{\r\nstring uid=1;\r\nstring uname=2;\r\n}\r\n\r\nsyntax = \"proto3\";\r\npackage com.mobuz;\r\noption java_package = \"com.proto.user\";\r\noption java_outer_classname = \"AddressInfo\";\r\n\r\nmessage Address{\r\nstring state=1;\r\nstring city=2;\r\n}\r\n\r\nHow do I import the AddressInfo into UserInfo by js\uff1f\r\nO(\u2229_\u2229)O\r\n\r\n\n Comments: \n Comment 0: If the two proto files are in the same directory, you can directly reference it, or you should use the full name. \n Comment 1: See the https://developers.google.com/protocol-buffers/docs/proto#other for importing other messages.\n Comment 2: I had the same problem as @yanxinyuan mentioned it. \r\nI have a Base.Proto file which include these messages :\r\n`message ResultProto{\r\n\tbool succeed = 1;\r\n}\r\nmessage empty{}`\r\n and then I'm trying to use these messages within another protos, but I have got bellow errors :\r\n\r\n`ResultProto\" is not defined`\r\n`empty is not defined`\r\n\r\nis there any solution?",
  "Issue title: keygen (!!!\u4e0d\u8981\u4fee\u6539\u8fd9\u91cc!!!)\n Issue body: ### \u673a\u5668\u7801\n\n<!--\r\neyJ2Ijoid2lufDEuMi41IiwiaSI6InhLU1Jia1Z2U2EiLCJsIjoiTEFQVE9QLUVVMVFGT1ZRIHwgSEFPIHwgV2luZG93cyJ9\r\n-->\r\n\n\n### \u7528\u6237\u540d\n\n<!--\r\nandrew15@example.net\r\n-->\r\n\n\n### \u6fc0\u6d3b\u7801\n\n<!--\r\nimtaozhiyu\r\n-->\r\n\n\n### \u514d\u8d23\u58f0\u660e\n\n- [X] \u6211\u5df2\u9605\u8bfb\u5e76\u540c\u610f\u9075\u5b88[\u514d\u8d23\u58f0\u660e](https://taozhiyu.github.io/TyProAction/Agreements.zh.html)\n Comments: \n Comment 0: \u60a8\u7684\u79bb\u7ebf\u6fc0\u6d3b\u7801\u4e3a/Your offline activation code is:\n\n`+h97jfGBuzmwrYwjasw4o4BliVLY4kYFpWVMAB7NGjG5GS8mkexXr6lJ8bjeyfFAigcBYATIfH7oOVDR34kEmEwQY5eZtF3cMgibb7phhsAQ8YmI1mO+9k0valgHkUCvUb9N3nIEVle6S4p5Pr2/pDtD/2CWW75IDQVpzmcTHaT8mfRcplll4Aa6/7oQgV+gZlJi/N49aO8pz12HIW7336sQpzfHycWnGblrhdodoIQZPKbNOaVtwgBnc61j59Hwy4oeLXUn54Q4WMYI+xjqFNKCETd8zndbWapVtTGzhUqo/uxWt/x1iCz7jz/18VIAjq+rO43PKkbBLXZ0b/jYQ0g==`\n\n---\n\u8bf7\u5148\u5728[release](https://github.com/taozhiyu/TyProAction/releases)\u4e2d\u4e0b\u8f7d\u5e76\u8986\u76d6\u66ff\u6362\u8865\u4e01\u6587\u4ef6\n\nPlease download and overwrite the patch in [**release**](https://github.com/taozhiyu/TyProAction/releases) first\n\n\u6211\u4eec\u4ece\u4ee3\u7801\u4e2d\u79fb\u9664\u4e86\u76f8\u5173\u7684\u68c0\u6d4b\uff0c\u65e0\u9700\u518d\u4fee\u6539 Host\n\nWe removed the relevant detection from the code, NO need to modify the Host anymore.",
  "Issue title: Assert Exception: min_to_receive.amount > 0\n Issue body: ## Expected Behavior\r\nthe DEXBot work normally in some assert, but not work well in btc_ltc trade.\r\n\r\n## Actual Behavior\r\nerror\r\n\r\n## Steps to Reproduce the Problem\r\n\r\naccount: cobb-chang-bot2\r\n      amount: 30.0\r\n      center_price: 0.0\r\n      center_price_dynamic: true\r\n      center_price_offset: false\r\n      fee_asset: CYB\r\n      manual_offset: 0.0\r\n      market: JADE.BTC/JADE.LTC\r\n      module: dexbot.strategies.relative_orders\r\n      relative_order_size: true\r\n      spread: 0.5\r\n\r\n## Specifications\r\n\r\n  - Version:\r\n  - OS:\r\n\r\n\r\n\r\n2018-08-16 13:48:23,156 - btc_ltc using account cobb-chang-bot2 on JADE.BTC/JADE.LTC - INFO - Initializing Relative Orders\r\n2018-08-16 13:48:23,173 - btc_ltc using account cobb-chang-bot2 on JADE.BTC/JADE.LTC - INFO - Change detected, updating orders\r\n2018-08-16 13:48:23,646 - btc_ltc using account cobb-chang-bot2 on JADE.BTC/JADE.LTC - INFO - Canceling all orders\r\n2018-08-16 13:48:23,728 - btc_ltc using account cobb-chang-bot2 on JADE.BTC/JADE.LTC - INFO - Orders canceled\r\n2018-08-16 13:48:23,808 - btc_ltc using account cobb-chang-bot2 on JADE.BTC/JADE.LTC - INFO - Placing a buy order for 0.0178266 JADE.LTC @ -94.68744366\r\n2018-08-16 13:48:30,432 - btc_ltc using account cobb-chang-bot2 on unknown - ERROR - Worker initialisation\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\potat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\graphenelib-0.6.6-py3.6.egg\\grapheneapi\\api.py\", line 137, in func\r\n    r = func(*args, **kwargs)\r\n  File \"C:\\Users\\potat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\graphenelib-0.6.6-py3.6.egg\\grapheneapi\\rpc.py\", line 93, in method\r\n    message = self.parse_response(r)\r\n  File \"C:\\Users\\potat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\graphenelib-0.6.6-py3.6.egg\\grapheneapi\\rpc.py\", line 63, in parse_response\r\n    raise RPCError(ret['error']['message'])\r\ngrapheneapi.exceptions.RPCError: Assert Exception: min_to_receive.amount > 0: \r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\File\\work file\\bitshare\\DEXBot-0.5.10\\dexbot\\worker.py\", line 76, in init_workers\r\n    view=self.view\r\n  File \"D:\\File\\work file\\bitshare\\DEXBot-0.5.10\\dexbot\\strategies\\relative_orders.py\", line 68, in __init__\r\n    self.check_orders()\r\n  File \"D:\\File\\work file\\bitshare\\DEXBot-0.5.10\\dexbot\\strategies\\relative_orders.py\", line 219, in check_orders\r\n    self.update_orders()\r\n  File \"D:\\File\\work file\\bitshare\\DEXBot-0.5.10\\dexbot\\strategies\\relative_orders.py\", line 192, in update_orders\r\n    buy_order = self.market_buy(amount_base, self.buy_price, True)\r\n  File \"D:\\File\\work file\\bitshare\\DEXBot-0.5.10\\dexbot\\basestrategy.py\", line 463, in market_buy\r\n    **kwargs\r\n  File \"D:\\File\\work file\\bitshare\\DEXBot-0.5.10\\dexbot\\basestrategy.py\", line 614, in retry_action\r\n    return action(*args, **kwargs)\r\n  File \"C:\\Users\\potat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\bitshares-0.1.19-py3.6.egg\\bitshares\\market.py\", line 432, in buy\r\n    tx = self.blockchain.finalizeOp(order, account[\"name\"], \"active\", **kwargs)\r\n  File \"C:\\Users\\potat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\bitshares-0.1.19-py3.6.egg\\bitshares\\bitshares.py\", line 275, in finalizeOp\r\n    return self.txbuffer.broadcast()\r\n  File \"C:\\Users\\potat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\bitshares-0.1.19-py3.6.egg\\bitshares\\transactionbuilder.py\", line 398, in broadcast\r\n    raise e\r\n  File \"C:\\Users\\potat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\bitshares-0.1.19-py3.6.egg\\bitshares\\transactionbuilder.py\", line 392, in broadcast\r\n    ret, api=\"network_broadcast\")\r\n  File \"C:\\Users\\potat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\graphenelib-0.6.6-py3.6.egg\\grapheneapi\\api.py\", line 145, in func\r\n    self.post_process_exception(e)\r\n  File \"C:\\Users\\potat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\bitshares-0.1.19-py3.6.egg\\bitsharesapi\\bitsharesnoderpc.py\", line 19, in post_process_exception\r\n    raise exceptions.UnhandledRPCError(msg)\r\nbitsharesapi.exceptions.UnhandledRPCError: Assert Exception: min_to_receive.amount > 0:\n Comments: \n Comment 0: > Placing a buy order for 0.0178266 JADE.LTC @ -94.68744366\r\n\r\nNegative price, because of `center_price: 0.0`. Probably strategy should not allow `canter_price = 0`. @MarkoPaasila?\n Comment 1: Oops, there is `center_price_dynamic: true`, so it definetely from the market. Probably the bug is somewhere else because price should not be negative. Need a testcase to reproduce.\n Comment 2: This looks like it makes center price negative when calculating from market orders. Could it be that some price is inverse at the time of calculating center?\r\n\n Comment 3: During handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\File\\work file\\bitshare\\DEXBot-0.5.10 - 20180816-21-23\\dexbot\\worker.py\", line 142, in on_market\r\n    self.workers[worker_name].onMarketUpdate(data)\r\n  File \"C:\\Users\\potat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\events\\events.py\", line 95, in __call__\r\n    f(*a, **kw)\r\n  File \"D:\\File\\work file\\bitshare\\DEXBot-0.5.10 - 20180816-21-23\\dexbot\\strategies\\relative_orders.py\", line 247, in check_orders\r\n    self.update_orders()\r\n  File \"D:\\File\\work file\\bitshare\\DEXBot-0.5.10 - 20180816-21-23\\dexbot\\strategies\\relative_orders.py\", line 221, in update_orders\r\n    self.update_orders()\r\n  File \"D:\\File\\work file\\bitshare\\DEXBot-0.5.10 - 20180816-21-23\\dexbot\\strategies\\relative_orders.py\", line 221, in update_orders\r\n    self.update_orders()\r\n  File \"",
  "Issue title: Swap swipe actions for delete and archive\n Issue body: - [x] I have [searched](https://github.com/klinker-apps/messenger-issues/issues), by keyword, for my issue/request to verify that there aren't any open or closed issues around this request.\r\n- [x] If this is an issue, and not a request, I have verified that this is something that is reproducible\r\n\r\n**Device with issue:** LG G4\r\n**Primary device:** LG G4\r\n**App version:** (339)220-5562\r\n\r\nCurrently swiping from left to right is for archive action and swiping from right to left is for delete action. \r\n\r\nOn the other hand, Google Inbox has these actions reversed. In Google Inbox app, left to right is for delete action and swiping from right to left is for archive action.\r\n\r\nWill you please add an option to swap the swipe actions or just swap the actions by default? \r\n\r\nI searched Google design documentation and couldn't find any recommended swipe direction for delete or archive. But it would be a great help if Pulse is consistent with Google Inbox. In the past I have deleted messages by mistake when I actually intended them to archive.\n Comments: \n Comment 0: Sorry, this is working the way I intended it. \r\n\r\nI chose those directions so that opening the drawer doesn't accidentally cause the user to delete a thread. That is the only other horizontal swipe gesture in the app, so they could conflict.\r\n\r\nAlso, inbox, by default has swiping from the left to right mark as done, which is similar to archive. I think that the way I have it now is how it needs to be\n Comment 1: I just sent this as a feature request but I see you provided feedback there. I think this should be up to the end user to decide which way this works. Prevention of accidentally deleting is something by forcing a specific way isn't really a solution because for every person who does it one direction, there is another person who does it in the opposite direction. Those opposite people would be deleting things accidentally as well. That's why having an option for this makes for a better UI. Your justification is also handled by the hamburger to expand the settings pane rather than swiping.\n Comment 2: If you are worried about accidental deletion, I recommend turning off swipe to delete all together. You can still long press the conversations to quickly delete them.\r\n\r\nAdding a setting for a UI tweak is what I want to avoid in Pulse, like I said. While I understand that some users want to customize everything and need everything their own way, that really isn't my goal here because it distracts from the app itself and it's features. \r\n\r\nThere are some things that I do need to just make the decision on, to add that simplicity factor. Many more users care about simplicity than complete customization and tweaks. I feel as though Pulse's success so far is a testament to that fact.\r\n\r\nAt this point, I am not going to be open to adding a setting just to customize swipe direction, sorry about that. Hopefully my reasoning makes sense",
  "Issue title: localnet docker image is sensitive to poor network conditions\n Issue body: I was using https://hub.docker.com/r/solanalabs/solana/ from a poor hotel wifi connection recently and it was unusable, the leader and/or drone was not starting correctly.\r\n\r\nNeed to replicate those conditions, perhaps find wifi with captive portal and don't login, and debug.\r\n\r\nCould be a problem for hackathon/conference-like environments where wifi can be poor\n Comments: \n Comment 0: Probably obsolete, I have not observed this issue since some time last year",
  "Issue title: Visual bugs\n Issue body: - [ ] Fix line-height 26 px on other in nav bar.\n\n Comments: \n Comment 0: Think this can be closed.  Was fixed in 67d53fe38f444b2d5deb1e98a4fb02b6b9e70f17 :+1: \n Comment 1: nope it was not :-1: \r\nSee last item in list above.![Custom Module](http://i.imgur.com/qSW7XmT.png)\r\nIve already created PR for it: https://github.com/Hellowlol/HTPC-Manager/pull/173",
  "Issue title: Questions related to STAC versions\n Issue body: Due to my work on a specification (openEO) that is based on STAC, some questions came up recently:\r\n\r\n1. Is STAC (i.e. releases and the field stac_version) following Semantic Versioning? So is any breaking change after 1.0.0 leading to a version 2.0? If not, how is the procedure regarding version numbers and breaking changes?\r\n  *Why is this important?* I want to future-proof the openEO API and not just allow version 0.9.0, but also also all versions that are non-breaking after 1.0.0. Getting this information allows me to actually validate the stac_version field (e.g. with a pattern such as `^(0\\.9|1)\\.`).\r\n2. Is it fine to deliver any STAC version via any STAC API version? For example, can I implement STAC API 0.9 and it responds with STAC 1.0 or 0.8 items/collections? According to the OpenAPI file it seems allowed: https://github.com/radiantearth/stac-api-spec/blob/master/STAC.yaml#L1311\r\n  *Why is this important?* How can I base a specification on STAC API that is STAC 1.0 compliant without having a \"final\" STAC API spec yet?\r\n    * If answered with \"yes\", how to detect which API version is implemented? This is related to https://github.com/radiantearth/stac-api-spec/issues/27.\r\n3. To use 1.0 extensions that are not part of 0.9, I think the way to expose these via \"stac_extensions\" is to not use `timestamps`, but (see #835) `https://schemas.stacspec.org/v1.0.0-beta.1/extensions/timestamps/schema.json`, right?\n Comments: \n Comment 0: 1. I'll take on - put in language about sem ver\r\n2. Discussed on call for 6-22-20, decided that the answer is 'yes', a STAC API can respond with different versions. For the betas we don't have a great way to resolve which api version is implemented, though the features api version may help a bit. And we will work to get it more clear for 1.0 of stac api.\r\n3. This is resolved\n Comment 1: 1. PR is #855\r\n2. I guess the way to resolve it is as follows:\r\n  - All STAC APIs prior to 0.9 are bound to the respective STAC versions\r\n  - STAC 0.9 can either be a STAC 0.9 or 1.0 API. It is distinguishable by the stac_api_version field, which we'll include for 1.0. If it's not available, it's a 0.9 API.\r\n   - Everything after STAC API 1.0 has the stac_api_version field.\r\n\r\n    Do we need to document that somewhere?",
  "Issue title: archive_request\n Issue body: https://m.bilibili.com/space/678873?from=video&unique_k=f5cb3X\n Comments: \n Comment 0: \u9519\u8bef Error: \u672a\u9002\u914d\u7f51\u7ad9",
  "Issue title: warp_ctc_loss_layer.cpp:56] Check failed: N_ == label_seq*** Check failure stack trace: *** ->num() (128 vs. 64) \n Issue body: \u53d1\u73b0\u4e00\u4e2a\u95ee\u9898, \u5e94\u8be5\u662fbug: \u8bad\u7ec3\u6837\u672c\u56fe\u50cf\u9ad8\u5ea6\u987b\u4e3a32\u50cf\u7d20\u9ad8\u5ea6, \u9ad8\u4e8e32, \u6bd4\u598236\u5c31\u4f1a\u51fa\u9519.\r\n\u662f\u5426\u53ef\u4ee5\u4fee\u590d\u4e0b,\u8c22\u8c22. @senlinuc \n Comments: \n Comment 0: \u7f51\u7edc\u7ed3\u6784\u8981\u6c42\u8f93\u5165\u9ad8\u5ea6\u4e3a32\uff0c\u60a8\u53ef\u4ee5\u4fee\u6539\u7f51\u7edc\u53c2\u6570\u9002\u914d\n Comment 1: \u5bf9\u6709\u4e9b\u6570\u636e\u96c6 leveldb \u8bad\u7ec3\u62a5\u9519\u600e\u4e48\u56de\u4e8b\r\nCheck failed: shape[i] >= 0 (-546308077 vs. 0)\n Comment 2: \u4fee\u6539\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u8be5\u600e\u4e48\u6539\u7f51\u7edc\u554a\uff1f\u6c42\u6307\u5bfc\uff0c\u60f3\u628a32\u6539\u4e3a64.\n Comment 3: \u770b\u90a3\u4e00\u5c42\u4e0d\u5408\u9002\uff0c\u4fee\u6539\u90a3\u4e00\u5c42\u7684\u7f51\u7edc\u7ed3\u6784\u3002\n\n\u5728 2019-05-16 11:23:14\uff0c\"zhudibo\" <randybrown@example.net> \u5199\u9053\uff1a\n\n\n\u4fee\u6539\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u8be5\u600e\u4e48\u6539\u7f51\u7edc\u554a\uff1f\u6c42\u6307\u5bfc\uff0c\u60f3\u628a32\u6539\u4e3a64.\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n Comment 4: \u6211\u5df2\u7ecf\u4fee\u6539\u597d\u7684\uff0c\u8bad\u7ec3\u51fa\u7684\u7ed3\u679c\u53d1\u73b0\uff0c\u6ca1\u670932\u7684\u597d\u3002\r\n\r\n\r\n \r\n---Original---\r\nFrom: \"prfans\"<randybrown@example.net>\r\nDate: 2019/5/20 10:16:55\r\nTo: \"senlinuc/caffe_ocr\"<randybrown@example.net>;\r\nCc: \"zhudibo\"<randybrown@example.net>;\"Comment\"<randybrown@example.net>;\r\nSubject: Re: [senlinuc/caffe_ocr] warp_ctc_loss_layer.cpp:56] Check failed: N_ == label_seq*** Check failure stack trace: *** ->num() (128 vs. 64)  (#59)\r\n\r\n\r\n\u770b\u90a3\u4e00\u5c42\u4e0d\u5408\u9002\uff0c\u4fee\u6539\u90a3\u4e00\u5c42\u7684\u7f51\u7edc\u7ed3\u6784\u3002\r\n \r\n \u5728 2019-05-16 11:23:14\uff0c\"zhudibo\" <randybrown@example.net> \u5199\u9053\uff1a\r\n \r\n \r\n \u4fee\u6539\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u8be5\u600e\u4e48\u6539\u7f51\u7edc\u554a\uff1f\u6c42\u6307\u5bfc\uff0c\u60f3\u628a32\u6539\u4e3a64.\r\n \r\n \u2014\r\n You are receiving this because you authored the thread.\r\n Reply to this email directly, view it on GitHub, or mute the thread. \r\n\u2014\r\nYou are receiving this because you commented.\r\nReply to this email directly, view it on GitHub, or mute the thread.\n Comment 5: \u8bad\u7ec3\u4e00\u76f4loss\u4e0d\u4e0b\u964d\u662f\u600e\u4e48\u56de\u4e8b\uff1f\n Comment 6: > \u7ec3\u51fa\u7684\u7ed3\u679c\u53d1\u73b0\uff0c\u6ca1\u670932\u7684\r\n\r\n\u5176\u4ed6\u7684\u53c2\u6570\u5e94\u8be5\u4e5f\u9700\u8981\u8c03\u6574\uff0c\u6bd4\u5982\u5377\u79ef\u6838\u5c3a\u5bf8\u7b49\u3002\n Comment 7: > \r\n> \r\n> \u8bad\u7ec3\u4e00\u76f4loss\u4e0d\u4e0b\u964d\u662f\u600e\u4e48\u56de\u4e8b\uff1f\r\n\r\n\u8fd9\u79cd\u95ee\u9898\u4e00\u822c\u68c0\u67e5\u4e0b\u6570\u636e\u6807\u6ce8\u6709\u65e0\u95ee\u9898\uff0c\u8f93\u51fa\u5c42\u6807\u7b7e\u6570\u91cf\u7b49\u9519\u8bef\u3002\n Comment 8: \u68c0\u67e5\u8fc7\u4e86 \u8f93\u51fa\u5c4236\u4e2a\u5b57\u7b26num_output: 37 \uff0c\u6570\u636e\u6807\u6ce8\u4e5f\u6ca1\u6709\u95ee\u9898\n Comment 9: > \u7ec3\u51fa\u7684\u7ed3\u679c\u53d1\u73b0\uff0c\u6ca1\u670932\u7684\r\n> \r\n> \u5176\u4ed6\u7684\u53c2\u6570\u5e94\u8be5\u4e5f\u9700\u8981\u8c03\u6574\uff0c\u6bd4\u5982\u5377\u79ef\u6838\u5c3a\u5bf8\u7b49\u3002\r\n\r\n32\u7684\u53d8\u4e3a64\u7684\uff0c\u5377\u79ef\u7684\u5927\u5c0f\u6211\u6ca1\u53d8\uff0c\u6211\u53ea\u662f\u628alstm\u4e4b\u524d\u7684\u4e00\u4e2a\u6c60\u5316\u5c42\u7684kner_h,\u75314\u6539\u4e3a8.\u4e0d\u77e5\u5927\u4f6c\u600e\u4e48\u6539\u7684\uff1f\n Comment 10: > \u636e\u6807\u6ce8\u4e5f\u6ca1\u6709\u95ee\u9898\r\n\r\n\u90a3\u53ef\u80fd\u662f\u8bad\u7ec3\u6570\u636e\u95ee\u9898\uff0c\u6216\u8005\u6807\u6ce8\u6709\u9519\u8bef\u7684\uff0c\u6216\u8005\u6570\u636e\u96c6\u672c\u8eab\u6bd4\u8f83\u96be\u8bad\u7ec3\u3002\u5982\u679c\u6570\u636e\u96c6\u6ca1\u6709\u95ee\u9898\uff0c\u5efa\u8bae\u4fee\u6539\u4e0b\u5b66\u4e60\u7387\u53c2\u6570\u8bd5\u8bd5\u3002\n Comment 11: > \r\n> \r\n> > \u7ec3\u51fa\u7684\u7ed3\u679c\u53d1\u73b0\uff0c\u6ca1\u670932\u7684\r\n> > \u5176\u4ed6\u7684\u53c2\u6570\u5e94\u8be5\u4e5f\u9700\u8981\u8c03\u6574\uff0c\u6bd4\u5982\u5377\u79ef\u6838\u5c3a\u5bf8\u7b49\u3002\r\n> \r\n> 32\u7684\u53d8\u4e3a64\u7684\uff0c\u5377\u79ef\u7684\u5927\u5c0f\u6211\u6ca1\u53d8\uff0c\u6211\u53ea\u662f\u628alstm\u4e4b\u524d\u7684\u4e00\u4e2a\u6c60\u5316\u5c42\u7684kner_h,\u75314\u6539\u4e3a8.\u4e0d\u77e5\u5927\u4f6c\u600e\u4e48\u6539\u7684\uff1f\r\n\r\n64\u7684\u56fe\u50cf\u80af\u5b9a\u5b57\u7b26\u53d8\u5927\u4e86\uff0c\u5377\u79ef\u6838\u7684\u5c3a\u5bf8\u53ef\u80fd\u4e5f\u5f97\u589e\u5927\u5904\u7406\uff0c\u53e6\u5916\uff0c\u4e5f\u53ef\u4ee5\u628a\u524d\u9762\u7684CNN\u53bb\u6389\uff0c\u6362\u6210inception v3\u7b49\u7f51\u7edc\uff0c\u7136\u540e\u5728CNN\u540e\u9762\u518d\u63a5LSTM\u548cctc\u3002\u795e\u7ecf\u7f51\u7edc\u8fd9\u7c7b\u65b9\u6cd5\uff0c\u53c2\u6570\u5f97\u4e0d\u505c\u5c1d\u8bd5\u3002\n Comment 12: \u6211\u4f7f\u7528\u7684\u662fdense\u90a3\u4e2a\u7f51\u7edc\u3002\u8fd9\u4e2a\u7f51\u7edc\u7684\u8bc6\u522b\u7387\u662f\u6700\u9ad8\u7684\uff0c\u7136\u540e\u5c31\u4f7f\u7528\u5b83\u4e86\uff0c\u5176\u4ed6\u7684\u6211\u6765\u8bd5\u8bd5\r\n\r\n\r\n \r\n---Original---\r\nFrom: \"prfans\"<randybrown@example.net>\r\nDate: 2019/5/20 10:50:27\r\nTo: \"senlinuc/caffe_ocr\"<randybrown@example.net>;\r\nCc: \"zhudibo\"<randybrown@example.net>;\"Comment\"<randybrown@example.net>;\r\nSubject: Re: [senlinuc/caffe_ocr] warp_ctc_loss_layer.cpp:56] Check failed: N_ == label_seq*** Check failure stack trace: *** ->num() (128 vs. 64)  (#59)\r\n\r\n\r\n  \r\n\u7ec3\u51fa\u7684\u7ed3\u679c\u53d1\u73b0\uff0c\u6ca1\u670932\u7684\r\n \u5176\u4ed6\u7684\u53c2\u6570\u5e94\u8be5\u4e5f\u9700\u8981\u8c03\u6574\uff0c\u6bd4\u5982\u5377\u79ef\u6838\u5c3a\u5bf8\u7b49\u3002\r\n  \r\n32\u7684\u53d8\u4e3a64\u7684\uff0c\u5377\u79ef\u7684\u5927\u5c0f\u6211\u6ca1\u53d8\uff0c\u6211\u53ea\u662f\u628alstm\u4e4b\u524d\u7684\u4e00\u4e2a\u6c60\u5316\u5c42\u7684kner_h,\u75314\u6539\u4e3a8.\u4e0d\u77e5\u5927\u4f6c\u600e\u4e48\u6539\u7684\uff1f\r\n  \r\n64\u7684\u56fe\u50cf\u80af\u5b9a\u5b57\u7b26\u53d8\u5927\u4e86\uff0c\u5377\u79ef\u6838\u7684\u5c3a\u5bf8\u53ef\u80fd\u4e5f\u5f97\u589e\u5927\u5904\u7406\uff0c\u53e6\u5916\uff0c\u4e5f\u53ef\u4ee5\u628a\u524d\u9762\u7684CNN\u53bb\u6389\uff0c\u6362\u6210inception v3\u7b49\u7f51\u7edc\uff0c\u7136\u540e\u5728CNN\u540e\u9762\u518d\u63a5LSTM\u548cctc\u3002\u795e\u7ecf\u7f51\u7edc\u8fd9\u7c7b\u65b9\u6cd5\uff0c\u53c2\u6570\u5f97\u4e0d\u505c\u5c1d\u8bd5\u3002\r\n \r\n\u2014\r\nYou are receiving this because you commented.\r\nReply to this email directly, view it on GitHub, or mute the thread.\n Comment 13: \u8fd9\u5b66\u4e60\u7387\u5df2\u7ecf\u5f88\u4f4e\u4e86\u5427\r\n\r\nI0520 10:58:05.349864 10564 solver.cpp:342] Iteration 13545000, Testing net (#0)\r\nI0520 10:58:06.535334  9736 data_layer.cpp:78] Restarting data prefetching from start.\r\nI0520 10:58:06.627910 10564 solver.cpp:409]     Test net output #0: acc = 0.045701\r\nI0520 10:58:06.627910 10564 solver.cpp:409]     Test net output #1: acc = 0\r\nI0520 10:58:06.627910 10564 solver.cpp:409]     Test net output #2: ctcloss = 21.4828 (* 1 = 21.4828 loss)\r\nI0520 10:58:06.674784 10564 solver.cpp:231] Iteration 13545000, loss = 21.2888\r\nI0520 10:58:06.674784 10564 solver.cpp:249]     Train net output #0: ctcloss = 21.2888 (* 1 =",
  "Issue title: Notification to slack\n Issue body: Can you add notification to slack\n Comments: \n Comment 0: @programmermarvin, Yes, there is a possibility to add this feature. But my time is limited and I will try to do it as soon as possible. \r\nIf you can to help expand this package, you can do the following.\r\n\r\nFork, then clone the repo:\r\n```bash\r\ngit clone mevans@example.org:your-username/laravel-social-auto-posting.git\r\n```\r\nMake your changes and push to your fork and submit a pull request.\r\n\r\nThanks for your interest.\r\n",
  "Issue title: Underbar changed to dash in generated url\n Issue body: If content is of the form \n    foo_bar.md\nthen\n    make html\ngenerates URLs of the form\n    foo-bar.html\n\nUnder-bar is silently changed to dash.\n\nFor SEO purposes, dash is preferred to under-bar; so, I agree that generated URLs should use dashes; however, there should be a warning. If there are internal links between pages, translating under-bar to dash will break these links. The warning should include an explanation that internal links using under-bar need to be changed to dash. Possibly a settings item to allow under-bar in URL should be included.\n\n Comments: \n Comment 0: The URL is generated from the `\"Title: foo bar\"` at the top of `foo_bar.md` which is different to how some other static site generators work (e.g. [Jekyll](https://github.com/mojombo/jekyll)).\n\n Comment 1: As @rupert mentioned, the URL slug auto-generation is based on the post title \u2014 not the source file name \u2014 and is only done if you do not explicitly set the slug yourself. If you want a URL slug that's different from the auto-generated version, simply specify it via the following metadata in your post:\n\n```\nslug: foo_bar\n```\n\nLet us know if we can be of further assistance. Issue closed.\n",
  "Issue title: There is no 'Click on Stores under Distribution in the left menu.'\n Issue body: Thank you for this tutorial.\nI was making good headway linking up the service account.\nQuestions:\n1) Where is the JSON service account private key saved to on my windows 10 file system?\n2) there is no Distribution nor Stores in the left hand menu. 'Click on Stores under Distribution in the left menu.' Have these been moved or do I need to enable something to get them to show?\n\nThanks\nStewart\n\n---\n#### Document Details\n\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\n\n* ID: 868e3edf-f3af-950e-4f8a-ea30c392e883\n* Version Independent ID: a725a1f2-fe7b-b7be-8e5e-6db22c2a756d\n* Content: [Publish to Google Play Store - Visual Studio App Center](https://docs.microsoft.com/en-us/appcenter/distribution/stores/googleplay)\n* Content Source: [docs/distribution/stores/googleplay.md](https://github.com/MicrosoftDocs/appcenter-docs/blob/live/docs/distribution/stores/googleplay.md)\n* Service: **vs-appcenter**\n* GitHub Login: @Oddj0b\n* Microsoft Alias: **vigimm**\n Comments: \n Comment 0: @stewa11 Did you navigate to your app's page? That's where the 'Distribute' menu option is. It doesn't explicitly say in the tutorial but the link to Google Play needs to be set up for each app individually in App Center.\r\n\r\n<img width=\"255\" alt=\"Screenshot 2019-11-26 at 09 54 08\" src=\"https://user-images.githubusercontent.com/27358441/69614234-1468a400-1033-11ea-87d1-aae728f0d9c5.png\">\r\n\n Comment 1: \r\nHi anne-k, ot-dchristopher,\r\n\r\nhuge thanks for helping me.\r\n\r\nCan you please confirm the URLs?\r\nIs this navigation correct? \r\nGoogle Play Console (**example** https://play.google.com/apps/publish/?account=XXXXXXXXXXXXXXXX#AppListPlace)\r\nClick on App, Release Management, then what (please)?\r\n\r\nI am happy too demonstrate/learn if you are available for 5 mins on a remote session.\r\n\r\nthanks \r\nStew\r\n\n Comment 2: > Hi anne-k, ot-dchristopher,\r\n> \r\n> huge thanks for helping me.\r\n> \r\n> Can you please confirm the URLs?\r\n> Is this navigation correct?\r\n> Google Play Console (**example** https://play.google.com/apps/publish/?account=XXXXXXXXXXXXXXXX#AppListPlace)\r\n> Click on App, Release Management, then what (please)?\r\n> \r\n> I am happy too demonstrate/learn if you are available for 5 mins on a remote session.\r\n> \r\n> thanks\r\n> Stew\r\n\r\nThe URL you mentioned is in the Google App Store. The one I was referring to is in App Center (https://appcenter.ms). Load your app in App Center, then follow the instructions in the earlier posts. \n Comment 3: Hi @stewa11, I have PR open to change Distribution to Distribute instead.",
  "Issue title: I just created a new project and I don't see the \"stories\" feature like I did in my first test? How does it get turned on?\n Issue body: **Do you want to request a *feature*, report a *bug*, or ask a *question* about wit?**\r\n\r\n**What is the current behavior?**\r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem.**\r\n\r\n**What is the expected behavior?**\r\n\r\n**What is the App ID where you are experiencing this issue (if applicable)?**\r\n\n Comments: \n Comment 0: Stories has been deprecated, see https://wit.ai/blog/2017/07/27/sunsetting-stories",
  "Issue title: Cumulative value for levels below scope\n Issue body: ## Steps to reproduce\r\n\r\nI've pre-computed the cumulative number of transactions with Pandas and I am able to see the cumulative value by date up to the time level. In this case, when I add the `trans_num`, I'm still able to see the number of accumulated transactions up till the transaction itself:\r\n![image](https://user-images.githubusercontent.com/35210495/143852901-b2256d2c-b157-44c6-b052-79325283d2c3.png)\r\n\r\nHowever, I would like to do the cumulative aggregation within atoti, instead of Pandas. \r\nBut by doing so, you can see that I do not have the cumulative value on the `trans_num` level. \r\n![image](https://user-images.githubusercontent.com/35210495/143853026-4ff7c209-6b9e-402a-b4c6-9ed3ec9434e5.png)\r\n\r\nIs there a way for me to achieve the same? I had wanted to export the cumulative value with the `trans_num` as my key for machine learning (and reimporting in to atoti later on).\r\n\r\n[cumulative.zip](https://github.com/atoti/atoti/files/7617527/cumulative.zip)\r\n\r\n## Environment\r\natoti: 0.6.3\r\nPython: 3.8.12\r\nOperating System: win32\r\n\r\n\r\n\r\n\n Comments: \n Comment 0: Hi Huifang,\r\n\r\nIn the first example, the aggregation doesn't work does it? It's correct at the trans_num/trans_time level but doesn't add up correctly at higher levels.\r\n\r\nRegarding the cumulative part, it looks like you want the aggregation to be done at the trans_date/trans_time level, instead of only trans_date. So you likely want to create a multi-level hierarchy. You also need trans_num to be of LocalDateTime / datetime type in this case.\n Comment 1: Hi Romain,\r\n\r\nyou are right on the aggregation for the first example. Therefore, it makes more sense to perform cumulative aggregation in atoti.\r\n\r\n`trans_num` can't be translated to datetime type. So I guess it's not possible in this case to get the cumulative value at the transaction level by date. \r\n\r\nI tried apply cumulative on DateTime level, but I can't explain its behaviour: https://github.com/atoti/atoti/issues/396#issuecomment-956100778\n Comment 2: \r\n> You also need trans_num to be of LocalDateTime / datetime type in this case.\r\n\r\nSorry that's a typo I meant trans_time. \r\nSo that you can build a trans_date/trans_time hierarchy to perform the cumulative sum.\r\n\r\n",
  "Issue title: Customisable front-page blocks\n Issue body: Ushahidi V2 had blocks of content that could be added to the front page. \n\nCopied from V2 feature request 629: \n\nIdeas:\n1. Video block pulling in from our YouTube, Vimeo accounts.\n2. Photo block pulling in from Flickr by album, tag, etc.\n3. Incoming SMS block; almost like twitter feed but isolated to just cell phone SMS\n\n*Created by bodacea on 2014-08-09 02:19:26.*\n\n*Imported from https://phabricator.ushahidi.com/T581*\n Comments: \n Comment 0: *Comment by shadowhand on 2014-10-28 02:53:46:*\n\nnot sure this is actionable, leaving on the wishlist for now.\n Comment 1: *Comment by shadowhand on 2014-10-28 02:54:05:*\n\nNone",
  "Issue title: rkt: When using the rkt runtime, images are pulled too aggressively with imagepolicy always\n Issue body: This is really a [rkt issue](https://github.com/coreos/rkt/issues/2937), but I think it's worth tracking in the Kubernetes repository as well.\r\n\r\nEssentially when the remote docker image has not changed at all, rkt will still download all the bytes again for `--no-store` fetch (which is now the default behaviour).\r\n\r\nThis is especially noticeable if the image is large and the tag is latest because the default `ImagePullPolicy` of `IfNotPresent`, for latest, is interpreted as `always`.\r\n\r\nThe action items we have on the Kubernetes side:\r\n- [x] Document for v1.4 in known-issues\r\n- [ ] Update recommended/required rkt version once this issue is fixed in upstream rkt\r\n\r\ncc @kubernetes/sig-rktnetes \r\n\n Comments: \n Comment 0: Updating 1.4 issue https://github.com/kubernetes/kubernetes.github.io/pull/1109\n Comment 1: Issues go stale after 30d of inactivity.\nMark the issue as fresh with `/remove-lifecycle stale`.\nStale issues rot after an additional 30d of inactivity and eventually close.\n\nPrevent issues from auto-closing with an `/lifecycle frozen` comment.\n\nIf this issue is safe to close now please do so with `/close`.\n\nSend feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.\n/lifecycle stale\n Comment 2: Image policy is handled differently via CRI, closing this as stale since rktnetes is being replaced by the CRI [rktlet](https://github.com/kubernetes-incubator/rktlet/).\r\n\r\n/close",
  "Issue title: python\u5982\u4f55\u8c03\u7528 api \u6dfb\u52a0 task\n Issue body: \u60f3\u95ee\u4e00\u4e0b python \u7528 requests \u5982\u4f55\u8c03\u7528 api \u6dfb\u52a0 task\uff0c\u65e0\u6cd5\u7528 post \u65b9\u6cd5\u3002\n Comments: \n Comment 0: AriaNg\u63d0\u4f9b\u7684API\u53ea\u80fd\u901a\u8fc7\u8bbf\u95ee\u7f51\u9875\u8c03\u7528\u3002\u5982\u679c\u4ecePython\u8c03\u7528\u7684\u8bdd\uff0c\u8bf7\u76f4\u63a5\u4f7f\u7528aria2\u7684rpc\u63a5\u53e3\u3002",
  "Issue title: Product show NULL when no login for see prices\n Issue body: Can anyone help me here? I am using 116.69.203.115 and when I choose in admin not to show the prices only after the user logs in, next to the Add to cart appears a NULL message. \nThank you!\n\n Comments: \n Comment 0: Please use the forum for general support http://forum.opencart.com/\n",
  "Issue title: Add debug logging to cloudstack provider\n Issue body: I'm happy to provide a PR for this, I wanted to check on the general policy for debug logging first.\n\nAt the moment it can be a little tricky to debug cloudstack failures, as there's nothing in the logs to show which API was called, and with what parameters.\n\nI can see two options here to improve this story\n1. Add debug logging capabilities into `go-cloudstack`, based on an environment variable\n2. Add debug logging next to every `go-cloudstack` api call in the terraform profider, which would respect `TF_LOG`\n\nThe latter would probably be simpler, as it it doesn't require a new way of enabling debug logging. Is there a general policy for what should or shouldn't be included in the TF_LOG output?\n\n Comments: \n Comment 0: @phinze I don't think there is a policy for this right? As long as common sense is used, it should be fine IMHO...\n Comment 1: Agreed! @glenjamin you can just go ahead with (2) and add debug logging to the provider.\n Comment 2: @glenjamin are you ok with me closing this one? Think your question is answered and your good to go write some logging right?\r\n\r\nAlso please keep an eye on PR #3380 as it seems that one will be merged shortly and it improves/extends the logging capabilities if TF.\n Comment 3: It's vaguely on my todo, might be better off keeping it open in case someone else wants to pick it up?\n\n Comment 4: Well in that case I'll go ahead and close it off... :wink: With well over 500 open issues I don't think it adds much value to leave this one open as well. Especially since the question in the issue is answered and can be found back for others when searching through the issues.\r\n\r\nThanks!\n Comment 5: I'm going to lock this issue because it has been closed for _30 days_ \u23f3. This helps our maintainers find and focus on the active issues.\n\nIf you have found a problem that seems similar to this, please open a new issue and complete the issue template so we can capture all the details necessary to investigate further.\n",
  "Issue title: boxes too small for content in '/browse'\n Issue body: The boxes are too small for my email address. \r\nthe settings icon hides some of the text, and the IMAP entry is completely hidden\n Comments: \n Comment 0: This seems to be an issue with Rebar. Looked into it, hard to fix without forking Rebar\n Comment 1: Switching to a completely different layout on that page is absolutely an option.\r\n\r\nIt doesn't need to be boxes, and in fact I'm not even sure the boxes are a good idea. That's just what I had to work with - I'm mostly working on the backend, getting the functionality in place. The idea was to sort of emulate the icon-view of a file manager, but a more boring list-based view would still get the job done.\n Comment 2: I'll look into it\n Comment 3: Going through it I found that `{{ info.display_name }}` has a bunch of whitespace before and after it. In fact pretty much anything, include icons which are dumped into templates seem to have a lot of whitespace before and after (spaces). Any reason for this?\n\n Comment 4: Whitespace shouldn't matter when rendering the HTML. If you are looking at what your web browser sees, then the whitespace is probably caused by the templating engine. I don't think it's worth worrying about.\n\n Comment 5: I think it is, because it is inside the tags and makes tables go weird.\nWhen I'm back home I will look into the engine.\n\nOn 2 Nov 2016 11:00, \"Bjarni R\u00fanar Einarsson\" phyllisschultz@example.net\nwrote:\n\n> Whitespace shouldn't matter when rendering the HTML. If you are looking at\n> what your web browser sees, then the whitespace is probably caused by the\n> templating engine. I don't think it's worth worrying about.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/mailpile/Mailpile/issues/1441#issuecomment-257820819,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AJjKqyghfClDsjWV4QR8jj-a0Eg2DiuVks5q6F8ygaJpZM4GdUvu\n>.\n\n Comment 6: Did some research, seems to be a Jinja \"feature\" of sorts. Adding a _\"-\"_ to the start of the tags should fix that. Now I can make it a table! Hurrah\n\n Comment 7: I have a almost-done fix for this one. Just one question: I can't seem to find the source for the `settings(attr, info)` function anywhere, it is being called to create a link to open a modal with settings, however the `a` tag is always surrounded with a div with class `right` which you really don't want in a table. Any way to get around that?",
  "Issue title: Make jinja really language indepened -> remove Hardcoded `Markup` and references\n Issue body: As described in #1377 I found that surprisingly Jinja hardcoded the usage of the `Markup` class quite deeply, i.e. to mark code as safe.\r\n\r\nI would like to try to remove the hardcoded dependency, without changing the current behaviour.\r\n\r\nMy idea would be to replace all `escape` usage and `Markup` class generations by a function that is generated by the context and add a default MarkupClass generator to the environment for the Marco generation (only special case I found in the source code for which the context is not guaranteed and no html is considered anyway (i.e. `htmlsafe_json_dumps` or `generate_lorem_ipsum` with `html` parameter).\r\n\r\nAlso I would try to create a Protocol for the Markup class so people that want to create a custom one know which functions/operators are actually used by jinja.\r\n\r\nWhat do you think about the idea? \r\n\n Comments: \n Comment 0: Addressed this in #1377",
  "Issue title: Simple RSS feed has stopped rendering xml file data on webpage\n Issue body: #### Expected result\n\nXML data from an RSS feed is updating as it should, it normaly then renders the xml data onto a our homepage.\n#### Actual result\n\nXML data from an RSS feed is updating as it should, it normaly then renders the xml data onto a our homepage but it is just keeps coming up blank.\n#### System information (as much as possible)\n\nRunning windeos server 2003 STD\nSite - The Nexus\nRunning Joomla 1.5.20\nModule name - mod_jw_srfr\n#### Expected result\n\nXML data from an RSS feed is updating as it should, it normally then renders the xml data onto our homepage.\n#### Actual result\n\nXML data from an RSS feed is updating as it should, it normally then renders the xml data onto our homepage but it is just keeps coming up blank.\n#### System information (as much as possible)\n\nRunning windows server 2003 STD\nSite - The Nexus\nRunning Joomla 1.5.20\nModule name - mod_jw_srfr\n#### Additional comments\n\nI am not the most knowledgeable person when it comes to working with joomla, but i have a good understanding of the workings of our site.\n#### Additional comments\n\nI am not the most knowledgebal person when it comes to working with joomla, but i have a good understanding of the workings of our site.\n\nIve cleared out the cache for the module, restarted services used to pull in the data to the XML file, change the link in the module to another XML document, disabled/enabled the module, disabled/enabled the site. all of the above have not worked for me.\n\n Comments: \n Comment 0: @kero1984 \r\n\r\n>Running Joomla 1.5.20\r\n\r\nThis is a very old Version of Joomla (18 July 2010) with known security issues. Please update at least now to 1.5.26 (download: http://joomlacode.org/gf/project/joomla/frs/?action=FrsReleaseBrowse&frs_package_id=6311)\r\n\r\nAfter this please apply this hotfix: \r\nhttp://joomlacode.org/gf/download/trackeritem/206.985.4984/UploadFix15v3.zip\r\nsee: http://joomlacode.org/gf/project/joomla/tracker/?action=TrackerItemEdit&tracker_item_id=31626\r\n\r\nThan please start planning a migration to 3.4.1\r\n\r\nThis is a migration component that can manage that: http://redcomponent.com/redcomponent/redmigrator\r\nhttp://redcomponent.com/redcomponent/redmigrator/redmigrator-component\r\n\r\n>Module name - mod_jw_srfr\r\n\r\nIf you successful migrated from 1.5 to 3.4 you can try this version of the external extension: http://www.joomlaworks.net/extensions/free/simple-rss-feed-reader\r\nThis is the last version that works with the current Joomla Version.\r\n\r\nI'm going to close this now as you use a very old version of Joomla and the issue is not in the Joomla core rather in a external extension. Thanks\n Comment 1: I have one last quick question on this, would it be that the older version of the RSS module is not compatiable with Rss2.0? I think the site i was recieving the updates from upgraded there RSS Feed to that lately.\r\n\r\nThanks for your reply we will have to do a feasibility on upgrading the server as we are ceasing operations later this year.\r\n\r\nRegards,\r\nKier\u00e1n\n Comment 2: >would it be that the older version of the RSS module is not compatiable with Rss2.0?\r\n\r\nmaybe. I don't know this old version. If you are on 3.4 and the last version of the extension you can ask the extension developer.",
  "Issue title: Specify jQuery version in readme\n Issue body: **Summary**\r\n\r\nI spent a fair amount of time debugging why the board wasn't working as expected. It turns out jQuery v3.3.1 was not up to date enough. I see that the demo websites are running jQuery v3.4.1\r\n\r\n**Proposal**\r\n\r\nCan you specify the minimum jQuery version in the readme?\n Comments: \n Comment 0: Seconded. It took me a full hour to get it working even though I've read the instructions on the website. Why is this still not inside the README? Is this project not being maintained anymore?\n Comment 1: > Can you specify the minimum jQuery version in the readme?\r\n\r\nDone with [commit f093aaf4](https://github.com/oakmac/chessboardjs/commit/f093aaf4e99e5fcfc3a8f156ea5338205869cc28)\r\n\r\nI'm sorry y'all had trouble with this; I agree it should be clear in the documentation. The minimum jQuery version is specified in the [package.json](https://github.com/oakmac/chessboardjs/blob/f093aaf4e99e5fcfc3a8f156ea5338205869cc28/package.json#L13-L15) file, but that is pretty obscure unless you know to look for it.\r\n\r\n> Is this project not being maintained anymore?\r\n\r\nI do not have any current plans for big changes for chessboard.js in the near future, but I have not ruled out working on a v2 completely. Meanwhile, I'm around to watch the repo for small stuff like this :wink: ",
  "Issue title: Removed columns in `glance.aov()`\n Issue body: One more reverse dependency failure for `0.7.0` that's yet to be addressed. Seems like there\u2019s been quite a bit of discussion about the `aov` tidiers. The `r.squared` and `adj.r.squared` columns were recently removed from `glance.aov()`, but don't seem to be an issue in the existing discussions on the method (#273, #626, #862). Considering adding those columns back in to the output.\r\n\r\nWaiting on filing issues/PRs for now.\r\n\r\n# CGPfunctions\r\n\r\n<details>\r\n\r\n* Version: 0.6.0\r\n* Source code: https://github.com/cran/CGPfunctions\r\n* URL: https://github.com/ibecav/CGPfunctions\r\n* BugReports: https://github.com/ibecav/CGPfunctions/issues\r\n* Date/Publication: 2020-04-02 14:10:03 UTC\r\n* Number of recursive dependencies: 174\r\n\r\nRun `revdep_details(,\"CGPfunctions\")` for more info\r\n\r\n</details>\r\n\r\n## Newly broken\r\n\r\n*   checking examples... ERROR\r\n    ```\r\n   ...\r\n    > ### ** Examples\r\n    > \r\n    > \r\n    > Plot2WayANOVA(mpg ~ am * cyl, mtcars, plottype = \"line\")\r\n    \r\n    Converting am to a factor --- check your results\r\n    \r\n    Converting cyl to a factor --- check your results\r\n    Warning: Unknown or uninitialised column: `r.squared`.\r\n    Warning: Unknown or uninitialised column: `r.squared`.\r\n    Warning: Unknown or uninitialised column: `r.squared`.\r\n    Warning: Unknown or uninitialised column: `r.squared`.\r\n    Warning in max(limit1, limit2) :\r\n      no non-missing arguments to max; returning -Inf\r\n    Warning in min(limit1, limit2) :\r\n      no non-missing arguments to min; returning Inf\r\n    Warning: Unknown or uninitialised column: `r.squared`.\r\n    Error in round(model_summary$r.squared, 3) : \r\n      non-numeric argument to mathematical function\r\n    Calls: Plot2WayANOVA\r\n    Execution halted\r\n    ```\r\n\n Comments: \n Comment 0: This issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with a reprex: <https://reprex.tidyverse.org>) and link to this issue.",
  "Issue title: [FlatOut] Can not select refresh rate above 60 Hz\n Issue body: I used to run Flatout at 100Hz, but after todays update I only get the 3 choices:\r\n\r\n - default\r\n - 59\r\n - 60\r\n\r\nCan this be related to WidescreenFixesPack?\r\n\r\nI have Windows 8.1 Pro, GTX 1050Ti, resolution 2560x1440x32\n Comments: \n Comment 0: Turns out it was the (new) monitor cable.\r\nWhile the desktop worked in 144Hz, Flatout Setup only offered 59 and 60.\r\nAfter switching back to my old cable, Flatout also offers higher refresh rates.\r\n",
  "Issue title: Grouped prices show 0.00\n Issue body: http://forum.jigoshop.com/discussions/problems/581-price-listed-as-000-on-some-grouped-products-when-all-simple-products-are-priced\n\n Comments: \n Comment 0: Already fixed in RHR\n\n Comment 1: Ah no way. I was just spending time trying to fix this damn thing lol. Glad you got it!\n\n Comment 2: Yep, will try & apply a patch over as soon as I can. Won't be tonight though I hope thats okay with you guys?\n\n Comment 3: I don't see any complaints. Just let us know when it's over :)\n",
  "Issue title: Misunderstanding about syncing tasks\n Issue body: I feel misunderstanding about syncing tasks. Could you make it clear?\nThere in the documention is said that returning a stream makes task asynchronous. That\u2019s quite common. I understand. Therefore, if I don\u2019t return a stream, task should be synchronous. Correct?\nThen why the snipped bellow shows that \u201cFinished\u201d and 'here is the end\u2019 messages printed out before debug log of gulp.src...?\n\n```\n'use strict';\n\nvar\n  gulp = require('gulp'),\n  jshint = require('gulp-jshint'),\n  debug = require('gulp-debug'),\n  gutil = require('gulp-util');\n\ngulp.task('jshint', function () {\n    gulp.src(['Gulpfile.js', 'public/js/**/*.js', '!./public/js/templates.js'])\n       .pipe(debug({title: 'jshint 1'}))\n       .pipe(jshint({\n          quotmark: true\n        }))\n       .pipe(jshint.reporter('jshint-stylish'))\n       .pipe(jshint.reporter('fail'));\n    gutil.log('here is the end');\n});\n```\n\nOutput:\n\n```\n$ gulp jshint\n[14:48:04] Using gulpfile c:\\WebProj\\EngMe\\web\\gulpfile.js\n[14:48:04] Starting 'jshint'...\n[14:48:04] here is the end\n[14:48:04] Finished 'jshint' after 170 ms\n[14:48:04] jshint 1 Gulpfile.js\n[14:48:04] jshint 1 public\\js\\app.js\n[14:48:04] jshint 1 public\\js\\main.js\n[14:48:04] jshint 1 public\\js\\plugins.js\n[14:48:05] jshint 1 4 items\n```\n\n Comments: \n Comment 0: @zhekaus If you won't return stream or won't call callback task won't know about end. Task will be finished in time when it was called, even with long operation. You just need to say when operations in task end.\n\n``` js\ngulp.task(name, function (done) {\n  del('dist', done);\n});\n```\n\n``` js\ngulp.task(name, function () {\n  return new Promise(function (resolve) {\n    del('dist', resolve);\n  });\n});\n```\n\n``` js\ngulp.task(name, function () {\n  return gulp.src('src')\n   .pipe(gulp.dest('dist'));\n});\n```\n\n Comment 1: Thank you so much!\r\nYou described her how to run tasks synchronously, didn\u2019t you?\r\nI\u2019m asking that because this technique described in documentation as \u201cAsync task support\u201d that makes me think about simultaneous running but not consecutive.\r\n\n Comment 2: @zhekaus Knowing when the task ends let you control async flow. Synchronously task will be if you will  use sync code. For example\n\n``` js\n// Sync task\ngulp.task(name, function () {\n  fs.readFileSync(filename);\n})\n\n// Async\ngulp.task(name, function (done) {\n  fs.readFile(filename, function () {\n    done();\n  });\n})\n\n// Still async, but you won't know when file will be loaded. Task will finished before.\ngulp.task(name, function () {\n  fs.readFile(filename, function () {});\n})\n```\n\n Comment 3: Sync tasks will be removed in 4.0, I suggest you always use `done` for an easier transition.\n Comment 4: @phated But what about returning streams and promises?\n Comment 5: @TrySound those are still supported as alternatives to `done` but `done` should be used will callback-style async tasks or sync tasks\n Comment 6: @phated Will gulp modify pipeline for error bubbling? Now I use this decision\r\n```js\r\ngulp.task(name, function (done) {\r\n  return gulp.src()\r\n   .pipe(uglify())\r\n   .on('error', done)\r\n   .pipe(gulp.dest())\r\n})\r\n```",
  "Issue title: Better organize chain.db and reduce storage \n Issue body: <!-- Please only use this template for submitting enhancement requests -->\r\n\r\n**What would you like to be added**:\r\nWhen working on separating index, found there are 2 improvement opportunities to better organize chain.db and reduce storage\r\n1. block is stored using hash (instead of height) as key, to access a block by height is quite complicated: height->hash lookup --> getBlockValue() --> getDBFromHash() --> getDBFromHeight() --> db.Get()\r\n2. block is broken into header, body, footer and stored separately \r\n\r\n**Why is this needed**:\r\nFirst, if we use height as key, the block can be stored using CountingIndex and set bucket.FillPercent = 1.0 to significantly reduce storage.\r\nAccess a block by height would reduce to getDBFromHeight(), then CountingIndex.Get(height)\r\n\r\nSecond, I tested the time to read block data from DB. Reading block header (286 bytes) takes about 20 micro-second, reading the entire block (2940 bytes) takes about 118 micro-second.\r\n\r\nSince this time is only 0.1 ms, I think it is not necessary to store block as header, body, footer separately. The entire block could be stored under 1 key instead of 3 keys, further reducing storage\n Comments: \n Comment 0: specific todos:\r\n1. store raw block using counting index, height as key\r\n2. store height->hash mapping using counting index, height as key\r\n3. hash->height mapping remain the same, no change\r\n4. clean-up and improve funcs: getBlockValue(), getDBFromHash(), getDBFromHeight() \n Comment 1: already doneinn latest code",
  "Issue title: Show that form updates are available with Google Drive integration\n Issue body: #### Software and hardware versions \r\nCollect v1.21.2 and prior\r\n\r\n#### Problem description\r\nWhen the server is set to Google Drive, there is no indication that form updates are available.\r\n\r\n#### Steps to reproduce the problem\r\nUpload a form to Google Drive, upload it or its media, go to Get Blank Form and see that there is no indication of updates.\r\n\r\n#### Expected behavior\r\nThe \"This is an update to a form you have\" message should show when updates are available.\r\n\r\n#### Other information \r\nWe should really consider abstracting away commonalities between the two download lists at some point.\r\n\n Comments: \n Comment 0: @opendatakit-bot claim\n Comment 1: Hello @chidauri, it looks like you've currently claimed 2 issues in this repository. We encourage new contributors to focus their efforts on at most 2 issues at a time, so please complete your work on your other claimed issues before trying to claim this issue again.\n\nWe look forward to your valuable contributions!\n Comment 2: Hi @lognaturel, when showing the files to user in the adapter we have access to `com.google.api.services.drive.model.File` which contains `getId()`, can this id be used to check if that form exists in formsdatabase or is that different id?\n Comment 3: @grzesiek2010 would it be okay to use last modified time to indicate form updates in this case? since md5 is not available until we download the files. \n Comment 4: Sorry we didn't get back to you on this, @chidauri! Yes, using the last modified time in this case is great since we don't get the same manifest as with custom servers.",
  "Issue title: BOE mounts still purchasable after 1 week\n Issue body: I can still buy the white raptor and unarmored kodo after one week.\n Comments: \n Comment 0: The updates haven't been applied yet, thus you can still purchase them!",
  "Issue title: Intermittent timeouts in OpenMP unit tests on KNL testbed Bowman\n Issue body: In gcc/6.1 and gcc/7.1 OpenMP builds on Bowman the `KokkosCore_UnitTest_OpenMP` is intermittently timing out.\r\n\r\nScanning over the times of the component tests in the [timeout](https://jenkins-son.sandia.gov/job/Kokkos_SLURM_inner_test/36086/console) vs [passing](https://jenkins-son.sandia.gov/job/Kokkos_SLURM_inner_test/36046/consoleFull) cases a couple observations are worth noting:\r\n\r\n1. Nearly 3X discrepancy in the `team_scan` test, I'm not sure if this degree of fluctuation is to be expected on KNL, poor affinity setting, or a sign of some underlying issue\r\n\r\ntest | passing case | timeout case\r\n--- | --- | ---\r\nopenmp.team_scan | 41618 ms | 118193 ms\r\n\r\n2. The total test time in passing cases is very near the timeout threshold - should the timeout be increased from 1500 s, or should problem sizes in the tests be reduced?\r\n\r\ntest | passing case | timeout case\r\n--- | --- | ---\r\nKokkosCore_UnitTest_OpenMP | 1451.48 sec | Timeout 1500.30 sec\r\n\r\nAside from the inconsistent `team_scan` test time, the two tests consistently taking the longest are:\r\n\r\n`openmp.team_long_reduce (582533 ms)`\r\n`openmp.team_double_reduce (582214 ms)`\r\n\r\nI'll mark as a question for now with the 3.1 milestone, others can relabel as appropriate. Adding @crtrott \r\n\r\nSample reproducer instructions:\r\n```\r\nmodule load gcc/7.1.0 hwloc/1.11.3\r\n\r\nexport OMP_PROC_BIND=spread\r\nexport OMP_PLACES=threads\r\nsource../scripts/testing_scripts/update_lib.sh bowman\r\n$KOKKOS_PATH/generate_makefile.bash \\\r\n    --arch=KNL \\\r\n    --cxxflags=\"-Wall -Wshadow -pedantic -Werror -Wsign-compare -Wtype-limits -Wignored-qualifiers -Wempty-body -Wclobbered -Wuninitialized\" \\\r\n    --with-hwloc=$HWLOC_ROOT \\\r\n    --compiler=g++ \\\r\n    --with-devices=OpenMP,Serial\r\n```\r\n\n Comments: \n Comment 0: Discussed briefly during the meeting, will add option to increase timeout and update for these tests\n Comment 1: Adjusted timeout in the nightly tests, closing.",
  "Issue title: OJS Reset Article Permissions action is unclear\n Issue body: In journal settings we have a button that says \"Reset article permissions\".\r\n\r\nThe description is:\r\n\r\n> Reset Article Permissions\r\n> Copyright statement and license information will be permanently attached to published content, ensuring that this data will not change in the case of a journal changing policies for new submissions. To reset stored permissions information already attached to published content, use the button below.\r\n\r\nMany journal managers (and me) think that this means they can change all article permissions with one bulk command to the settings they have defined in the same form. We have had similar situations and have seen questions concerning this in the forum. \r\n\r\nHowever, what the Reset button actually does is that it just removes all the attached permissions from all articles.\r\n\r\nI am not a native speaker, but for me \"reset\" means something else than \"remove\" or \"delete\". I, and many others, expect that \"reset\" means resetting the permissions to the given default values. \r\n\r\nI suggest that we:\r\n\r\n1. Change the language there and use the word \"Delete\" or \"Remove\":\r\n\r\n> **Delete** all article permissions\r\n\r\n> \"To **remove** stored permissions information already attached to published content, use the button below.\"\r\n\r\nAND\r\n\r\n2. Add a secondary button that allows journals to bulk set all published article permissions to match the defaults given in the settings.\r\n\r\n> Reset all article permissions using the default values\r\n\r\nI think that we definitely need to do at least number 1.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n Comments: \n Comment 0: @ajnyga, I agree with your assessment of the problem. I'm not sure two buttons are justified, though -- what about making the button behave as you expect (to reset all permissions on published content)? If someone wants to clear permissions and leave them empty, they can empty the journal settings first and use the button.\n Comment 1: Sounds good.\n Comment 2: @asmecher \r\nojs: https://github.com/pkp/ojs/pull/2353\r\nlib: https://github.com/pkp/pkp-lib/pull/4651\r\n\r\nNoticed that a close issue (https://github.com/pkp/pkp-lib/issues/1466) has been dealt with recently so tagging @NateWr here as well. \r\n\r\nI think that the new description text in master branch does not need any revision? The desrciption there mentions \"current default settings\" and that is actually what has been fixed now with this pr.\r\n\r\nedit: tests passed\n Comment 3: @NateWr, may I leave this one with you?\n Comment 4: :+1: merged. Thanks @ajnyga!\r\n\r\n@asmecher since this fix _will_ go out with 3.2, should I assign it to the 3.2 milestone now that it's closed, so that we know which milestone it contributed to?\n Comment 5: One small thing to consider left here. \r\n\r\nWith the license and copyright holder you can now empty the fields by leaving the default settings blank and running reset. However, with the copyright year you have a radio button selection. If you have already chosen one of the two options, then you can not reset the articles to have no copyright year. You can only reset the value to one of the two options available...\r\n\r\nNot sure if that is necessarely an issue though\n Comment 6: I believe this is correct. When resetting, it will use the `copyrightYearBasis` setting for the context, which will set the year to either the article's publication date or the issue's publication date.\r\n\r\nI notice that the `copyrightYearBasis` property is `nullable` and has no default value. In such a case that would lead to an `assert(false)` in `Articl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5_getContextLicenseFieldValue()`. Perhaps that's something that should be addressed, by preventing it from being nullable and setting a default value to `issue`.\r\n\r\nIf you agree I'll open a  new issue.\n Comment 7: yes I noticed that when I was doing this pr, see https://github.com/pkp/pkp-lib/issues/4654\r\n\r\nAnd I guess that fixes this minor issue as well. I am thinking a (maybe non-existing) situation where a journal wants to *remove* all copyright year data from all articles. Now they can only choose between the two available options.\r\n\n Comment 8: Excellent, it's already filed! I'll drop a quick note in about how to do this in the schema system.\r\n\r\n> Now they can only choose between the two available options.\r\n\r\nThat sounds reasonable but maybe a separate use-case. I like that we've aligned things here along the \"reset\" use case. That they can delete is ok, but if they need full deletion, maybe it's best to make them jump through a few hoops. It seems like it would be something to discourage except under extraordinary circumstances.\n Comment 9: yes agreed, even resetting all article permissions is something that has to be a bit difficult to do.\n Comment 10: @NateWr:\r\n\r\n> since this fix will go out with 3.2, should I assign it to the 3.2 milestone now that it's closed, so that we know which milestone it contributed to?\r\n\r\nYes, I've done that!\n Comment 11: Thanks, @ajnyga, this is great! (And thanks for tackling the review, @NateWr.)",
  "Issue title: SOEM and SOES with EVB-LAN9252-SPI and Raspberry Pi\n Issue body: Goodmorning to all,\r\nI'm using a MacBook as Ethercat Master and an Ethercat Slave which uses a EVB-LAN9252-SPI and a Raspberry Pi 3B. \r\nThe slave info with -map reports the following:\r\n```\r\n$./slaveinfo en24 -map\r\nSOEM (Simple Open EtherCAT Master)\r\nSlaveinfo\r\nStarting slaveinfo\r\nec_init on en24 succeeded.\r\n1 slaves found and configured.\r\nCalculated workcounter 3\r\n\r\nSlave:1\r\n Name:LAN9252-C2000 Sample Application\r\n Output size: 8bits\r\n Input size: 8bits\r\n State: 4\r\n Delay: 0[ns]\r\n Has DC: 1\r\n DCParentport:0\r\n Activeports:116.69.203.115\r\n Configured address: 1001\r\n Man: 000004d8 ID: 0000000d Rev: 00000001\r\n SM0 A:1000 L:   1 F:00090044 Type:3\r\n SM1 A:1200 L:   1 F:00010000 Type:4\r\n FMMU0 Ls:00000000 Ll:   1 Lsb:0 Leb:7 Ps:1000 Psb:0 Ty:02 Act:01\r\n FMMU1 Ls:00000001 Ll:   1 Lsb:0 Leb:7 Ps:1200 Psb:0 Ty:01 Act:01\r\n FMMUfunc 0:1 1:2 2:0 3:0\r\n MBX length wr: 0 rd: 0 MBX protocols : 00\r\n CoE details: 00 FoE details: 00 EoE details: 00 SoE details: 00\r\n Ebus current: 0[mA]\r\n only LRD/LWR:0\r\nPDO mapping according to SII :\r\n  SM0 RXPDO 0x1A00 Byte 0\r\n     addr b   index: sub bitl data_type    name\r\n  [0x0000.0] 0x3101:0x01 0x08 OCTET_STR(8) Output\r\n  SM1 TXPDO 0x1600 Byte 0\r\n     addr b   index: sub bitl data_type    name\r\n  [0x0001.0] 0x3001:0x01 0x08 OCTET_STR(8) Input\r\nEnd slaveinfo, close socket\r\nEnd program\r\n```\r\nI want to use SOES's [raspberry_lan9252demo](https://github.com/OpenEtherCATsociety/SOES/tree/master/applications/raspberry_lan9252demo) to control LEDs and buttons connected to Raspberry Pi's GPIO. The [ESCREG_ALEVENT_SM2](https://github.com/OpenEtherCATsociety/SOES/blob/fc72fbeeecc10d53c9c0655c88d43214c4ef0759/soes/ecat_slv.c#L221) parameter is used when judging whether to use the button's function([cb_set_outputs()](https://github.com/OpenEtherCATsociety/SOES/blob/8de160a85159b1a4667004a4ec927389c1bee582/applications/raspberry_lan9252demo/main.c#L33)).\r\n\r\n**Below is my train of thought, please correct me if I'm wrong.**\r\n\r\nAbove my slaveinfo SM2 doesn't seem to start, so I should edit the ESI file to configure SM2 and SM3.\r\nI used siitool to successfully convert the xml file into a bin file, and then used SOEM's [eepromtool.c](https://github.com/OpenEtherCATsociety/SOEM/blob/master/test/linux/eepromtool/eepromtool.c) to successfully write the bin file into the slave.\r\nUnfortunately, the SDK of EVB-LAN9252-SPI is [LAN9252_C2000_SDK_V1.0](http://ww1.microchip.com/downloads/en/DeviceDoc/50002604A.pdf), and I did not find this SDK. The XML files I found on the web did not match my EVB-LAN9252-SPI. After forcibly writing, it will become the following result.\r\nusing [LAN9252_PIC32_SDK_v1.1](https://www.microchip.com/en-us/software-library/lan9252-ethercat-sdk)/ESI Files/SPI-withGPIO-2PortMode.xml\r\n```\r\n$.slaveinfo en24 -map\r\nSOEM (Simple Open EtherCAT Master)\r\nSlaveinfo\r\nStarting slaveinfo\r\nec_init on en24 succeeded.\r\n1 slaves found and configured.\r\nCalculated workcounter 0\r\n\r\nSlave:1\r\n Name:Microchip PIC32 Slaves\r\n Output size: 0bits\r\n Input size: 0bits\r\n State: 4\r\n Delay: 0[ns]\r\n Has DC: 1\r\n DCParentport:0\r\n Activeports:116.69.203.115\r\n Configured address: 1001\r\n Man: e00004d8 ID: 00009252 Rev: 00000001\r\n SM0 A:1000 L: 128 F:00010026 Type:1\r\n SM1 A:1080 L: 128 F:00010022 Type:2\r\n SM2 A:1100 L:   4 F:00010064 Type:3\r\n SM3 A:1400 L:   4 F:00010020 Type:4\r\n FMMUfunc 0:1 1:2 2:0 3:0\r\n MBX length wr: 128 rd: 128 MBX protocols : 0e\r\n CoE details: 01 FoE details: 01 EoE details: 01 SoE details: 00\r\n Ebus current: 0[mA]\r\n only LRD/LWR:0\r\nPDO mapping according to CoE :\r\nEnd slaveinfo, close socket\r\nEnd program\r\n```\r\nrunning slample_test\r\n```\r\n$./simple_test en24\r\nSOEM (Simple Open EtherCAT Master)\r\nSimple test\r\nStarting simple test\r\nec_init on en24 succeeded.\r\n1 slaves found and configured.\r\nSlaves mapped, state to SAFE_OP.\r\nsegments : 1 : 0 0 0 0\r\nRequest operational state for all slaves\r\nCalculated workcounter 0\r\nOperational state reached for all slaves.\r\nOK : all slaves resumed OPERATIONAL.\r\nOK : all slaves resumed OPERATIONAL.\r\nOK : all slaves resumed OPERATIONAL.\r\nOK : all slaves resumed OPERATIONAL.\r\nOK : all slaves resumed OPERATIONAL.\r\nOK : all slaves resumed OPERATIONAL.\r\nOK : all slaves resumed OPERATIONAL.\r\nOK : all slaves resumed OPERATIONAL.\r\nOK : all slaves resumed OPERATIONAL.\r\n...\r\n```\r\n\n Comments: \n Comment 0: This is not a master but slave question. Better post this in the SOES section. SOEM seems to work OK.\n Comment 1: > \r\n\r\nOk, thanks for your reply. I will go to SOES to ask question.",
  "Issue title: Missing Exception Codes\n Issue body: Metadata seems to be missing these exception codes:\r\n\r\n```\r\nEXCEPTION_ACCESS_VIOLATION\r\nEXCEPTION_ARRAY_BOUNDS_EXCEEDED\r\nEXCEPTION_BREAKPOINT\r\nEXCEPTION_DATATYPE_MISALIGNMENT\r\nEXCEPTION_FLT_DENORMAL_OPERAND\r\nEXCEPTION_FLT_DIVIDE_BY_ZERO\r\nEXCEPTION_FLT_INEXACT_RESULT\r\nEXCEPTION_FLT_INVALID_OPERATION\r\nEXCEPTION_FLT_OVERFLOW\r\nEXCEPTION_FLT_STACK_CHECK\r\nEXCEPTION_FLT_UNDERFLOW\r\nEXCEPTION_ILLEGAL_INSTRUCTION\r\nEXCEPTION_IN_PAGE_ERROR\r\nEXCEPTION_INT_DIVIDE_BY_ZERO\r\nEXCEPTION_INT_OVERFLOW\r\nEXCEPTION_INVALID_DISPOSITION\r\nEXCEPTION_NONCONTINUABLE_EXCEPTION\r\nEXCEPTION_PRIV_INSTRUCTION\r\nEXCEPTION_SINGLE_STEP\r\nEXCEPTION_STACK_OVERFLOW\r\n```\r\n\r\nThese constants are values that can be used in the `ExceptionCode` field of an `EXCEPTION_RECORD` (https://docs.microsoft.com/en-us/windows/win32/api/winnt/ns-winnt-exception_record).\r\n\r\n\n Comments: \n Comment 0: Need to add these manually to the NTSTATUS enum. They are aliases for existing members.",
  "Issue title: Cannot read property 'low' of undefined\n Issue body: `long/dist/long.js:310\r\n        return fromBits(val.low, val.high, val.unsigned);`\n Comments: \n Comment 0: have you found a solution? @kubili2013 ",
  "Issue title: [Accessibility]: Role defined for \"Azure Sign in\" is document. \n Issue body: **Test Environment:**\r\nDownload [Eclipse IDE](https://www.eclipse.org/downloads/download.php?file=/oomph/epp/2022-06/R/eclipse-inst-jre-win64.exe&mirror_id=1248)\r\nOS: Windows_11 Version: 22H2 (OS Build: 22598.200)\r\n\r\n**Application/Product Impacted:**\r\nEclipse\u202fIDE for Enterprise Java and Web Developers \r\nVersion: 2022-03 (4.23.0) \r\n\r\n**Pre-Requisites (if any):**\r\n1. Download latest version of Eclipse \r\n2. Download \u201cAzure Toolkit for Eclipse\u201d from \u201cHelp\u201d window (Navigation: Open Eclipse -> Help -> Eclipse Marketplace) \r\n\r\n**Repro Steps:**\r\n1. Tab till tools-->Azure-->Azure Sign in and press enter \r\n2. Open \"Accessibility Insights for Window\" to Inspect \"Azure Sign in\". \r\n3. Verify \"Azure Sign In\" element MAS Compliant. \r\n\r\n**Actual Result:**\r\nRole for \"Azure Sign In\" element present under \"Azure Sign In\" text is defined as \"document\". \r\n\r\nSimilar issues for the following. \r\nEclipse Installation and Sign-in_Eclipse Select Subscriptions scenario---->\u202fOpen Java EE - Eclipse application-->Install 'Azure Toolkit for Eclipse' from Marketplace-->Tab till tools-->Azure-->Azure Sign in and press enter-->Select 'Device login' and tab till sign in and press enter--> Tab till 'Copy and Open' button and press enter-->Paste the code in the browser and click on next--> Verify \"Select subscription(s) you want to use.\" element is MAS Compliant. \r\n\r\n \r\nDeploying web app to Azure_Deploy Web App\u202fscenario---->Open Java EE - Eclipse application-->Install 'Azure Toolkit for Eclipse' from Marketplace.-->Tab till tools-->Azure-->Azure Sign in and sign into Azure account and select any subscription-->Tab till File-->New-->Project--->Dynamic Web Project-->Tab till Next button and press enter--> In Project Explorer view, right-click your project, choose Azure-->Publish as Azure Web App-->Opens \"Deploy Web App\" dialog box.-->Verify the \"Select App Service to deploy to:\" element is MAS compliant. \r\nDeploying web app to Azure_Create New Web App\u202fscenario---->Open Java EE - Eclipse application-->Install 'Azure Toolkit for Eclipse' from Marketplace.-->Tab till tools-->Azure-->Azure Sign in and sign into Azure account and select any subscription-->Tab till File-->New-->Project--->Dynamic Web Project-->Tab till Next button and press enter--> In Project Explorer view, right-click your project, choose Azure-->Publish as Azure Web App-->Opens \"Deploy Web App\" dialog box.-->Tab to \"Create\" and enter. Verify the \"Create Azure App Service\" is MAS compliant. \r\n\r\n**Expected Result:**\r\n\"Azure Sign in\" element shouldn't be defined as \"Document\". It is rather a normal text. \r\n\r\n**Attachments:**\r\n![1952147_A11y_JavaToolingEclipse_Azure Sign-in_Role](https://user-images.githubusercontent.com/93735775/191514659-72794b77-820f-447d-8a0a-655da6e96ce8.png)\r\n![1952147_Similar Issue_Select Subscriptions](https://user-images.githubusercontent.com/93735775/191514689-ea76f0a7-20e9-4478-88a0-b084f4ec3d80.png)\r\n![1952147_Similar Issue_Deploy Azure web App](https://user-images.githubusercontent.com/93735775/191514712-d2829178-b55c-470a-b1f9-19362b76598b.png)\r\n![1952147_Similar Issue_Create web app service](https://user-images.githubusercontent.com/93735775/191514734-b683410a-5bf4-44ca-87bd-bfa539a79362.png)\r\n\r\n\n Comments: \n Comment 0: We are not responsible for the azure sign in page, that is managed by someone else.",
  "Issue title: [Plugin] Bamboo Server\n Issue body: ## Summary\r\nProvide summarized version of Bamboo Build and Deployment status under a selected Component in Backstage.\r\n\r\n## Project website\r\nhttps://www.atlassian.com/software/bamboo\r\nBamboo Server (on-prem, self-hosted)\r\n\r\n## Context\r\nProvide summarized view of Bamboo Build and Deployment Status with references back to bamboo project.\r\n\r\n- Bamboo BuildPlan name\r\n- Build status and timestamp\r\n- User who triggerred\r\n- Status of last N builds\r\n- Deployment (Version, Env, Status)\r\n\n Comments: \n Comment 0: Nice! Is this something that you intend to work on?\n Comment 1: yes, you can assign it to me.\n Comment 2: Awesome, done!\n Comment 3: This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n\n Comment 4: Re-opening since plugin suggestion issues are now exempt from [stalebot](https://github.com/backstage/backstage/blob/18f7345a6c29dcfccef7df081b1708f2bf8f62ff/.github/stale.yml#L9).\n Comment 5: > yes, you can assign it to me.\r\n\r\nAny updates about this plugin development?\n Comment 6: Actually, we have a plugin working in production for our instance of Backstage.\r\n\r\nLet me take sometime to do a bit of clean up and raise PR for the backstage github repo\n Comment 7: Cant wait for it \ud83e\udd1e \r\n \r\nIt would be great to create linked repositories with this integration!\n Comment 8: Looking forward to see it!\n Comment 9: Nice! This is something I was looking for some time. Can't wait\n Comment 10: am I too optimistic to assume this has already been merged? Can't find it on the repo, nor can I find a PR relayetd to this\n Comment 11: @dejoost yes you are \ud83d\ude05\r\n\r\n@kiranpatel11 any update from your end?\n Comment 12: @kiranpatel11  - any update on this PR, would be much appreciated.\n Comment 13: @Rugvip, @tspreeth,\r\n\r\nsorry guys, I am on a vacation atm, and can pick up this in December.\r\nThe code is sitting in the laptop, which I don't have a access too atm.",
  "Issue title: Support upserts in concat function\n Issue body: #### Describe your feature request\r\n\r\nAt the moment the is the existing behaviour in polars for vertical concats is to just append all rows from one dataframe into another. But having a upsert=true parameter would work like doing an upsert in SQL. A 'key' -parameter would most likely be needed as well to specify the column(s) used for calculating the intersect between source and target. So given two dataframes with identical schema, _source_ and _target_, upsert=true would do the following things:\r\n\r\n- Append rows from source to target where keys don't match\r\n- Update rows that have the same key in source and target\r\n- Don't append the rows that have the same key and rest of the column values are identical in source and target\r\n\r\nThis is a common pattern for doing data loads into a persistent table in data warehouses, and it would be awesome if polars could support it.\n Comments: \n Comment 0: @jkausti  \r\n\r\nGreat idea.\r\nAnd may I to know how to append all rows from one dataframe into another at this moment? I just want to insert a new row into a dataframe. Thank you very much.\r\n\n Comment 1: > @jkausti\r\n> \r\n> Great idea. And may I to know how to append all rows from one dataframe into another at this moment? I just want to insert a new row into a dataframe. Thank you very much.\r\n\r\nYou can use the polars.concat function. So you need to create a dataframe first of the row(s) you want to append to the other dataframe. It is documented here: [https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.concat.html]()\n Comment 2: Thanks @jkausti \r\nThis is Python Polars APIs, but is there any Rust Polars APIs for concat function? I use Rust Polars for my program.\n Comment 3: > Thanks @jkausti This is Python Polars APIs, but is there any Rust Polars APIs for concat function? I use Rust Polars for my program.\r\n\r\n@CHCP can you use stackoverflow for that and keep this issue on topic?\r\n\r\n#### Please use StackOverflow \r\n\r\nIs your question related to syntax or how you could do something with the polars library?\r\nPlease use [stackoverflow](https://stackoverflow.com/) and one of the following tags:\r\n\r\n* [python-polars](https://stackoverflow.com/questions/tagged/python-polars)\r\n* [rust-polars](https://stackoverflow.com/questions/tagged/rust-polars)\r\n* [nodejs-polars](https://stackoverflow.com/questions/tagged/nodejs-polars)\r\n\r\nThis allows us to create high quality answers that remain updated and will save us from\r\nanswering the same questions over and over again.\r\n\r\nIf a question is not yet on stackoverflow, please create a new question and post the link here, so we are noted.\r\n\r\n#### Other\r\n\r\nIf your question doesn't fit stackoverflow, feel fry to ask here. :)",
  "Issue title: Bulk API with conflicting fields creates randomly different mapping\n Issue body: **Elasticsearch version** (`bin/elasticsearch --version`): 6.4.0\r\n\r\n**Steps to reproduce**:\r\n\r\nThe following snippet from the console randomly either indexes both documents or correctly throws an error due to the mapping. The `bar` field contains a string in one document and a number in another, and it seems as if the order of indexing gets changed due to the fact which shard indexes first using dynamic mapping and thus decides about the mapping.\r\n\r\nAn index template or preexisting mapping can properly solve this of course - calling the same endpoint with the same data and getting different results can be confusing for the user though.\r\n\r\n```\r\nDELETE foo\r\n\r\nPUT foo/doc/_bulk\r\n{ \"index\" : { \"_id\" : \"2\" } }\r\n{ \"foo\" : \"spam\", \"bar\" : 123 }\r\n{ \"index\" : { \"_id\" : \"3\" } }\r\n{ \"foo\" : \"bar\", \"bar\" : \"foo\" }\r\n```\r\n\r\nThe first case is this response, where the field gets indexed as a long\r\n\r\n```\r\n# DELETE foo\r\n{\r\n  \"acknowledged\": true\r\n}\r\n\r\n# PUT foo/doc/_bulk\r\n#! Deprecation: the default number of shards will change from [5] to [1] in 7.0.0; if you wish to continue using the default of [5] shards, you must manage this on the create index request or with an index template\r\n{\r\n  \"took\": 526,\r\n  \"errors\": true,\r\n  \"items\": [\r\n    {\r\n      \"index\": {\r\n        \"_index\": \"foo\",\r\n        \"_type\": \"doc\",\r\n        \"_id\": \"2\",\r\n        \"_version\": 1,\r\n        \"result\": \"created\",\r\n        \"_shards\": {\r\n          \"total\": 2,\r\n          \"successful\": 1,\r\n          \"failed\": 0\r\n        },\r\n        \"_seq_no\": 0,\r\n        \"_primary_term\": 1,\r\n        \"status\": 201\r\n      }\r\n    },\r\n    {\r\n      \"index\": {\r\n        \"_index\": \"foo\",\r\n        \"_type\": \"doc\",\r\n        \"_id\": \"3\",\r\n        \"status\": 400,\r\n        \"error\": {\r\n          \"type\": \"mapper_parsing_exception\",\r\n          \"reason\": \"failed to parse [bar]\",\r\n          \"caused_by\": {\r\n            \"type\": \"illegal_argument_exception\",\r\n            \"reason\": \"\"\"For input string: \"foo\"\"\"\"\r\n          }\r\n        }\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nthe second case is that both documents are being indexed as string, which happens roghly 50% of the cases\r\n\r\n```\r\n# DELETE foo\r\n{\r\n  \"acknowledged\": true\r\n}\r\n\r\n# PUT foo/doc/_bulk\r\n#! Deprecation: the default number of shards will change from [5] to [1] in 7.0.0; if you wish to continue using the default of [5] shards, you must manage this on the create index request or with an index template\r\n{\r\n  \"took\": 508,\r\n  \"errors\": false,\r\n  \"items\": [\r\n    {\r\n      \"index\": {\r\n        \"_index\": \"foo\",\r\n        \"_type\": \"doc\",\r\n        \"_id\": \"2\",\r\n        \"_version\": 1,\r\n        \"result\": \"created\",\r\n        \"_shards\": {\r\n          \"total\": 2,\r\n          \"successful\": 1,\r\n          \"failed\": 0\r\n        },\r\n        \"_seq_no\": 0,\r\n        \"_primary_term\": 1,\r\n        \"status\": 201\r\n      }\r\n    },\r\n    {\r\n      \"index\": {\r\n        \"_index\": \"foo\",\r\n        \"_type\": \"doc\",\r\n        \"_id\": \"3\",\r\n        \"_version\": 1,\r\n        \"result\": \"created\",\r\n        \"_shards\": {\r\n          \"total\": 2,\r\n          \"successful\": 1,\r\n          \"failed\": 0\r\n        },\r\n        \"_seq_no\": 0,\r\n        \"_primary_term\": 1,\r\n        \"status\": 201\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nYou can verify the different mapping by checking the `bar` field in both cases\r\n\r\n```\r\nGET foo/doc/_mapping?filter_path=**.bar\r\n```\n Comments: \n Comment 0: This is expected? Each shard processes its share of the bulk request independently and the first one that introduces a mapping for `bar` wins.",
  "Issue title: State change in scripts\n Issue body: R_\\mathfrak{e} should work.\n Comments: \n Comment 0: Update, this is true for macro arguments as well.  For instance, the following fails to parse:\r\n`\\frac\\mathfrac{e}2` which should parse like `\\frac{\\mathfrac{e}}{2}`",
  "Issue title: Docksal update 1.79.4 causing different DB container names\n Issue body: <!--\r\nIf you are reporting a new issue, make sure that we do not have any duplicates\r\nalready open. You can ensure this by searching the issue list for this\r\nrepository. If there is a duplicate, please close your issue and add a comment\r\nto the existing issue instead.\r\n\r\n---------------------------------------------------\r\nBUG REPORT INFORMATION\r\n---------------------------------------------------\r\nUse the commands below to provide key information from your environment:\r\nYou do NOT have to include this information if this is a FEATURE REQUEST\r\n-->\r\n\r\n**Description**\r\n\r\nAfter doing a `fin update` to get 1.79.4, when doing a `fin start` in a project, our DB container seems to have a different name.  Previously it was `projectname_db_1` and now it is `abe69dd6448e_projectname_db_1` (the \"abe69dd6448e\" is a different uuid for each project).\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n1. `fin stop`\r\n2. `fin update`\r\n3. `fin start`\r\n\r\n**Describe the results you received:**\r\n\r\nDB containers have a UUID added to them.  This causes the `fin db dump filename` command to error with: `Error: No such container: projectname_db_1`\r\n\r\n**Describe the results you expected:**\r\n\r\nI expected containers to retain their proper names.\r\n\r\n**Output of `fin config`:**\r\n\r\n<details>\r\n  <summary>fin config output</summary>\r\n\r\n```\r\n---------------------\r\nCOMPOSE_PROJECT_NAME_SAFE: projectname\r\nCOMPOSE_FILE:\r\n/Users/michaelpotter/.docksal/stacks/overrides-osxfs.yml\r\n/Users/michaelpotter/.docksal/stacks/volumes-bind.yml\r\n/Users/michaelpotter/.docksal/stacks/stack-default.yml\r\n/Users/michaelpotter/Projects/projectname/.docksal/docksal.yml\r\nENV_FILE:\r\n/Users/michaelpotter/Projects/projectname/.docksal/docksal.env\r\n\r\nPROJECT_ROOT: /Users/michaelpotter/Projects/projectname\r\nDOCROOT: build/html\r\nVIRTUAL_HOST: projectname.docksal\r\nVIRTUAL_HOST_ALIASES: *.projectname.docksal\r\nIP: 116.69.203.115\r\nMYSQL: 116.69.203.115:32817\r\n\r\nDocker Compose configuration\r\n---------------------\r\nservices:\r\n  cli:\r\n    dns:\r\n    - 116.69.203.115\r\n    - 116.69.203.115\r\n    environment:\r\n      BLACKFIRE_CLIENT_ID: null\r\n      BLACKFIRE_CLIENT_TOKEN: null\r\n      DOCKER_ENV: local\r\n      DOCROOT: build/html\r\n      HOST_GID: '20'\r\n      HOST_UID: '501'\r\n      PHP_IDE_CONFIG: serverName=projectname.docksal\r\n      SECRET_ACAPI_EMAIL: null\r\n      SECRET_ACAPI_KEY: null\r\n      SECRET_PLATFORMSH_CLI_TOKEN: null\r\n      SECRET_SSH_PRIVATE_KEY: null\r\n      SECRET_TERMINUS_TOKEN: null\r\n      VIRTUAL_HOST: projectname.docksal\r\n      XDEBUG_CONFIG: remote_connect_back=0 remote_host=116.69.203.115\r\n      XDEBUG_ENABLED: '1'\r\n    hostname: cli\r\n    image: docksal/cli:2.4-php7.2\r\n    ports:\r\n    - 3001:3001/tcp\r\n    - 3050:3050/tcp\r\n    volumes:\r\n    - docksal_ssh_agent:/.ssh-agent:ro\r\n    - cli_home:/home/docker:rw\r\n    - /Users/michaelpotter/Projects/projectname:/var/www:rw,cached\r\n  db:\r\n    dns:\r\n    - 116.69.203.115\r\n    - 116.69.203.115\r\n    environment:\r\n      MYSQL_ALLOW_EMPTY_PASSWORD: null\r\n      MYSQL_DATABASE: projectname_d8_drupal\r\n      MYSQL_INITDB_SKIP_TZINFO: null\r\n      MYSQL_ONETIME_PASSWORD: null\r\n      MYSQL_PASSWORD: user\r\n      MYSQL_RANDOM_ROOT_PASSWORD: null\r\n      MYSQL_ROOT_PASSWORD: root\r\n      MYSQL_USER: user\r\n    hostname: db\r\n    image: docksal/db:1.2-mysql-5.6\r\n    ports:\r\n    - 0:3306/tcp\r\n    volumes:\r\n    - db_data:/var/lib/mysql:rw\r\n    - project_root:/var/www:ro,nocopy\r\n  mail:\r\n    dns:\r\n    - 116.69.203.115\r\n    - 116.69.203.115\r\n    hostname: mail\r\n    image: mailhog/mailhog\r\n    labels:\r\n      io.docksal.cert-name: none\r\n      io.docksal.virtual-host: mail.projectname.docksal,mail.projectname.docksal.*\r\n      io.docksal.virtual-port: '8025'\r\n    volumes:\r\n    - project_root:/var/www:ro,nocopy\r\n  memcached:\r\n    command:\r\n    - -m\r\n    - '256'\r\n    dns:\r\n    - 116.69.203.115\r\n    - 116.69.203.115\r\n    hostname: memcached\r\n    image: memcached:1.4-alpine\r\n  solr:\r\n    build:\r\n      context: /Users/michaelpotter/Projects/projectname/env/solr/docker\r\n    hostname: solr\r\n    labels:\r\n      io.docksal.virtual-host: solr.projectname.docksal\r\n    ports:\r\n    - 8983:8983/tcp\r\n    volumes:\r\n    - /Users/michaelpotter/Projects/projectname/env/solr/cores/sitesearch:/opt/solr/server/solr/sitesearch:rw\r\n    - search-data:/var/lib/solr:rw\r\n  web:\r\n    depends_on:\r\n      cli:\r\n        condition: service_started\r\n    dns:\r\n    - 116.69.203.115\r\n    - 116.69.203.115\r\n    environment:\r\n      APACHE_BASIC_AUTH_PASS: null\r\n      APACHE_BASIC_AUTH_USER: null\r\n      APACHE_DOCUMENTROOT: /var/www/build/html\r\n      DOCKER_ENV: local\r\n    hostname: web\r\n    image: docksal/web:2.1-apache2.4\r\n    labels:\r\n      io.docksal.cert-name: none\r\n      io.docksal.permanent: \"false\"\r\n      io.docksal.project-root: /Users/michaelpotter/Projects/projectname\r\n      io.docksal.virtual-host: projectname.docksal,*.projectname.docksal,projectname.docksal.*\r\n    volumes:\r\n    - project_root:/var/www:ro,nocopy\r\nversion: '2.1'\r\nvolumes:\r\n  cli_home: {}\r\n  db_data: {}\r\n  docksal_ssh_agent:\r\n    external: true\r\n    name: docksal_ssh_agent\r\n  project_root:\r\n    driver: local\r\n    driver_opts:\r\n      device: /Users/michaelpotter/Projects/projectname\r\n      o: bind\r\n      type: none\r\n  search-data: {}\r\n\r\n---------------------\r\n```\r\n\r\n</details>\r\n\r\n<br>\r\n\r\n**Output of `fin sysinfo`:**\r\n\r\n<details>\r\n  <summary>fin sysinfo output</summary>\r\n\r\n  ```\r\n \u2588\u2588\u2588  OS\r\nDarwin Mac OS X 10.14.1\r\nDarwin Michaels-MacBook-Pro.local 18.2.0 Darwin Kernel Version 18.2.0: Fri Oct  5 19:41:49 PDT 2018; root:xnu-4903.221.2~2/RELEASE_X86_64 x86_64\r\n\r\n\u2588\u2588\u2588  ENVIRONMENT\r\nMODE : Docker for Mac\r\n\r\n\u2588\u2588\u2588  FIN\r\nfin version: 1.79.4\r\n\r\n\u2588\u2588\u2588  DOCKER COMPOSE\r\nEXPECTED VERSION: 1.22.0\r",
  "Issue title: \u5f00\u542fadb\u65f6\u7684\u5f39\u7a97\n Issue body: 1)\u5982\u679c\u6ca1\u5148\u5f00\u8c03\u8bd5\u94fe\u63a5USB\uff0c\u5f00\u53d1\u8005\u9009\u9879\u5c31\u53d8\u590d\u5236\u6307\u4ee4\u4e86\uff0c\u5e94\u8be5\u7b49\u5f00\u4e86\u8c03\u8bd5\u518d\u53d8\u3002\u867d\u7136\u6709\u63d0\u793a\u4f46\u8003\u8651\u6709\u65f6\u7528\u6237\u4e60\u60ef\u5148\u94fe\u63a5USB\uff0c\u800c\u4e14\u6709\u65f6\u8c03\u8bd5\u8981\u901a\u8fc7\u5141\u8bb8\uff0c\u7b49\u8c03\u8bd5\u5141\u8bb8\u540e\u518d\u53d8\u66f4\u7b26\u5408\u5b9e\u9645\u60c5\u51b5\u3002\r\n\r\n2)\u8fd9\u91cc\u6ca1\u6cd5\u56de\u5230\u5411\u5bfc\uff0c\u5efa\u8bae\u52a0\u4e2a\u5411\u5bfc\u8ba9\u7528\u6237\u518d\u770b\u4e00\u4e0badb\u6307\u4ee4\u3002\n Comments: \n Comment 0: \u611f\u8c22\u5efa\u8bae\n Comment 1: \u611f\u8c22\u56de\u590d\n Comment 2: @liudongmiao \u67f3\u5927\u6211\u660e\u767d\u4f60\u5728#76\u8bf4\u7684\u76f4\u63a5\u9000\u51fa\u4e86\uff0c\u4f46\u4f60\u4e5f\u6ca1\u5fc5\u8981lock\u554a\uff0c\u6211\u53ea\u80fd\u5728\u8fd9\u91cc\u56de\u590d\u4e86\u3002\u4ece\u90a3\u4e2a\u5f39\u7a97\u8fdb\u5165\u5f00\u53d1\u8005\u8fd4\u56de\u9ed1\u57df\u76f4\u63a5\u9000\u51fa\u540e\uff0c\u80fd\u4e0d\u80fd\u8ba9\u9ed1\u57df\u663e\u793a\u5728\u6700\u8fd1\u4efb\u52a1\u4e2d\uff0c\u6211\u77e5\u9053\u9ed1\u57df\u9000\u51fa\u540e\u5c31\u6ca1\u4e86\uff0c\u4f46\u8d77\u7801\u5728\u8fd9\u79cd\u60c5\u51b5\u5e94\u8be5\u8ba9\u9ed1\u57df\u51fa\u73b0\u5728\u6700\u8fd1\u4efb\u52a1\uff0c\u8fd9\u6837\u5c31\u80fd\u591f\u5feb\u901f\u8fd4\u56de\u9ed1\u57df\uff0c\u8fde\u7eed\u4e24\u4e0b\u25a1\u4e5f\u80fd\u8fd4\u56de\uff0c\u8fd9\u6837\u5c31\u597d\u7528\u4e86\u3002\n Comment 3: \u660e\u767d\u4f60\u7684\u610f\u601d\u4e86\u3002",
  "Issue title: Refine plugin architecture\n Issue body: - Make Webapp and Crawler objects singletons\n  - Remove instantiation out of init.php and in beginning of tests\n  - Add instantiation to controller file\n- Convert webappPlugin->renderConfiguration method to new controller architecture\n\n Comments: \n Comment 0: First step:\nhttp://github.com/ginatrapani/thinktank/commit/5725535118d465c22b0dc0e1a5b96c66b8953cbe\n\nNext step: convert account page to new controller architecture, and suss out how the plugin will deal with that.\n\n Comment 1: Done:\nhttp://github.com/ginatrapani/thinktank/commit/93bad80a3e34302ced2ca34b1a39ab77043f3329\n",
  "Issue title: mouseover\n Issue body: The [`mouseover`](https://developer.mozilla.org/en-US/docs/Web/Events/mouseover) event is not part of the library. It'll be great if you added it.\n Comments: \n Comment 0: Are there any browsers that don't support this?\n Comment 1: Well I wasn't sure of that for a problem I was trying to fix. But thankfully it's all resolved now and wasn't anything to do with the `mouseover`. \r\n\r\nIt seems `mouseover` has strong browser support so feel free to leave this out. \n Comment 2: Available at https://caniuse.com/#feat=mdn-api_element_mouseover_event",
  "Issue title: 404 on ftpmirror.gnu.org installs\n Issue body: In trying to install wget and aspell I am getting 404 errors. It seems that ftpmirror.gnu.org is not resolving to a valid mirror url for my location (I'm in Canada). For instance my closest mirror is the CS Club in Waterloo, aspell is hosted there (I can browse to the file) but the url returned by gnu is: http://mirror.csclub.uwaterloo.ca/gnuaspell/aspell-116.69.203.115.tar.gz which is invalid. Should the mirror link be reverted back to the main GNU link (or at least have the option)?\n\n Comments: \n Comment 0: I am having similar problems today as well (though I'm in the US), specifically trying to install readline. The requested URL is:\n\n```\nError: Download failed: http://ftpmirror.gnu.org/readline/readline-6.2.tar.gz\n```\n\nWhen I enter this into the browser, I get a mirrored URL like:\n\n```\nhttp://mirror.anl.gov/pub/gnureadline/readline-6.2.tar.gz\n```\n\nIt looks like the GNU FTP mirror might not be adding a / correctly. When I manually change the URL to:\n\n```\nhttp://mirror.anl.gov/pub/gnu/readline/readline-6.2.tar.gz\n```\n\nThe file is found and downloads. \n\nIn the meantime, is there a way to manually download these.gz files and have brew install them?\n\n Comment 1: Mirrors added in 164c57f284aa254a96935bb75ca5f25cf4e50714, `brew update`.\n",
  "Issue title: Memory leaks\n Issue body: There are multiple memory leaks, which needs to be removed\n Comments: \n Comment 0: Yes, agree that we have some memory leaks. How did you find them? Unexpected crashes or were you using some tool like valgrind? Could you list the ones that you are aware of?\n Comment 1: The hardware the library is running on has very limited ram (2 megabytes). It was running out of memory very quickly. For the detection of leaks i used the gcc address sanitizer. I have already some fixes but i wanted to discuss one more aspect. The memory used for an inference can be freed while the inference is running, to reduce the memory foot print. Only the results of prior node is needed to calculate the actual node.\n Comment 2: Could you provide the commands you used for the gcc address sanitizer? In the future some kind of memory leak detection should be included in the GitHub Action CI.\r\n\r\nRegarding freeing memory from past nodes, I agree that there are some optimisations that can be made, but note that its not that straight forward. A model like mnist is a set of nodes connected in series to each other, so freeing the memory from the previous node output will work just fine, but there are more complex models that contain \"branches\" and \"Only the results of prior node is needed to calculate the actual node.\" won't be true.\r\n\r\nSo we would need some kind of algorithm that scans the model an decides which outputs can be freed, and which ones will be needed later on in a different node. Having a flag with this choice (free unused outputs vs keep them) would be a really nice future, but imho it needs a bit of thinking. Feel free to open a new issue with this feature request :)\n Comment 3: You can compile the software with the additional gcc flag `-fsanitize=address`. This will enable the address sanitizer, which detect out-of-bounds and use-after-free bugs and memory leaks.",
  "Issue title: Azure File Copy: System.Management.Automation.ParameterBindingValidationException: Cannot bind argument to parameter'storageKey' because it is an empty string.\n Issue body: TFS 2013 U 3\r\n\r\nWas working in Update 2.\r\n\r\nI'm trying to copy files up to a VM during my deployment I've not changed or modified the task since it worked in Update 2.\r\n\r\nDetail from Logs below. I have tested the storage account name and the keys from the log and they work fine.\r\n```\r\n2016-06-28T02:57:34.9320997Z ##[debug]============================ HTTP RESPONSE ============================\r\n2016-06-28T02:57:34.9320997Z Status Code:\r\n2016-06-28T02:57:34.9320997Z OK\r\n2016-06-28T02:57:34.9320997Z Headers:\r\n2016-06-28T02:57:34.9320997Z Pragma                        : no-cache\r\n2016-06-28T02:57:34.9320997Z x-ms-request-id               : cda6a734-5bad-49a6-9119-a12357fcc2ee\r\n2016-06-28T02:57:34.9320997Z Cache-Control                 : no-cache\r\n2016-06-28T02:57:34.9320997Z Server                        : Microsoft-Azure-Storage-Resource-Provider/1.0,Microsoft-HTTPAPI/2.0\r\n2016-06-28T02:57:34.9320997Z x-ms-ratelimit-remaining-subscription-writes: 1197\r\n2016-06-28T02:57:34.9320997Z x-ms-correlation-request-id   : cda6a734-5bad-49a6-9119-a12357fcc2ee\r\n2016-06-28T02:57:34.9320997Z x-ms-routing-request-id       : AUSTRALIAEAST:20160628T025734Z:cda6a734-5bad-49a6-9119-a12357fcc2ee\r\n2016-06-28T02:57:34.9320997Z Strict-Transport-Security     : max-age=31536000; includeSubDomains\r\n2016-06-28T02:57:34.9320997Z Date                          : Tue, 28 Jun 2016 02:57:33 GMT\r\n2016-06-28T02:57:34.9320997Z Connection                    : close\r\n2016-06-28T02:57:34.9477003Z Body:\r\n2016-06-28T02:57:34.9477003Z {\r\n2016-06-28T02:57:34.9477003Z   \"keys\": [\r\n2016-06-28T02:57:34.9477003Z     {\r\n2016-06-28T02:57:34.9477003Z       \"keyName\": \"key1\",\r\n2016-06-28T02:57:34.9477003Z       \"permissions\": \"Full\",\r\n2016-06-28T02:57:34.9477003Z       \"value\": \"ThisWasAValidKey1==\"\r\n2016-06-28T02:57:34.9477003Z     },\r\n2016-06-28T02:57:34.9477003Z     {\r\n2016-06-28T02:57:34.9477003Z       \"keyName\": \"key2\",\r\n2016-06-28T02:57:34.9477003Z       \"permissions\": \"Full\",\r\n2016-06-28T02:57:34.9477003Z       \"value\": \"ThisWasAValidKey2==\"\r\n2016-06-28T02:57:34.9477003Z     }\r\n2016-06-28T02:57:34.9477003Z   ]\r\n2016-06-28T02:57:34.9477003Z }\r\n2016-06-28T02:57:34.9477003Z ##[debug]AzureQoSEvent: CommandName - Get-AzureRmStorageAccountKey; IsSuccess - True; Duration - 00:00:00.6117927; Exception - ;\r\n2016-06-28T02:57:35.7589315Z ##[debug]Finish sending metric.\r\n2016-06-28T02:57:35.7589315Z ##[debug]12:57:35 PM - GetAzureStorageAccountKeyCommand end processing.\r\n2016-06-28T02:57:35.7589315Z ##[debug]12:57:35 PM - GetAzureStorageAccountKeyCommand end processing.\r\n2016-06-28T02:57:35.7745321Z ##[debug][Azure Call]Retrieved storage key successfully for the storage account: projectnamedevzxqun5wz in resource group: projectnameDev\r\n2016-06-28T02:57:35.8369345Z ##[error]System.Management.Automation.ParameterBindingValidationException: Cannot bind argument to parameter'storageKey' because it is an empty string.\r\n2016-06-28T02:57:35.8369345Z ##[error]   at System.Management.Automation.ExceptionHandlingOps.CheckActionPreference(FunctionContext funcContext, Exception exception)\r\n2016-06-28T02:57:35.8369345Z ##[error]   at System.Management.Automation.Interpreter.ActionCallInstruction`2.Run(InterpretedFrame frame)\r\n2016-06-28T02:57:35.8369345Z ##[error]   at System.Management.Automation.Interpreter.EnterTryCatchFinallyInstruction.Run(InterpretedFrame frame)\r\n2016-06-28T02:57:35.8369345Z ##[error]   at System.Management.Automation.Interpreter.EnterTryCatchFinallyInstruction.Run(InterpretedFrame frame)\r\n2016-06-28T02:57:35.8369345Z ##[error]   at System.Management.Automation.Interpreter.Interpreter.Run(InterpretedFrame frame)\r\n2016-06-28T02:57:35.8369345Z ##[error]   at System.Management.Automation.Interpreter.LightLambda.RunVoid1[T0](T0 arg0)\r\n2016-06-28T02:57:35.8369345Z ##[error]   at System.Management.Automation.PSScriptCmdlet.RunClause(Action`1 clause, Object dollarUnderbar, Object inputToProcess)\r\n2016-06-28T02:57:35.8369345Z ##[error]   at System.Management.Automation.PSScriptCmdlet.DoEndProcessing()\r\n2016-06-28T02:57:35.8369345Z ##[error]   at System.Management.Automation.CommandProcessorBase.Complete()\r\n```\n Comments: \n Comment 0: I think this is issue #1660, i've worked around by editing the.ps1 file in the task on the build agent.\n Comment 1: This fix also worked for me but my ps1 file was located in tasks\\AzureFileCopy\\1.0.62 (more recent version I presume)\r\n\r\nCan someone tell me how tasks present on the agent folder are updated and when? I don't see them in the.zip agent that is downloaded from VSTS.",
  "Issue title: ng-cordova.js + ng-cordova.min.js defined at the same time\n Issue body: In your bower.json (0.1.4-alpha) you define both \"./dist/ng-cordova.js\" and \"./dist/ng-cordova.min.js\".\nDue this the grunt-wiredep Grunt plugin add both as dependency to my index.html\n\n```\n<script src=\"bower_components/ngCordova/dist/ng-cordova.js\"></script>\n<script src=\"bower_components/ngCordova/dist/ng-cordova.min.js\"></script>\n```\n\nSo my app has two times ng-cordova in it.\n\n Comments: \n Comment 0: @ScreenDriver I see what you mean, but I'm not totally sure we can do this. If I understand bower `main`, we should allow the user to choose between the `.min` and `.js` files depending on development / debugging and production use. I'll look into this more, since Bower docs are a bit fuzzy here.\n\nIf you could point me out to a good explanation of the `main` part of bower, it would help make this decision a lot easier\n\n Comment 1: Unfortunately I am very unexperienced with bower at the moment :confused:\n\n Comment 2: Had same issue with both files being added from grunt task.\nIn the bower.json spec, it says the following about `main`:\n\n\"Do not include minified files.\"\n\nhttps://github.com/bower/bower.json-spec#main\n\n Comment 3: @rastographics perfect, that's exactly what I needed to determine this issue.\n",
  "Issue title: Krolan is present on the map after you kill him\n Issue body: Go to Krolan map, kill him, do not open chest, leave map and go back. He is present again. Don't know maybe he is not spawned when you open the chest, but he should not be spawned at all after you kill him.\n Comments: \n Comment 0: All bosses/mini-bosses respawn intentionally. Each one has a piece of unique gear with a low drop rate, so the player can fight them multiple times to obtain those items.",
  "Issue title: 'ng-click-active' remains stuck\n Issue body: This is hard to track and thus hard to fix as it doesn't happen every time, but can be definitely reproduced on desktop Chrome and mobile browsers (Chrome, Safari, Android browser).\r\n\r\n- When element with ng-click defined and '.ng-click-active' style defined in CSS is clicked on, it gets class 'ng-click-active' as long as element is in pressed/touched state\r\n- Once click/touch has finished, 'ng-click-active' class should be removed from the element.\r\n\r\nHowever, this is sometimes not the case and element remains in 'clicked' state with class still on long after click had finished.\r\nUnfortunately it's not easy to reproduce this as it doesn't happen every time, but it's pretty annoying.\n Comments: \n Comment 0: Can you please post a plnkr.co etc? Even if it doesn't happen all the time, there must be some circumstances that make it more probable to happen.\n Comment 1: http://plnkr.co/edit/B6ciPQuyO4yYTCAVKOXv\r\n\r\nHere it is, but I can't reproduce it on such a small scale. It could be related maybe to sliding 3D animations on switching between menu pages. I will try to enrich it with animations to get closer to what we have in our app. Otherwise I can only send you link where to see it live (thou obfuscated, so no debugging would be possible).\n Comment 2: Definitely reproducible when there is an element replacing/overlaying touched element. Except touch events there are mouse events triggered as well. Observer order of events is deterministic and always in this order: touchstart, touchend, (mousemove), mousedown, mouseup. So in normal scenario ng-click-active class is added/removed/(removed)/added/removed. Source element for those events is for all touchstart, touchend, (mousemove), mousedown always touched element. For mouseup however sometimes happens that event source element is not touched element, but some element from overlaying layer. Hence the ng-click-active class is not properly removed.\n",
  "Issue title: jxl Content-Encoding\n Issue body: Saluton TAG!\r\n\r\nI'm requesting a TAG review of \"jxl Content-Encoding\".\r\n\r\nOne of the features of JPEG XL is byte-wise lossless JPEG image repacking. On average, an encoded image is 22% smaller. We propose it as a new HTTP \"Content-Encoding\".\r\n\r\n  - Explainer: https://github.com/google/brunsli/blob/master/explainer.md\r\n  - Specification URL: https://arxiv.org/pdf/1908.03565.pdf\r\n  - Tests: N/A, fetch API forbids altering \"Accept-Encoding\" header\r\n  - Security and Privacy self-review: https://github.com/google/brunsli/blob/master/security-privacy-questionnaire.md\r\n  - GitHub repo: https://github.com/google/brunsli\r\n  - Primary contacts:\r\n      - Eugene Kliuchnikov (eustas), Google\r\n  - Organization(s)/project(s) driving the specification: Google, JPEG XL\r\n  - Key pieces of existing multi-stakeholder review or discussion of this specification: -\r\n  - External status/issue trackers for this specification: https://www.chromestatus.com/feature/5678152091172864\r\n\r\nFurther details:\r\n\r\n  - [x] I have reviewed the TAG's [API Design Principles](https://w3ctag.github.io/design-principles/)\r\n  - Relevant time constraints or deadlines: 2020Q3\r\n  - The group where the work on this specification is currently being done:?\r\n  - The group where standardization of this work is intended to be done:?\r\n  - Major unresolved issues with or opposition to this specification: none\r\n  - This work is being funded by:?\r\n\r\nWe'd prefer the TAG provide feedback as:\r\n  \ud83d\udc1b open issues in our GitHub repo for **each point of feedback**\r\n\n Comments: \n Comment 0: Is this not specific to JPEG despite the name? If it is specific to JPEG it seems a bit weird to use `Content-Encoding` for this.\n Comment 1: The format could be used for encoding any type of data. So it fits the definition of HTTP Content-Encoding.\r\n It is unlikely that the compression ratio will surpass the compression ratio of gzip / brotli unless content is a JPEG file.\r\n\r\nThe volume of JPEGs traffic is bigger than total volume of HTML, CSS and JS traffic.\r\njxl Content-Encoding will cover the weaknesses of gzip and brotli for such kind of traffic.\n Comment 2: In the specification, I see this:\r\n`If the codestream starts with bytes {0xFF, 0xD8, 0xFF, 0xE0}, the decoder shall decode a JPEG1 as specified in ISO/IEC 10918-1:1993(E). Otherwise, if the codestream starts with bytes {0x0A, 0x04, 0x42, 0xD2, 0xD5, 0x4E}, the decoder shall reconstruct the original JPEG1 codestream as specified in Annex M. Otherwise, the codestream shall be structured as shown in Table 1; the syntax is described in Annex A.`\r\n\r\nSo it seems linked heavily to JPEG processing, at least for the `{0x0A, 0x04, 0x42, 0xD2, 0xD5, 0x4E}` case. \r\n\r\nIs there a way to recognise the generic encoding, if this applies to other formats, or just the signature above is used and only for JPEG? \r\nIf it is only for JPEG, then a new media type would be easier to deploy than going through the [IETF Review](https://tools.ietf.org/html/rfc5226#section-4.1) which is needed to update https://www.iana.org/assignments/http-parameters/http-parameters.xhtml, although the Content coding option is not wrong.\r\n\r\n@annevk mime sniff applies only after Content-Encoding is processed, so it shouldn't be an issue if the content coding option is used (ie: no need to add a new signature for a repacking of jpeg)\n Comment 3: It is proposed only to process `{0x0A, 0x04, 0x42, 0xD2, 0xD5, 0x4E}` case as Content-Encoding.\r\nSo, you are correct: only JPEG1 streams could be expressed in compressed form; arbitrary data could be \"framed\" (see `M.5.1`) as well.\r\n\r\n`image/jxl` is already registered as provisional standard media type (see https://www.iana.org/assignments/provisional-standard-media-types/provisional-standard-media-types.txt). This media type corresponds to fully-fledged JPEG XL encoding.\r\n\r\nPerhaps explainer lacks the motivation, why we want to add the lossless past of JPEG XL as Content-Encoding.\r\nGoing to update  explainer with the following information soon:\r\n\r\n```\r\nPros\r\n + faster JPEG rendering of cached content: JPEG uses less CPU compared to modern image formats\r\n + compatibility: there are a lot of expensive cameras / smartphones that produce JPEGs; it will take at least 10 years to transition to the new format\r\n + seamless experience: when user saves the image (JPEG) it is guaranteed to be supported by existing software\r\n + lower deployment risks: Content-Encoding story is similar to Brotli, so it would not cause new risks\r\n + risk-free serving: no re-review is required for transcoded images, as those are guaranteed to be exactly the same\r\n + easier for webmasters: no image optimization stack is involved; nginx / Apache plugins will support the new encoding with the zero effort\r\n + exactly same pixels for legacy clients and new clients (both are decoding the same jpeg)\r\n + same behaviour: same progression\r\n\r\nContras\r\n - systems for image optimization / re-coding already exist (cloudinary, cloudflare, akamai, etc.): adding a new image format looks easier for those than adding new Content-Encoding\r\n - adding \"save-as\" in browsers would solve the \"seamless experience\" point (however it would unexpectedly for users loose transparency / animation / etc. features)\r\n```\r\n\r\n\n Comment 4: Note that `Content-Encoding` is a property of the payload, so saving-as will save the `jxl` version, as opposed to `Transfer-Encoding` which has the drawback of being hop-by-hop. So you will probably need a specific'save-as after resolving content-encoding' while brunsli is available everywhere.\r\n\r\nAlso conneg done via plugins like that are often either not really doing a proper job, as they don't have access to all the axis available for content negotiation, so listing those plugins as \"pros\" is debatable.\r\n\r\nThe real \"pro\" is that the jpeg/jxl/jpeg conversion is lossless, and that is only what matters when asking for a new content coding, even if it is not generic but tight to a specific media type (there are some examples in the [IANA listing of content codings](https://www.iana.org/assignments/http-parameters/http-parameters.xhtml))\n Comment 5: Looked at this in our VF2F with @rossen and @LeaVerou, we're concerned that while this is perfectly valid, it seems to be adding a lot of complexity relative to the value. The same end goal could be achieved by the server having both jpeg and jxl versions of the file on the server and using content negotiation, rather than encoding negotiation. Doing so prevents the server from having to constantly re-encode the source file and spending CPU cycles and energy.\n Comment 6: > Note that `Content-Encoding` is a property of the payload, so saving-as will save the `jxl` version\r\n\r\n'Content-Encoding' is a property of _network_ payload. Most browsers decode the network payload first and then provide it to users. Example: load a text file with `Content-Encoding: br` (or `gzip`). \"Save\" will save plain text...\r\nWith jxl Content-Encoding the output is a normal JPEG file, so users don't have to have support of new format to use the saved images.\n Comment 7: @plinss The benefit of jxl Content-Encoding is that users will be able to \"save\" images right away and those will be normal JPEGs, not jxl. Also with \"Content-Encoding\" we make a promise that users will be receiving the _same_ content without any possible conversion loss.\n Comment 8: Thanks for the responses. @ylafon and I took a look a this in today's breakout session and we don't see any issues with this proceeding. We think it's to be seen how much this gets taken up in the wild vs just switching to jxl content types. At some point this may be a target for deprecation if usage numbers are low, but given the amount of jpeg usage this may have some demonstrable short-term benefits.",
  "Issue title: Wrong exit code in install.sh \n Issue body: New installations of YouCompleteMe will fail, if the exit code of install.sh is checked.\n\nSee: https://github.com/Valloric/YouCompleteMe/commit/6572635c67df24d8f4955d10ffe9bdede2f84bc1\n\n Comments: \n Comment 0: Fixed by 6b7e7361571bf6b54dc78c46fe76849c64bb59d5\n",
  "Issue title: Pub on Windows fails with TLS error\n Issue body: From https://ci.appveyor.com/project/flutter/flutter/build/1.0.9587 which keeps going on indefinitely\r\n\r\n```\r\nBuild started\r\ngit clone -q https://github.com/flutter/flutter.git C:\\projects\\flutter\r\ngit fetch -q origin +refs/pull/14610/merge:\r\ngit checkout -qf FETCH_HEAD\r\nRestoring build cache\r\nCache 'C:\\Users\\appveyor\\AppData\\Roaming\\Pub\\Cache' - Restored\r\nRunning Install scripts\r\ncd..\r\nmove flutter \"flutter sdk\"\r\n        1 dir(s) moved.\r\ncd \"flutter sdk\"\r\nbin\\flutter.bat config --no-analytics\r\nChecking Dart SDK version...\r\nDownloading Dart SDK from Flutter engine f5a4a9378740c3d5996583a9ed1f7e28ff08ee85...\r\nUnzipping Dart SDK...\r\nUpdating flutter tool...\r\nGot TLS error trying to find package archive at https://pub.dartlang.org.\r\nError: Unable to 'pub upgrade' flutter tool. Retrying in five seconds...\r\nWaiting for 5 seconds, press CTRL+C to quit...\b4\b3\b2\b1\b0\r\nGot TLS error trying to find package archive at https://pub.dartlang.org.\r\nError: Unable to 'pub upgrade' flutter tool. Retrying in five seconds...\r\nWaiting for 5 seconds, press CTRL+C to quit...\b4\b3\b2\b1\b0\r\nGot TLS error trying to find package archive at https://pub.dartlang.org.\r\nError: Unable to 'pub upgrade' flutter tool. Retrying in five seconds...\r\nWaiting for 5 seconds, press CTRL+C to quit...\b4\b3\b2\b1\b0\r\nGot TLS error trying to find package archive at https://pub.dartlang.org.\r\nError: Unable to 'pub upgrade' flutter tool. Retrying in five seconds...\r\nWaiting for 5 seconds, press CTRL+C to quit...\b4\b3\b2\b1\b0\r\nGot TLS error trying to find package archive at https://pub.dartlang.org.\r\nError: Unable to 'pub upgrade' flutter tool. Retrying in five seconds...\r\n...\r\n```\n Comments: \n Comment 0: Pub just uses `dart:io`'s HTTP implementation. Any protocol errors either come from there or from https://github.com/dart-lang/pub-dartlang-dart.\n Comment 1: Here is more output from actual dev windows box:\r\n```\r\nC:\\src\\flutter\\flutter\\packages\\flutter_tools [use-host-dart-sdk \u2261 +4 ~1 -0!]> C:\\src\\flutter\\flutter\\bin\\cache\\dart-sdk\\bin\\pub.bat upgrade --verbosity=all --no\r\n-packages-dir\r\nFINE: Pub 2.0.0-edge.28757928b47b192efcec082c78258102beb03f78\r\nIO  : Spawning \"cmd /c ver\" in C:\\src\\flutter\\flutter\\packages\\flutter_tools\\.\r\nIO  : Finished ver. Exit code 0.\r\n    | stdout:\r\n    | |\r\n    | | Microsoft Windows [Version 10.0.14393]\r\n    | Nothing output on stderr.\r\nMSG : Resolving dependencies...\r\nSLVR: Solving dependencies:\r\n    | - coverage 0.10.0 from hosted (coverage)\r\n    | - test 0.12.30+3 from hosted (test)\r\n    | - file 2.3.6 from hosted (file)\r\n    | - mustache 1.0.0 from hosted (mustache)\r\n    | - meta 1.1.2 from hosted (meta)\r\n    | - web_socket_channel 1.0.7 from hosted (web_socket_channel)\r\n    | - http 0.11.3+16 from hosted (http)\r\n    | - xml 2.6.0 from hosted (xml)\r\n    | - json_rpc_2 2.0.7 from hosted (json_rpc_2)\r\n    | - stream_channel 1.6.3 from hosted (stream_channel)\r\n    | - process 2.0.7 from hosted (process)\r\n    | - vm_service_client 0.2.4+1 from hosted (vm_service_client)\r\n    | - front_end any from hosted (front_end)\r\n    | - linter 0.1.43 from hosted (linter)\r\n    | - quiver 0.28.0 from hosted (quiver)\r\n    | - args 1.3.0 from hosted (args)\r\n    | - package_config 1.0.3 from hosted (package_config)\r\n    | - crypto 2.0.2+1 from hosted (crypto)\r\n    | - platform 2.1.2 from hosted (platform)\r\n    | - plugin 0.2.0+2 from hosted (plugin)\r\n    | - stack_trace 1.9.1 from hosted (stack_trace)\r\n    | - usage 3.3.0 from hosted (usage)\r\n    | - intl 0.15.2 from hosted (intl)\r\n    | - archive 1.0.33 from hosted (archive)\r\n    | - cli_util 0.1.2+1 from hosted (cli_util)\r\n    | - json_schema 1.0.8 from hosted (json_schema)\r\n    | - yaml 2.1.13 from hosted (yaml)\r\n    | - analyzer any from hosted (analyzer)\r\nIO  : Get versions from https://pub.dartlang.org/api/packages/coverage.\r\nIO  : HTTP GET https://pub.dartlang.org/api/packages/coverage\r\n    | Accept: application/vnd.pub.v2+json\r\n    | X-Pub-OS: windows\r\n    | X-Pub-Command: upgrade\r\n    | X-Pub-Session-ID: 1AA465EA-FD18-4E59-AED7-AA340932B152\r\n    | X-Pub-Reason: direct\r\n    | user-agent: Dart pub 2.0.0-edge.28757928b47b192efcec082c78258102beb03f78\r\nSLVR: Could not get versions for coverage from hosted:\r\n    | Got TLS error trying to find package coverage at https://pub.dartlang.org.\r\n    |\r\n    | package:pub/src/utils.dart 733                            fail\r\n    | package:pub/src/source/hosted.dart 335                    BoundHostedSource._throwFriendlyError\r\n    | package:pub/src/source/hosted.dart 141                    BoundHostedSource.doGetVersions\r\n    | ===== asynchronous gap ===========================\r\n    | dart:async                                                _Completer.completeError\r\n    | package:pub/src/source/hosted.dart                        BoundHostedSource.doGetVersions\r\n    | ===== asynchronous gap ===========================\r\n    | dart:async                                                _asyncErrorWrapperHelper\r\n    | package:pub/src/source/hosted.dart 130                    BoundHostedSource.doGetVersions\r\n    | package:pub/src/source.dart 169                           BoundSource.getVersions\r\n    | package:pub/src/solver/version_solver.dart 237            SolverCache.getVersions.<fn>\r\n    | dart:async                                                runZoned\r\n    | package:pub/src/http.dart 267                             withDependencyType\r\n    | package:pub/src/solver/version_solver.dart 236            SolverCache.getVersions\r\n    | ===== asynchronous gap ===========================\r\n    | dart:async                                                new Future.microtask\r\n    | package:pub/src/solver/version_solver.dart 210            SolverCache.getVersions\r\n    | package:pub/src/solver/unselected_package_queue.dart 121  UnselectedPackageQueue._getNumVersions\r\n    | ===== asynchronous gap ===========================\r\n    | dart:async                                                new Future.microtask\r\n    | package:pub/src/solver/unselected_package_queue.dart 115  UnselectedPackageQueue._getNumVersions\r\n    | package:pub/src/solver/unselected_package_queue.dart 50   UnselectedPackageQueue.add\r\n    | ===== asynchronous gap ===========================\r\n    | dart:async                                                new Future.microtask\r\n    | package:pub/src/solver/unselected_package_queue.dart 44   UnselectedPackageQueue.add\r\n    | package:pub/src/solver/version_selection.dart 88          Version",
  "Issue title: Water Heater component does not support target_temperature_step\n Issue body: ## Context\r\n\r\nI am working on integration ( https://github.com/chomupashchuk/ariston-remotethermo-home-assistant ) which includes water_heater. Ariston supports steps of \"0.5\" for climate but \"1.0\" for water_heater. There is no attribute for water_heater to indicate temperature step and by default it is \"0.5\", which means in my case i need to make 2 clicks every time to change temperature by 1 degree (please see how entity looks https://i.postimg.cc/qqh7Mxk6/Capture.png).\r\nI was referred from https://github.com/home-assistant/core/issues/32356\r\n\r\n## Proposal\r\n\r\nSupport property target_temperature_step within water_heater\r\n\r\n## Consequences\r\n\r\nLess annoying change of temperature for water heater and rounding or truncating values in the code.\r\n\n Comments: \n Comment 0: It's possible now.\r\n\r\nDo:\r\n```\r\n@property\r\n    def device_state_attributes(self):\r\n        \"\"\"Return the optional device state attributes.\"\"\"\r\n        data = {\"target_temp_step\": 1}\r\n        return data\r\n```\r\n\r\nCheck it out here: https://github.com/pszafer/home-assistant-bosch-custom-component/blob/cf75aa304b02239d67455a2286de8185a121d47b/custom_components/bosch/water_heater.py#L147\n Comment 1: Thanks, such setting of property worked",
  "Issue title: Please consider fixing ViewPort module.\n Issue body: Right now its behavior is not quite accustomed for many users. In particular, zooming is happening at the center of view, rather than under the mouse and dragging process is canceled when the mouse leaves the view area.\n Comments: \n Comment 0: When I was playing with javascript and modules I was trying to create zoom and was having the same problem, I managed to fix it by doing this. https://github.com/MultiStruct/Zoom/blob/master/src/main/resources/view/modules/ViewModule.js#L10\r\nThis is no zoom module by any means, but it zooms to where your cursor is.\n Comment 1: I did not see any issue when using the viewport module myself.\r\n\r\nhttps://user-images.githubusercontent.com/31545590/190669296-1b9671ca-d082-4ad7-91a1-fabd4a9088f2.mp4\r\n\r\n\n Comment 2: The dragging outside the view area problem: could not find a fix.",
  "Issue title: [Epic] Frontend Refactor (Channels)\n Issue body: This is a WIP epic - I'm still working out the steps needed to get from A-B and I'll break it down into sub tasks/sub issues as and when, in the meantime, the goal is clear and documented here.\r\n\r\n---\r\n\r\nThe frontend of Ghost - that is the server side code which renders a blog using the active theme - has been somewhat unloved for a little while now. It essentially consists of some hard coded routes in `/routes/frontend.js`, which in turn call the monolithic functions in `/controllers/frontend.js`. It's time for this part of Ghost to be refactored into something more elegant, and importantly, something more extensible.\r\n\r\nOn the [wiki](https://github.com/TryGhost/Ghost/wiki/Channels-101) you'll find a new document, titled [Channels 101](https://github.com/TryGhost/Ghost/wiki/Channels-101), which introduces and explains the concept of Channels for the frontend. In short channels are the abstracted concept of a list of posts, i.e. the homepage, the tag archive, the author archive or any other group of posts you could conceive of.\r\n\r\nAnd the very end of the document it talks about working to slowly remove hardcoded bits of the fontend and refactor it into configuration & generation code, before finally moving towards making channels a model & API endpoint just like Posts, Tags and Users.\r\n\r\nThis issue is the 'epic' where we'll keep track of our progress towards achieving this New World Order.\r\n- [x] Refactor out the hardcoded slug keywords #4519\r\n- [x] Convert sitemaps & rpc pings to use events #5069 \r\n- [x] Move RSS from frontend controller & refactor to use events\r\n- [x] Move post-processing of author data out of the frontend controller #5159  \r\n- [x] Refactor frontend controller #5192\r\n\r\nNeed to solve:\r\n- [x] Dynamic routing for channels\r\n- [x] Pagination when in channel\r\n- [ ] meta data for channels\r\n- [ ] sitemap for channels\r\n- [ ] Improve the channels API\r\n\r\nMaybe later:\r\n- [ ] ~~add a channel registration mechanism that works whilst Ghost is running~~\r\n- [ ] ~~Support offset, rather than page, in the API #2896~~\r\n- [ ] RSS feeds for each channel linked in that channel\r\n- [ ] Post urls & next/prev post when in channel\r\n\r\n-----\r\n\r\n## Updates: Aug 2017\r\n\r\nThe current state of channels is that it the functionality is largely refactored and in place, but can only be accessed by modifying the core file `channels-config.js`. This is because, although the basics are working, advanced behaviour of Ghost isn't yet properly linked to channels.\r\n\r\nExamples of missing pieces (some listed above) are:\r\n- Sitemaps\r\n- Meta data\r\n- RSS feed (URLs only)\r\n- Next/prev post when in a channel\r\n- Deep customisation, e.g. disabling RSS feeds\r\n\r\nThere is also some pure-refactoring that needs to be done:\r\nE.g. \r\n- moving channels to a proper home\r\n- moving non-channel pieces from controllers/frontend.js to a proper home\r\n- strengthening the implementation to make channels more of a first class object\r\n- better/clearer default configuration\r\n- proper use of express\r\n- exposing channels without core modification\r\n\r\nBasically, we need to iron out a few more of the major pieces, and then expose this config. Short term, we're going to start publishing blog posts on how to use the functionality that is there by hacking core.\r\n\r\n\r\n\r\n\n Comments: \n Comment 0: ^ As you can see from the long list of linked commits. I continue to make slow but steady progress on moving this towards reality. \n\nI have many of the pieces for channels in place, and a PR almost ready to land for dynamic routing\n\nThe splitting out of structured data is a project that could be worked on separately, so I've raised an issue for it #6186\n\nI also need to start playing with how to move the whole of the frontend (inc single posts) to be config driven and auto-generated in the same way, such that effectively, a 'context' is a thing from which we can determine what to do in all sorts of circumstances like meta title, body  classes, view, etc. So far I've kept the concept of'single' and 'channel' separate, and it's working OK, not sure if that's going to last.\n\n Comment 1: As I can't comment on the wiki page (https://github.com/TryGhost/Ghost/wiki/Channels-101), I'll make my comment here.\r\n\r\nI feel Channels are a real benefit for most people who don't need a 'blog' (per say). For those folks, regular content generation is not part of their strategy. Basically, viewing posts by default makes them uncomfortable as they don't post regularly. I think most people still want a nice website where they can manage their stuff from time to time over a blog. \r\n\r\nNow.\r\n\r\nI'd would love to be able to define my default page via the Channel I choose. Something like mysite.com/welcome or mysite.com/hey\r\n\r\nThis way, I can control better the user experience and point to the regular blog (The most obvious example of a channel in Ghost is the home page) view when needed. \r\n\r\nI feel the channel functionality could be under the navigation tab. From there we could choose:\r\n\r\n- blog view, newest first\r\n- blog view, oldest first\r\n- custom page: (URL FIELD)\r\n\r\nWould it be possible that when a user enters mysite.com in it's browser, the ghost engine open the page mysite.com/hey with the custom channel? Now, this might brings the issue regarding the URL of the default blog view.\r\n\r\nHow do you see this @ErisDS?\r\n \n Comment 2: I need this feature for production, so I hacked the core to expose the channels API to the config file. Probably not the best way to implement it, but here it is: phaseOne/Ghost@eb2543e370db47bf0791341f2c09817dc207d496\n\nOne would add something like this to their `config.js` file:\n\n```\nchannels: {\n  blog: {\n    name: 'blog',\n    route: '/blog/'\n  }\n}\n```\n\n Comment 3: I've updated the original issue with a bit of a status review. It's not very in depth just now, as I'm just warming up to working on this again.\r\n\r\nShort term, I have a couple of key goals for spikes & small changes:\r\n\r\n- [x] configurable rss/pagination: https://github.com/TryGhost/Ghost/pull/8857\r\n- [ ] blog post about how to use this to make a static homepage\r\n- [ ] prev/next inside of channels\r\n- [ ] theme helper improvements to go with this\r\n- [x] using res.locals to store channel config (likely needed for prev/next and meta data)\r\n- [ ] context load sitemap problem, to see if I can at least spec a solution\n Comment 4: How far off completion is this? I'd love to contribute but I'm no Node developer lol\n Comment 5: Closing in favour of #9601 ",
  "Issue title: \u30d7\u30ec\u30d3\u30e5\u30fc\u8868\u793a\u306b\u3066\u30b5\u30a4\u30c8\u30c8\u30c3\u30d7\u306e\u30ea\u30f3\u30af\u304c\u516c\u958b\u753b\u9762\u306b\u306a\u3063\u3066\u3057\u307e\u3046\n Issue body: \u30d7\u30ec\u30d3\u30e5\u30fc\u8868\u793a\u306e\u30b5\u30a4\u30c8\u30c8\u30c3\u30d7\u30ea\u30f3\u30af\u304c\u304a\u304b\u3057\u3044\nhttp://demo.ss-proj.org/.demo/preview/docs/30.html\n\n Comments: \n Comment 0: https://github.com/itowtips/shirasagi/commit/badaaf0ae20462b6e8e83f1cb63643a7a738772f\n\u30d7\u30ec\u30d3\u30e5\u30fc\u8868\u793a\u30ea\u30f3\u30af\u7f6e\u63db\u90e8\u306e\u6b63\u898f\u8868\u73fe\u3092\u4fee\u6b63\n",
  "Issue title: setCenterViewController:(UIViewController *) withCloseAnimation:YES does not animate\n Issue body: With 0.5.7, when I call: \n\nsetCenterViewController:(UIViewController *) withCloseAnimation:YES\n\nIf the new centre view controller is different, then there will be no slide in/out animation even though I've specified YES. My work around was to call setCenterViewController and closeDrawerAnimated independently: \n\n```\n    [mm_drawerController setCenterViewController: newViewController];\n    [mm_drawerController closeDrawerAnimated:YES completion:nil];\n```\n\n Comments: \n Comment 0: Turns out that this issue I am having was due to the parent view changing its layout/frame size... So technically there's nothing wrong with setCenterViewController: afterall...\n",
  "Issue title: folding a node at execution time close address listening\n Issue body: I though this was resolved but it is still possible to close/open address listening during execution by folding/unfolding node into the device explorer : \r\n\r\n![capture d ecran 2016-02-03 a 11 09 38](https://cloud.githubusercontent.com/assets/118426/12779241/33902850-ca67-11e5-9b02-160763f080cd.png)\r\n\r\nthis is a critical bug as it breaks all trigger interactions.\n Comments: \n Comment 0: @jcelerier I have added a post in API to see if an address is closing/opening the listening.\r\nby the way it seems there are some strange behaviors also into the API relative to listening activation but I would like to be sure the interface is not doing anything at execution time.\n Comment 1: okay, this will require a bit of time to do this properly. \n Comment 2: Pushed in dev  to fix this, but please test many cases because it changed a lot of things.\n Comment 3: ok thx. I'll made some test later before to close this issue\n Comment 4: this is ok now!",
  "Issue title: Crash reports every second regarding surface rock materials\n Issue body: [crash-2020-04-19_20.59.49-client.txt](https://github.com/GregTechCE/GregTech/files/4524675/crash-2020-04-19_20.59.49-client.txt)\r\n\r\nI'm using version +1-544-251-4084, I erased the previous gregtech config file to see if that was the mistake but I keep getting the errors. The game can be played but I got like 100 of those files on 2 minutes of play time. They all seem to look the same.\n Comments: \n Comment 0: I go through crash log and I have 4 things to discuss.\r\n\r\n1. Version which you are writing that you are using is not same as one reported in crash log. Are you sure you are using right version?\r\n2. I don't see anything related to surface rocks. Can you please point me to it?\r\n3. Crash log does not state from which mode crash comes and GTCE is not only one installed. Did you reported to other mods too?\r\n4. Crash log shows that problems occurred when constructing **gtadditions**. Shouldn't you go first to that mod?\r\n\r\nPlease provide answers to my questions so I can move on with investigation.\n Comment 1: [crash-2020-04-23_14.48.40-client.txt](https://github.com/GregTechCE/GregTech/files/4524865/crash-2020-04-23_14.48.40-client.txt)\r\nI uploaded the wrong crash report, sorry for that. This is the one\n Comment 2: Yep, that looks exactly like surface rock crash on latest build. I will take look at it later.\n Comment 3: **Version:**\r\n1.9.1 (dev build on e3668e38c3bb77e74479d78425558e37d2dc0257 same source as version +1-544-251-4084)\r\n\r\n**Environment:**\r\nGTCE dev; new world generated; default world gen\r\n\r\n**Outcome:**\r\nUnable to reproduce. \r\n\r\nPlease provide information when and with which version was world created. Was GTCE data for worldgen edited in any way? Also it seems that you have vanilla fix installed which may be interfering with NBT system. Please uninstall it first and try on new world.\n Comment 4: [report.txt](https://github.com/GregTechCE/GregTech/files/4530869/report.txt)\r\nAfter removing VanillaFix the game doesn't give crash files, but MultiMC gives these messages that have the same text as the crash log, every second. \r\n\r\nI tested erasing the config file and opening my game with the GTCE version from Curseforge +1-544-251-4084) and the MultiMC log doesn't show anything wrong.\r\n\r\nI'm creating new worlds everytime I try this tests, and the GTCE config data is clean too. I'm erasing  and letting them generate each time just to make sure the problem is not related to that.\n Comment 5: **Version:**\r\ngregtech-1.12.2-116.69.203.1151; forge-1.12.2-116.69.203.11554\r\n\r\n**Environment:**\r\nTwitch Launcher; new world generated; default world gen\r\n\r\n**Outcome:**\r\nBug confirmed.\r\n\r\n**Additional notes:**\r\nSurface rocks are generated correctly. After save load all Surface rocks are aluminium with same exactly same look. After first \"touching\" them they change it's look random surface rock formation. Material still aluminium.\r\n\r\nError descriptions is pointing to problem with different build/run version of underlying lib (most likely forge) additional investigation needed.\n Comment 6: **Proposed solution:**\r\nUse latest official version of Forge: 1.12.2 - 116.69.203.11547.\r\n\r\n**Additional notes:**\r\nLast three specific versions were produced after official drop of MC 1.12 Forge support. They were build with new template which is not compatible with official Gradle build pipeline.\n Comment 7: Fixed by #1093.",
  "Issue title: Accumulative sampling SPTWalker use wrong speed for time interpolation on edge in CAR/BIKE modes\n Issue body: Quote from [this thread](https://groups.google.com/forum/#!topic/opentripplanner-dev/sdKmyBXqvRI):\n\n> I made a test on http://116.69.203.115/demo/master/marseille/ with the mode CAR and max time 0:30.\n> It generates an isochrone where some accessible roads appears as islands. Some road sections farthest from the starting point are accessible while  nearest road are not as you can see on the image attached. I don't  understand how it's possible. Is there a way to avoid this?\n\n![sample_auriol](https://cloud.githubusercontent.com/assets/959548/5162926/c8b9cd7c-73c5-11e4-8472-6074e945520c.png)\n\n Comments: \n Comment 0: It's a bug (also known as a \"feature\") in the [code here](https://github.com/opentripplanner/OpenTripPlanner/blob/master/src/main/java/org/opentripplanner/analyst/request/SampleGridRenderer.java#L208).\n\nBasically in this code I was assuming walking speed (off-road walking speed, 1 m/s = 3.6 km/h) to interpolate the time alongside road segment at various points along the road to generate the result, where we should have taken the car speed on the edge. We never saw that problem before because the issue only appear for CAR mode (which was not a top priority for isochrones) and only for long stretches of road. This interpolation is necessary as the data we have from the trip plan only contains a state for each vertex, so we have to interpolate back the data (time, etc...) alongside long edges (used for the \"accumulative sampler algorithm\").\n\nIn order to solve this, we simply have to take the real speed on the edge, given the current non transit mode of the end-states of the edge (to accomodate mixed modes such as P+R for example). Unfortunately this is simpler said than done, because effective speed on a given segment can depend on a lot of factors and is not necessarely available at the time we sample the SPT (shortest path tree). But we could take a good approximation by using the edge max. car speed for CAR mode, and default speed of the request for other modes. The longer the edge, the bigger the error; but for actual edges this should give good approximation. We should also make sure that the assumed speed is never _faster_ than the average speed to go from both end edges states (taking actual state time and edge length) to prevent discontinuity at one end of the edge.\n\n Comment 1: Should be fixed by the pull request #1626.\n\nPlease see an example which show CAR isolines starting on a motorway (notice the asymetry of the result):\n![isoline_nantes](https://cloud.githubusercontent.com/assets/959548/5166396/c5d10664-73ef-11e4-95c8-9ff8e689dec5.jpg)\n\nThere are still the possibility of having unconnected result, when two road crosses each other. For different roads near each other, the sampling algorithm will average the various values for each sampling point, so you could end-up with a cut in a road segment (in the attached example you can see a cut at the bridge below \"Saint-Herblain\").\n",
  "Issue title: LowerBoundNewtonRaphson: how to check if converged\n Issue body: I'm currently updating some old to code to the new version Accord and I'm wondering how to check if the LowerBoundNewtonRaphson Learning converged when not using the obsolete methods.\r\nComparing Solution with Previous or checking Gradient?\r\nSorry, if this is a stupid question...\r\n\n Comments: \n Comment 0: Hi @deng0,\r\n\r\nCurrently there is no easy way to check whether the algorithm converged in the last call to.Learn(). I am working on currently standardizing the convergence checks in the new API, and unfortunately I haven't updated LowerBoundNewtonRaphson yet.\r\n\r\nHowever, as a quick fix you might be able to check the convergence of LowerBoundNewtonRaphson by accessing one of its private fields through reflection:\r\n\r\n```\r\nIConvergence<double> status = (IConvergence<double>)typeof(LowerBoundNewtonRaphson)\r\n               .GetField(\"convergence\", BindingFlags.NonPublic | BindingFlags.Instance)\r\n               .GetValue(lowerBoundNewtonRaphson);\r\n```\r\n\r\nIn any case, soon I will be adding a commit adding a HasConverged method in LowerBoundNewtonRaphson that can be used to check for convergence.\r\n\r\nRegards,\r\nCesar\n Comment 1: Thanks for the reply.\r\nGood to know that you are adding it to one of the next releases.\r\nI will stick with the obsolete method for now.\n Comment 2: Added in release 3.6.0.",
  "Issue title: put chosen values in multi list on the top of the dropdown\n Issue body: use case:\r\ni choose something from very long list\r\nrun the script.\r\nnow need change, but\r\ni don't know what is chosen in the dropdown\r\ni don't want to reload the rest of the fields because there are a lot of them\r\n\r\nanother problem:\r\ni FORGET that something is already chosen\r\nand delete something by mistake\r\n\r\nthnanks\r\n\n Comments: \n Comment 0: Hi @yosefy, thanks for the proposal, nice idea. I need to rethink how to properly implement it from the UX perspective: to avoid jumping values on the selection and probably keep a default behaviour for short lists.\n Comment 1: i took the idea from past usage of  rundeck\nit was very useful from experience\nthaks\n\nOn Wed, Apr 17, 2019 at 10:55 AM Iaroslav Shepilov <aharper@example.org>\nwrote:\n\n> Hi @yosefy <https://github.com/yosefy>, thanks for the proposal, nice\n> idea. I need to rethink how to properly implement it from the UX\n> perspective: to avoid jumping values on the selection and probably keep a\n> default behaviour for short lists.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/bugy/script-server/issues/208#issuecomment-483978502>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AMVy7TEQvBJt-7GaeUAPIYXNH6Rxx-G2ks5vhtNtgaJpZM4c0anc>\n>.\n>\n\n Comment 2: Maybe second answer from here can help? \r\n\r\nhttps://stackoverflow.com/questions/63299745/how-to-highlight-certain-value-on-select-box-dropdown-first-time-expanding-list",
  "Issue title: Critical Error during the upgrade process\n Issue body: After fresh install (i download last.zip today = 0.2.24), i got a message to upgrade piwik (same like http://piwik.org/blog/wp-content/uploads/2008/11/piwik_update.png)\n\nAfter click \"Upgrade piwik\", i got this message :\nCritical Error during the upgrade process: \nError trying to create the option table in Mysql: SQLSTATE[42S01]: Base table or view already exists: 1050 La table 'option' existe dj\n\n Comments: \n Comment 0: I think same problem that 444 (#444)\n\n Comment 1: see #444\n",
  "Issue title: Ubuntu15.04 fcitx\u5019\u9009\u5b57\u4f53\u6709\u9634\u5f71\n Issue body: Ubuntu15.04 fcitx\u5019\u9009\u5b57\u4f53\u6709\u9634\u5f71\n![img_20150505_074637](https://cloud.githubusercontent.com/assets/7426281/7466100/ec954446-f30f-11e4-8093-65cd891403e5.jpg)\n\n Comments: \n Comment 0: \u611f\u89c9\u662f\u663e\u5361\u9a71\u52a8\u95ee\u9898\u2026\n Comment 1: \u8dd1\u4e00\u4e0bfcitx-diagnose?",
  "Issue title: answerCbQuery examples explanation\n Issue body: Documentation is not clear about usage of answerCbQuery.\r\n\r\nI have question about next example:\r\nhttps://github.com/telegraf/telegraf/blob/develop/docs/examples/keyboard-bot.js\r\n\r\n1. Why next function does not use `answerCbQuery`?\r\n```\r\nbot.action('Dr Pepper', (ctx, next) => {\r\n  return ctx.reply('\ud83d\udc4d').then(() => next())\r\n})\r\n```\r\n\r\n2. Why next function use two `await`. What happens without one or both `await`?\r\n3. Why `answerCbQuery` is called before `editMessageCaption`. What happens in another order?\r\n```\r\nbot.action('plain', async (ctx) => {\r\n  await ctx.answerCbQuery()\r\n  await ctx.editMessageCaption('Caption', Markup.inlineKeyboard([\r\n    Markup.callbackButton('Plain', 'plain'),\r\n    Markup.callbackButton('Italic', 'italic')\r\n  ]))\r\n})\r\n```\n Comments: \n Comment 0: 1. Because this is a \"pass-through\" middleware. It replies with \ud83d\udc4d and calls next, so next middlewares can handle the same update and `answerCbQuery` if they want to.\r\n2. What do you mean? `await` controls asynchronous requests. If you'll try to send 2 messages w/o `await`, the order of messages might be broken. But if you use `await`, the next message starts sending only after the first one is sent\r\n3. It doesn't matter\n Comment 1: @Loskir thanks for reply.\r\n\r\nIt confused when order of messages doesn't matter in this example and `await` used.\r\n\r\nAlso I found when using webhook the order of messages might be broken w/o `ctx.webhookReply = false`",
  "Issue title: Silently restart with additional child processes\n Issue body: I'd like to add a vote for this TODO entry: \n\n> When watching, it'd be good to perhaps bring up a new child and then kill the old one gently, rather than just crashing the child abruptly\n\n Comments: \n Comment 0: I think this would probably need to be off by default and enabled with a flag, because if the child is using a resource (for example, if it's a server bound to a port), starting a new process will fail with the resource already in use.\n\n Comment 1: Unless there's a way to bring up a new child process on the same port and they would share. Basically Supervisor would become the proxy to the child processes.\n\n Comment 2: Unfortunately, no. Supervisor is (by design) agnostic about what the child\nprocess is doing, so it can't dip its fingers into ports and whatnot.\n\n Comment 3: Closing, as I think this is unlikely to happen, sorry. It's more of a production use-case, and supervisor is more of a development tool.\n",
  "Issue title: Add Friendica Thumbnail\n Issue body: Hi all,\r\n\r\nPlease add the Friendica Thumbnail, since 2FA is now enabled.\r\n\r\nYou can find the SVG here:\r\nhttps://github.com/friendica/docker/blob/master/friendica.svg\r\n\r\nThank you :-)\n Comments: \n Comment 0: @flocke: Was included with 0.7.0 and can be closed.",
  "Issue title: Switch from paketo-community Ruby Buildpack to paketo-buildpacks Ruby Buildpack\n Issue body: **Is your feature request related to a problem? Please describe.**\r\nHi from the Paketo team! We've [recently promoted](https://github.com/paketo-buildpacks/rfcs/blob/master/accepted/0005-ruby-promotion.md) the Ruby Buildpack from a community buildpack to an official Paketo Buildpack. \r\n\r\nAs a part of this change, the buildpack ID has been updated from `paketo-community/ruby` to `paketo-buildpacks/ruby` and buildpackage artifacts will get published to `gcr.io/paketo-buildpacks/ruby`\r\n\r\n**Describe the solution you'd like**\r\nPlease start consuming the latest Ruby Buildpack with ID `paketo-buildpacks/ruby`. The existing location (`gcr.io/paketo-community/ruby`) will continue to work, but you will need use `gcr.io/paketo-buildpacks/ruby` in order to continue receiving buildpack releases\r\n\n Comments: \n Comment 0: We have created an issue in Pivotal Tracker to manage this: \n\nhttps://www.pivotaltracker.com/story/show/175065881 \n\nThe labels on this github issue will be updated when the story is started.\n Comment 1: @paulcwarren I think we can close this? I see this on the latest version of CF for K8s\n Comment 2: Delivered in 1.0",
  "Issue title: Same icon for Five or more and Four in a row\n Issue body: Currently, Five or more and Four in a row have the same icon but they are totally different games.\r\n\r\nTwo distinct icons would be better since they are usually installed together because they are part of the gnome-games meta-package. The Papirus version also has only 3 dots instead of four or five.\r\n\r\n**Papirus: Five or more and Four in a row**\r\n\r\n![four-in-a-row](https://user-images.githubusercontent.com/7804464/61300153-bb197a00-a7e1-11e9-8a36-15af788c655a.png)\r\n\r\n\r\n**Original: Five or more**\r\n\r\n![org gnome five-or-more](https://user-images.githubusercontent.com/7804464/61298815-2d3c8f80-a7df-11e9-91b2-14ee6adfd74d.png)\r\n\r\n**Original: Four in a row**\r\n\r\n![org gnome Four-in-a-row](https://user-images.githubusercontent.com/7804464/61298838-36c5f780-a7df-11e9-9348-c5787b719888.png)\r\n\n Comments: \n Comment 0: I suppose it's because hard to place more than 3 dots to icon smaller than 24px.\n Comment 1: Maybe for Five or More recolor 5 dots, and 4 dots for Four in a row?\n Comment 2: @SmartFinn Sounds good to me.",
  "Issue title: element does not have fadeIn method?\n Issue body: I'm using the Zepto build from you test page which includes the data module, but now I'm seeing this error:\nUncaught TypeError: Object #<Object> has no method 'fadeIn'                         parsley.js:780\n\nI just placed a simple form on the page to test:\n\n```\n<form data-validate=\"parsley\">\n    <label for=\"username\">User name</label>\n    <input id=\"username\" name=\"username\" data-rangelength=\"[6,15]\" data-required=\"true\" placeholder=\"6-15 Characters\" autocorrect=\"off\" type=\"text\" value=\"\">\n```\n\n   <input type=\"submit\" value=\"submit\" />\n</form>\n\n Comments: \n Comment 0: I'm tried your bug with latest `master` branch dist/parsley-standalone.min.js and do not find your error.\n\nCould you check if still there with this latest one? If so, could you create a proper jsfiddle?\n\nThanks\n",
  "Issue title: Is project depreciated?\n Issue body: Still maintaining? \n Comments: \n Comment 0: Looks like it has been abandoned by the maintainers (I don't blame them, OSS takes a lot of someone's personal time). Probably a good idea for someone to fork and maintain the project, if they are willing to put the time in.\n Comment 1: Hey @SD10! Any news?\n Comment 2: Bump, consider adding more maintainers.\n Comment 3: Bump\n Comment 4: Bump\n Comment 5: #617\n Comment 6: Closing. New discord and maintainers in above linked issue",
  "Issue title: Bug in smx decompilation\n Issue body: good afternoon guys! during this week I found out that there is a bug in sourcemod where if we make a specific code it is not allowed to decompile to smx I tried everything to try to find this bug where it came from but I didn't get the error that appears when we decompile is ERROR NULL, and no version of sourcemod is created, they simply put the code in the compile and don't let it decompile.\n Comments: \n Comment 0: This is a problem with Lysis on headline's website, not sourcemod",
  "Issue title: equihash.so migrato from libsodium to use same blake2b function in modCrypto\n Issue body: This change will help clean up the unnecessary dependency in :\r\nhttps://github.com/aionnetwork/aion/tree/dev/native/linux/sodium/sodium\r\nby replace blake2b function from libsodium to libblake2b.\n Comments: \n Comment 0: Done.",
  "Issue title: Setup page blank\n Issue body: Hello there.\r\nI am trying to install OpenSupports on my Raspberry Pi with Raspbian installed and I can't get past the blank page.\r\nI know i know, there are already tons of issues for this. I have been wasting dozens of hours trying to fix this. I have read through every issue regarding this and I couldn't find any fix.\r\n\r\nI have also checked my Apache2 config multiple times and validated that the.htaccess are right.\r\n\r\nI have the latest version of OpenSupports installed.\r\n\r\nHere is a screenshot of the Chrome console.\r\n[https://prnt.sc/16r3pux](https://prnt.sc/16r3pux)\r\n\r\nI really hope someone can help me with this I really don't have any more ideas.\n Comments: \n Comment 0: Cloudflare automatically redirected everything to HTTPS. Turning that off fixed it :|",
  "Issue title: Encounter NAN value when calculating the metrics\n Issue body: We train and validate the Swin-Transformer on a custom datasest. The number of classes is set as 2. The model can be trained as normal, but encounter NAN value when calculating the metrics, shown in the figure below. It seems like the images and annotations are correctly loaded, since the validation program can be executed as normal.\r\n![\u56fe\u7247](https://user-images.githubusercontent.com/36557512/168205692-9f85e53b-0af8-465a-8236-4bf61d006f64.png)\r\n\n Comments: \n Comment 0: OK, I found the problem. The annotation classes are mislabeled. ",
  "Issue title: Text does not get translated with _ if such text is inside a macro\n Issue body: I have the following Macro:\r\n```\r\n{% macro display_errors(errors,modal=false) %}\r\n    {% if modal == false %}\r\n        {% for error in errors %}\r\n            <div class=\"alert alert-danger alert-dismissable\">\r\n                <button aria-hidden=\"true\" data-dismiss=\"alert\" class=\"close\" type=\"button\">\u00d7</button>\r\n                {{ error }}.\r\n            </div>\r\n        {% endfor %}\r\n    {% else %}\r\n        {% if errors|length > 0 %}\r\n            <div class=\"alert alert-danger alert-dismissable\">\r\n                <button aria-hidden=\"true\" data-dismiss=\"alert\" class=\"close\" type=\"button\">\u00d7</button>\r\n                {{ _('The last action reported errors') }}. <button type=\"button\" class=\"btn btn-danger\" data-toggle=\"modal\" data-target=\"#error_modal\">{{ _('See errors') }}</button>\r\n            </div>\r\n        {% endif %}\r\n    {% endif %}\r\n{% endmacro %}\r\n```\r\nWhich I use with a code like:\r\n```\r\n{% import 'dashboard/macros/form.jinja2' as form %}\r\n...\r\n{{ form.display_errors(errors,true) }}\r\n```\r\nEven though I have the text \"The last action reported errors\" in the.po files and the rest of the App translates properly, the message inside the macro does not get translated.\r\n\r\n```\r\n#: formshare/templates/dashboard/macros/form.jinja2:17\r\nmsgid \"The last action reported errors\"\r\nmsgstr \"La \u00faltima acci\u00f3n report\u00f3 errores\"\r\n```\r\n\r\n\r\nEnvironment:\r\n- Python version: 3.8.5\r\n- Jinja version: 2.11.3\r\n- Babel version: 2.8.0\r\n\n Comments: \n Comment 0: Translating inside a macro works for me. Maybe you forgot to recompile the.po to.pm (this happens to me a lot)\r\n\r\n\r\n-   Python version: 3.8.7\r\n-    Jinja version: 2.11.2\r\n-    Babel version: 2.9.0\r\n\n Comment 1: I recompile the.po into.mo. All my translations use `_` \r\n\r\nI tried by adding a new translation string to the macro file for example `title=\"{{ _('Close') }}\"` and other just the same in an element outside the macro.\r\n\r\nAfter `python setup.py extract_messages`, `python setup.py update_catalog`, translating the string, and `python setup.py compile_catalog` the string inside the macro does not translate but the one outside does.\r\n\r\n",
  "Issue title: bot identifies lot of files due to docs.ansible.com in description\n Issue body: Bot identifies a lot of files due to occurrence of docs.ansible.com in issue description \r\n- https://github.com/ansible/ansible/issues/53274\n Comments: \n Comment 0: `docs.ansible.com` shouldn't match `docs` directory. It should only ping the docs team\n Comment 1: I think this happened because that issue was marked `cloud` and referenced the AWS modules. @Akasurde if you see new issues that do this, please let me know, but I think this was an anomaly. \r\n\r\n@gundalow I think this issue can be closed.",
  "Issue title: Communication error\n Issue body: #### What were you doing?\r\nStart the print as normal, then aft first layer it just stops and the text comes up:\r\nUnhandled communication error\r\nThere was an unhandled error while talking to the printer. Due to that OctoPrint disconnected. Error: Too many consecutive timeouts, printer still connected and alive?\r\n\r\n#### What did you expect to happen?\r\nA finnished print\r\n\r\n#### What happened instead?\r\nJust stopped\r\n\r\n#### Branch & Commit or Version of OctoPrint\r\nVersion: 1.2.18 (master branch)\r\n\r\n#### Printer model & used firmware incl. version\r\nCraftbot+ 1.1.9657/3\r\n\r\n#### Browser and Version of Browser, Operating System running Browser\r\nGoogle Chrome Version 54.0.2840.99 m (64-bit)\r\n\r\n#### Link to octoprint.log\r\n[octoprint.txt1.txt](https://github.com/foosel/OctoPrint/files/627315/octoprint.txt1.txt)\r\n\r\n#### Link to contents of terminal tab or serial.log\r\n[OctoPrint1.txt](https://github.com/foosel/OctoPrint/files/627441/OctoPrint1.txt)\r\n\r\n\r\n#### Link to contents of Javascript console in the browser\r\nDont know how to add that link\r\n\r\n\r\n#### Screenshot(s) showing the problem:\r\n![octoprint](https://cloud.githubusercontent.com/assets/18622410/20838296/3ad2414a-b8a8-11e6-99c3-e42f52b0ceca.png)\r\n\r\n\r\n\n Comments: \n Comment 0: Hi @Jpson67,\n\nIt looks like there is some **information missing** from your bug report that will be needed in order to solve the problem. Read the [Contribution Guidelines](https://github.com/foosel/OctoPrint/blob/master/CONTRIBUTING.md) which will provide you with a template to fill out here so that your bug report is ready to be investigated (I promise I'll go away then too!).\n\nIf you did not intend to report a bug but wanted to **request a feature or brain storm** about some kind of development, please take special note of the title format to use as described in the [Contribution Guidelines](https://github.com/foosel/OctoPrint/blob/master/CONTRIBUTING.md).\n\n**Please do not abuse the bug tracker as a support forum** - if you have a question or otherwise need some kind of help or support refer to the [Mailinglist](https://groups.google.com/group/octoprint) or the [G+ Community](https://plus.google.com/communities/102771308349328485741) instead of here.\n\nAlso **make sure you are at the right place** - this is the bug tracker of the official version of OctoPrint, not the Raspberry Pi image OctoPi nor any unbundled third party OctoPrint plugins or unofficial versions. Make sure too that you have **read through the [Frequently Asked Questions](https://github.com/foosel/OctoPrint/wiki/FAQ)** and searched the [**existing tickets**](https://github.com/foosel/OctoPrint/search?q=&ref=cmdform&type=Issues) for your problem - try multiple search terms please.\n\nI'm marking this one now as needing some more information. Please understand that if you do not provide that information within the next two weeks (until 2016-12-16 11:00 UTC) I'll close this ticket so it doesn't clutter the bug tracker. This is nothing personal, so please just be considerate and help the maintainers solve this problem quickly by following the guidelines linked above. Remember, the less time the devs have to spend running after information on tickets, the more time they have to actually solve problems and add awesome new features. Thank you!\n\nBest regards,\n~ Your friendly GitIssueBot\n\nPS: I'm just an automated script, not a human being, so don't expect any replies from me :) Your ticket is read by humans too, I'm just not one of them.\n\n Comment 1: > collect all requested information **(don't forget the terminal)**, \r\n\r\n^-- quoted from your initial ticket #1595. Something apparently goes wrong between your printer and OctoPrint. Without being able to *see* what they are talking about (NOT only the error but what goes *before* this), how is anyone supposed to analyse this? \r\n\r\nFULL ticket. \r\n\r\nPlease. \r\n\r\nIncluding the FULL terminal output and your `octoprint.log` (no, what you provided there is NOT the requested log, the requested log can be found under Settings > Logs and definitely not a truncated version of your terminal output). Do not truncate anything, you are making it impossible for anyone to help you here.\n Comment 2: Seems to be the same problem as #1603, to me.\n Comment 3: Going by this excerpt from the terminal output which was finally provided apparently:\r\n\r\n```\r\nSend: N1328 G21*34\r\nCommunication timeout while printing, trying to trigger response from printer. Configure long running commands or increase communication timeout if that happens regularly on specific commands or long moves.\r\nSend: N1329 M105*30\r\nCommunication timeout while printing, trying to trigger response from printer. Configure long running commands or increase communication timeout if that happens regularly on specific commands or long moves.\r\nSend: N1330 M105*22\r\nCommunication timeout while printing, trying to trigger response from printer. Configure long running commands or increase communication timeout if that happens regularly on specific commands or long moves.\r\nSend: N1331 M105*23\r\nCommunication timeout while printing, trying to trigger response from printer. Configure long running commands or increase communication timeout if that happens regularly on specific commands or long moves.\r\nSend: N1332 M105*20\r\nCommunication timeout while printing, trying to trigger response from printer. Configure long running commands or increase communication timeout if that happens regularly on specific commands or long moves.\r\nSend: N1333 M105*21\r\nNo response from printer after 6 consecutive communication timeouts, considering it dead. Configure long running commands or increase communication timeout if that happens regularly on specific commands or long moves.\r\nChanging monitoring state from 'Printing' to 'Offline: Too many consecutive timeouts, printer still connected and alive?'\r\nConnection closed, closing down monitor\r\n```\r\n\r\nThe printer basically goes AWOL and refuses to respond entirely to anything sent to it. So either the firmware crashed, or something else happened with the printer, but this is nothing that can be solved by OctoPrint. You need to figure out why your printer stops responding. I've seen issues like this with overheating controllers, so maybe check that. But unless your printer/your printer's firmware keeps on replying to messages sent by OctoPrint, printing via serial will be impossible (with any host for that matter).\r\n\r\n@skorokithakis doesn't look like #1603, it's not the serial port that's actually breaking off (which would indicate a possible power issue) but instead it's the printer simply stopping to reply. Which of course makes it impossible to tell it to print. After a while OctoPrint simply gives up and throws an error to tell the user \"Look, something's seriously broken with your printer here\".\n Comment 4:?\n\n/Jimmy\n> 5 dec. 2016 kl. 13:58 skrev Gina H\u00e4u\u00dfge <rodriguezpatrick@example.com>:\n> \n> Closed #1615 <https://github.com/foosel/OctoPrint/issues/1615>.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub <https://github.com/foosel/OctoPrint/issues/1615#event-881996765>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ARwnyoiCo3PlIALhZnIXK9fcifUc_MB0ks5rFAqJgaJpZM4LCbb2>.\n> \n\n\n Comment 5: Dont get this error when the printer its hooked up direct to computer\n Comment 6: > Dont get this error when the printer its hooked up direct to computer\r\n\r\nAha. And I'm supposed to know this how? Also, hooked up how? Same USB cable, other cable? And through what software? You realize you haven't been very forthcoming with information so far, right? \r\n\r\nIf it's not working with the Pi *with the same printed GCODE file and USB cable* but it's working fine with a regular PC *with the same printed GCODE file and USB cable*, @skorokithakis might be right after all and this is in fact another manifestation of a brown-out issue due to some weird power issues of the Pi. Or it might be something else, but we won't be able to figure this out unless you are a bit more forthcoming with regards to the exact steps to reproduce this issue.\r\n\r\n",
  "Issue title: [1.16.5] Incompatible mod?\n Issue body: \r\n**Steps to Reproduce :**\r\n 1. Installed mohist-1.16.5-449-server.jar\r\n 2. add supplementaries-1.16.5-0.12.1.jar to mods folder\r\n 3. Try to start the thing\r\n\r\n**Description of issue :** {Give all details about your issue}\r\n\r\nI'm trying to run Valhelsia 3 modpack. But one mod is causing an issue.\r\nMohist ver.: mohist-1.16.5-449-server.jar\r\nJava: Oracle 11.0.11\r\nThe mod that is causing the issue is supplementaries-1.16.5-0.12.1.jar\r\nI'm not getting any debug.log or crash report. only thing is latest.log, which is here https://pastebin.com/EK6FURk5\r\n\r\nIt doeswork with mohist-1.16.5-529-server.jar, but that is an other forge version, so I can't use that since it's not my modpack.\r\n\r\nThanks.\r\n\n Comments: \n Comment 0: Supplementaries startup is broken in builds 479 and lower.\r\nYour best bet is to update to 480+ or implement [the fix](https://github.com/Mohist-Community/Mohist/commit/195538ae74f79e1b3041797a9bb7d7d6b501f8a9) yourself on top of the desired build.",
  "Issue title: Event_base_dispatch blocking main thread!\n Issue body: Hi, i am trying to start event base loop in another thread and then after some time I eventually try to exit the loop from main thread. I tried to add a while loop isRunning and call event base loop with EVLOOP_NONBLOCK flag but this solution uses more cpu resources. How can I start the loop async and be able to break the event loop if so?\n Comments: \n Comment 0: Have you tried breaking the loop via `event_base_loopbreak()`\n Comment 1: > Have you tried breaking the loop via `event_base_loopbreak()`\r\n\r\nit dosen't work.\n Comment 2: Are you using the native thread functionality in evhtp?\r\n\r\nIf so, note that each thread creates its own `event_base` independent of the others. You can do one of the following:\r\n\r\n1. Manually break the threads own event base:\r\n\r\n```C\r\nstruct event_base * base = evthr_get_base(evthr_context);\r\n\r\nevent_base_loopbreak(base);\r\n```\r\n\r\n2. Hard-terminate the entire thread-pool or thread using `evthr_pool_stop` or `evthr_stop`\n Comment 3: Greetings @ipandayu, were you able to look at my reply?\r\n\r\nCheers!\n Comment 4: > Greetings @ipandayu, were you able to look at my reply?\r\n> \r\n> Cheers!\r\n\r\nI always use my way in my first reply,  use event_base_loopbreak in other thread doesn't work\n Comment 5: > > Greetings @ipandayu, were you able to look at my reply?\r\n> > Cheers!\r\n> \r\n> I always use my way in my first reply, use event_base_loopbreak in other thread doesn't work\r\n\r\nYes, but did you use the thread-specific event_base? Please read the entire reply:\r\n\r\n```\r\nstruct event_base * base = evthr_get_base(evthr_context); // NOTE THIS STATEMENT HERE\r\n\r\nevent_base_loopbreak(base);\r\n```\n Comment 6: > > > Greetings @ipandayu, were you able to look at my reply?\r\n> > > Cheers!\r\n> > \r\n> > \r\n> > I always use my way in my first reply, use event_base_loopbreak in other thread doesn't work\r\n> \r\n> Yes, but did you use the thread-specific event_base? Please read the entire reply:\r\n> \r\n> ```\r\n> struct event_base * base = evthr_get_base(evthr_context); // NOTE THIS STATEMENT HERE\r\n> \r\n> event_base_loopbreak(base);\r\n> ```\r\n\r\nNO, did I misunderstand yr meaning? that's what we usually wrote below:\r\nMain Thread: create and call \r\nclass Server {\r\n Server() {\r\n   evthread_use_pthreads(); // it's very important in my code\r\n   base_ = event_base_new();\r\n   htp_ = evhtp_new(base_, NULL);\r\n }\r\n bool Start() {\r\n   \r\n   evhtp_use_threads_wexit(htp_, init_callback, exit_callback, thread_num, this);\r\n   evhtp_bind_socket(...);\r\n   main_run_loop_ = st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5thread(&Server38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5Run, this);\r\n }\r\nvoid Run() {\r\n   event_base_loop(base_, EVLOOP_NO_EXIT_ON_EMPTY);\r\n}\r\n bool Stop() {\r\n   event_base_loopexit(base_, NULL/*timeout*/);  // sometimes it's useless, blocked\r\n   evhtp_unbind_socket(htp_);\r\n }\r\n}",
  "Issue title: Installing Passport removes parallel testing capabilities\n Issue body: <!-- DO NOT THROW THIS AWAY -->\r\n<!-- Fill out the FULL versions with patch versions -->\r\n\r\n- Passport Version: v10.1.3\r\n- Laravel Version: v8.36.1\r\n- PHP Version: 8.0.3\r\n- Database Driver & Version: MySQL\r\n\r\n### Description:\r\nWhen installing Laravel Passport, composer removes the `brianium/paratest` package required for the parallel testing feature of Laravel >= 8.25.\r\n\r\n### Steps To Reproduce:\r\n- Scaffold a fresh Laravel app using Laravel >= 8.25.\r\n- Install run `php artisan test --parallel` and follow this instructions to install `brianium/paratest`\r\n- Install Laravel Passport at the latest version (v10.1.3 at time of reporting)\r\n- See composer removing `brianium/paratest`\n Comments: \n Comment 0: Think there's something really specific going on for your use case because it works fine for me with the steps from above.",
  "Issue title: Name Bikeshedding\n Issue body: I would like to come up with a specific branded name for ***TNG-wrapped function***, because that phrase is too cumbersome and not well-descriptive of its nature. The analog of it, in React, is a \"component\", or more specifically \"stateful function component\".\r\n\r\nI don't imagine that making TNG-wrapped functions will be limited to rendering components. But that's certainly one of the many possible use cases. So I don't necessarily want to limit them with \"component\" or \"component function\" or whatever.\r\n\r\nSome names to consider:\r\n\r\n* \"TNG function\" -- don't really like that, since `TNG(..)` is a specific utility, **a function**, that wraps the functions in question\r\n* \"stateful function\" -- this is decent, and describes its main characteristic well, but it's also kinda blah\r\n\r\nOther thoughts?\n Comments: \n Comment 0: You could pretend that \u201cTNG\u201d is a verb and use the term **TNGed function**.\r\n\r\nThis opens up some nice variants like:\r\n\r\n- \u201cI recommend **TNGing** that function\u201d\r\n- \u201cAre you sure that you that function is **TNGable**?\u201d\n Comment 1: Some name ideas that I'm considering:\r\n\r\n* \"Articulate\", \"Articulate Function\" -- bonus: it's also the verb, as in \"Articulate the function\", and the descriptor of it, \"Articulated Function\"\r\n\r\n* \"Subject\", \"Subject Function\"\r\n\r\n* \"Relation\", \"Relation Function\", \"Relational Function\"\r\n\r\n* \"Captive Function\"\r\n\r\n* \"Substrate Function\"\n Comment 2: I propose to select \"Articulate Function\" to describe a function that has been TNG-wrapped to provide the hooks context (state, effects).\r\n\r\nPlease vote thumbs up or thumbs down on this selection. Thanks! :)\n Comment 3: Seriously though, what about Articulated Functions?\r\n\r\narticulated (adjective)\r\n\r\nhaving two or more sections connected by a flexible joint.\n Comment 4: OK, I'm satisfied, we'll pick \"Articulated Function\" (to replace \"TNG-wrapped function\") for describing normal functions which are *decorated* with a TNG hook context. Docs updates to follow.",
  "Issue title: Can you use without advanced configuration?\n Issue body: Hi!\r\n\r\nI was trying to use this plugin but without the jss insertion specified here https://www.gatsbyjs.org/packages/gatsby-plugin-material-ui/#advanced you can't override styles properly. I think this should be done by default instead of requiring every project to setup another extra js file of config.\n Comments: \n Comment 0: What's your use case? \n Comment 1: Just override a style with emotion.js. You can't use this plugin out of the box, you need to use advanced mode. I think that should be by default as most of the people need to override material ui styles.\n Comment 2: Ok, thanks. I have added your comment in https://trello.com/c/QZN9Zz69/2557-https-githubcom-mui-org-material-ui-issues-20776issuecomment-619633328. We might change the default injection order in v5, we will see.\n Comment 3: This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n\n Comment 4: This issue has been automatically closed because of inactivity. Please open a new issue if are still encountering problems.\n",
  "Issue title: \"Testing with CoreFX\" documentation incorrect?\n Issue body: I wanted to run the CoreFX System.Runtime tests to test some mscorlib changes.\r\n\r\nThe instructions detailed [here](https://github.com/dotnet/coreclr/blob/master/Documentation/building/testing-with-corefx.md) don't seem to work.\r\n\r\nThe CoreCLR package was correctly published to the location I specified in `InstallationLocation` (`C:\\dev\\corefx\\packages` on my machine), but when I ran `msbuild /t:BuildAndTest` from `C:\\dev\\corefx\\src\\System.Runtime\\tests`, it didn't run the tests with the locally published CoreCLR package.\r\n\r\nIn order to run the tests against my changes, I had to manually copy/replace the locally built CoreCLR dll's into `C:\\dev\\corefx\\bin\\tests\\Windows_NT.AnyCPU.Debug\\System.Runtime.Tests\\dnxcore50`.\r\n\r\nIs the documentation incorrect, or am I doing something wrong?\r\n\r\nThanks!\n Comments: \n Comment 0: Note: The example `localpublish.props` content in the doc wasn't rendering on GitHub correctly; the only way to see it was to look at the raw markdown. I submitted #1196 to address this.\n Comment 1: Sorry, Justin.  I don't have any expertise here, I'm on the copy everything into dnxcore50 plan, but maybe @blackdwarf, who wrote the instructions knows how this is supposed to work?\n Comment 2: I would have to ask @terrajobst to take a look.\n Comment 3: I think the instructions are no longer correct as we don't use Microsoft.DotNet.CoreCLR package any more after @ericstj switch to using Microsoft.NETCore.Runtime.CoreCLR-x86 in corefx. Looks like we need to figure out the right workflow and update the instructions.\n Comment 4: Fixed a long time ago",
  "Issue title: Feature Request: Move galleries with specific tags to a specified folder\n Issue body: This might be completely out of scope, but I've been thinking about this for awhile and would like to know if you think it's feasible. I'd be happy to donate $50 if it were to be added.\r\n\r\n**Background**\r\nAs my archive has grown into the thousands trying to sort galleries with specific tags into folders becomes more and more time consuming. And I only have a few tags that I bother sorting! If LANraragi could do that automatically... how amazing would that be? It also has a nice side effect of if a user were to upload a gallery it will be sorted properly without them needing to have access to the servers file-structure.\r\n\r\n**Implementation**\r\nHave users create a list of rules, each with one or multiple user defined tags e.g `language:english, parody:fate_stay_night` and then you would set the path the gallery moves to if it matches that rule, e.g `/english/parody/fate/stay night`. Each rule would have a definable priority level (1-5) so in the case of multiple rules being matched to one gallery LRR just picks the highest priority rule. You should also be able to prevent it from moving galleries if they are in a specified folder, e.g some people might have a folder for incomplete or purged galleries which they want to keep separate.\r\n\r\nAnd while this is optional, if it could work with wildcards, that would be very handy for things like:\r\n`parody:*, parody:*` > `/parody/various` or `parody:fate*, parody:fate*` > `parody/fate/various`. But i don't want to make this more complicated than it probably already is. \r\n\r\nIf setting priority rules is too hard, asking the user which rule to use when a gallery matches multiple rules would work as well, although not ideal since it would slow things down a lot.\r\n\r\n**Outcome**\r\nImagine just dropping a huge batch of files onto LRR library, and having it sort them all automatically as each galleries meta-data is read and ran through the rule-set. That would be a huge time-saver for anyone who cares about sorting their gallery.\n Comments: \n Comment 0:![33ad6305454e3c95438f405ca5127aeaecd1608a8189abeefbc23c3942bae241](https://user-images.githubusercontent.com/8237712/73137878-09df8080-405d-11ea-9a5a-9affc3bf46fa.jpg)  \r\n\r\nYeah, I'll have to say this goes far off the scope as far as I'm concerned -- While it would be possible within the current design since it's just shuffling files around, I really don't consider keeping/creating a folder structure parallel to what we store in database an essential feature.  \r\n\r\nIf you want something like this, it'd probably be better to write a script/program that consumes the API to see the tags assigned to each file, and then moves the files.  \r\n\n Comment 1: Yeah i thought it would probably be out of scope, oh well.",
  "Issue title: hfuzz-cc seems to be failing to compile code from stdin\n Issue body: Trying to build elfutils with various fuzzing engines I ran into what seems to be a bug in hfuzz-cc:\r\n```\r\necho \"int main() { return 1; }\" | hfuzz-gcc -g -xc -\r\n\r\n2021-12-18T19:22:17.5920479Z /tmp/libhfnetdriver.0.e2d9a39cafc710dc.a:1:1: error: expected identifier or '(' before '!' token\r\n2021-12-18T19:22:17.5921331Z     1 |!<arch>\r\n2021-12-18T19:22:17.5921659Z       | ^\r\n2021-12-18T19:22:17.5922560Z /tmp/libhfnetdriver.0.e2d9a39cafc710dc.a:2:59: error: stray '`' in program\r\n2021-12-18T19:22:17.5923350Z     2 | /               0           0     0     0       222       `\r\n2021-12-18T19:22:17.5923750Z       |                                                           ^\r\n2021-12-18T19:22:17.5924579Z /tmp/libhfnetdriver.0.e2d9a39cafc710dc.a:3:1: warning: null character(s) ignored\r\n2021-12-18T19:22:17.5927546Z     3 |    ^G  ^A\"  ^A\"  ^A\"  ^A\"  ^A\"  ^A\"  ^A\"HonggfuzzNetDriverPort HonggfuzzNetDriverArgsForServer HonggfuzzNetDriverTempdir HonggfuzzNetDriverServerAddress LLVMFuzzerInitialize LLVMFuzzerTestOneInput LIBHFNETDRIVER_module_netdriver  netdriver.o/    0           0     0     644     58648     `\r\n2021-12-18T19:22:17.5929594Z       | ^\r\n2021-12-18T19:22:17.5930600Z /tmp/libhfnetdriver.0.e2d9a39cafc710dc.a:3:4: error: stray '\\7' in program\r\n2021-12-18T19:22:17.5933633Z     3 |    ^G  ^A\"  ^A\"  ^A\"  ^A\"  ^A\"  ^A\"  ^A\"HonggfuzzNetDriverPort HonggfuzzNetDriverArgsForServer HonggfuzzNetDriverTempdir HonggfuzzNetDriverServerAddress LLVMFuzzerInitialize LLVMFuzzerTestOneInput LIBHFNETDRIVER_module_netdriver  netdriver.o/    0           0     0     644     58648     `\r\n2021-12-18T19:22:17.5935664Z       |    ^\r\n2021-12-18T19:22:17.5936516Z /tmp/libhfnetdriver.0.e2d9a39cafc710dc.a:3:5: warning: null character(s) ignored\r\n2021-12-18T19:22:17.5939307Z     3 |    ^G  ^A\"  ^A\"  ^A\"  ^A\"  ^A\"  ^A\"  ^A\"HonggfuzzNetDriverPort HonggfuzzNetDriverArgsForServer HonggfuzzNetDriverTempdir HonggfuzzNetDriverServerAddress LLVMFuzzerInitialize LLVMFuzzerTestOneInput LIBHFNETDRIVER_module_netdriver  netdriver.o/    0           0     0     644     58648     `\r\n2021-12-18T19:22:17.5940789Z       |     ^\r\n...\r\n```\r\nTo get it around I replaced command lines like that with commands using temporary files.\r\n\r\nhonggfuzz was built using the top of the master branch (c83f254a) and below are the versions of the underlying compilers:\r\n```\r\n$ hfuzz-gcc --version\r\ngcc (GCC) 11.2.1 20211203 (Red Hat 11.2.1-7)\r\nCopyright (C) 2021 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n$ hfuzz-clang --version\r\nclang version 13.0.0 (Fedora 13.0.0-3.fc35)\r\nTarget: x86_64-redhat-linux-gnu\r\nThread model: posix\r\nInstalledDir: /usr/bin\r\n```\n Comments: \n Comment 0: Thanks for the report. Please try at https://github.com/google/honggfuzz/commit/4a2c88a2e7392462086d9fc03f002367a0f38440\n Comment 1: It seems to work in the the sense that I've just built elfutils successfully without my patches. Thanks!\r\n\r\nI'm not sure how honggfuzz is released but I think it would be great if this commit and most notably `--exit_code_upon_crash` could be included in the next release. Thanks again!\n Comment 2: Thanks for checking. Will do a release soon.",
  "Issue title: Pages 404 when upload files in my server\n Issue body: question:\n\nWhen I am finished I have the backend project, when I upload the files also upload files Phreeze???\nBecause I get 404 calls from api / hidraulicasanitarias? Page = 1 and others... I suspect it's something of the include / require and why the routing does not work well.\n\nMany Thanks to anyone who can help me :)\n\n Comments: \n Comment 0: It sounds like maybe on the server the rewrite extension is not enabled..?  If you're using Apache, then mod_rewrite needs to be enabled in order for the \"friendly\" URLs to work\n\n Comment 1: but, also, you can either upload the whole Phreeze library to the server or you can use the phreeze.phar file instead - the builder will give you the option to make your app \"self contained\" in which case you don't have to upload the Phreeze library folder.\n",
  "Issue title: Incorrect space deletion\u00a0after parenthesis\n Issue body: **TypeScript Version:** \u00a0master branch\r\n\r\n**Code**\r\n\r\n```ts\r\n({});\r\n```\r\n\r\n**Expected behavior:**\r\n\r\n```ts\r\n( {} ); // with insertSpaceAfterOpeningAndBeforeClosingNonemptyParenthesis\r\n```\r\n\r\n**Actual behavior:**\r\n\r\n```ts\r\n( {}); // with insertSpaceAfterOpeningAndBeforeClosingNonemptyParenthesis\r\n```\n Comments: \n Comment 0: thanks @flowmemo!",
  "Issue title: HTML Entities in Browser Title\n Issue body: ## Bug Report\r\n\r\n**Current Behavior**\r\nHTML Entities in browser title.\r\n\r\n**Steps to Reproduce**\r\n1. Create a post with a title that includes apostrophes\r\n2. Look at tab title\r\n\r\n**Screenshots**\r\n![](https://i.ibb.co/JK74kp9/Screen-Shot-2022-02-08-at-3-20-21-AM.png)\r\n\r\n**Environment**\r\n- Flarum version: 1.2\r\n- Website URL: https://discuss.flarum.org\r\n- Browser: Safari\n Comments: \n Comment 0: Thanks for the report!\r\n\r\nThis was fixed by a7254773dd1a22f43b1d7ee714fe29737ba9fa9f. :)",
  "Issue title: Autosuggest should show error message when no results found.\n Issue body: ### Expected behaviour\r\n\r\nIn the cases where activePeerSet was not called, calls to autosuggest search will respond with failure.\r\n\r\nIn such cases a default 'No results found' should appear in the dropdown. \r\n\r\nAlternatively find a better way to distinguish: \r\n\r\n- peers connectivity down\r\n- no results found\r\n\r\n\r\n### Actual behaviour\r\n\r\n### Steps to reproduce\r\n\n Comments: \n Comment 0: After giving this some thought, I would say that the logout should clear the account, but not the active peer. \r\nWe are already setting the active peer on starting the app:\r\nhttps://github.com/LiskHQ/lisk-hub/blob/cd367e3a4f567807c2d538fa4b3cb1bdc83dcd8a/src/store/middlewares/peers.js#L17-L18\r\nIt should however use last active network, instead of always Mainnet:\r\nhttps://github.com/LiskHQ/lisk-hub/blob/cd367e3a4f567807c2d538fa4b3cb1bdc83dcd8a/src/store/middlewares/peers.js#L10\n Comment 1: This one should be not a bug but enhancement with thoroughly specified requirements\n Comment 2: This issue is a result of the integration of two features: logged out dashboard and not-saving accounts anymore. Therefore it is not a product bug but unforeseen circumstances which were not specified. Specification should come then first",
  "Issue title: google\u691c\u7d22\u7d50\u679c\u306btitle\u3068description\u304c\u6b63\u3057\u304f\u53cd\u6620\u3055\u308c\u3066\u3044\u306a\u3044\n Issue body: ## \u8d77\u3053\u3063\u3066\u3044\u308b\u554f\u984c / The Problem\r\n- \u6771\u4eac\u90fd\u304b\u3089\u4ee5\u4e0b\u306e\u5831\u544a\u304c\u3042\u308a\u307e\u3057\u305f\u3002\r\n> Google\u3067\u300c\u5bfe\u7b56\u30b5\u30a4\u30c8\u300d\u3067\u691c\u7d22\u3057\u305f\u5834\u5408\r\n>![image002](https://user-images.githubusercontent.com/14883063/84722105-3fa9e500-afbd-11ea-9abb-af91e1ebd0f1.png)\r\n> title\u304c\u300c\u6771\u4eac\u90fd\u300d\u3068\u306a\u3063\u3066\u3057\u307e\u3063\u3066\u304a\u308a\u3001description \u306b\u306fJavaScript\u7121\u52b9\u306e\u969b\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u51fa\u3066\u3044\u307e\u3059\u3002\r\n> \u307e\u305f\u3001\u300c\u5bfe\u7b56\u30b5\u30a4\u30c8 \u6771\u4eac\u90fd\u300d\u3067\u691c\u7d22\u3057\u305f\u5834\u5408\u306b\u306f\r\n> title\u306f\u300c\u6771\u4eac\u90fd\u300d\u3001description\u306f\u300cLast update: 2020/06/14: This website was opened by the Tokyo Metropolitan Government to provide the latest information of COVID-19.\u300d\u304c\u8868\u793a\u3055\u308c\u307e\u3059\u3002\r\n> \u3061\u306a\u307f\u306bBing\u3067\u306f\u3069\u3061\u3089\u306e\u30ef\u30fc\u30c9\u691c\u7d22\u3067\u3082\r\n> title:\u6771\u4eac\u90fd \u65b0\u578b\u30b3\u30ed\u30ca\u30a6\u30a4\u30eb\u30b9\u611f\u67d3\u75c7 \u5bfe\u7b56\u30b5\u30a4\u30c8\r\n> description:2020/06/12 \u66f4\u65b0: \u5f53\u30b5\u30a4\u30c8\u306f\u65b0\u578b\u30b3\u30ed\u30ca\u30a6\u30a4\u30eb\u30b9\u611f\u67d3\u75c7 (COVID-19) \u306b\u95a2\u3059\u308b\u6700\u65b0\u60c5\u5831\u3092\u63d0\u4f9b\u3059\u308b\u305f\u3081\u306b\u3001\u6771\u4eac\u90fd\u304c\u958b\u8a2d\u3057\u305f\u3082\u306e\u3067\u3059\u3002\r\n> \u3068\u3001meta\u30bf\u30b0\u306b\u8a18\u8ff0\u3057\u305f\u3068\u304a\u308a\u8868\u793a\u3055\u308c\u308b\u3088\u3046\u3067\u3059\u3002\r\n\r\n- \u30b5\u30a4\u30c8\u30c8\u30c3\u30d7\u306b\u30b0\u30e9\u30d5\u985e\u306e\u30bf\u30d6\u5207\u66ff\u3092\u5b9f\u88c5\u3057\u305f\u969b\u306b\u3001\u30bf\u30d6\u306b\u30d1\u30fc\u30de\u30ea\u30f3\u30af\u3092\u6301\u305f\u305b\u305f\u306e\u3067\u3059\u304c\u3001[\u300c\u305d\u306e\u4ed6\u53c2\u8003\u6307\u6a19\u300d\u30bf\u30d6\u306b\u76f4\u63a5\u30a2\u30af\u30bb\u30b9](https://stopcovid19.metro.tokyo.lg.jp/?tab=reference)\u3067\u304d\u306a\u304b\u3063\u305f\u305f\u3081\u306b\uff08 #4706 \uff09`client-only`  \u3092\u4f7f\u3063\u305f\u306e\u304c\u526f\u4f5c\u7528\u3092\u3082\u305f\u3089\u3057\u3066\u3044\u308b\u306e\u3067\u306f\u306a\u3044\u304b\u3068\u601d\u3063\u3066\u3044\u307e\u3059\u3002\r\n\r\n## \u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 / Screenshot\r\n\u73fe\u5728\u306egoogle\u691c\u7d22\u7d50\u679c\r\n<img width=\"850\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2020-06-16 10 29 14\" src=\"https://user-images.githubusercontent.com/14883063/84722717-f65a9500-afbe-11ea-96c8-bb6c56d6aeaf.png\">\r\n<img width=\"850\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2020-06-16 10 31 16\" src=\"https://user-images.githubusercontent.com/14883063/84722733-007c9380-afbf-11ea-8058-552a37d7b39c.png\">\r\n\r\n\r\n## \u671f\u5f85\u3059\u308b\u898b\u305b\u65b9\u30fb\u6319\u52d5 / Expected Behavior\r\n- google\u691c\u7d22\u7d50\u679c\u306btitle\u3068description\u306e\u5185\u5bb9\u304c\u53cd\u6620\u3055\u308c\u308b\u3088\u3046\u306b\u306a\u308b\r\n\r\n## \u8d77\u3053\u3063\u3066\u3044\u308b\u554f\u984c\u306e\u518d\u73fe\u624b\u6bb5 / Steps to Reproduce\r\n1. google\u3067\u691c\u7d22\uff08\u691c\u7d22\u30ef\u30fc\u30c9\u306f\u300c\u5bfe\u7b56\u30b5\u30a4\u30c8\u300d\u300c\u6771\u4eac\u90fd \u30b3\u30ed\u30ca \u30b5\u30a4\u30c8\u300d\uff09\r\n\r\n## \u52d5\u4f5c\u74b0\u5883\u30fb\u30d6\u30e9\u30a6\u30b6 / Environment\r\n- macOS / Windows / Linux / iOS / Android\r\n- Chrome / Safari / Firefox / Edge / Internet Explorer\r\n\n Comments: \n Comment 0: \u3053\u3061\u3089\u5bfe\u5fdc\u3057\u307e\u3059\n Comment 1: \u3053\u3061\u3089\u306e\u4ef6\u3001 #4810 \u306ePR\u306b\u3088\u308a\u89e3\u6c7a\u3057\u305f\u3088\u3046\u306a\u306e\u3067\u30af\u30ed\u30fc\u30ba\u3057\u307e\u3059\u3002\r\n![google\u691c\u7d22](https://user-images.githubusercontent.com/14883063/84863369-c9d27600-b0af-11ea-9ff9-2905e0cebc8f.jpg)\r\n",
  "Issue title: Automate some management of open source repos\n Issue body: Some things to lighten the overall workload and get more done:\n- [ ] Every time a PR is created from an external contributor, add a comment that does the following:\n  - thanks them for the PR & says there will probably be a wait before a review is done\n  - if it is for a new feature, a summary of the feature must be described clearly in the PR text\n  - mentions requirements for PRs to be accepted: passing tests, tests for new code, minimal changes only, no development files, etc.\n  - asks to mention if they would rather a core contributor fix the PR themselves\n- [ ] Every time a PR is created from an external contributor, add the PR to the short term milestone so it will be triaged eventually.\n- [ ] Run code coverage for PRs to find out how much of PRs changes are covered.\n\nAll should be done by a bot.\n\n Comments: \n Comment 0: > thanks them for the PR & says there will probably be a wait before a review is done\r\n\r\nI don't like that one. It's very impersonal and something like this shouldn't be automated in a community where we welcome and appreciate contributions etc. IMO we should always thank contributors manually and ideally we should also work on the response time so they won't have to wait too long. At least a first feedback can be usually given quickly.\r\n\r\nAlso not sure re the others \"must do this, must mention that\". I reckon it always depends on the PR and the issue. If we consider ourselves too good for giving them such feedback when needed we should maybe ask users not to issue pull requests? The community was recently removed from our mission statement in https://github.com/piwik/piwik/issues/8518 but I think it should be still important to really appreciate and value contributions coming from the community.  \r\n\r\nI know it's meant in a good way and exaggerate maybe a little but personally I think it's very important to not have something like this automated. Are there other good community projects that automate these things? I wouldn't want to contribute to a project and having to deal with responses from a \"computer\" and even if it's only a first response.\r\n\r\nAlso I think we should add such PRs rather to the current milestone instead of short term milestone.\n Comment 1: > I don't like that one. It's very impersonal and something like this shouldn't be automated in a community where we welcome and appreciate contributions etc. IMO we should always thank contributors manually and ideally we should also work on the response time so they won't have to wait too long.\r\n\r\nWhat's the difference between an automated \"Thanks, you may have to wait\" and a manual \"Thanks, you may have to wait\"?\r\n\r\nThere will always be other priorities, and most of the PRs I've seen need a lot of work and guidance. And regardless of the potential value, if no one's paying for something, my priorities will likely be conducted elsewhere.\r\n\r\nCurrently, these PRs are greeted with silence. I assumed a message would be better. And unless you are willing to use your personal time to take care of all PRs from start to merge, while still finishing what's required of you in other areas, I don't believe these PRs will get attention w/o some sort of automation.\r\n\r\n>  If we consider ourselves too good for giving them such feedback when needed we should maybe ask users not to issue pull requests?\r\n\r\nWhat does it mean to be \"too good for giving them such feedback\"? You seem to be taking an awful lot of offence at the notion of an automated message.\r\n\r\n> Also I think we should add such PRs rather to the current milestone instead of short term milestone.\r\n\r\nMatt mentioned during the meetup he triages short-term issues. I assumed he would get to those if they were there. They should be put wherever they will be triaged.\n Comment 2: I said I'm exaggerating but think there's a huge difference when there's a personal message with a thumbs up (or thx) compared to a thx from a bot. \r\n\r\nI think it would be rather something for [guidelines for contributing](https://github.com/piwik/piwik/blob/master/CONTRIBUTING.md) which is also linked to when creating a new issue etc.\r\n\r\nI usually always try to give some feedback within a few days but doesn't always work. If this is a problem I can check more on it to give an initial feedback and maybe others can do too. At least to give a first rough feedback shouldn't take too long. We can provide a checklist which maybe also helps for developers and reviewers in the guidelines for contributions. \r\n\r\nI'd personally have rather no attention to a PR vs an automated message and nobody has a look afterwards either. PR's from users are highly valuable in such a community project that claims to have/be a community so maybe we can find ways and talk about some way to process these kinda reviews faster and more \"process controlled\". Instead of automating a \"please wait\" response I'd appreciate tools that help us manage these PRs. Eg showing which PRs from 3rd party haven't gotten any feedback within 5 days etc. Maybe there are existing tools for this or maybe we can build something for this? \r\n\r\nI don't have a problem having a look at them and I can fit it into my daily work. When I start working I always check my emails (follow up on existing issues etc), new issues, whether there are PR reviews to be made, then work on my own PRs that require change because of reviews and then for the rest of the day ignore everything and work on my actual issues.\r\n\r\n`short-term` is usually a milestone were more and more issues are put into but we don't work on them. It's unrealistic to say these issues will be worked on in the next months. Especially now that we focus bit more on other work. When working on the open source project we will work on Piwik 3.0 and probably no `short-term` issue will be touched in like next 6 months (just a rough guess). Meaning we would not give any feedback to PRs in months. Would be good to have them in the current spring so it will also make sure we actually work on getting them merged. If a developer doesn't get feedback after a while we can still move it into `short-term` until a developer worked on it again. \r\n\r\nIn general I think we should rather focus on finding ways to get PRs merged faster etc (we had this discussion for PRs from core developers but not really for 3rd party developers). Eg it may help to assign a PR to a core developer and to move it into current sprint. This would at least help me in having an overview of the work I need to do and where I need to follow up.\n Comment 3: > I don't have a problem having a look at them and I can fit it into my daily work.\n\nAs you will then.\n\n Comment 4: I'm not sure if we should close it as I think we can automate other things as mentioned in the previous comment. Eg we could automise to which PRs we need to pay attention. Eg we could have a \"dashboard\" listing all new PRs, PRs that were changed in any way by the developer or other non-core developers (new commits, comments,...) and PRs that were not changed in the last 7 days. Maybe bit like a Kanban dashboard. \n\nQuickly googled for \"GitHub reviews\" and there came up eg https://reviewable.io/ which seems to \"only\" make it easier to review code, http://gerrithub.io/ where it says you can define a workflow and it seems to help manage external contributors etc, there's https://www.codereviewhub.com/ which adds tasks for each code comment in the review. I'm sure by finding a way to merge and handle 3rd party PRs better we also improve the workflow for our own PRs. Possibly it's also possible to find PRs that need attention with Github just by using the right queries.\n\nAlso we could discuss how to make sure we follow up on these issues. As said for me personally it would help to have them in current milestone and assigned to a person so I can check which work is left to be done.\n\n Comment 5: > IMO we should always thank contributors manually and ideally we should also work on the response time so they won't have to wait too long. At least a first feedback can be usually given quickly.\r\n\r\n:+1: \r\n\r\nwe need someone in the team who will be responsible and taking care of this, maybe @tsteur you'd like to try over next few months?\r\n\r\n> Possibly it's also possible to find PRs that need attention with Github just by using the right queries.\r\n\r\nas a start here is a Github issue search that will [list all Pull requests that are opened and not yet assigned a milestone.](https://github.com/issues?utf8=%E2%9C%93&q=is%3Aopen+is%3Apr+user%3Apiwik+-repo%3Apiwik%2Freferrer-spam-blacklist+no%3Amilestone+-repo%3Apiwik%2Fpiwik-mobile-2+-repo%3Apiwik%2Fpiwik-dotnet-tracker+-repo%3Apiwik%2Fpiwik-python-api+-repo%3Apiwik%2Fpiwik-ruby-api",
  "Issue title: Is the method MetricRegistry.getOrAdd() threadsafe?\n Issue body: Assume the metrics map doesn't contain a counter named 'Count1'. \r\nWhen two threads get into this method simultaneously and the method get() return null.  Then they try to register one new instance under the given name respectively. One will create the metric instance successfully and the other will cause a IllegalArgumentException.\r\n\r\nAm I right? Does this method getOrAdd() need to be synchronized?\r\n   ` \r\n@SuppressWarnings(\"unchecked\")\r\n    private <T extends Metric> T getOrAdd(String name, MetricBuilder<T> builder) {\r\n        final Metric metric = metrics.get(name);\r\n        if (builder.isInstance(metric)) {\r\n            return (T) metric;\r\n        } else if (metric == null) {\r\n            try {\r\n                return register(name, builder.newMetric());\r\n            } catch (IllegalArgumentException e) {\r\n                final Metric added = metrics.get(name);\r\n                if (builder.isInstance(added)) {\r\n                    return (T) added;\r\n                }\r\n            }\r\n        }\r\n        throw new IllegalArgumentException(name + \" is already used for a different type of metric\");\r\n    }`\n Comments: \n Comment 0: You're right, but the 2nd thread will catch that IllegalArgumentException [here](https://github.com/dropwizard/metrics/blob/c309a8b55880dc6022e666e7c231d5a897f74140/metrics-core/src/main/java/com/codahale/metrics/MetricRegistry.java#L318), retrieve the counter created by the 1st thread, and return it. Because of this and that the Map in use is a `ConcurrentHashMap`, synchronization is not required.",
  "Issue title: Website buttons on certain pages dont fully display embedded image\n Issue body: This should have the facebook logo displayed in it.\r\n\r\n![screen shot 2018-10-10 at 11 13 05 pm](https://user-images.githubusercontent.com/39230578/46780455-6570e800-cd0c-11e8-9eb9-3ab537a853c2.png)\r\n\n Comments: \n Comment 0: This appears to work for me in my latest build.. and for you? (testing heavily my latest ContentPolicy changes... so testing random websites and noticed)\n Comment 1: Still flaky on a few sites for me. Probably slight differences in our installed packages for our build environments.\n Comment 2: Do you have references to these flaky site so we can try who.18 performs?",
  "Issue title: Results the same every time data is polled\n Issue body: Code keeps a cached copy of the data and doesn't re-download. This is fine when pulling data that doesn't change but if you are trying to pull the market price periodically it doesn't work.\r\n\r\nMaybe provide a switch for deactivating the cache?\n Comments: \n Comment 0: Create a new instance of the object when you want fresh data.",
  "Issue title: Netlify cms\n Issue body: ---\r\nname: Bug report\r\nabout: Code blocks\r\n---\r\n\r\n<!-- Please don't delete this template because we'll close your issue -->\r\n<!-- Before creating an issue please make sure you are using the latest version of the starter. -->\r\n<!-- This project is starter project using Gatsby and NetlifyCMS in it, if you think the issue can originate from upstream then please report it-->\r\n# Bug report\r\n\r\n<!-- Please ask questions on Spectrum for Gatsby questions or the Gitter channel for NetlifyCMS. -->\r\n<!-- https://spectrum.chat/?t=da07ec65-96f9-41be-baf0-0271b5b772ef -->\r\n<!-- https://gitter.im/netlify/NetlifyCMS -->\r\n<!-- Issues which contain questions or support requests will be closed. -->\r\n\r\n**What is the current behavior?**\r\nI dont know if this is for here or netlify cms specific but when i add a code block to site is saves as inline code ie `<html><body><p>example p tag</p></body></html>` on both netlify cms as well as in the starter site even tho in the cms i add line breaks\r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce.**\r\n\r\n\r\n<!-- A great way to do this is to provide your configuration via a GitHub repository -->\r\n<!-- The most helpful is a minimal reproduction with instructions on how to reproduce -->\r\n<!-- Please only add small code snippets directly into this issue -->\r\n<!-- https://gist.github.com is a good place for longer code snippets -->\r\n<!-- If your issue is caused by a plugin or loader, please create an issue on the loader/plugin repository instead -->\r\n\r\n**What is the expected behavior?**\r\n`\r\n<html>\r\n<body>\r\n<p>example p tag</p>\r\n</body>\r\n</html>\r\n`\r\n\r\n<!-- \"It should work\" is not a helpful explanation -->\r\n<!-- Explain exactly how it should behave -->\r\n\r\n**Other relevant information:**\r\n\r\n<!--Run `gatsby info --clipboard` in your project directory and paste the output here. Not working? You may need to update your global gatsby-cli - `npm install -g gatsby-cli` -->\r\n\r\nNode.js version:  v10.15.3\r\nNPM/Yarn version: v1.13.0\r\nOperating System: linux mint 19.1\r\nAdditional tools:\r\n\n Comments: \n Comment 0: I don't think embedding code example is working in the current version of NetlifyCMS. @erquhart Can you confirm my suspicion? If not, is there a documentation on how to fix this? i can't seem to find anything related to this\n Comment 1: You need to add a gatsby plugin to handle code examples,[see how NetlifyCMS website is handling this](https://github.com/netlify/netlify-cms/blob/63582dcbc7920cfcc09551926d898060a689cb24/website/gatsby-config.js#L59), apart from that i found that they include the [prismjs style explicitly in the temaplate](https://github.com/netlify/netlify-cms/blob/63582dcbc7920cfcc09551926d898060a689cb24/website/src/templates/doc-page.js#L4)\r\n\n Comment 2: ok thanks!",
  "Issue title: HTTP Port unification does not work\n Issue body: # Description #\r\n----------\r\n\r\nFollowing the Glassfish WIKIs description on how to do port unification (HTTP->HTTPS) results in a ClassCastException and the HTTP port not being usable.\r\n\r\nhttps://glassfish.java.net/wiki-archive/GlassFish%20MS3%20Port%20Unification%20Demo.html\r\n\r\nAttention: Change the mentioned classes package names with `org.glassfish.grizzly.config.portunif` 'cause the demo operates on Grizzly 1.x.\r\n\r\n## Expected Outcome\r\n\r\nA proper forward to the HTTPS port.\r\n\r\n## Current Outcome\r\n\r\n`[2017-03-20T11:26:12.395+0100] [Payara 4.1] [WARNING] [] [org.glassfish.grizzly.filterchain.DefaultFilterChain] [tid: _ThreadID=85 _ThreadName=http-thread-pool38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5http-listener-1(3)] [timeMillis: 1490005572395] [levelValue: 900] [[\r\n  GRIZZLY0013: Exception during FilterChain execution\r\njava.lang.ClassCastException: org.glassfish.grizzly.memory.HeapMemoryManager$TrimmableHeapBuffer cannot be cast to org.glassfish.grizzly.http.HttpContent\r\n\tat org.glassfish.grizzly.config.portunif.HttpRedirectFilter.handleRead(HttpRedirectFilter.java:99)\r\n\tat org.glassfish.grizzly.filterchain.ExecutorResolver$9.execute(ExecutorResolver.java:119)\r\n\tat org.glassfish.grizzly.filterchain.DefaultFilterChain.executeFilter(DefaultFilterChain.java:284)\r\n\tat org.glassfish.grizzly.filterchain.DefaultFilterChain.executeChainPart(DefaultFilterChain.java:201)\r\n\tat org.glassfish.grizzly.filterchain.DefaultFilterChain.execute(DefaultFilterChain.java:133)\r\n\tat org.glassfish.grizzly.filterchain.DefaultFilterChain.process(DefaultFilterChain.java:112)\r\n\tat org.glassfish.grizzly.ProcessorExecutor.execute(ProcessorExecutor.java:77)\r\n\tat org.glassfish.grizzly.portunif.PUFilter.handleRead(PUFilter.java:231)\r\n\tat org.glassfish.grizzly.filterchain.ExecutorResolver$9.execute(ExecutorResolver.java:119)\r\n\tat org.glassfish.grizzly.filterchain.DefaultFilterChain.executeFilter(DefaultFilterChain.java:284)\r\n\tat org.glassfish.grizzly.filterchain.DefaultFilterChain.executeChainPart(DefaultFilterChain.java:201)\r\n\tat org.glassfish.grizzly.filterchain.DefaultFilterChain.execute(DefaultFilterChain.java:133)\r\n\tat org.glassfish.grizzly.filterchain.DefaultFilterChain.process(DefaultFilterChain.java:112)\r\n\tat org.glassfish.grizzly.ProcessorExecutor.execute(ProcessorExecutor.java:77)\r\n\tat org.glassfish.grizzly.nio.transport.TCPNIOTransport.fireIOEvent(TCPNIOTransport.java:526)\r\n\tat org.glassfish.grizzly.strategies.AbstractIOStrategy.fireIOEvent(AbstractIOStrategy.java:112)\r\n\tat org.glassfish.grizzly.strategies.WorkerThreadIOStrategy.run0(WorkerThreadIOStrategy.java:117)\r\n\tat org.glassfish.grizzly.strategies.WorkerThreadIOStrategy.access$100(WorkerThreadIOStrategy.java:56)\r\n\tat org.glassfish.grizzly.strategies.WorkerThreadIOStrategy$WorkerThreadRunnable.run(WorkerThreadIOStrategy.java:137)\r\n\tat org.glassfish.grizzly.threadpool.AbstractThreadPool$Worker.doWork(AbstractThreadPool.java:591)\r\n\tat org.glassfish.grizzly.threadpool.AbstractThreadPool$Worker.run(AbstractThreadPool.java:571)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n]]`\r\n\r\n## Steps to reproduce (Only for bug reports) \r\n\r\n1 -**  Start the domain\r\n\r\n   ./asadmin start-domain domain1\r\n\r\n2 -**  Make changes to the domain.xml configuration:\r\n\r\n\tFollow the steps in the GF WIKI: https://glassfish.java.net/wiki-archive/GlassFish%20MS3%20Port%20Unification%20Demo.html\r\n\r\nAttention: Change the mentioned classes package names with `org.glassfish.grizzly.config.portunif`.\r\n\r\n## Environment ##\r\n\r\n- **Payara Version**: 116.69.203.115.0.1\r\n- **Edition**: FULL\r\n- **JDK Version**: 116.69.203.115\r\n- **Operating System**: Linux, Mac\r\n\r\n\n Comments: \n Comment 0: Greetings @svendiedrichsen, \r\n\r\nPayara Server already uses port unification for its admin web console when the secure admin listener is enabled. In this case, the protocol` pu-protocol` and the HTTP Protocol finder` http-finder` are already available from the go. I've tested this behaviour and the recommended way to proceed is to run the following asadmin commands from a fresh domain:\r\n\r\n```shell\r\nasadmin enable-secure-admin\r\nasadmin create-protocol http-redirect\r\nasadmin create-protocol-filter --protocol http-redirect --classname org.glassfish.grizzly.config.portunif.HttpRedirectFilter redirect-filter\r\nasadmin create-protocol-finder --protocol pu-protocol --targetprotocol http-redirect --classname org.glassfish.grizzly.config.portunif.HttpProtocolFinder http-redirect\r\nasadmin set configs.config.server-config.network-config.network-listeners.network-listener.http-listener-1.protocol=pu-protocol\r\n```\r\n\r\nThis way, you'll end up with the following configuration in the domain.xml:\r\n\r\n```xml\r\n<protocol name=\"sec-admin-listener\" security-enabled=\"true\">\r\n  <http encoded-slash-enabled=\"true\" default-virtual-server=\"__asadmin\">\r\n    <file-cache></file-cache>\r\n  </http>\r\n  <ssl classname=\"com.sun.enterprise.security.ssl.GlassfishSSLImpl\" client-auth=\"want\" cert-nickname=\"fturizo_certificate\"></ssl>\r\n</protocol>\r\n<protocol name=\"admin-http-redirect\">\r\n  <http-redirect secure=\"true\"></http-redirect>\r\n</protocol>\r\n<protocol name=\"http-redirect\">\r\n  <protocol-chain-instance-handler>\r\n    <protocol-chain>\r\n      <protocol-filter classname=\"org.glassfish.grizzly.config.portunif.HttpRedirectFilter\" name=\"redirect-filter\"></protocol-filter>\r\n    </protocol-chain>\r\n  </protocol-chain-instance-handler>\r\n</protocol>\r\n<protocol name=\"pu-protocol\">\r\n  <port-unification>\r\n    <protocol-finder protocol=\"sec-admin-listener\" classname=\"org.glassfish.grizzly.config.portunif.HttpProtocolFinder\" name=\"http-finder\"></protocol-finder>\r\n    <protocol-finder protocol=\"admin-http-redirect\" classname=\"org.glassfish.grizzly.config.portunif.HttpProtocolFinder\" name=\"admin-http-redirect\"></protocol-finder>\r\n    <protocol-finder protocol=\"http-redirect\" classname=\"org.glassfish.grizzly.config.portunif.HttpProtocolFinder\" name=\"http-redirect\"></protocol-finder>\r\n  </port-unification>\r\n</protocol>\r\n<network-listeners>\r\n  <network-listener protocol=\"pu-protocol\" port=\"8080\" name=\"http-listener-1\" thread-pool=\"http-thread-pool\" transport=\"tcp\"></network-listener>\r\n  <network-listener protocol=\"http-listener-2\" port=\"8181\" name=\"http-listener-2\" thread-pool=\"http-thread-pool\" transport=\"tcp\"></network-listener>\r\n  <network-listener protocol=\"pu-protocol\" port=\"4848\" name=\"admin-listener\" thread-pool=\"admin-thread-pool\" transport=\"tcp\"></network-listener>\r\n</network-listeners> \r\n```\r\n\r\nAnd the port unification should work out without issues.\n Comment 1: Thank you very much, I'll check this out.",
  "Issue title: YOLO-lablImg \n Issue body: I'm trying to train the program, and I not sure what the problem is.\r\n\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n_np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n_np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n_np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n_np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nnp_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nnp_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py_init.py:36: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.\r\nfrom._conv import register_converters as _register_converters\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n_np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n_np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n_np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n_np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n_np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\nC:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nnp_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0924 00:52:29.(843)631-5690 deprecation_wrapper.py:119] From C:\\pythonwork\\darkflow-master\\darkflow\\net\\build.py:15: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\r\n\r\nW0924 00:52:29.(843)631-5690 deprecation_wrapper.py:119] From C:\\pythonwork\\darkflow-master\\darkflow\\net\\build.py:16: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\r\n\r\nW0924 00:52:29.(843)631-5690 deprecation_wrapper.py:119] From C:\\pythonwork\\darkflow-master\\darkflow\\net\\build.py:17: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\r\n\r\nW0924 00:52:29.(843)631-5690 deprecation_wrapper.py:119] From C:\\pythonwork\\darkflow-master\\darkflow\\net\\build.py:18: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\r\n\r\nW0924 00:52:29.(843)631-5690 deprecation_wrapper.py:119] From C:\\pythonwork\\darkflow-master\\darkflow\\net\\build.py:19: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\r\n\r\nParsing cfg/model.cfg\r\nTraceback (most recent call last):\r\nFile \"flow\", line 6, in \r\ncliHandler(sys.argv)\r\nFile \"C:\\pythonwork\\darkflow-master\\darkflow\\cli.py\", line 26, in cliHandler\r\ntfnet = TFNet(FLAGS)\r\n",
  "Issue title: Add Custom Template\n Issue body: --add custom template like from -- https://github.com/jeretc/cfp\n Comments: \n Comment 0: @jepunband I'll add this but captive portal is useful in mitm attack like spawning a fake AP then redirect victim to fake portal page to capture creds.I'll still add this just to extend the functionality of the tool.\n Comment 1: @An0nUD4Y next time when you gonna release something please use \"pre-release\" tag\n Comment 2: Too old... Not respond....\r\nSuggestions not applied...\r\nOpen Again if Have any quory..",
  "Issue title: No traffic captured\n Issue body: Hello,\r\n\r\nI have problems getting any traffic using mitmf. Tried non-https sites. Check Wireshark, packages from target system are picked up. Installed from git. Added upsidedownternet just to easily see if it works. Sometimes it takes several tries to resolve MAC address, but after resolving, nothing happens. \r\n\r\nSetup:\r\n```\r\nTarget router ip: 116.69.203.115, open connection\r\nTarget system ip: 116.69.203.115, connected by separate wifi adapter\r\nKali on VM, with TP-Link TL-WN722N adapter, connected to the router, ip 116.69.203.115\r\n```\r\n\r\nCommand:\r\n```\r\npython mitmf.py -i wlan0 --spoof --arp --gateway 116.69.203.115 --target 116.69.203.115 --log-level debug --upsidedownternet\r\n```\r\n\r\nOutput:\r\n```\r\n v0.9.8 - 'The Dark Side'\r\n|\r\n|_ Net-Creds v1.0 online\r\n2015-09-02 02:10:01 [ProxyPlugins] Adding Spoof plugin\r\n|_ Spoof v0.6\r\n2015-09-02 02:10:01 [ARPpoisoner] gatewayip  => 116.69.203.115\r\n2015-09-02 02:10:01 [ARPpoisoner] gatewaymac => e8:39:df:29:6c:08\r\n2015-09-02 02:10:01 [ARPpoisoner] targets    => [IPAddress('116.69.203.115')]\r\n2015-09-02 02:10:01 [ARPpoisoner] ignore     => []\r\n2015-09-02 02:10:01 [ARPpoisoner] ip         => 116.69.203.115\r\n2015-09-02 02:10:01 [ARPpoisoner] mac        => c4:e9:84:0d:57:e4\r\n2015-09-02 02:10:01 [ARPpoisoner] interface  => wlan0\r\n2015-09-02 02:10:01 [ARPpoisoner] arpmode    => rep\r\n2015-09-02 02:10:01 [ARPpoisoner] interval   => 3\r\n2015-09-02 02:10:01 [Utils] Setting ip forwarding to 1\r\n|  |_ ARP spoofing enabled\r\n2015-09-02 02:10:01 [ProxyPlugins] Adding Upsidedownternet plugin\r\n|_ Upsidedownternet v0.1\r\n|_ Sergio-Proxy v0.2.1 online\r\n|_ SSLstrip v0.9 by Moxie Marlinspike online\r\n|\r\n|_ MITMf-API online\r\n * Running on http://116.69.203.115:9999/ (Press CTRL+C to quit)\r\n|_ HTTP server online\r\n|_ DNSChef v0.4 online\r\n|_ SMB server online\r\n\r\n2015-09-02 02:10:03 [ARPpoisoner] Resolved 116.69.203.115 => 6c:71:d9:f2:ee:6d\r\n ```\r\n\r\nOS:\r\n```\r\nAttack OS: Kali 2.0\r\nVictim OS: Windows 8.1; Firefox 40.0.3\r\n```\r\n\r\npip freeze:\r\n```\r\n(MITMf)root@kali:~/MITMf# pip freeze\r\nbeautifulsoup4==4.4.0\r\ncapstone==3.0.4\r\ncffi==1.2.1\r\ncharacteristic==14.3.0\r\nchardet==2.3.0\r\nconfigobj==5.0.6\r\ncryptography==1.0\r\ndnslib==0.9.4\r\ndnspython==1.12.0\r\nenum34==1.0.4\r\nFlask==0.10.1\r\nidna==2.0\r\nipaddress==1.0.14\r\nIPy==0.83\r\nitsdangerous==0.24\r\nJinja2==2.8\r\nlxml==3.4.4\r\nMarkupSafe==0.23\r\nmsgpack-python==0.4.6\r\nnetaddr==0.7.17\r\nNetfilterQueue==0.6\r\npefile==1.2.10.post114\r\nPillow==2.9.0\r\npyasn1==0.1.8\r\npyasn1-modules==0.0.7\r\npycparser==2.14\r\npycrypto==2.6.1\r\npyinotify==0.9.6\r\npyOpenSSL==0.15.1\r\npypcap==1.1.3\r\npython-magic==0.4.6\r\nrequests==2.7.0\r\nscapy==2.3.1\r\nservice-identity==14.0.0\r\nsix==1.9.0\r\nTwisted==15.3.0\r\nua-parser==0.3.6\r\nuser-agents==0.3.2\r\nWerkzeug==0.10.4\r\nwheel==0.24.0\r\nzope.interface==4.1.2\r\n```\n Comments: \n Comment 0: Hi,\r\n\r\nAs your scenario says it seems arp poisoner does not work correctly, you can verify this condition by using `arp -a` command on target and see if router mac is the same as kali mac address.\r\n\r\nSo Please check #178 issue (https://github.com/byt3bl33d3r/MITMf/issues/178) and its probable fix commit.\r\n\r\nYou can make the changes manually and revert back then.\r\n\r\nAlso repeat running MITMf multiple times to see if it happens frequently or not.\r\n\r\nAnd if it is possible please verify your situation on seprated environment which target can be a phone or another pc.\r\n\r\n@byt3bl33d3r, sorry for interrupting ;)\r\n\r\nThank you\n Comment 1: Maybe the same problem? \r\nhttps://github.com/byt3bl33d3r/MITMf/issues/180\n Comment 2: @micapoltron thanks for the well written report\r\nyesterday I introduced a bug that was causing iptables to not set the rules for HTTP redirection, do a git pull and everything should be back to normal, If not comment below \r\n\r\nThanks \n Comment 3: thanks byt3bl33d3r!\n Comment 4: @byt3bl33d3r Thanks for quick reply\r\nPulled the changes, and everything works.\r\nMuch obliged!\n Comment 5: What do you mean by git pull it didn't work for me\r\n\n Comment 6: port 9999 having same issue even if i change port under mitmf api i changed to 333 and this port nor 9999 is being used also fixed networking and interface problem this script is one of the best it would be nice to get a tutor i am just begginer but love coding and have alittle free time to do so anyways i definetly want to understand my issue more and seek to further my knowloledge love name btw good alias \n Comment 7: also running linux mint 18 xfce 64 bit using katoolin as install source for kali tools \n Comment 8: [*] MITMf v0.9.8 - 'The Dark Side'\r\n|_ Inject v0.4\r\n|_ Spoof v0.6\r\n|  |_ ARP spoofing enabled\r\n|\r\n|_ Sergio-Proxy v0.2.1 online\r\n|_ SSLstrip v0.9 by Moxie Marlinspike online\r\n|\r\n|_ Net-Creds v1.0 online\r\n|_ MITMf-API online\r\nError starting HTTP server: [Errno 98] Address already in use\r\n|_ HTTP server online\r\nException in thread mitmfapi:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/usr/share/mitmf/core/mitmfapi.py\", line 90, in startFlask\r\n    app.run(debug=False, host=self.host, port=self.port)\r\n  File \"/usr/lib/python2.7/dist-packages/flask/app.py\", line 841, in run\r\n    run_simple(host, port, self, **options)\r\n  File \"/usr/lib/python2.7/dist-packages/werkzeug/serving.py\", line 708, in run_simple\r\n    inner()\r\n  File \"/usr/lib/python2",
  "Issue title: Move tetgen external to superbuild\n Issue body: For the SCIRun 5 build, move tetgen out of the Externals folder and add to super build. Issue #1240 depends on this.\n\n Comments: \n Comment 0: Completed in 1a0f49319891ae15c654447a4abd663dbc34174a.",
  "Issue title: news.yahoo.co.jp\n Issue body: \r\n### Issue URL (Social Widget)\r\n [https://news.yahoo.co.jp/articles/e286a12998c670616980846dfe44957792108e83](https://adguardteam.github.io/AnonymousRedirect/redirect.html?url=https%3A%2F%2Fnews.yahoo.co.jp%2Farticles%2Fe286a12998c670616980846dfe44957792108e83)\r\n### Comment\r\n> \u30c4\u30a4\u30c3\u30bf\u30fc\u306e\u5171\u6709\u30dc\u30bf\u30f3\u304c\u3042\u308a\u307e\u3059\u3002\r\n\r\n### Screenshots\r\n<details>\r\n  <summary>Screenshot 1</summary>\r\n\r\n ![Screenshot 1](https://reports-img.adguard.com/TLyxp3e.png)\r\n</details>\r\n\r\n### System configuration\r\n\r\nInformation | value\r\n--- | ---\r\nAdGuard product: | AdGuard Browser extension v3.6.17\r\nBrowser: | Chrome\r\nStealth mode: | disabled\r\nFilters: | <b>Ad Blocking:</b><br/>AdGuard Base<br/><br/><b>Privacy:</b><br/>AdGuard URL Tracking, <br/>AdGuard Tracking Protection<br/><br/><b>Social Widgets:</b><br/>AdGuard Social Media<br/><br/><b>Annoyances:</b><br/>AdGuard Annoyances<br/><br/><b>Other:</b><br/>AdGuard Experimental<br/><br/><b>Language-specific:</b><br/>AdGuard Japanese\n Comments: \n Comment 0: \r\n### Issue URL (Incorrect Blocking)\r\n [https://news.yahoo.co.jp/pickup/6417551](https://adguardteam.github.io/AnonymousRedirect/redirect.html?url=https%3A%2F%2Fnews.yahoo.co.jp%2Fpickup%2F6417551)\r\n### Comment\r\n> Click comment\r\n> ||approach.yahoo.co.jp^$removeparam=src,badfilter\r\n\r\n### Screenshots\r\n<details>\r\n  <summary>Screenshot 1</summary>\r\n\r\n ![Screenshot 1](https://reports-img.adguard.com/CtFkIuI.png)\r\n</details>\r\n<details>\r\n  <summary>Screenshot 2</summary>\r\n\r\n ![Screenshot 2](https://reports-img.adguard.com/5CkMj1F.png)\r\n</details>\r\n\r\n### System configuration\r\n\r\nInformation | value\r\n--- | ---\r\nPlatform: | Android 12\r\nAdGuard product: | AdGuard for Android v3.6.7\r\nBrowser: | Chrome\r\nAdGuard mode: | VPN\r\nFiltering quality: | High-quality\r\nHTTPS filtering: | enabled\r\nStealth mode: | disabled\r\nDNS filtering: | disabled\r\nFilters: | <b>Ad Blocking:</b><br/>AdGuard Base, <br/>AdGuard Mobile Ads<br/><br/><b>Privacy:</b><br/>AdGuard Tracking Protection, <br/>AdGuard URL Tracking<br/><br/><b>Social Widgets:</b><br/>AdGuard Social Media<br/><br/><b>Annoyances:</b><br/>AdGuard Annoyances<br/><br/><b>Language-specific:</b><br/>AdGuard Japanese\r\nUserscripts: | disabled",
  "Issue title: Add CONTRIBUTING.md\n Issue body: For the same reasons as https://github.com/openhatch/oh-mainline/issues/1560\n Comments: \n Comment 0: :+1:\n Comment 1: @pdurbin Are you waiting for me to do this or am I waiting for a PR from you? :)\n Comment 2: @prologic I think you should write it up since you'll know best how people can effectively contribute.\n Comment 3: Okay :)\n\n\nJames Mills / prologic\n\nE: gutierrezcheryl@example.com\nW: prologic.shortcircuit.net.au\n\nOn Sun, Apr 19, 2015 at 10:30 PM, Philip Durbin <gutierrezcheryl@example.com>\nwrote:\n\n> @prologic <https://github.com/prologic> I think you should write it up\n> since you'll know best how people can effectively contribute.\n>\n> \u2014\n> Reply to this email directly or view it on GitHub\n> <https://github.com/circuits/circuits/issues/14#issuecomment-94271348>.\n>\n\n Comment 4: Came across [CONTRIBUTING.md](http://contribute.md/)\r\n\r\nGoing to use this as a template :)\n Comment 5: @pdurbin @spaceone @y0no Any thoughts on this? Feedback? :)\n Comment 6: See PR #71 \n Comment 7: I'm okay with that\n Comment 8: :+1: ",
  "Issue title: Truncate statement not recognized\n Issue body: Statement does not exist in ABAPv755(or parser error).\r\nStatement exist even in 755.\r\n\r\ndata:\r\n  i_filename type c length 255 value '/user/sap/data/....'.\r\n\r\ntruncate dataset i_filename at current position.\n Comments: \n Comment 0: ```abap\r\ndata i_filename type c length 255 value '/user/sap/data/....'.\r\ntruncate dataset i_filename at current position.\r\n```\n Comment 1: heh, there are always more ABAP statements :)",
  "Issue title: Cannot remove telescope-tags package\n Issue body: Using \"meteor remove telescope-tags\" to remove telescope-tags package, telescope-tags is removed in /.meteor/packages.\r\nHowever, pparker@example.com is still in /.meteor/versions, even remove it manually. \r\n\r\nIs it due to no version # in /packages/telescope-tags/package.js?\n Comments: \n Comment 0: That's strange\u2026 In any case if the package is not in `/packages` I don't think it can be loaded. \n Comment 1: Is it due to no version number in /packages/telescope-tags/package.js?\r\nThe default version number is 0.0.0\n Comment 2: Maybe, but I don't think so. It might just be a bug in Meteor? Are you sure the package is really loaded? Do categories still appear in the app?\n Comment 3: Yes, it might be a bug in Meteor.\r\n\r\nYou can run \"meteor remove telescope-tags\" and \"git status\"\r\nGet \"modified:  .meteor/packages\"\r\nBut no \"modified:  .meteor/versions\"\r\n\r\nThe package is loaded and categories still appears.\n Comment 4: Hmm\u2026 So the package really is removed from `.meteor/packages` but still\ngets loaded? That's definitely a bug.\n\nOn Sun, Apr 12, 2015 at 1:03 PM, xuanus <pparker@example.com> wrote:\n\n> Yes, it might be a bug in Meteor.\n>\n> You can run \"meteor remove telescope-tags\" and \"git status\"\n> Get \"modified:.meteor/packages\"\n> But no \"modified:.meteor/versions\"\n>\n> The package is loaded and categories still appears.\n>\n> \u2014\n> Reply to this email directly or view it on GitHub\n> <https://github.com/TelescopeJS/Telescope/issues/901#issuecomment-91983433>\n>.\n>\n",
  "Issue title: unable to find/test antd component which appears outside wrapper\n Issue body: MyComponent\r\n```\r\nimport React, { Component } from \"react\";\r\nimport { connect } from \"react-redux\";\r\nimport moment from \"moment\";\r\nimport { Select, Dropdown, Menu, Button, Table } from \"antd\";\r\nimport ShowConfirm from \"../../../../../common/widgets/ModalConfirmation\";\r\nimport UploadDocument from \"../../Modals/UploadDocument\";\r\nimport { manageRfq } from \"../../../duck/actions\";\r\nconst { Option } = Select;\r\nconst dateFormat = \"DD MMM YYYY\";\r\n\r\nconst columns = [\r\n  {\r\n    title: \"Type\",\r\n    dataIndex: \"documentType\",\r\n    render: text => (\r\n      <p className={`doc-type-${text}`} style={{ fontSize: \"16px\" }}>\r\n        {text}\r\n      </p>\r\n    )\r\n  },\r\n  {\r\n    title: \"File Name\",\r\n    dataIndex: \"fileName\",\r\n    render: value => {\r\n      return <span style={{ fontSize: \"16px\" }}>{value}</span>;\r\n    }\r\n  },\r\n  {\r\n    title: \"Date\",\r\n    dataIndex: \"date\",\r\n    render: text => <p style={{ fontSize: \"16px\" }}>{moment(text).format(dateFormat)}</p>\r\n  }\r\n];\r\n\r\nexport const selectType = (type, documentData) => {\r\n  switch (type) {\r\n    case \"ALL\":\r\n      return documentData;\r\n    case \"INTERNAL\":\r\n      return documentData.filter(x => x.documentType === \"INTERNAL\");\r\n    case \"EXTERNAL\":\r\n      return documentData.filter(x => x.documentType === \"EXTERNAL\");\r\n    default:\r\n      return documentData;\r\n  }\r\n};\r\n//this component is opening outside root component\r\nconst menuAction = ({ flag, onUploadHandle, deleteHandle, downloadHandle }) => (\r\n  <Menu className=\"actions-wrapper\">\r\n    <Menu.Item key=\"external-doc\" onClick={onUploadHandle}>\r\n      Add External Document\r\n    </Menu.Item>\r\n    <Menu.Item key=\"internal-doc\" onClick={onUploadHandle}>\r\n      Add Internal Document\r\n    </Menu.Item>\r\n    <Menu.Item onClick={downloadHandle} disabled={flag}>\r\n      Download\r\n    </Menu.Item>\r\n    <Menu.Item onClick={deleteHandle} disabled={flag} className={flag? \"\" : \"delete-document\"}>\r\n      Delete\r\n    </Menu.Item>\r\n  </Menu>\r\n);\r\n\r\nexport class DocumentsTab extends Component {\r\n  constructor(props) {\r\n    super(props);\r\n    this.state = {\r\n      selectedDocs: [],\r\n      newDocs: [],\r\n      loading: false,\r\n      type: \"ALL\",\r\n      documents: [],\r\n      isDraggerDisabled: false,\r\n      visible: false,\r\n      selectedRowKeys: []\r\n    };\r\n    this.selectDocumentTyepHandler = this.selectDocumentTyepHandler.bind(this);\r\n    this.onUploadHandler = this.onUploadHandler.bind(this);\r\n    this.deleteHandler = this.deleteHandler.bind(this);\r\n    this.downloadHandler = this.downloadHandler.bind(this);\r\n    this.clearTable = this.clearTable.bind(this);\r\n    this.onSelectChange = this.onSelectChange.bind(this);\r\n  }\r\n\r\n  static getDerivedStateFromProps(props, state) {\r\n    if (props.rfqDto) {\r\n      return {\r\n       ...state,\r\n        documents: [...props.rfqDto.internalDocumentListDtos,...props.rfqDto.externalDocumentListDtos]\r\n      };\r\n    }\r\n    return null;\r\n  }\r\n\r\n  selectDocumentTyepHandler(value) {\r\n    this.setState({ type: value });\r\n  }\r\n\r\n  onAdd = response => {\r\n    let newData = [];\r\n    newData.push(response);\r\n    this.setState({\r\n      newDocs: [...newData]\r\n    });\r\n  };\r\n\r\n  deleteHandler(e) {\r\n    const { selectedDocs } = this.state;\r\n    const { clearTable } = this;\r\n    const { uuid, deleteDocumentBulk } = this.props;\r\n    const uuidArr = selectedDocs.map(a => a.uuid);\r\n    ShowConfirm({\r\n      title: \"Confirmation\",\r\n      content: <p>Are you sure to delete {selectedDocs.length} document(s)?</p>,\r\n      okText: \"Confirm\",\r\n      cancelText: \"Cancel\",\r\n      onOk() {\r\n        deleteDocumentBulk(uuid, uuidArr, clearTable);\r\n      }\r\n    });\r\n  }\r\n  downloadHandler() {\r\n    const uuidArr = this.state.selectedDocs.map(a => a.uuid);\r\n    this.props.downloadDocument(this.props.uuid, uuidArr);\r\n  }\r\n\r\n  onUploadHandler(e) {\r\n    this.setState({ visible:!this.state.visible, typeKey: e.key });\r\n  }\r\n\r\n  highlighter = (record, index) => {\r\n    let highlightClassName;\r\n    this.state.newDocs.forEach(re => {\r\n      if (re.uuid === record.uuid) {\r\n        highlightClassName = \"highlight-doc\";\r\n      }\r\n    });\r\n    return highlightClassName;\r\n  };\r\n  clearTable() {\r\n    // ajax request after empty completing\r\n    this.setState({\r\n      selectedRowKeys: []\r\n    });\r\n  }\r\n  onSelectChange(selectedRowKeys, selectedRows) {\r\n    this.setState({ selectedRowKeys, selectedDocs: selectedRows });\r\n  }\r\n\r\n  render() {\r\n    const { selectedDocs, selectedRowKeys } = this.state;\r\n    const rowSelection = {\r\n      selectedRowKeys,\r\n      onChange: this.onSelectChange\r\n    };\r\n\r\n    return (\r\n      <div className=\"document-tab-wrapper\">\r\n        <div style={{ marginTop: \"40px\", marginBottom: \"15px\" }}>\r\n          <div className=\"bullet-points-container\">\r\n            <p className=\"bullets\">1</p> <p>MANAGE RFQ DOCUMENTS</p>\r\n          </div>\r\n          <h5>Type of Documents</h5>\r\n          <Select defaultValue=\"All\" style={{ width: 400, height: 50 }} onChange={this.selectDocumentTyepHandler}>\r\n            <Option value=\"ALL\">All</Option>\r\n            <Option value=\"EXTERNAL\">External Document</Option>\r\n            <Option value=\"INTERNAL\">Internal Document</Option>\r\n          </Select>\r\n          <br />\r\n          <Dropdown\r\n            overlay={menuAction({\r\n              flag: selectedDocs.length === 0,\r\n              onUploadHandle: this.onUploadHandler,\r\n              deleteHandle: this.deleteHandler,\r\n              downloadHandle: this.downloadHandler\r\n            })}\r\n            placement=\"bottomLeft\">\r\n            <Button>More Actions</Button>\r\n          </Dropdown>\r\n        </div>\r\n        <div>\r\n          <Table\r\n            rowSelection={rowSelection}\r\n            columns={columns}\r\n            dataSource={selectType(this.state.type, this.state.documents)}\r\n            pagination={false}\r\n            rowClassName={this.highlighter}\r\n          />\r\n        </div>\r\n        <UploadDocument\r\n          type={this.state.typeKey === \"internal-doc\"? \"INTERNAL\" : \"EXTERNAL\"}\r\n          uuid={this.props.uuid}\r\n          uploadSupportingDocument={this.props.uploadSupportingDocument}\r\n          onAdd={this.onAdd}\r\n          isModalVisible={this.state.visible}\r\n          onModalVisible={() => {\r\n            this.setState({ visible:!this.state.visible });\r\n          }}\r\n        />\r\n      </div>\r\n    );\r\n  }\r\n}\r\nexport function mapStateToProps(state) {\r\n  return {\r\n    rfqDto: state.manageRFQ.rfqDto\r\n  };\r\n}\r\n\r\nconst actionCreators = {\r\n  getSupportingDocument: manageRfq.getSupportingDocument,\r\n  downloadDocument: manageRfq.downloadDocument,\r\n  deleteDocumentBulk: manageRfq.deleteDocumentBulk,\r\n  uploadSupportingDocument: manageRfq.uploadSupportingDocument\r\n};\r\n\r\nexport default connect(\r\n  mapStateToProps,\r\n  actionCreators\r\n)(DocumentsTab);\r\n\r\n```\r\n\r\nTest\r\nDrpdown list is opening outside the root component \r\n```\r\ndescribe(\"DocumentsTab\", () => {\r\n  let wrapper;\r\n  beforeEach(() => {\r\n    const component = (\r\n      <MemoryRouter>\r\n        <DocumentsTab />\r\n      </MemoryRouter>",
  "Issue title: Use Base64 string as source\n Issue body: Hi,\r\n\r\nIs it possible to use a base64 string a source?\n Comments: \n Comment 0: Yes. See this [example](https://cdn.pannellum.org/2.2/pannellum.htm?panorama=data:image/jpeg;base64,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",
  "Issue title: \u4e0a\u62c9\u5230\u5e95\u90e8,\u52a0\u8f7d\u66f4\u591a\u7684\u65f6\u5019,\u5feb\u901f\u5f80\u4e0a\u5212\u4e00\u4e0b,\u6709\u65f6\u4f1a\u89e6\u53d1\u4e24\u6b21onLoadNextPage,\u5bfc\u81f4\u6570\u636e\u91cd\u590d\n Issue body: \u53ef\u80fd\u662f\u6211\u6ca1\u7528\u5bf9,\u4e5f\u53ef\u80fd\u786e\u6709bug\r\n\u76ee\u524d\u6682\u65f6\u89e3\u51b3\u529e\u6cd5\u662f\u5728EndlessRecyclerOnScrollListener\u4e2d\u7684onScrollStateChanged()\u65b9\u6cd5\u4e2d\u8fdb\u884c\u5224\u65ad;\r\n\u5982\u679c\u8ddd\u4e0a\u6b21\u89e6\u53d1onScrollStateChanged()\u65f6\u95f4\u4e0d\u52301\u79d2\u5c31\u76f4\u63a5return.\r\n\u4e0d\u77e5\u9053\u6709\u6ca1\u6709\u66f4\u597d\u7684\u89e3\u51b3\u529e\u6cd5\r\n\u6211\u7528\u7684\u4e0d\u662f\u6700\u65b0\u7248,\u7531\u4e8e\u6211\u76ee\u524d\u662f\u76f4\u63a5\u6539\u4e86EndlessRecyclerOnScrollListener, \u5e76\u6ca1\u6709\u76f4\u63a5\u6362\u6700\u65b0.\r\n\u4e0d\u77e5\u9053\u6700\u65b0\u7248\u8fd8\u6709\u6ca1\u6709\u8fd9\u4e2a\u95ee\u9898\r\n\r\n\u53e6\u5916,\r\n\u6709\u65f6\u5019\u5212\u52a8\u5230\u5e95\u90e8\u5df2\u7ecf\u6ca1\u6709\u66f4\u591a\u6570\u636e,\u4f46footer\u4ecd\u7136\u662floading\u72b6\u6001,  \u9700\u8981\u7a0d\u5fae\u4e0b\u62c9\u518d\u4e0a\u5212\u624d\u53d8\u6210end\u72b6\u6001\n Comments: \n Comment 0: > \u8c22\u8c22\u53cd\u9988\u54c8\r\n\r\n### \u91cd\u590d\u52a0\u8f7d\u95ee\u9898\r\nEndlessRecyclerOnScrollListener\u8fd9\u4e2a\u7c7b\u6539\u6389\u4e86\uff0c\u4f60\u770b\u4e0b\u6709\u6ca1\u6709\u52a0\u8f7d\u4e2d\u7684\u5224\u65ad\u3002\r\n\r\n\u4e0d\u77e5\u9053\u4ec0\u4e48\u65f6\u5019\u7684\u7248\u672c\uff0c\u73b0\u5728\u5982\u679c\u52a0\u8f7d\u4e2d\uff0c\u76f4\u63a5\u5ffd\u7565\u3002\r\n\u589e\u52a0\u4e86\u65b9\u6cd5\uff1amRefreshRecyclerView.loadMoreComplete();\r\n\r\n```\r\n// LinearLayoutWithRecyclerOnScrollListener.java\r\n    @Override\r\n    public void onScrolled(RecyclerView recyclerView, int dx, int dy) {\r\n        super.onScrolled(recyclerView, dx, dy);\r\n        if (!isLoading()) {\r\n            visibleItemCount = recyclerView.getChildCount();\r\n            totalItemCount = mLinearLayoutManager.getItemCount();\r\n            firstVisibleItem = mLinearLayoutManager.findFirstVisibleItemPosition();\r\n\r\n            //totalItemCount > visibleItemCount load more\r\n            if (loadMoreEnable &&!loading && totalItemCount > visibleItemCount && (totalItemCount - visibleItemCount) <= (firstVisibleItem + visibleThreshold)) {\r\n                // End has been reached\r\n                loading = true;\r\n                pagination++;\r\n                onLoadMore(pagination, pageSize);\r\n            }\r\n        }\r\n    }\r\n```\r\n### footer\u4ecd\u7136\u662floading\u72b6\u6001\r\n\u6bcf\u6b21\u6570\u636e\u52a0\u8f7d\u5b8c\u6210\u540e(\u4e0d\u7ba1\u6210\u529f\u3001\u5931\u8d25)\uff0c\u9700\u8981mRefreshRecyclerView.hideFooterView();\r\n```\r\n        public void onSuccess(S result) {\r\n            if (result == null || (result instanceof List && ((List)result).size() == 0)) {\r\n                if (isDataEmpty()) {\r\n                    showDataEmptyView();\r\n                } else {\r\n                    showNoMoreDataView();\r\n                    mRefreshRecyclerView.disableLoadMore();\r\n                }\r\n            } else {\r\n                if (isRefresh) {\r\n                    onRefreshDataSuccess(result);\r\n                } else {\r\n                    onLoadMoreDataSuccess(result);\r\n                }\r\n                hideLoadMoreView();\r\n                currPage++;\r\n            }\r\n        }\r\n\r\n        @Override\r\n        public void onAfter() {\r\n            if(isRefresh){\r\n                hideRefreshView();\r\n            }\r\n            mRefreshRecyclerView.loadMoreComplete();\r\n            if(!isDataEmpty()){\r\n                hideDataEmptyView();\r\n            }\r\n        }\r\n```\r\n\r\n\u8fd9\u4e9b\u72b6\u6001\u7684\u5207\u6362\u662f\u5f88\u9ebb\u70e6\uff0c\u7b49\u51e0\u5929\u628a\u6211\u7684\u4e8c\u6b21\u5c01\u88c5\u653e\u4e0a\u6765\u3002\n Comment 1: ###\u53ef\u4ee5\u53c2\u8003\uff1a\r\n[BaseRecyclerActivity](https://github.com/captain-miao/RecyclerViewUtils/blob/master/app/src/main/java/com/github/learn/base/BaseRecyclerActivity.java)\r\n[RefreshRecyclerActivity](https://github.com/captain-miao/RecyclerViewUtils/blob/master/app/src/main/java/com/github/learn/refreshandload/RefreshRecyclerActivity.java)\n Comment 2: thks",
  "Issue title: Japscan failed again\n Issue body: > **From:** HakuNeko User\n\n**Version:** [6.1.7@fa9106](https://github.com/manga-download/hakuneko/commits/fa9106)\n\nThank you for you job! But there are no amelioration with japscan...it always failed..\n\n<details><summary>What has been done?</summary>\n\n\n\n</details>\n Comments: \n Comment 0: I also observed that the japscan site still does not work unfortunately. The download goes wrong from the start. \r\nI tested with the Linux version of HakuNeko and I observe the same problem...\r\n\r\nThank you again for your work!\n Comment 1: See #1451 \r\nTry to increase throttling for JapScan in settings",
  "Issue title: Q_ASSERT in InspectorServerQt\n Issue body: Steps to reproduce:\r\n\r\n1. Open remote WebInspector page\r\n2. And close it immediately\r\n3. Q_ASSERT on https://github.com/annulen/webkit/blob/qtwebkit-stable/Source/WebKit/qt/WebCoreSupport/InspectorServerQt.cpp#L312 will fail.\n Comments: \n Comment 0: Does it reproduce with legacy QtWebKit?\n Comment 1: Yes.\n Comment 2: If you identified source of issue, maybe you can provide fix?",
  "Issue title: Diagnosing HMC: Energy Distribution\n Issue body: To better diagnose HMC, in particular the choice of kinetic energy and adaptation thereof, it may be worthwhile to provide metrics that compare the marginal and conditional (on a particular location) energy distributions. As explain on p. 28 in [1], mismatch between the two may greatly negatively impact performance of the sampler. A simple metric to compute is outlined in Section 6.1, also in [1]. \r\n\r\n[1] https://arxiv.org/pdf/1701.02434.pdf\n Comments: \n Comment 0: Closed by https://github.com/TuringLang/AdvancedHMC.jl/pull/5",
  "Issue title: how to scroll source panel?\n Issue body: when using coffeescript, the source panel of the transliterated javascript does not have a scroll bar.  How do I see the javascript code that is rendered below the viewport?\n\n Comments: \n Comment 0: This is a bug. I will get it fixed in a few days and let you know.\n\nOn Sun, 28 Jul 2013 15:38:59 -0400, rickdog joshuabowman@example.net  \nwrote:\n\n> when using coffeescript, the source panel of the transliterated  \n> javascript does not have a scroll bar. How do I see the javascript code  \n> that is >rendered below the viewport?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub.\n\n Comment 1: It's been fixed on the site. \n\n Comment 2: thank you kindly\n\nOn Sun, Jul 28, 2013 at 6:18 PM, Yuguang Zhang joshuabowman@example.net:\n\n> It's been fixed on the site.\n> \n> \u2014\n> Reply to this email directly or view it on GitHubhttps://github.com/yuguang/fiddlesalad/issues/22#issuecomment-21693368\n>.\n\n Comment 3: No problem, thanks for reporting it. I think the bug showed up after the  \nrecent upgrade of the editor library. The version on the site now also  \nshows JavaScript errors in the result window. For CoffeeScript, it shows  \non hover.\n\nOn Sun, 28 Jul 2013 20:01:20 -0400, rickdog joshuabowman@example.net  \nwrote:\n\n> thank you kindly\n> \n> On Sun, Jul 28, 2013 at 6:18 PM, Yuguang Zhang  \n> joshuabowman@example.net:\n> \n> > It's been fixed on the site.\u2014Reply to this email directly or view it on  \n> > GitHubhttps://github.com/yuguang/fiddlesalad/issues/22#issuecomment-21693368 \n> >.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub.\n\n Comment 4: thank you, you have the best jsfiddle-like clone out there!  Many very nice\nfeatures.\n\nOn Sun, Jul 28, 2013 at 7:17 PM, Yuguang Zhang joshuabowman@example.net:\n\n> No problem, thanks for reporting it. I think the bug showed up after the\n> recent upgrade of the editor library. The version on the site now also\n> shows JavaScript errors in the result window. For CoffeeScript, it shows\n> on hover.\n> \n> On Sun, 28 Jul 2013 20:01:20 -0400, rickdog joshuabowman@example.net\n> wrote:\n> \n> > thank you kindly\n> > \n> > On Sun, Jul 28, 2013 at 6:18 PM, Yuguang Zhang\n> > joshuabowman@example.net:\n> > \n> > > It's been fixed on the site.\u2014Reply to this email directly or view it on\n> > > GitHub<\n> > > https://github.com/yuguang/fiddlesalad/issues/22#issuecomment-21693368>\n> > >.\n> > \n> > \u2014\n> > Reply to this email directly or view it on GitHub.\n> \n> \u2014\n> Reply to this email directly or view it on GitHubhttps://github.com/yuguang/fiddlesalad/issues/22#issuecomment-21694262\n>.\n",
  "Issue title: Update text for unlinking third party account\n Issue body: From https://github.com/mozilla/fxa-content-server-l10n/pull/554, we should update the text per l10n request.\n Comments: \n Comment 0: \u27a4 Bianca Oltean commented:\n\nThis ticket is verified as done on Production [Train 227.1] under Windows 10 64-bit. The text is correctly updated. See new situation:\n\n!unlink account modal.PNG|width=359,height=288!",
  "Issue title: In getFeatureInfo, add an easy way to search all pixels in requested map\n Issue body: **Reporter: mraross**\n**Date: 2010/10/08 - 03:04**\n**Trac URL:** http://trac.osgeo.org/mapserver/ticket/3561\nIn the common getFeatureInfo scenario, a client app requests attributes of the feature under or near the cursor (see attached searchPixelsnearCursor.jpg). This is conveniently specified using &x, &y, and &radius parameters. \nIn another, less common but important scenario, an client app requests attributes of all features within the current &width and &height of the requested map (see attached searchAllPixels.jpg). It isn't possible to specify this in terms of &x, &y, and &radius from some clients such as Google Earth since it requires a the runtime computation of &width/2,&height/2, etc.  We propose an adding support for an additional boolean parameter called &searchAllPixels that, if set to true, means that &width and &height should be used to define the search extent instead of &x, &y, and &radius; if false, search extent is determined by &x, Y, and &radius.  By default, &searchAllPixels=false.\n\n Comments: \n Comment 0: **Author: assefa**\n**Date: 2010/11/16 - 00:34**\nI understand the issue but I am not sure how this will be received by others. We are going outside the specs of getfeatureinfo. \nI am thinking of maybe using a specific word like allmap for radius that could indicate to set query tolerance to the map->widtth/height.\n\n Comment 1: **Author: assefa**\n**Date: 2010/11/16 - 00:34**\nWould this be acceptable if others agree?\n\n Comment 2: **Author: chodgson**\n**Date: 2011/01/22 - 01:30**\nThis simple patch checks for radius=allmap and sets the query point to the center of the map and the radius to the smaller of half the width or half the height. It is important that the radius define a circle which is inscribed within the map rectangle because if features are selected that are not within the map, the [shplabel] template tag will not work (mraross is requesting this feature specifically for use with custom template-driven kml output).\n\n Comment 3: **Author: chodgson**\n**Date: 2011/01/22 - 01:34**\nNote that it is not possible to support actually querying the whole map using a bbox rather than a radius query (while also supporting the feature_count limit), without either putting in a big inefficient hack, or implementing the fix to #2424.\n\n Comment 4: **Author: assefa**\n**Date: 2011/01/24 - 20:52**\nwill review/commit before 6.0\n\n Comment 5: **Author: chodgson**\n**Date: 2011/01/27 - 02:17**\nmraross decided that the circular query (as radius would normally be) is not acceptable and he wants allmap functionality to instead do a rectangular bbox query, while still maintaining the feature_count limit. \n\nBecause msQueryByRect doesn't support the query.maxresults limit, I implemented a new version which does (msQueryByRectWithLimit), and when radius=allmap, this function is called instead of msQueryByPoint. It is possible that msQueryByRectWithLimit could just replace the existing msQuerByRect, but I'm not sure if the query.maxresults limit may be set in other circumstances, causing unintended side effects, so this is a bit of an ugly copy/past hack. It uses the same inefficient two-stage query and then filter/limit technique as is used in msQueryByPoint, because I don't currently have the time or budget to look at fixing #2424 properly.\n\nThis feature isn't required for raster layers, so I haven't implemented a msQueryRasterByRectWithLimit - querying a raster layer with radius=allmap will ignore the feature_limit.\n\n Comment 6: **Author: assefa**\n**Date: 2011/02/01 - 15:38**\nThis is beyond the initial bug description. Adding other in cc to have their opinion.\n\n Comment 7: **Author: sdlime**\n**Date: 2011/03/03 - 05:52**\nI guess I have the most heartburn with adding another query method. I suppose it would be ok to leave it in as a place holder now with the intent of removing it when proper maxresults support is added to ALL query functions. Now (6.0's) the time in some respects to do stuff like implement maxresults... I'd like Dan to weigh in as one of the WMS gurus.\n\nFor what it's worth I would just do radius=bbox. As I understand it that's what you're after, a bbox query. So it would make sense to let the radius reference the bbox parameter name.\n\nSteve\n\n Comment 8: **Author: assefa**\n**Date: 2011/03/22 - 21:26**\nany news on this? \n\n Comment 9: **Author: chodgson**\n**Date: 2011/03/29 - 23:21**\nI think Steve was looking for some input or approval from Dan? I'm happy to change the name of the magic parameter from allmap to bbox.\n\nThe reason I added the additional query method was because I wasn't sure what side effects might occur if the existing queryByRect was changed to obey the maxfeatures limit which it ignored before... based on the fact that queryByRect is used to get all the features in the bbox for rendering, etc, it seemed likely that something could go wrong by just adding in the limiting code.\n\n Comment 10: **Author: dmorissette**\n**Date: 2011/04/06 - 03:34**\nI'm fine with adding radius=bbox from a WMS perspective. Makes sense as a vendor-specific extension, and I think Assefa agrees with that too.\n\n Comment 11: **Author: sdlime**\n**Date: 2011/04/06 - 20:47**\nI'd like to avoid a custom query function though. Can we rely on similar max results support that the WFS server has? That is, set layer->maxresults and rely on the drivers to respect that.\n\nSteve\n\n Comment 12: **Author: dmorissette**\n**Date: 2011/04/06 - 21:28**\nI agree that we should try to handle the max results the same way as WFS GetFeature does.\n\nWho is taking the lead on this? It's getting quite late for 6.0 (technically we're past feature freeze and this doesn't qualify as a bug fix). Can we push this to 6.2?\n\n Comment 13: **Author: chodgson**\n**Date: 2011/04/06 - 21:46**\nDan, I'm doing this work. \n\nIn my testing, the WFS GetFeature max_features parameter doesn't actually work, if you also supply a bbox filter. Otherwise we could probably just use that. So there you go, now it's a bug ;) - however I wasn't actually addressing fixing this at this time. The \"right\" fix, as I mentioned before, is implementing more generic handling of all filtering, ideally passing it down to the drivers as per #2424. Unfortunately my client didn't really have the budget for that and also would really like it in 6.0.\n\nTell me what I can do to make that happen... I don't think #2424 is going to fly before 6.0. I'd like to see #2424 done though... seems like it could clean up a lot of things.\n\n Comment 14: **Author: chodgson**\n**Date: 2011/04/06 - 22:16**\nOK so re-reading the latest comments on #2424 and following the link to #3739 it seems like these are heavily intertwined. Once all the drivers support maxfeatures then we can do this using the same query method as WFS GetFeatures does, getting rid of the ugly extra query method hack.\n\nIIRC, when I started looking at this 2 months ago, I tested using WFS getfeature with max features and a bbox filter and one of the two was ignored, because msQueryBy... method that was called simply ignored that part of the filter. This was testing against a shapefile.\n\n Comment 15: **Author: sdlime**\n**Date: 2011/04/08 - 16:10**\nIf Chris readies a patch I can review/apply. While it is late in the game this functionality is isolated and doesn't impact anything existing.\n\nChris, we're looking for a patch against mapwms.c that handles the radius=bbox parameter. The patch should take take value for layer->maxfeatures from metadata as in WFS if available.  I guess I'd look for wms_, ows_ or wfs_ maxfeatures in that order.\n\nThe query functions will rely on the drivers to support layer->maxfeatures. Shapefile, PostGIS and Oracle all do and those are the biggies. So I don't think there's a need for a specialized bbox query file.\n\nWe'll address #2424/#3739 across",
  "Issue title: Support Overhang Problem \n Issue body: _2.3.1+win64\r\n\r\nwindows 10 home \r\n\r\nmodified anycubic i3 mega with Klipper firmware\r\n\r\nIn the settings, my support contact distance is 0.2mm, but when the supports are generated the 0.2mm clearance is from a little extrusion trying to support the hole. So the clearance from the flat surface of the overhang to the part of the support that touches it is 0.6mm not 0.2mm. This leads to having really bad overhangs that are barely supported because the support interface is so far away from the actual overhang, not the hole. \r\n\r\n\r\n[3mf.zip](https://github.com/prusa3d/PrusaSlicer/files/6360850/3mf.zip)\r\n![Capture](https://user-images.githubusercontent.com/65318265/115775802-2b1a4400-a368-11eb-963d-82ee89f2df96.JPG)\r\n![Capture1](https://user-images.githubusercontent.com/65318265/115776122-9f54e780-a368-11eb-850c-e1170a146ff0.JPG)\r\n![Capture2](https://user-images.githubusercontent.com/65318265/115776124-9fed7e00-a368-11eb-8b01-2fff03fc059f.JPG)\r\n![Capture3](https://user-images.githubusercontent.com/65318265/115776126-9fed7e00-a368-11eb-87e4-794778d58df2.JPG)\r\n\r\n\r\n\n Comments: \n Comment 0: > that touches it is 0.6mm not 0.2mm\r\nIt is related to thick bridge flow used for bottom most layer of the supported object. It is correct (0.2mm contact distance + 0.4mm round extrusion). See #102 and other linked issues for more information.\r\n\r\nWe have recently added a new parameter, that will allow to optionally disable standard thick bridges. See https://github.com/prusa3d/PrusaSlicer/issues/102#issuecomment-802206617. This option will be available in PS2.4.0.\r\n\r\n `To improve quality of the object over support, we have added a new settings: \"thick bridges\". If enabled (that is by default), PrusaSlicer behaves as before. If disabled, bridges are printed as in any other slicer: The extrusion rate is given by the normal layer height x extrusion width * bridge flow ratio.`\r\n\r\nYou can reduce your contact Z distance value to improve the result.\r\n\r\nClosing.\n Comment 1: Oh, so the bridge layer is thicker than the 0.2mm layer height",
  "Issue title: Permissons: IdentityBadge not vertically aligned\n Issue body: We probably forgot to update the padding and widths when we upgraded aragonUI:\r\n\r\n<img width=\"1184\" alt=\"Screen Shot 2019-03-15 at 1 42 04 PM\" src=\"https://user-images.githubusercontent.com/4166642/54435357-38e05280-4728-11e9-93fb-f47c84dde5d0.png\">\r\n\n Comments: \n Comment 0: Looks like this was fixed with `@rosebrandy@example.org` \ud83c\udf89 ",
  "Issue title: Appium Locator displayed unknown symbols\n Issue body: ## Appium Desktop\r\n\r\n## The problem\r\nAppium Locator displayed unknown symbols in the `Selected Element` window\r\n\r\n\r\n## Environment\r\n\r\n- I am running Appium Desktop version _Version 1.15.1 (116.69.203.11591013.2)_.\r\n- I am on (pick one):\r\n    - [x] Mac\r\n    - [ ] Windows\r\n    - [ ] Linux\r\n<img width=\"1007\" alt=\"Screen Shot 2020-03-06 at 16 32 17\" src=\"https://user-images.githubusercontent.com/44227371/76092764-a2581180-5fc8-11ea-935d-436e568eb9a1.png\">\n Comments: \n Comment 0: What about them in the result of `source` command?\n Comment 1: Perhaps https://github.com/appium/appium-desktop/pull/1348 fixed this, too",
  "Issue title: :db/default attribute operation broken?\n Issue body: Hi, \r\n\r\nSubmitting a tx-doc with a [:db/default value] results in\r\n```\r\nERROR com.biffweb.impl.middleware - Exception while handling request\r\njava.lang.IllegalArgumentException: Don't know how to create ISeq from: clojure.lang.Keyword\r\n```\r\n\r\nThe stack trace ends in `apply-special-vals`, and an inspection seems to reveal an inconsistency in the return value of the `:db/default` case.\r\n\r\nhttps://github.com/jacobobryant/biff/blob/92a03324f98836d579878fc669eb702746551858/src/com/biffweb/impl/xtdb.clj#L182\r\n\n Comments: \n Comment 0: Thanks for fixing that! Very embarrassing :). I'll add a test for that and the other operations soon. ",
  "Issue title: phyDat:arguments imply differing number of rows: \n Issue body: Hello,\r\nI am trying to read a.fasta file through function phyDat, however, it showed that Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE, :\r\narguments imply differing number of rows: 300, 311, 309, 307, 302, 331, 328, 329, 312, 298, 292, 293, 297, 274, 276, 322.\r\n\r\nMy coding as follows:\r\nlibrary(\"ape\")\r\nlibrary(Biostrings)\r\nlibrary(\"seqinr\")\r\nlibrary(\"phangorn\")\r\n\r\npwp <- read.phyDat(file.path(\"~/Desktop/bioinformatic/project/phylogenetics\", \"PF02171_seed.fasta\"),type=\"AA\", format = \"fasta\")\r\n\r\nparsimony(treeNJ, pwp,method = \"sankoff\")\r\npwtreePars <- optim.parsimony(treeNJ, pwp,method = \"sankoff\")\r\nplot(pwtreePars, \"unrooted\", main=\"parsimony\")\r\n\r\nThe.fasta file is a multiple sequence seed alignment download from pfam. Can anyone tell me where the problem is?\r\n\r\nThank you\n Comments: \n Comment 0: Hi @SHIGURREE,\r\n\r\nthe sequences in the fasta file have different length and need to be aligned first.\r\n```\r\npwp <- read.FASTA(file.path(\"~/Desktop/bioinformatic/project/phylogenetics\", \"PF02171_seed.fasta\", type=\"AA\")\r\nlengths(pwp)\r\n```\r\nThe lengths of these amino acids should vary.  \r\n\r\nIf you want to align these sequences inside R, there are some possibilities using the ape package (`?muscle` assuming you have installed these programs on your machine) or you can use the `msa` package from bioconductor. \r\n\r\nI made some small change inside `read.phyDat` to catch this error and return a warning message (commit 7248b29bcd253d899b236c759d482dc195120307).  \r\n\r\nRegards, \r\nKlaus\r\n \r\n",
  "Issue title: Get rid of references to nctoolbox google code site\n Issue body: We still have references to the google code site, which users find confusing.\n\nLet's move any remaining documentation to github\n\nWhat still needs to be done?\n\n Comments: \n Comment 0: I think we still need to finish moving documentation from the google site to github. I don't suppose anyone on your end is working on that?\n\n Comment 1: I could do some of this if I knew what to move.  @acrosby do you remember what is still left to be done?\n(I can just poke around and try to figure it out, but if you remember what you have already done and what is left to do, we could itemize it in this issue).\n\n Comment 2: bump.\n\nIt looks like none of the http://code.google.com/p/nctoolbox/wiki/Documentation is ported over here.  The tutorial and reference documentation is helpful.\n\nAck.  There seems to be help on the http://nctoolbox.github.io/nctoolbox/ but where is the code or whatever for it?  It seems to show a working demos/geodemo4 somehow: http://nctoolbox.github.io/nctoolbox/demos/geodemo_4.html \n\nEdit: the code for some of the help stuff is on the https://github.com/nctoolbox/nctoolbox/tree/gh-pages while there is other help on the https://github.com/nctoolbox/nctoolbox/wiki link.\n\n Comment 3: I think the only remaining references to googlecode are to:\n- html5shiv.googlecode.com/svn/trunk/html5.js in some headers\n- some help files where it refers to the old site explicitly.\n- Issue #41 or GC Issue# 27\n\n Comment 4: html5shiv is a reference to an external javascript library. Please do not change the reference. \n\n Comment 5: It looked like it was important, and probably not what this ticket was about.\n",
  "Issue title: apt.txt is installed after R, but user is NB_USER not root\n Issue body: ### Bug description\r\nReported in\r\nhttps://discourse.jupyter.org/t/binder-failing-to-build-when-using-apt-txt-for-r-package-dependencies/12659\r\n\r\nIt sounds like R dependencies are installed before `apt.txt`. The last R installation script currently runs as `NB_USER` (changed in https://github.com/jupyterhub/repo2docker/pull/1104):\r\n\r\nhttps://github.com/jupyterhub/repo2docker/blob/a37a205c0e8a59240933d20c1c4fb80767e71db2/repo2docker/buildpacks/r.py#L347-L357\r\n\r\nwhereas previously it ran as `root`\r\nhttps://github.com/jupyterhub/repo2docker/blob/d688997aeec52ff1898265bccf1bbfd5a56f6a3f/repo2docker/buildpacks/r.py#L317-L327\r\n\r\nhttps://github.com/jupyterhub/repo2docker/blob/a37a205c0e8a59240933d20c1c4fb80767e71db2/repo2docker/buildpacks/base.py#L473-L474\r\nonly checks whether the requested user is `root`, it doesn't check what the _actual_ user is, so NB_USER remains in the Dockerfile and therefore `apt.txt` fails.\r\n\r\n### How to reproduce\r\n\r\nhttps://mybinder.org/v2/gh/admivsn/r_with_python/f74afef0105dfae48bf5b4a552a44a392092e7d7\r\n\r\nExample log below:\r\n\r\n<details>\r\n\r\n```\r\nWaiting for build to start...\r\nPicked Git content provider.\r\nCloning into '/tmp/repo2dockercni2iasz'...\r\nHEAD is now at f74afef Create apt.txt\r\nBuilding conda environment for python=3.7Using RBuildPack builder\r\nBuilding conda environment for python=3.7Building conda environment for python=3.7Step 1/69 : FROM buildpack-deps:bionic\r\n ---> 872a6bfe806a\r\nStep 2/69 : ENV DEBIAN_FRONTEND=noninteractive\r\n ---> Using cache\r\n ---> 5429cf904159\r\nStep 3/69 : RUN apt-get -qq update &&     apt-get -qq install --yes --no-install-recommends locales > /dev/null &&     apt-get -qq purge &&     apt-get -qq clean &&     rm -rf /var/lib/apt/lists/*\r\n ---> Using cache\r\n ---> 3a6d744f8fc2\r\nStep 4/69 : RUN echo \"en_US.UTF-8 UTF-8\" > /etc/locale.gen &&     locale-gen\r\n ---> Using cache\r\n ---> 3e5043c5a3b9\r\nStep 5/69 : ENV LC_ALL en_US.UTF-8\r\n ---> Using cache\r\n ---> f6d7dfc1fd91\r\nStep 6/69 : ENV LANG en_US.UTF-8\r\n ---> Using cache\r\n ---> 6f250ad18d9c\r\nStep 7/69 : ENV LANGUAGE en_US.UTF-8\r\n ---> Using cache\r\n ---> 46a25e22e1b9\r\nStep 8/69 : ENV SHELL /bin/bash\r\n ---> Using cache\r\n ---> 22aaa3abc963\r\nStep 9/69 : ARG NB_USER\r\n ---> Using cache\r\n ---> 06858f8ceec7\r\nStep 10/69 : ARG NB_UID\r\n ---> Using cache\r\n ---> 824b8ce23dcf\r\nStep 11/69 : ENV USER ${NB_USER}\r\n ---> Using cache\r\n ---> 0f86c6990172\r\nStep 12/69 : ENV HOME /home/${NB_USER}\r\n ---> Using cache\r\n ---> 7fb25afd19b7\r\nStep 13/69 : RUN groupadd         --gid ${NB_UID}         ${NB_USER} &&     useradd         --comment \"Default user\"         --create-home         --gid ${NB_UID}         --no-log-init         --shell /bin/bash         --uid ${NB_UID}         ${NB_USER}\r\n ---> Using cache\r\n ---> 8c496325764b\r\nStep 14/69 : RUN apt-get -qq update &&     apt-get -qq install --yes --no-install-recommends        less        unzip        > /dev/null &&     apt-get -qq purge &&     apt-get -qq clean &&     rm -rf /var/lib/apt/lists/*\r\n ---> Using cache\r\n ---> c17414a3f0a6\r\nStep 15/69 : RUN apt-get -qq update &&     apt-get -qq install --yes        libapparmor1        lsb-release        psmisc        sudo        > /dev/null &&     apt-get -qq purge &&     apt-get -qq clean &&     rm -rf /var/lib/apt/lists/*\r\n ---> Using cache\r\n ---> 1a5c890fbaa5\r\nStep 16/69 : EXPOSE 8888\r\n ---> Using cache\r\n ---> 9217a48f49e1\r\nStep 17/69 : ENV APP_BASE /srv\r\n ---> Using cache\r\n ---> 37e89778e15e\r\nStep 18/69 : ENV CONDA_DIR ${APP_BASE}/conda\r\n ---> Using cache\r\n ---> a9b7e7f7317a\r\nStep 19/69 : ENV NB_PYTHON_PREFIX ${CONDA_DIR}/envs/notebook\r\n ---> Using cache\r\n ---> 71d38a4aa907\r\nStep 20/69 : ENV NPM_DIR ${APP_BASE}/npm\r\n ---> Using cache\r\n ---> 03e8b60712bc\r\nStep 21/69 : ENV NPM_CONFIG_GLOBALCONFIG ${NPM_DIR}/npmrc\r\n ---> Using cache\r\n ---> 60dba4756e63\r\nStep 22/69 : ENV NB_ENVIRONMENT_FILE /tmp/env/environment.lock\r\n ---> Using cache\r\n ---> 5671ec76c193\r\nStep 23/69 : ENV KERNEL_PYTHON_PREFIX ${NB_PYTHON_PREFIX}\r\n ---> Using cache\r\n ---> 075b7f3bf2ea\r\nStep 24/69 : ENV R_LIBS_USER ${APP_BASE}/rlibs\r\n ---> Using cache\r\n ---> 61b748230d31\r\nStep 25/69 : ENV PATH ${NB_PYTHON_PREFIX}/bin:${CONDA_DIR}/bin:${NPM_DIR}/bin:/usr/lib/rstudio-server/bin/:${PATH}\r\n ---> Using cache\r\n ---> aad718415127\r\nStep 26/69 : COPY --chown=1000:1000 build_script_files/-2fusr-2flib-2fpython3-2e8-2fsite-2dpackages-2frepo2docker-2fbuildpacks-2fconda-2factivate-2dconda-2esh-391af5 /etc/profile.d/activate-conda.sh\r\n ---> Using cache\r\n ---> b42df1bd8a3e\r\nStep 27/69 : COPY --chown=1000:1000 build_script_files/-2fusr-2flib-2fpython3-2e8-2fsite-2dpackages-2frepo2docker-2fbuildpacks-2fconda-2fenvironment-2epy-2d3-2e7-2elock-4f1154 /tmp/env/environment.lock\r\n ---> Using cache\r\n ---> a8baeac06b9b\r\nStep 28/69 : COPY --chown=1000:1000 build_script_files/-2fusr-2flib-2fpython3-2e8-2fsite-2dpackages-2frepo2docker-2fbuildpacks-2fconda-2finstall-2dminiforge-2ebash-514214 /tmp/install-miniforge.bash\r\n ---> Using cache\r\n ---> cfa934b5e1a8\r\nStep 29/69 : RUN TIMEFORMAT='time: %3R' bash -c 'time /tmp/install-miniforge.bash' && rm -rf /tmp/install-miniforge.bash /tmp/env\r\n ---> Using cache\r\n ---> a196f765",
  "Issue title: add command: jx trigger nameOfPipeline\n Issue body: it would be nice to have a command line that can be used to trigger a pipeline build on the current jenkins.\r\n\r\nSomething like...\r\n```\r\n$ jx trigger foo\r\nPipeline foo has started\r\n```\r\n\r\nMaybe if no pipeline name is specified then we could show a combo box list of options to select (using the `survey stuff`) \r\ne.g.\r\n```\r\n$ jx trigger \r\nPlease select the pipeline to trigger\r\n> [x]: pipeline1\r\n   [  ]: pipeline2\r\n   [  ]: pipeline3\r\n```\r\n\r\n\n Comments: \n Comment 0: am not sure if the command should be `trigger` or `start` though - I guess we could add an alias for both ;)",
  "Issue title: md, \u65e2\u7136\u4e0d\u652f\u6301base64\u56fe\u7247\uff0c\u8fd9\u600e\u4e48\u641e\n Issue body: md, \u65e2\u7136\u4e0d\u652f\u6301base64\u56fe\u7247\uff0c\u8fd9\u600e\u4e48\u641e\n Comments: \n Comment 0: \u5148\u4e0b\u8f7d\uff0c\u518d\u7ed8\u5236",
  "Issue title: RFC: Add syntaxic sugar for struct expressions fields from variables of the same name\n Issue body: <a href=\"https://github.com/SimonSapin\"><img src=\"https://avatars.githubusercontent.com/u/291359?v=2\" align=\"left\" width=\"96\" height=\"96\" hspace=\"10\"></img></a> **Issue by [SimonSapin](https://github.com/SimonSapin)**\n_Sunday Feb 02, 2014 at 12:29 GMT_\n\n_For earlier discussion, see https://github.com/rust-lang/rust/issues/11990_\n\n_This issue was labelled with: A-parser, B-RFC in the Rust repository_\n\n---\n\nThe general syntax for a struct pattern is: \n\n```\nStructName { field_name: new_variable_name }\n```\n\nBut when the desired variable name is the same as the field name, it does not need to be repeated:\n\n```\nlet MyStruct { name } = struct_value;\ndo_something_with(name);\n```\n\nThis proposal is to add similar syntax sugar for struct expressions:\n\n```\nlet name = \u2026;\nlet struct_value = MyStruct { name };\n```\n\n\u2026 would be the same as: \n\n```\nlet name = \u2026;\nlet struct_value = MyStruct { name: name };\n```\n\nCC: @eddyb\n\n Comments: \n Comment 0: This was discussed in https://github.com/rust-lang/meeting-minutes/blob/master/weekly-meetings/2014-02-11.md#binding-in-struct-patterns\n\nThere were some concerns about ambiguities in e.g. `for x in Foo { x } { }`, but the grammar was changed since then (I think?) so that the desugared form of this would not be valid either.\n\n``` rust\nfn main() {\n    struct Foo { x: () }\n    impl Iterator<()> for Foo {\n        fn next(&mut self) -> Option<()> { None }\n    }\n    let x = ();\n    for i in Foo { x: x } { }\n}\n```\n\n```\na.rs:7:21: 7:22 error: expected one of `;`, `}`, found `:`\na.rs:7     for i in Foo { x: x } { }\n```\n\nCC @nick29581\n\n Comment 1: Is this still unambiguous with [type ascription](https://github.com/rust-lang/rust/issues/23416)?\n Comment 2: @theemathas: it is still unambiguous; the full form of struct initialisation is defined appropriately so that type ascription works, and the additional, simpler form that this permits cannot have any colons (it\u2019s commas and identifiers only), so there is no interaction with the type ascription feature.\n Comment 3: So, this feature was suggested (https://github.com/rust-lang/rust/issues/11990) and then prototyped ( https://github.com/rust-lang/rust/pull/11994 ) back in February 2014\r\n\r\nThe team collectively declined to adopt the feature for Rust 1.0 : https://github.com/rust-lang/rust/issues/11990#issuecomment-34791865 (again, back in Febuary 2014).\r\n\r\nBut then in June 2014, we accepted RFC 92, that restricted the use of struct literals to only appear in *certain* expression positions.\r\n * RFC text: https://github.com/rust-lang/rfcs/blob/master/text/0092-struct-grammar.md\r\n * RFC PR: https://github.com/rust-lang/rfcs/pull/92 (May 2014)\r\n * Implementation: https://github.com/rust-lang/rust/issues/14885 (also June 2014)\r\n\r\nI believe that with the restriction specified by RFC 92, we could readily add this feature to the language backwards compatibly; that is, the parsing ambiguity issues are no longer present, I think.\r\n * Parsing ambiguity was the primary reason we declined to do this according to https://github.com/rust-lang/meeting-minutes/blob/master/weekly-meetings/2014-02-11.md#binding-in-struct-patterns \r\n * There were other more abstract reasons also discussed there (e.g. is such a form \"hygienic\"), but I think all those points are debatable. In particular, even king of hygiene @dherman said \"it's such great sugar that it's hard to avoid\"\r\n\r\nI'm going to assign this to myself as a reminder to try to draft up a formal RFC for it at some point in the (hopefully near) future.\n Comment 4: Sounds great, thanks for championing this Felix!\n Comment 5: In feature we will have feature *Rename variable* which will break code or should be insert field name.\n Comment 6: @KalitaAlexey I infer you are talking about an IDE feature.\n\nI think the language design should not hinder itself on how IDE features are to be implemented\n\n Comment 7: @pnkfelix \nAny updates? Do you still plan to write an RFC?\nSince implementation is trivial, it's only a matter of decision.\n\n Comment 8: @petrochenkov I've been distracted. Anyone else is free to draft up an RFC; I won't be upset if that happens.\n\n Comment 9: This is implemented and stabilized in https://github.com/rust-lang/rust/pull/39761\r\nping @SimonSapin @pnkfelix for closing",
  "Issue title: [BUG] Searching cache, unhandled exception.\n Issue body: Hello @iamkroot!\r\n\r\nFound an unhandled exception in the logs. \r\nIts just an FYI report, i dont think theres so many shows/movies with names like that. :)\r\n\r\nThe show title is [9-1-1](https://trakt.tv/shows/9-1-1-2018). \r\nand the guessit module found it as\r\n\r\n`MatchesDict([('title', ['9', '1-1'])`\r\n\r\nProbably why it throw the script off its rails\r\n\r\n```\r\n - DEBUG - mpchc - file_info - Filepath X:\\9-1-1.S03E06.1080p.WEB.x264-TBS\\9-1-1.s03e06.1080p.web.x264-tbs.mkv\r\n - DEBUG - mpchc - file_info - Trying to match custom regex.\r\n - DEBUG - mpchc - file_info - No regex matches for X:/9-1-1.S03E06.1080p.WEB.x264-TBS/9-1-1.s03e06.1080p.web.x264-tbs.mkv\r\n - DEBUG - mpchc - file_info - Using guessit module to match.\r\n - DEBUG - mpchc - file_info - MatchesDict([('title', ['9', '1-1']), ('season', 3), ('episode', 6), ('screen_size', '1080p'), ('source', 'Web'), ('video_codec', 'H.264'), ('release_group', 'tbs'), ('container','mkv'), ('mimetype', 'video/x-matroska'), ('type', 'episode')])\r\n - DEBUG - scrobbler - trakt_interface - Searching cache.\r\n - ERROR - scrobbler - main - Unhandled exception\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\username\\AppData\\Local\\trakt-scrobbler\\main.py\", line 56, in run_with_except_hook\r\n    run_original(*args2, **kwargs2)\r\n  File \"C:\\Users\\username\\AppData\\Local\\trakt-scrobbler\\scrobbler.py\", line 26, in run\r\n    self.scrobble(*scrobble_item)\r\n  File \"C:\\Users\\username\\AppData\\Local\\trakt-scrobbler\\scrobbler.py\", line 30, in scrobble\r\n    if trakt.scrobble(verb, **data):\r\n  File \"C:\\Users\\username\\AppData\\Local\\trakt-scrobbler\\trakt_interface.py\", line 185, in scrobble\r\n    scrobble_data = prepare_scrobble_data(**media_info)\r\n  File \"C:\\Users\\username\\AppData\\Local\\trakt-scrobbler\\trakt_interface.py\", line 169, in prepare_scrobble_data\r\n    trakt_id = get_trakt_id(title, type)\r\n  File \"C:\\Users\\username\\AppData\\Local\\trakt-scrobbler\\trakt_interface.py\", line 147, in get_trakt_id\r\n    trakt_id = trakt_cache[required_type].get(title)\r\nTypeError: unhashable type: 'list'\r\n```\n Comments: \n Comment 0: Ah nice catch. Thanks for taking the time to go through the logs! I'll add a check for this soon. Plus I've been wanting to update the searching functionality for some time. This gives me a good reason to work on it now :P\n Comment 1: Hey @GMFalka, fixed the bug. Do update and check.",
  "Issue title: Deprecated warning on PHP 8.1\n Issue body: https://github.com/JackieDo/Laravel-Dotenv-Editor/blob/f93690a80915d51552931d9406d79b312da226b9/src/Jackiedo/DotenvEditor/DotenvReader.php#L138\r\n\r\nThe line above will return the following warning on PHP 8.1 : \r\n\r\n```\r\nPHP Deprecated:  auto_detect_line_endings is deprecated in {...}/jackiedo/dotenv-editor/src/Jackiedo/DotenvEditor/DotenvReader.php on line 138\r\n```\r\n\r\nhttps://wiki.php.net/rfc/deprecations_php_8_1#auto_detect_line_endings_ini_setting\n Comments: \n Comment 0: I'm also getting these:\r\n\r\n> Deprecation Notice: strlen(): Passing null to parameter #1 ($string) of type string is deprecated in /var/www/html/britishhamper2021/vendor/jackiedo/dotenv-editor/src/Jackiedo/DotenvEditor/DotenvFormatter.php:59\r\n> Deprecation Notice: trim(): Passing null to parameter #1 ($string) of type string is deprecated in /var/www/html/britishhamper2021/vendor/jackiedo/dotenv-editor/src/Jackiedo/DotenvEditor/DotenvFormatter.php:79\r\n\r\nFor background, see https://php.watch/versions/8.1/internal-func-non-nullable-null-deprecation & https://wiki.php.net/rfc/deprecate_null_to_scalar_internal_arg\n Comment 1: @lcharette, @jontjs:\r\nThis issue has been resolved (commit 154228bacd1f3eddc38371cb309c45e0e0d3f071) and included in the [1.2.1](https://github.com/JackieDo/Laravel-Dotenv-Editor/releases/tag/1.2.1) release",
  "Issue title: [Submission] Apps2SD Pro Privileged\n Issue body: https://github.com/reiryuki/Apps2SD-Pro-Privileged-Magisk-Module\r\n\r\nSome people with low internal storage phone in Android Oreo and Up may need Apps2SD Pro features. But some features like \"Running Service\" and \"Task Manager\" in the app are not working properly due to newer Android version restrictions. This module will break it.\n Comments: \n Comment 0: Submission older than 21 days, you can re-submit your module if you want.",
  "Issue title: Ankush Singh\n Issue body: \r\n![ATCtech](https://user-images.githubusercontent.com/50258860/94898939-046dec00-04b0-11eb-8a6a-10a0c59da3f0.JPG)\r\n\r\n\n Comments: \n Comment 0: Due we close new issues on PR merge and voting is still possible on closed issues I will close this one.",
  "Issue title: Bump Documenter version\n Issue body: The `DocTestSetup` in `@meta` blocks should now be defined in `make.jl`. See https://github.com/JuliaDocs/Documenter.jl/blob/v0.23.0/CHANGELOG.md#version-v0230\n Comments: \n Comment 0: Furthermore, doctests in the test suite now have better support.\r\n\r\n> makedocs now accepts the doctest = :only keyword, which allows doctests to be run while most other build steps, such as rendering, are skipped. This makes it more feasible to run doctests as part of the test suite (see the manual for more information).\r\n\r\n> Documenter now exports the doctest function, which verifies the doctests in all the docstrings of a given module. This can be used to verify docstring doctests as part of test suite, or to fix doctests right in the REPL.",
  "Issue title: Meta: Maintenance status and future of Protractor\n Issue body: At my workplace, we are at a crossroads deciding how to take our e2e automation forward. We have used Protractor for over 3 years across a large number of projects, and probably have thousands of tests written in it as of current.\r\n\r\nA great concern to us is the maintenance status of Protractor. It has been close to a year since the last major commit (working towards 6.0), and there are a lot of unmerged PRs (some being simple typo corrections) outstanding. I'm very sorry if we have missed anything, but there has been very little communication from active developers on the project as well.\r\n\r\nNeedless to say, I know and appreciate that this is an open source project which we are in no way entitled to updates to. Even so, it would be helpful to know if Google are committed to actively maintaining this project and have a roadmap for it. If not, I believe the community should be informed so that appropriate decisions can be made about the future of our own e2e stacks.\r\n\n Comments: \n Comment 0: After support for legacy wire protocol is removed in Chromedriver, we will no longer be able to run Protractor 5+ with latest Chromedriver. Current workaround is to set w3c=false. Future of Protractor depends on version 6.\r\n\r\n**Issue 2596: Remove legacy wire protocol support**\r\nhttps://bugs.chromium.org/p/chromedriver/issues/detail?id=2596&sort=-id&colspec=ID%20Status%20Pri%20Owner%20Summary&q=w3c&can=2\n Comment 1: One of the people currently working on the project gave a short and vague update on the current status in one of the issues from last week. You can see the update here. https://github.com/angular/protractor/issues/5390\n Comment 2: Since there have been no updates, we have decided to move our future e2e testing to Cypress. \n Comment 3: There really needs to be some information regarding this.\r\n\r\nSince this tool ships with angular a lot of people are probably going to assume they should be using it for their tests, however if it is practically unsupported it would be of great help to people to know this up front, before they sink time into building out their test suite.\n Comment 4: Protractor is mentioned in the Angular roadmap:\r\n\r\nhttps://angular.io/guide/roadmap\r\n\r\n\"Update our e2e testing strategy\r\nTo ensure we provide a future-proof e2e testing strategy, we want to evaluate the state of Protractor, community innovations, e2e best practices, and explore novel opportunities.\"\r\n\n Comment 5: Perhaps a viable path would be to recommend Cypress and maintain a set of Angular-specific plugins and commands for it? This was one of the first things we did as part of our own migration, and it made both writing new and migrating existing tests extremely clean.\r\n\n Comment 6: The roadmap at https://angular.io/guide/roadmap doesn't really help unfortunately.\r\n\r\nIt gives some vague information that's effectively meaningless without something more tangible to go with it. For example, where are the github issues that people are working in in relation to this?\r\n\r\nThere are no estimated timelines in the roadmap, there's zero activity on this repository in over 4 months, seemingly nothing related to protractor or e2e in the Angular issues, no information from any maintainers in any of the issues related to this. Communication regarding the status is abysmal.\r\n\r\nThe 6 release was pulled without explanation, which in random issue comments maintainers have said will come back when there is appropriate documentation but there is nothing about it on github or npm project pages except a \"Protractor 6 has been deprecated.\" for unknown reasons. \r\n\r\nBut there is also a 7.0.0 version on npm, which is the current npm tag. There is a tag in github for 7.0.0 but no github release for that version. There is a vague message on the github project page about 5 and 7 being for different node versions but you have to assume that they're otherwise the same as that isn't explicitly stated.\r\nThe npm page says \"Protractor 5 is compatible with nodejs v6 and newer.\", which conflicts with what is stated on the github page.\r\nTo add to that confusion, protractor does seem to run on node > v8 and throws no warnings, despite what is stated on the project page. Maybe it would run more smoothly on newer node versions?\r\n\r\nIt's upsetting that this is the recommended (bundled) e2e solution that more and more new Angular users will be using without realising that it's effectively unmaintained and they're in for some frustrating times.\r\n\n Comment 7: Seems like Protractor is officially dead.\r\n\r\nhttps://github.com/angular/protractor/issues/5502",
  "Issue title: Linker failure on Windows due to delay load hook\n Issue body: * **Node Version**: v16.11.0 (node-gyp v8.2.0)\r\n* **Platform**: Windows Server 2019 (Github Actions)\r\n* **Compiler**: VS2019\r\n* **Module**: (not public yet)\r\n\r\nI wasn't quite sure where to ask this, but figured I'd start here because node-gyp deals with the compiling side of things.\r\n\r\nBasically I'm writing a node addon that uses a class that inherits from `v38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5String38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5xternalOneByteStringResource` (like node does in its src/string_bytes.cc for example). Everything compiles and works just fine in *nix, but on Windows the linker errors out, complaining:\r\n\r\n```\r\nLINK : fatal error LNK1194: cannot delay-load 'node.exe' due to import of data symbol '\"__declspec(dllimport) const v38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5String38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5xternalOneByteStringResour38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5`vftable'\" (__imp_??_7ExternalOneByteStringResource@String@v8@@6B@)'; link without /DELAYLOAD:node.exe [D:\\a\\myaddon\\build\\myaddon.vcxproj]\r\n```\r\n\r\nMy binding.gyp is very minimal and besides the required fields, I only have `'cflags': [ '-O3' ],`. From what I've read this error can go away by setting the `'win_delay_look_hook'` to `'false'` in my binding.gyp, but of course that makes the addon incompatible with projects like Electron.\r\n\r\nIs there something I'm missing here possibly either in my code or in my binding.gyp, could it be there is something that node needs to be (re-)exporting specifically for Windows (like it does to re-export OpenSSL symbols for example), or something else?\r\n\r\nI looked at `nan`'s tests, hoping to find an answer there and while they do have a test that subclasses `v38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5String38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5xternalOneByteStringResource`, they unfortunately disable the delay load hook in the binding.gyp.\n Comments: \n Comment 0: Hi I ran into the sam problem, do you solved it?\r\nmy error is\r\n`LINK : fatal error LNK1194: cannot delay-load 'node.exe' due to import of data symbol '\"__declspec(dllimport) const st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5basic_ostream<char,struct st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5char_traits<char> >38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5`vftable'\" (__imp_??_7?$basic_ostream@DU?$char_traits@D@std@@@std@@6B@)'; link without /DELAYLOAD:node.exe`\r\n\r\n",
  "Issue title: When running MultiHeadAttention I get \"AttributeError: module 'keras' has no attribute 'applications\"\n Issue body: When runnning the code I get the error: AttributeError: module 'keras' has no attribute 'applications'\r\n\r\n**Version Info**\r\n\r\nI am using Keras version 2.4.3\r\n\r\n**Minimal Codes To Reproduce**\r\n\r\n```\r\nimport keras\r\nfrom keras.layers import Input\r\nfrom keras_multi_head import MultiHeadAttention\r\n\r\nprint(keras.getversion())\r\n\r\ninput_layer =Input(\r\n    shape=(2, 3),\r\n    name='Input',\r\n)\r\natt_layer = MultiHeadAttention(\r\n    head_num=3,\r\n    name='Multi-Head',\r\n)(input_layer)\r\nmodel = keras.models.Model(inputs=input_layer, outputs=att_layer)\r\n```\r\n\n Comments: \n Comment 0: Is this still relevant? If so, what is blocking it? Is there anything you can do to help move it forward?\n\nThis issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.\n Comment 1: Fixed in `0.28.0`.",
  "Issue title: how to run this website?\n Issue body: <!-- File issues with the `pub` client at\r\nhttps://github.com/dart-lang/pub/issues/new' -->\r\n\r\n * Explain the issue,\r\n * Using bullet points!\r\n * Link to screenshot.\r\n\r\n```dart\r\n// Write example code here\r\n```\r\n\n Comments: \n Comment 0: @LUJYM I'm not sure what the question is about, please explain it a bit more.",
  "Issue title: EDNP\n Issue body: Pfarrkirchen Airport, Bavaria, Germany.\r\nTiny GA airport.\n Comments: \n Comment 0: Aaaaaaand sent for review.\n Comment 1:![image](https://cloud.githubusercontent.com/assets/14023167/21080947/604b1e26-bf81-11e6-9e28-144aca2f1035.png)\r\n",
  "Issue title: Leaving @profile decorators in when code isn't profiled\n Issue body: I've found it a bit annoying to comment out the @profile decorations so I wrote a really simple decorator to use instead of profile. Actually, it\u2019s a bit obvious so maybe there is another way to do this already which is better; I just couldn't find it \u263a\r\n\r\nIt took an hour to look up the syntax and get it working so I thought it might be useful. I use another decorator to check if the profile decorator is available.  Separating the second profiled_func assignment from its execution is to ensure that NameError exceptions, from func, are still propagated and the try...except block only detects if profile is present.\r\n\r\n```\r\ndef proxyprofile(func):\r\n    def profile_check_proxy(*args, **kwargs):\r\n        profiled_func = func\r\n        try:\r\n            profiled_func = profile(func)\r\n        except NameError:\r\n            pass\r\n        return profiled_func(*args, **kwargs)\r\n    return profile_check_proxy\r\n```\n Comments: \n Comment 0: Here is how I would implement that:\n\n```\ndef proxyprofile(func):\n    try:\n        func = profile(func)\n    except NameError:\n        pass\n    return func\n```\n\nI _think_ I understand the intended workflow. Import `proxyprofile` and mark everything you want to profile, but go back and forth between using `kernprof` and just plain running the code (e.g. running the test suite) until you've fixed the problem, then go back and remove the `@proxyprofile`s before checking things in. Is that right?\n\n Comment 1: Hi Robert,\n\nyes, your workflow description is appropriate but the use case I have is profiling some sqlalchemy code used in a simulation. I have some simple scripts to load functions into iPython to analyse the results. It\u2019s really not a big deal, removing the @profile stuff but it got annoying. I thought it could be streamlined a bit and, it turns out, it\u2019s quite easy. \u00a0\n\nThanks for suggesting a simpler alternative.\n\nBest,\n\nPeter.\n\nOn 26 February 2016 at 19:10:52, Robert Kern (prestonneal@example.net) wrote:\n\nHere is how I would implement that:\n\ndef proxyprofile(func):\n    try:\n        func = profile(func)\n    except NameError:\n        pass\n    return func\n\nI think I understand the intended workflow. Import proxyprofile and mark everything you want to profile, but go back and forth between using kernprof and just plain running the code (e.g. running the test suite) until you've fixed the problem, then go back and remove the @proxyprofiles before checking things in. Is that right?\n\n\u2014\nReply to this email directly or view it on GitHub.\n\n\n Comment 2: I just put this at the top of my code:\n\n```\ntry:\n    profile\nexcept NameError:\n    profile = lambda x: x\n```\n\n Comment 3: Ok, that looks good too but I like the idea of importing a module rather than adding a try block to every file I want to profile.\n\nBefore I posted my stab at this I checked to see if profile comes from locals, globals or __builtins__. It comes from __builtins__ but you can\u2019t find it in an interactive shell (python -i -m kernprof -l.)\n\nAfter a bit more digging just now I realised you can but only in the script which is being profiled (python -m kernprof -l proxyprofile.py, for example.) So how about this:\n\n\u2014proxyprofile.py\u2014\nimport __builtin__\n\nif 'profile' not in dir(__builtin__):\n\u00a0 \u00a0 __builtin__.profile = lambda x: x\n\nIt\u2019s obviously based on what you just sent me but is only an import now.\n\nBest,\n\nPeter.\n\nOn 26 February 2016 at 22:00:58, Joseph Martinot-Lagarde (prestonneal@example.net) wrote:\n\nI just put this at the top of my code:\n\ntry:\n    profile\nexcept NameError:\n    profile = lambda x: x\n\n\u2014\nReply to this email directly or view it on GitHub.\n\n\n Comment 4: Ok, that looks good too but I like the idea of importing a module rather than adding a try block to every file I want to profile.\n\nBefore I posted my stab at this I checked to see if profile comes from `locals`, `globals` or `__builtins__`. It comes from `__builtins__` but you can\u2019t find it in an interactive shell (`python -i -m kernprof -l.`)\n\nAfter a bit more digging just now I realised you can but only in the script which is being profiled (`python -m kernprof -l proxyprofile.py`, for example.) So how about this:\n\n\u2014proxyprofile.py\u2014\n\n``` python\nimport __builtin__\n\nif getattr(__builtin__, 'profile', None) is None:\n    __builtin__.profile = lambda x: x\n```\n\nIt\u2019s obviously based on your last comment me but is only an import now. I suppose it would be more pythonic if it were like this:\n\n\u2014proxyprofile.py\u2014\n\n``` python\nimport __builtin__\n\ntry:\n    __builtin__.profile\nexcept NameError:\n    __builtin__.profile = lambda x: x\n```\n\n Comment 5: 2 comments:\r\n* `__builtin__` is python2 only, replaced by `builtins` in python3\r\n* `__builtin__.profile` would raise `AttributeError` here\r\n\r\nHere is my try:\r\n```python\r\ntry:\r\n    import builtins\r\nexcept ImportError:\r\n    import __builtin__ as builtins\r\n\r\ntry:\r\n    builtins.profile\r\nexcept AttributeError:\r\n    builtins.profile = lambda x: x\r\n```\n Comment 6: I use this technique in Python 2. (Add @Nodd's technique to handle Python 2 and 3.) It works smoothly and doesn't generate `unresolved reference 'profile'` warnings in PyCharm like try/except does:\r\n\r\n    import __builtin__\r\n    profile = __builtin__.__dict__.get('profile', lambda f: f)",
  "Issue title: Axis ticks are redundantly aligned to empty axis ticks\n Issue body: Demo: http://jsfiddle.net/highcharts/1dbt0cca/\r\n\r\nThe right Y axis is empty, nonetheless the left axis ticks are aligned to a pre-computed tick amount.\n Comments: \n Comment 0: Demo with fix applied: http://jsfiddle.net/highcharts/1dbt0cca/1/",
  "Issue title: Call drawImage() in loop with only one GImage instance\n Issue body: Hello,\r\n\r\nFirst of all, thanks for maintaining the lib!\r\n\r\nWhat I'm trying to do is to ```drawImage()``` many times as new small chunk of base64 encoded images keep coming in. It was working fine but I noticed memory leak as ```new GImage()``` is called in each loop, and these images are not attached to the DOM so removing ```<GCanvas>``` will not trigger GC.\r\n\r\nI decided to try to reuse ```<GImage>``` and refactored to something like this:\r\n\r\n```\r\nlet gimg = new GImage(); // create only once\r\n\r\nasync draw(imgbase64) {\r\n  gimg.src = 'data:image/png;base64,' + imgbase64;\r\n  let res = await this.redraw();\r\n  return res;\r\n}\r\n\r\nasync redraw() {\r\n  return new Promise((resolve, reject) => {\r\n    gimg.onload = () => {\r\n      this.ctx.clearRect(0, 0, canvasWidth, canvasHeight);\r\n      this.ctx.drawImage(gimg, 0, 0, canvasWidth, canvasHeight);\r\n      // 'gimg._src' changes correctly here\r\n      // log: gcanvasCore: GCanvasWeex38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5rawImage texture 1 (which is 'gimg._id') is NULL\r\n      let gimgData = this.ctx.getImageData(0, 0, canvasWidth, canvasHeight);\r\n      resolve(gimgData);\r\n    };\r\n    gimg.onerror = (err) => {\r\n      reject(err);\r\n    };\r\n  });\r\n}\r\n\r\nasync loop() {\r\n  let img = await getImgbase64();\r\n  let imgData = await this.draw(img); // failed to get new imgData\r\n}\r\n```\r\n\r\nNow I get ```gcanvasCore: GCanvasWeex38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5rawImage texture 1 (which is 'gimg._id') is NULL```.\r\nAm a missing something or are there other better ways to prevent memory leak?\r\n\r\nThanks!\n Comments: \n Comment 0: I think you can resuse `<GImage>` to avoid memory leak.\r\n\r\nBut there is a bug in your code: `gimg.src =` will trigger `onload` or `onerror` event, so `gimg.onload =` should run before `gimg.src =`\r\n\r\nYou can try below and tell me the result:\r\n```\r\nlet gimg = new GImage(); // create only once\r\n\r\ndraw(imgbase64) {\r\n  return new Promise((resolve, reject) => {\r\n    gimg.onload = () => {\r\n      this.ctx.clearRect(0, 0, canvasWidth, canvasHeight);\r\n      this.ctx.drawImage(gimg, 0, 0, canvasWidth, canvasHeight);\r\n\r\n      let gimgData = this.ctx.getImageData(0, 0, canvasWidth, canvasHeight);\r\n      resolve(gimgData);\r\n    };\r\n    gimg.onerror = (err) => {\r\n      reject(err);\r\n    };\r\n\r\n    gimg.src = 'data:image/png;base64,' + imgbase64;\r\n  });\r\n}\r\n\r\nasync loop() {\r\n  let img = await getImgbase64();\r\n  let imgData = await this.draw(img); // failed to get new imgData\r\n}\r\n```\n Comment 1: Yes you are right, ```src``` should be set after ```onload```, to something like this:\r\n\r\n```\r\nlet gimg = new GImage(); // create only once\r\n\r\ndraw(imgbase64) {\r\n  return new Promise((resolve, reject) => {\r\n    gimg.onload = () => {\r\n      this.ctx.clearRect(0, 0, canvasWidth, canvasHeight);\r\n      this.ctx.drawImage(gimg, 0, 0, canvasWidth, canvasHeight);\r\n    };\r\n    gimg.onerror = (err) => {\r\n      reject(err);\r\n    };\r\n    gimg.src = 'data:image/png;base64,' + img;\r\n    let res = this.ctx.getImageData(0, 0, canvasWidth, canvasHeight);\r\n    resolve(res);\r\n  });\r\n}\r\n\r\nasync loop() {\r\n  let img = await getImgbase64();\r\n  let imgData = await this.draw(img); // only first draw\r\n}\r\n```\r\n\r\nThis removed ```gcanvasCore: GCanvasWeex38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5rawImage texture 1 is NULL```, but it draws only once with the first call(which is my initial issue anyway...). All following ```draw()``` with new ```imgbase64``` doesn't draw anything new on canvas unless I create ```new GImage()``` in each loop. \r\n\r\nThanks for taking time to look into this... on the weekend! :-)\n Comment 2: I will take several weekends to refactor the lib to reuse `<GImage>` -- only on weekend I have enought time to maintain the lib \ud83d\ude1d \n Comment 3: Could you tell me the resource of `getImgbase64()`? Comes from a video or fetch from a server?\n Comment 4: Hi!\r\nI have the same problem. i create \"img\"  out side draw() then set \"img.src\" inside. call draw() every frame received. On android it works fine but on ios the onload event is fired but only the first frame is drawn.\r\ni had try with:\r\n\"@flyskywhy/react-native-gcanvas\": \"^2.3.21\"\r\n\"@flyskywhy/react-native-gcanvas\": \"^2.3.7\"\r\ntest on iphone xs max os 14.2, iphone 7 plus os 14.6\n Comment 5: > Hi! I have the same problem. i create \"img\" out side draw() then set \"img.src\" inside. call draw() every frame received. On android it works fine but on ios the onload event is fired but only the first frame is drawn. i had try with: \"@flyskywhy/react-native-gcanvas\": \"^2.3.21\" \"@flyskywhy/react-native-gcanvas\": \"^2.3.7\" test on iphone xs max os 14.2, iphone 7 plus os 14.6\r\n\r\nPlease show me the `img.src = ` code.\n Comment 6: > \r\n`let imageHttp = new GImage();\r\n  imageHttp.crossOrigin = false; \r\n  imageHttp.onload = () => {\r\n        ctx.drawImage(imageHttp, 0, 0, imageHttp.width, imageHttp.height, 0, 0, 320, 240);\r\n    };\r\n  imageHttp.onerror = (error: any) => {\r\n        console.log(error);\r\n  };`\r\nand this is draw():\r\n`const draw = async (database64:string) => {\r\n       imageHttp.src = database64;\r\n };`\n Comment 7: @cwashington@example.net support it.\r\n\r\nPS: @unmec, as you can see in README.md\r\n\r\n      // for (let i = 0; i < 10; i++) {\r\n      //   await sleepMs(1000);\r\n      //   if (i % 2) {\r\n      //     imageHttp.src =\r\n      //       'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAIAAAACCAIAAAD91JpzAAAADklEQVR4AWP4nwZCUAoAKxYFld+CjjoAAAAASUVORK5CYII=';\r\n      //   } else {\r\n      //     imageHttp.src =\r\n      //       'https://gw.alicdn.com/tfs/TB1KwRTlh6I8KJjy0FgXXXXzVXa-225-75.png';\r\n      //   }\r\n      // }\r\n\r\nyou may directly fetch images then `imageHttp.src =`, without convert to `data:image`\n Comment 8: Cool! I'll update packages and try it out, thanks for the great news!",
  "Issue title: YouTube\u65e0\u6cd5\u4e0a\u4f20\u89c6\u9891\uff0c\u6c42\u89e3\uff01\n Issue body: \u5982\u9898\uff0c\u89c2\u770b\u89c6\u9891\u6ca1\u6709\u95ee\u9898\uff0c\u5c31\u662f\u65e0\u6cd5\u4e0a\u4f20\u89c6\u9891\u3002\u8fd9\u662f\u600e\u4e48\u56de\u4e8b\uff1f\u8c01\u77e5\u9053\u89e3\u51b3\u529e\u6cd5\uff0c\u8c22\u8c22\uff01\n Comments: \n Comment 0: \u540c\u95ee\uff0c\u80fd\u89e3\u51b3\u4e0d\uff1f\n Comment 1: \u540c\n Comment 2: youtube\u6709\u81ea\u5df1\u7684\u4e00\u5957\u7684\u5b89\u5168\u673a\u5236\uff0c\u4f1a\u5c01\u6389\u4e00\u4e9b\u4f7f\u7528\u91cf\u8f83\u5927\u7684\u4ee3\u7406\u3002\r\n\u7ed9\u4f60\u63a8\u8350\u4e00\u4e2a\u7f51\u7ad9\uff1aezyoutube.net. \u521d\u6b21\u4f7f\u7528\u9700\u8981\u7ed1\u5b9a\u4f60\u7684YouTube\u8d26\u53f7\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u9700\u8981\u7ffb\u5899\u3002\u7ed1\u5b9a\u5b8c\u81ea\u540e\uff0c\u4ee5\u540e\u4e0a\u4f20\u89c6\u9891\u5c31\u4e0d\u518d\u9700\u8981\u7ffb\u5899\u3002",
  "Issue title: Is fastlane compatible with xcode 9?\n Issue body: I changed my commandline version of xcode to 9.0 and my projects timeout when running fastlane. Is this because its not supported yet?\n Comments: \n Comment 0: It seems like you have not included the output of `fastlane env`\n\nTo make it easier for us help you resolve this issue, please update the issue to include the output of `fastlane env` :+1:\n Comment 1: Yeah, it's mostly working with the exception of screenshots. \r\nPlease file any issues you see, as we're trying to make sure it works \ud83d\udcaf \r\n\ud83d\udc4d \n Comment 2: @taquitos what is the best issue to follow for the screenshots work?\n Comment 3: The PR we're working on is: https://github.com/fastlane/fastlane/pull/9570\r\nI think because there are so many issues, it's best to just watch that PR \ud83d\ude04 ",
  "Issue title: plaso does not parse recent versions of Amcache.hve\n Issue body: **Description of problem:**\r\n\r\nAccording to [ANALYSIS OF THE AMCACHE](https://www.ssi.gouv.fr/uploads/2019/01/anssi-coriin_2019-analysis_amcache.pdf), since Windows 10 version 1807 (Redstone 5) the four keys from the first AmCache.hve, File, Programs, Orphan and Generic have been deleted, marking the end of the transition to their new counterparts: InventoryApplicationFile, InventoryApplication and InventoryDriverBinary.\r\n\r\nPlaso parses the File and Programs keys.\r\n\r\n**Plaso version:**\r\n\r\n20191203\n Comments: \n Comment 0: If you can please provide some test files, that will make adding support easier\n Comment 1: I have put a sample at https://people.freebsd.org/~antoine/Amcache.hve\r\n\r\nSHA256 (Amcache.hve) = 4e574ac939d423947701302bc35d9a0da0b669a5fb86dbf8157a46c6f38f2c6d\n Comment 2: thx, I have a look shortly\n Comment 3: Note to self consider merging https://github.com/log2timeline/plaso/pull/2563 as part of amcache parser revamp\n Comment 4: Started looking into this, amcache parser can use some clean up as well.\n Comment 5: moving adding support for new subkeys to next milestone\n Comment 6: Not making the April release, bumping to next\n Comment 7: Note to self also have a look at https://github.com/log2timeline/plaso/issues/2059\n Comment 8: https://github.com/log2timeline/plaso/pull/3340 should provide most information in Amcache.hve files. Keeping issue open since there are additional date time values that could be extracted\r\n\n Comment 9: Added support for application LinkDate, InstallDate and InstallDateMsi in https://github.com/log2timeline/plaso/pull/3701\n Comment 10: Based on value names there are a couple of more date and time values https://github.com/libyal/dtformats/blob/main/documentation/AMCache%20file%20(AMCache.hve)%20format.asciidoc but unclear at this point how useful / frequently these are used.\r\n\r\nAdded a reminder to https://github.com/log2timeline/plaso/issues/3702, closing this issue.",
  "Issue title: gry-online.pl\n Issue body: dalej to samo \r\n\r\n||ads.gry-online.pl/160616_SteelSeries_E3/stare/Screening_ROS_Siberia_v3.jpg\r\n###ws-cnt\r\n\r\n![capture](https://cloud.githubusercontent.com/assets/15007183/16177683/36465a68-3602-11e6-98c1-4ac72d5b8fd8.PNG)\r\n\n Comments: \n Comment 0: Potwierdzam, u mnie jest to samo.\r\nDodanie tej regu\u0142y rozwi\u0105zuje problem `gry-online.pl###ws-cnt`\r\n\r\n![image](https://cloud.githubusercontent.com/assets/11742596/16177724/5004d88e-3635-11e6-9eb4-e58e73ad09a8.png)\r\n\n Comment 1: caly czas tam cos sie zmienia\n Comment 2: Skoro tak m\u00f3wicie to tak robi\u0119. Dzi\u0119ki, ",
  "Issue title: Templates not installed on Linux \n Issue body: I installed the monogame-sdk for linux, version (203)339-6732.  No templates were installed.\r\nI can run my existing projects, but I'm getting frustrated trying to creating a new game without a template. \r\n\r\nelementary OS 0.4 Loki (64-bit) Built on \"Ubuntu 16.04 LTS\"\r\nmonodevelop version 6.1.1\r\n\r\nInterestingly, the install couldn't tell that I have version 6 of monodevelop installed:\r\n\r\nVerifying archive integrity... All good.\r\nUncompressing Monogame Pipeline Installer...........................................................................................\r\nDependencies:\r\n - mono-runtime...................................[Found]\r\n - gtk-sharp3.....................................[Found]\r\n\r\nOptional Dependencies:\r\n - MonoDevelop 6..................................[Not Found]\r\n - Rider..........................................[Not Found]\r\n - referenceassemblies-pcl / mono-pcl.............[Found]\r\n - ttf-mscorefonts-installer / mscore-fonts.......[Not Found]\r\n\r\nContinue (Y, n): Y\r\nInstalling MonoGame SDK...\r\nCreating launcher items...\r\ngtk-update-icon-cache: Cache file created successfully.\r\nAdding mimetype...\r\nTo uninstall MonoGame SDK you can run \"monogame-uninstall\" from terminal.\r\n\n Comments: \n Comment 0: Ok, so I actually installed version 6 because of the message in the monogame-sdk install log. It didn't help that. But I've noticed that it does return the monogame addin to the addins menu. So I was able to install it there. So this is solved, I guess.\r\n\r\nThe last time I upgraded, I had to switch from the addin to the nuget. Now we switch from nuget to install script. Now back to addin. \r\nI waste a dis-proportionate amount of my time trying to cope with breaking changes on ever minor version change. It would be nice if there were some documentation or road map or something so that people who are not insiders can tell what's going on. \r\n",
  "Issue title: [REQ] UTF-8 Unicode via Latin 1 default encoding preferences\n Issue body: Issue imported from Google Code: https://code.google.com/p/sequel-pro/issues/detail?id=1223\nReporter:lia.bede...@gmail.com Date:2011-11-01 09:09:26 Status:New\n\nUTF-8 Unicode via Latin 1 is an available option under Database &gt; View Using Encoding. Could this also be added as an option to the Default Encoding Preferences? Thanks\n\n Comments: \n Comment 0: This issue has been marked as stale because it has not had recent activity. It will be closed if no further activity occurs.\n\n Comment 1: This issue has been auto-closed because there hasn't been any activity for at least 21 days. However, we really appreciate your contribution, so thank you for that! \ud83d\ude4f Also, feel free to [open a new issue](https://github.com/sequelpro/sequelpro/issues/new) if you still experience this problem \ud83d\udc4d.\n",
  "Issue title: Capabilities timestamp is not always updated upon reception of an option\n Issue body: Upon reception of an unsollicited option (i.e. a request), update of the contact provider is only performed if capabilities have changed. Timestamp of the last capabilities refresh should always be updated.\r\nIf received options were requested (i.e. it is a response), timestamp of the last capabilities refresh is always updated.\r\nReproducible.\r\n\r\nInitial conditions: A and B are both RCS contacts\r\nAction: A invite B for a one to one chat\r\nResult: when entering the conversation A sends an option request to B. B sends back the response.\r\nAction: wait one minute (until the validity of the capabilities have expired)\r\nResult: The B capabilities are no more valid\r\nAction: B sends a capability request to A\r\nExpected result: A updates the last time response for the B capabilities.\r\nResult: B capabilities are not updated (and are no more valid).\n Comments: \n Comment 0: Bug fixed with commit ID fb5464bd20df670caad1ba5842898bc80b58a3b3",
  "Issue title: Customize the registration page\n Issue body: It can be interesting the add options for the registration page like :\r\n- Registration active Y/N (existing)\r\n- Manual validation\r\n- Personnalized fields (content stored for manual validation or sent via email)\r\n\n Comments: \n Comment 0: I plan to remove the current registration system once I complete the billing plugin as it introduces a new registration system on the front and back end. \r\n\r\nI may introduce a separate plugin that solely focuses on free registration, but these changes are not possible with the way I currently have the registration system built.\n Comment 1: Any ETA on the working billing system?\n Comment 2: @BartManX Right now the entire project has been on hold, including VWI & the billing system, because of my classes and other jobs. I will try to work on this if I have any free time this summer, but my guess is that it will take at least 2 months if I do have the time to work on it consistently. Sorry for the delays.",
  "Issue title: Adding balanced text layout would really improve the slides\n Issue body: https://github.com/adobe-webplatform/balance-text implements this as a polyfill, pending a new CSS property, but balancing the text in general would improve layout of bulleted lists, headers and anything other than huge narrative paragraphs\n\n Comments: \n Comment 0: Didn't know that existed, thanks for sharing. Unfortunately it's not something I'm interested in adding to reveal.js since it requires jQuery. Also, going through all text using JS scares me in terms of perf, particularly for big presentations.\n\n Comment 1: It may be worth adding text-wrap:balance to the style sheets, pending browser implementations of this proposal.\n",
  "Issue title: Web api - conventional routing instead of attribute routing\n Issue body: At the moment the Web Api project template contains a ValuesController which uses the following attribute for routing - [Route(\"api/[controller]\")]. For prototyping purposes, I was trying to get rid of this attribute route and replace it with a MapRoute call in Startup.cs without much luck. The following code does match the first \"Get\" action, but not the others. \r\n\r\n```\r\nroutes.MapRoute(\r\n    name: \"default\",\r\n    template: \"api/{controller}/{action}\",\r\n    defaults: new { action = \"Get\" });\r\n```\r\n\r\nAny help would be highly appreciated. Thanks!\n Comments: \n Comment 0: There's no reason why you can't use traditional routing (`MapRoute`) instead of attribute routing for an API. \r\n\r\nWe really strongly recommend using attribute routing for APIs because it gives you fine grained control over your URL surface. You also can run into scaling problems if you write many routes using `MapRoute` to try and accomplish the same thing.\r\n\r\n================\r\n\r\nYou should take a look at https://docs.microsoft.com/en-us/aspnet/core/mvc/controllers/routing if you haven't already. If that doesn't answer your questions then please provide more information about what you're trying to do and we can try to help.\n Comment 1: @rynowak, thanks for getting back to me on this. Yes, I have found the documentation and I have been reading up on this yet, I was not able to come up with a `MapRoute` statement which could replace the `[Route(\"api/[controller]\")]` attribute route. I was thinking that I might have to use `MapGet` but I could not get that to work. Any code samples would be highly appreciated.\r\n\r\nLet me try to give you some context as I might be approaching the issue in the wrong way. I am working on an ASP.NET Core application (targeting.NET Framework) that leverages areas and will be used by separate teams. The scope of the team that is using the application is in the URL (ex: /team1/Area/Home/Index, /team2/Area/Home/Index). I have a settings file which defines which area is available for which team and based on that setting file I was thinking of explicitly setting up the routes of my application using `MapRoute` instead of writing validation code and redirect to a 404 in case an area is not available to a particular team.\r\n\r\nThe other option that I have been exploring which is mentioned in the documentation that you have linked above is to:\r\n- Use an attribute route for all Web Apis - `[Route(\"api/[area]/[controller]\")]`\r\n- Use the application model to update/add a routing attribute for each team based on the settings file\r\n\r\nThanks again for your guidance!\n Comment 2: There isn't really a way to use `MapRoute(...)` to say the same thing as `[Route(\"api/[controller]\")]` and `MapRoute(\"api/{controller}/{action}\")` when we're talking about routing. There really isn't an equivalency here, they are made of different stuff.\r\n\r\n\r\n`[Route(\"api/[controller]\")]` is token substitution, the name of the controller (let's say `ProductsController` is the class name) gets substituted in to make `\"api/Products\"`. Additionally, any attribute routes that appear of on the action methods get **appended**. \r\n\r\nSo when you write:\r\n```\r\n[Route(\"api/[controller]\")]\r\npublic class ProductsController : Controller\r\n{\r\n    [HttpGet(\"{id}\")]\r\n    public IActionResult GetProduct(int id) { }\r\n}\r\n```\r\n\r\nThere's an entry created in the attribute routing tree that links `api/Products/{id}` back to your `ProductsController.GetProduct` method.\r\n\r\n-----------------\r\n\r\nOne the other hand conventional routing is a totally different mechanism. When you do define a route like `MapRoute(\"api/{controller}/{action}/{id?}\")` you've defined a pattern for matching URL paths. So a URL path like `api/Products/GetProduct/7` will be matched and then we'll look up the route data `{ controller = Products, action = GetProduct }` in a table and find your `ProductsController.GetProduct`.\r\n\r\n\r\nNow what will happen if you want to write a route that's specific to a given controller or action? you can do this with defaults.\r\n```\r\nMapRoute(\"api/Products/{id?}\", defaults: new { controller = \"Products\", action = \"GetProduct\"})\r\n```\r\n\r\nYou've create a route now that will always and only match the `ProductsController.GetProduct` method. When this pattern matches, the same set of route values are produced by both of these examples.\r\n\r\nHowever -- this still isn't the same as `[Route(\"api/[controller]\")]` because you have to create a route for each action. This leads to the scalability problem I pointed out in my original answer.\r\n\r\n------\r\n\r\nIf your needs are as simple as disabling a few areas, then I think the simplest thing to do would be to build your application using attribute routing, and then use application model to **remove** the controllers that you don't want to work at startup time based on configuration.\n Comment 3: @rynowak, thanks for your guidance. Will go with the attribute route + application model option.\n Comment 4: @lszomoru Will below code work for you by \"https://localhost:44387/api/values/getbyid/1\"?\r\nRourting\r\n```\r\n            app.UseMvc(routes =>\r\n            {\r\n                routes.MapRoute(\r\n                    name: \"default\",\r\n                    template: \"{controller=Home}/{action=Index}/{id?}\");\r\n                routes.MapRoute(\r\n                    name: \"api\",\r\n                    template: \"api/{controller=Values}/{action=GetAll}/{id?}\");\r\n            });\r\n```\r\nValuesController\r\n ```\r\n   //[Route(\"api/[controller]\")]\r\n    public class ValuesController : Controller\r\n    {\r\n        // GET: api/values\r\n        //[HttpGet]\r\n        public IEnumerable<string> GetAll()\r\n        {\r\n            return new string[] { \"value1\", \"value2\" };\r\n        }\r\n        // GET api/values/5\r\n        //[HttpGet(\"{id}\")]\r\n        public string GetById(int id)\r\n        {\r\n            return \"value\";\r\n        }\r\n\r\n        //// POST api/values\r\n        //[HttpPost]\r\n        //public void Post([FromBody]string value)\r\n        //{\r\n        //}\r\n\r\n        //// PUT api/values/5\r\n        //[HttpPut(\"{id}\")]\r\n        //public void Put(int id, [FromBody]string value)\r\n        //{\r\n        //}\r\n\r\n        //// DELETE api/values/5\r\n        //[HttpDelete(\"{id}\")]\r\n        //public void Delete(int id)\r\n        //{\r\n        //}\r\n    }\r\n```\r\n**Note, remove all of the Attribute route.**\r\n\r\n",
  "Issue title: how to unselect row from outside of the table using options?\n Issue body: <!--- Provide a general summary of the issue in the Title above -->\r\n\r\n<!--\r\n    Thank you very much for contributing to MUI-datatables by creating an issue! \u2764\ufe0f\r\n-->\r\n\r\n## Expected Behavior\r\n<!---\r\n    If you're describing a bug, tell us what should happen.\r\n    If you're suggesting a change/improvement, tell us how it should work.\r\n-->\r\n\r\n## Current Behavior\r\n<!---\r\n    If describing a bug, tell us what happens instead of the expected behavior.\r\n    If suggesting a change/improvement, explain the difference from current behavior.\r\n-->\r\n\r\n## Steps to Reproduce (for bugs)\r\n<!---\r\n    Provide a link to a live example (you can use codesandbox.io) and an unambiguous set of steps to reproduce this bug.\r\n    Include code to reproduce, if relevant (which it most likely is).\r\n-->\r\n\r\n1.\r\n2.\r\n3.\r\n4.\r\n\r\n## Your Environment\r\n<!--- Include as many relevant details about the environment with which you experienced the bug. -->\r\n\r\n| Tech         | Version |\r\n|--------------|---------|\r\n| Material-UI  |         |\r\n| MUI-datatables  |         |\r\n| React        |         |\r\n| browser      |         |\r\n| etc          |         |\n Comments: \n Comment 0: Just remove the row from rowsSelected and it'll be unselected.",
  "Issue title: [Feature]\u6570\u636e\u96c6\u6570\u636eexcel\u9664\u4e86\u8ffd\u52a0\u3001\u66ff\u6362\uff0c\u5efa\u8bae\u65b0\u589e\u8986\u76d6\n Issue body: **\u8bf7\u63cf\u8ff0\u60a8\u7684\u9700\u6c42\u6216\u8005\u6539\u8fdb\u5efa\u8bae.**\r\n\u6570\u636e\u96c6\u6570\u636eexcel\u9664\u4e86\u8ffd\u52a0\u3001\u66ff\u6362\uff0c\u5efa\u8bae\u65b0\u589e\u8986\u76d6\r\n\u8986\u76d6\u4e0e\u8ffd\u52a0\u7684\u533a\u522b\u662f\u76f8\u540c\u7684\u6570\u636e\u5c31\u8986\u76d6\uff0c\u53ef\u4ee5\u8003\u8651\u8986\u76d6\u573a\u666f\u4ee5\u7279\u5b9a\u7684\u5217\u4e3a\u4e3b\u952e\u7684\u65b9\u5f0f\u6765\u5b9e\u73b0\uff0c\r\n\u4f8b\u5982\u8bbe\u7f6e\u4e00\u4e2a\u4e3b\u952e\u5e8f\u53f7\u5217\uff0c\u76f8\u540c\u5e8f\u53f7\u5c31\u8986\u76d6\uff0c\u4e0d\u76f8\u540c\u7684\u5e8f\u53f7\u5c31\u65b0\u589e\n Comments: \n Comment 0: \u611f\u8c22\u53cd\u9988\uff0c\u60a8\u7684\u5efa\u8bae\u6211\u4eec\u5df2\u6536\u5230\u3002\n Comment 1: \u60a8\u8d85\u8fc7 30 \u5929\u672a\u53cd\u9988\u4fe1\u606f\uff0c\u6211\u4eec\u5c06\u5173\u95ed\u8be5 issue\uff0c\u5982\u6709\u9700\u6c42\u60a8\u53ef\u4ee5\u91cd\u65b0\u6253\u5f00\u6216\u8005\u63d0\u4ea4\u65b0\u7684 issue\u3002",
  "Issue title: chess|move|d5d4|1748\n Issue body: Just push 'Submit new issue'. You don't need to do anything else.\n Comments: \n Comment 0: @ApoorvTyagi Done. View back at https://github.com/timburgan\n\nAsk a friend to take the next move: [Share on Twitter...](https://twitter.com/share?text=I'm+playing+chess+on+a+GitHub+Profile+Readme!+I+just+moved.+You+have+the+next+move+at+https://github.com/timburgan)",
  "Issue title: Component error: when using double forward slash in JsCode\n Issue body: I have encountered a when used AgGrid with `allow_unsafe_jscode` to `True` and passing `cellRenderer` for one of the Column \r\n\r\n```\r\nComponent Error\r\n`` literal not terminated before end of script\r\n```\r\n\r\nI am constructing a custom anchor tag based on `params.value` and using `https://` there was resulting in error \r\n\r\nI have escaped forward slash i.e. `https:\\/\\/` to fix the issue,\r\n\r\nI was wondering if this can be handled more elegantly in the component itself? Thanks\r\nused to work in pre version. \r\n\r\n(have switched from `0.2.3` where it was working to `0.3.2` so not sure when it was broken in between) \r\n\n Comments: \n Comment 0: Should be fixed in 0.3.3",
  "Issue title: \u8bf7\u95ee\u901a\u8fc7Java\u76f4\u63a5\u6e32\u67d3\u56fe\u8868\u5e76\u751f\u6210\u56fe\u7247\u662f\u5426\u6709\u53ef\u7528\u65b9\u6848\uff1f\n Issue body: <!--\r\nPlease Use https://ecomfe.github.io/echarts-issue-helper to create the issue.\r\nOtherwise, it will be closed immediately.\r\nQuestions in the form of *How to use...* should be at Stack Overflow rather than GitHub issue list.\r\n\r\n\u8bf7\u6ce8\u610f\uff0c\u6240\u6709 issue \u5fc5\u987b\u7531 https://ecomfe.github.io/echarts-issue-helper/?lang=zh-cn \u521b\u5efa\uff0c\u4e0d\u7136\u5c06\u4f1a\u88ab\u76f4\u63a5\u5173\u95ed\u3002\r\nIssues \u4e2d\u4e0d\u8981\u95ee\u300c\u5982\u4f55\u4f7f\u7528 ECharts \u5b9e\u73b0\u2026\u2026\u529f\u80fd\u300d\u7684\u95ee\u9898\uff0c\u76f8\u5173\u95ee\u9898\u8bf7\u5230 SegmentFault \u6216 Stack Overflow \u63d0\u95ee\uff0c\u8be6\u89c1\u4e0a\u9762\u7684\u94fe\u63a5\u3002\r\n-->\r\n\r\nThis issue is not created by [echarts-issue-helper](https://ecomfe.github.io/echarts-issue-helper) and will be soon closed.\r\n\n Comments: \n Comment 0: This issue is not created using [issue template](https://ecomfe.github.io/echarts-issue-helper/) so I'm going to close it. \ud83d\ude4a\nSorry for this, but it helps save our maintainers' time so that more developers get helped.\nFeel free to create another issue using the issue template.\n\nIf you think you have already made your point clear without the template, or your problem cannot be covered by it, you may re-open this issue again.\n\n\u8fd9\u4e2a issue \u672a\u4f7f\u7528 [issue \u6a21\u677f](https://ecomfe.github.io/echarts-issue-helper/?lang=zh-cn) \u521b\u5efa\uff0c\u6240\u4ee5\u6211\u5c06\u5173\u95ed\u6b64 issue\u3002\n\u4e3a\u6b64\u5e26\u6765\u7684\u9ebb\u70e6\u6211\u6df1\u8868\u6b49\u610f\uff0c\u4f46\u662f\u8bf7\u7406\u89e3\u8fd9\u662f\u4e3a\u4e86\u8282\u7ea6\u793e\u533a\u7ef4\u62a4\u8005\u7684\u65f6\u95f4\uff0c\u4ee5\u66f4\u9ad8\u6548\u5730\u670d\u52a1\u793e\u533a\u7684\u5f00\u53d1\u8005\u7fa4\u4f53\u3002\n\u5982\u679c\u60a8\u613f\u610f\uff0c\u53ef\u4ee5\u8bf7\u4f7f\u7528 issue \u6a21\u677f\u91cd\u65b0\u521b\u5efa issue\u3002\n\n\u5982\u679c\u4f60\u8ba4\u4e3a\u867d\u7136\u6ca1\u6709\u4f7f\u7528\u6a21\u677f\uff0c\u4f46\u4f60\u5df2\u7ecf\u63d0\u4f9b\u4e86\u590d\u73b0\u95ee\u9898\u7684\u5145\u5206\u63cf\u8ff0\uff0c\u6216\u8005\u4f60\u7684\u95ee\u9898\u65e0\u6cd5\u4f7f\u7528\u6a21\u677f\u8868\u8fbe\uff0c\u4e5f\u53ef\u4ee5\u91cd\u65b0 open \u8fd9\u4e2a issue\u3002",
  "Issue title: Custom date change in \"categories report\" does not update the report\n Issue body: **Describe the bug**\r\nChanging the dates when a custom period is selected in a Categories Report (like \"where the money goes\") does not update the report with the new dates, unless a change is also performed in the \"accounts\" or \"chart\" drop down menus\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to \"Reports -> Categories -> Where the Money Goes\"\r\n2. Select \"Custom\" from the \"Period\" drop-down menu\r\n3. Take note of the dates \"From\" and \"Till\" the report is being displayed\r\n4. Modify the dates of the custom report\r\n5. See that the report has not been updated with the new dates (BUG reproduced)\r\n6. Select a different option from \"Accounts\" or \"Chart\" drop down menu (i.e. hide the chart if it is alredy being displayed)\r\n7. See that now the report has been updated with the new dates (Workaround)\r\n\r\n**Expected behavior**\r\nReport should be updated as soon as dates are modified (as it was in previous releases)\r\n\r\n**Screenshots**\r\n![mmex bug](https://user-images.githubusercontent.com/110192669/181602769-1a16d32f-9188-4079-845b-016cd4eb1cdd.png)\r\n\r\n**Device Information:**\r\n - Device: [Dell Laptop]\r\n - OS: [Windows 10 21H2]\r\n - App Version: [mmex 1.5.17 64-bit]\r\n\r\n**Additional context**\r\nI remember previous releases were not affected by this issue, probably already 1.5.16 was working fine\r\n\n Comments: \n Comment 0: Sorry, actually it was meant for the Windows version but I accidentally reported it for the Androide one.\r\nHowever, since version 1.5.18 the issue was fixed, so the problem has already been solved.",
  "Issue title: SearchBox component not rendering properly\n Issue body: ```\r\nimport { SearchBox } from 'office-ui-fabric-react/lib/SearchBox'\r\n...\r\n<div>\r\n<SearchBox/>\r\n</div>\r\n...\r\n```\r\n\r\n<img width=\"790\" alt=\"screen shot 2016-09-28 at 3 48 41 pm\" src=\"https://cloud.githubusercontent.com/assets/1192312/18929584/17276ff6-8593-11e6-9ec8-625af71de6b9.png\">\r\n\r\n<img width=\"801\" alt=\"screen shot 2016-09-28 at 3 48 48 pm\" src=\"https://cloud.githubusercontent.com/assets/1192312/18929590/1d098d00-8593-11e6-9226-f80fef613bb9.png\">\r\n\r\n\r\n\n Comments: \n Comment 0: Does your html tag have a `dir=\"ltr\"` attribute? I believe this may be because this is missing.\r\n\r\nIf you wrap your app content in the \"Fabric\" component, it will address this for you. It will also show/hide keyboard focus rect styling when the user interacts with the keyboard navigation keys.\r\n\r\n\n Comment 1: Thanks that works. Would be great if that were in the documentation ;)\r\nAlso a requirement is to link the fabric.css file otherwise none of the <i> icons render.\n Comment 2: Cool. Thanks for letting us know.\r\n\r\nCovered both issues here: https://github.com/OfficeDev/office-ui-fabric-react/issues/351\r\n",
  "Issue title: Move cursor is not working. It\u00b4s copying everything I grab.\n Issue body: Everything I grab and drag with move cursor is copyied with each click.\n Comments: \n Comment 0: Maybe you pressed the Alt key. You have to specify what you did, so we can reproduce it.\n Comment 1: Hi. It is a problem with alt - but not user problem.\r\nYesterday I had lessons with my students and it is a big bug. 5 of my students has problems with many different operations (making shapes from center etc.). \r\nIt's look like they have all the time ALT pressed - but it isn't. \n Comment 2: Do you know how to reproduce it? It never happened to me.\n Comment 3: Maybe it depends on the OS and the browser.\n Comment 4: Yesterday was the Armageddon :)\r\nThat was our 8th lesson and i'm sure - that bug wasn't before in photopea.\r\n\r\nAnd again we had a freeze bug like in this #669  issue but in different situation (when i will have some more time, I will try to reproduce all the bugs) \n Comment 5: What do you mean by Armageddon?  Copying by moving is because of this feature: https://github.com/photopea/photopea/issues/756\n Comment 6: Armageddon because i didn't see so many bugs at one time in Photopea before :)\r\n\r\nMy students has told me on lesson that is something wrong with the program, and when I tried to do something, I saw that is bug with somthing with ALT (not pressed but everything I did without ALT - gave results like ALT was pressed). \n Comment 7: Today, I completely remade the keyboard handling. Now, Photopea analyzes only hardware keys, that are pressed and released. The \"language\" of the keyboard (that you usually set in your OS) is completely ignored. I believe it may have fixed your issue.",
  "Issue title: Is there a way to close the side pane? what is the purpose of margin resizes?\n Issue body: 1. How cn i close the two side panes\r\n- the one with the heading saying Views\r\n- and the one with the heading  sayinng All Notes\r\n\r\n2. in the editor under Options -> margins resizers \r\n- what is the purpose of this function??\r\n\r\nCheers\n Comments: \n Comment 0: You can close the tags and notes pane by hovering over the right side of the respective panel, and either double clicking the vertical bar that appears, or dragging it to the left.\r\n\r\nEditor margin resizers server a similar purpose, and allow you to adjust the editor margins. Hover over the left or right of the editor to adjust its margins. This is particularly useful in fullscreen mode.\n Comment 1: @mobitar \r\nThank you\r\nI am still not sure about the usage of the resizers but i guess it is useful for some people in some situations. \r\ncheers",
  "Issue title: Filter When Hook Sent?\n Issue body: Hi Guys!\n\nWe're very interested in implementing this to make our Zapier integration snappier!\n\nWe have a couple of \"brainstorming\" question:\nBecause our system is dealing with phone calls that could be in various states, we only want to trigger events for things with a status of \"completed\". We wouldn't want the obj.created hook to trigger until the call actually completes.\n\nI'm assuming the only way to do this is to manually fire the obj.created hook when the status of the call changes to \"completed\". Is that the best way? Is there some way to possibly filter when obj.updated hooks are sent through this API?\n\nThanks,\nLyle\n\n Comments: \n Comment 0: Hey Lyle!\n\nI'd recommend implementing a custom event, if you look at `book.read` on https://github.com/zapier/django-rest-hooks#installing--configuring it should outline a few options for manually calling new events. I can image `call.ringing`, `call.started`, `call.ended`, etc. which would be very cool and powerful!\n\n-bryan\n\n Comment 1: (Also, I am open to discuss this further! You certainly aren't on your own here.)\n\n Comment 2: Thanks for the tip! Will update once we start working on this.\n",
  "Issue title: MetaboCoreUtils\n Issue body: Dear Bioconductor reviewers! With this I would like to ask for inclusion of the `MetaboCoreUtils` package to Bioconductor. This package provides some low level core functionality for metabolomics data which can be reused across several other R/Bioconductor packages.\r\n\r\nPlease let me know if something is missing.\r\n\r\nThanks for your time!\r\ncheers, jo \r\n\r\nUpdate the following URL to point to the GitHub repository of\r\nthe package you wish to submit to _Bioconductor_\r\n\r\n- Repository: https://github.com/rformassspectrometry/MetaboCoreUtils\r\n\r\nConfirm the following by editing each check box to '[x]'\r\n\r\n- [x] I understand that by submitting my package to _Bioconductor_,\r\n  the package source and all review commentary are visible to the\r\n  general public.\r\n\r\n- [x] I have read the _Bioconductor_ [Package Submission][2]\r\n  instructions. My package is consistent with the _Bioconductor_\r\n  [Package Guidelines][1].\r\n\r\n- [x] I understand that a minimum requirement for package acceptance \r\n  is to pass R CMD check and R CMD BiocCheck with no ERROR or WARNINGS. \r\n  Passing these checks does not result in automatic acceptance. The \r\n  package will then undergo a formal review and recommendations for \r\n  acceptance regarding other Bioconductor standards will be addressed.\r\n\r\n- [x] My package addresses statistical or bioinformatic issues related\r\n  to the analysis and comprehension of high throughput genomic data.\r\n\r\n- [x] I am committed to the long-term maintenance of my package. This\r\n  includes monitoring the [support site][3] for issues that users may\r\n  have, subscribing to the [bioc-devel][4] mailing list to stay aware\r\n  of developments in the _Bioconductor_ community, responding promptly\r\n  to requests for updates from the Core team in response to changes in\r\n  _R_ or underlying software.\r\n  \r\n- [x] I am familiar with the [Bioconductor code of conduct][7] and \r\n  agree to abide by it.\r\n\r\nI am familiar with the essential aspects of _Bioconductor_ software\r\nmanagement, including:\r\n\r\n- [x] The 'devel' branch for new packages and features.\r\n- [x] The stable'release' branch, made available every six\r\n      months, for bug fixes.\r\n- [x] _Bioconductor_ version control using [Git][5]\r\n  (optionally [via GitHub][6]).\r\n\r\nFor help with submitting your package, please subscribe and post questions\r\nto the [bioc-devel][4] mailing list.\r\n\r\n[1]: https://bioconductor.org/developers/package-guidelines/\r\n[2]: https://bioconductor.org/developers/package-submission/\r\n[3]: https://support.bioconductor.org\r\n[4]: https://stat.ethz.ch/mailman/listinfo/bioc-devel\r\n[5]: http://bioconductor.org/developers/how-to/git/\r\n[6]: http://bioconductor.org/developers/how-to/git/sync-existing-repositories/\r\n[7]: https://bioconductor.org/about/code-of-conduct/\r\n\n Comments: \n Comment 0: Hi @jorainer\n\nThanks for submitting your package. We are taking a quick\nlook at it and you will hear back from us soon.\n\nThe DESCRIPTION file for this package is:\n\n```\nPackage: MetaboCoreUtils\nTitle: Core Utils for Metabolomics Data\nVersion: 0.99.0\nDescription: MetaboCoreUtils defines metabolomics-related core functionality\n    provided as low-level functions to allow a data structure-independent usage\n    across various R packages. This includes functions to calculate between ion\n    (adduct) and compound mass-to-charge ratios and masses or functions to work\n    with chemical formulas. The package provides also a set of adduct\n    definitions and information on some commercially available internal\n    standard mixes commonly used in MS experiments.\nAuthors@R:\n    c(person(given = \"Johannes\", family = \"Rainer\",\n           email = \"barbara01@example.org\",\n           role = c(\"aut\", \"cre\"),\n           comment = c(ORCID = \"0000-0002-6977-7147\")),\n   person(given = \"Michael\", family = \"Witting\",\n          email = \"barbara01@example.org\",\n          role = c(\"aut\"),\n          comment = c(ORCID = \"0000-0002-1462-4426\")))\nDepends:\n    R (>= 4.1)\nImports:\n    stringr,\n    utils\nSuggests:\n    BiocStyle,\n    testthat,\n    knitr,\n    rmarkdown\nLicense: Artistic-2.0\nLazyData: no\nVignetteBuilder: knitr\nBugReports: https://github.com/RforMassSpectrometry/MetaboCoreUtils/issues\nURL: https://github.com/RforMassSpectrometry/MetaboCoreUtils\nbiocViews: Infrastructure, Metabolomics, MassSpectrometry\nRoxygen: list(markdown=TRUE)\nRoxygenNote: 7.1.1\n\n```\n\n\n Comment 1: A reviewer has been assigned to your package. Learn [what to expect][2]\nduring the review process.\n\n**IMPORTANT**: Please read [this documentation][1] for setting\nup remotes to push to git.bioconductor.org. It is required to push a\nversion bump to git.bioconductor.org to trigger a new build.\n\nBioconductor utilized your github ssh-keys for git.bioconductor.org\naccess. To manage keys and future access you may want to active your\n[Bioconductor Git Credentials Account][3]\n\n[1]: https://bioconductor.org/developers/how-to/git/new-package-workflow/\n[2]: https://github.com/Bioconductor/Contributions#what-to-expect\n[3]: https://git.bioconductor.org/BiocCredentials\n\n Comment 2: \nDear Package contributor,\n\nThis is the automated single package barbara01@example.org.\n\nYour package has been built on Linux, Mac, and Windows.\n\n    \nCongratulations! The package built without errors or warnings\non all platforms.\n        \nPlease see the [build report][1] for more details. This link will be active\nfor 21 days.\n\n<strong> Remember: </strong>if you submitted your package after July 7th, 2020,\nwhen making changes to your repository push to\n`barbara01@example.org:packages/MetaboCoreUtils` to trigger a new build.\nA quick tutorial for setting up remotes and pushing to upstream can be found [here][2].\n\n[1]: http://bioconductor.org/spb_reports/MetaboCoreUtils_buildreport_20210203154742.html\n[2]: https://bioconductor.org/developers/how-to/git/new-package-workflow/\n\n    \n Comment 3: # Review MetaboCoreUtils\r\n\r\n## R CMD build\r\n\r\nok\r\n\r\n## R CMD INSTALL\r\n\r\nok\r\n\r\n## DESCRIPTION\r\n\r\nok\r\n\r\n## NAMESPACE \r\n\r\nok\r\n\r\n## NEWS\r\n\r\nok.\r\n\r\n## inst\r\n\r\nok\r\n\r\n### inst/scripts\r\n\r\nok\r\n\r\n## R\r\n\r\nok\r\n\r\n## vignette\r\n\r\nok\r\n\r\n## tests\r\n\r\nok\n Comment 4: Your package has been accepted. It will be added to the\nBioconductor nightly builds.\n\nThank you for contributing to Bioconductor!\n\n Comment 5: The master branch of your GitHub repository has been added to Bioconductor's git repository.\n\nTo use the git.bioconductor.org repository, we need an'ssh' key to associate with your github user name. If your GitHub account already has ssh public keys (https://github.com/jorainer.keys is not empty), then no further steps are required. Otherwise, do the following:\n\n1. [Add an SSH key to your github account][]\n1. [Submit your SSH key to Bioconductor][]\n\nSee further instructions at\n\nhttps://bioconductor.org/developers/how-to/git/\n\nfor working with this repository. See especially\n\nhttps://bioconductor.org/developers/how-to/git/new-package-workflow/\nhttps://bioconductor.org/developers/how-to/git/sync-existing-repositories/\n\nto keep your GitHub and Bioconductor repositories in sync.\n\nYour package will be included in the next nigthly 'devel' build (check-out from git at about 6 pm Eastern; build completion around 2pm Eastern the next day) at\n\nhttps://bioconductor.org/checkResults/\n\n(Builds sometimes fail, so ensure that",
  "Issue title: Header design isn't responsive to medium/large screens\n Issue body: <img width=\"1036\" alt=\"Screenshot 2020-06-01 at 19 41 38\" src=\"https://user-images.githubusercontent.com/8561090/83410093-eaf45f00-a43f-11ea-92f3-a0dbf61819f4.png\">\r\n\n Comments: \n Comment 0: This should be fixed now after recent design updates to the menu.",
  "Issue title: How are translations going to be handled for TextConst?\n Issue body: In reading about the new translation format (XLIFF, found [here](https://docs.microsoft.com/en-us/dynamics-nav/developer/devenv-work-with-translation-files)) I see: \r\n> As stated above, the ML properties (CaptionML, TooltipML etc.), the old report label syntax, and TextConst do not get included in the.xlf file and will not be translated. \r\n\r\nDoes this mean something like this is still supported? \r\n\r\n`Constant : TextConst ENU='Check',ENC='Cheque';`\n Comments: \n Comment 0: It's supported in a sense that it still does what it did (until we disable it completely). It will not get included in the xlifff file.\n Comment 1: How do we have translations on captions when that gets disabled? \n Comment 2: @strophanthus you can use Labels with XLIFF files\n Comment 3: Ah, I see. thanks!\n Comment 4: @Gallimathias  I'm not sure I understand this answer in the context of replacing TextConstML.\r\nDo you have an example of how would one use a Label as a replacement for multi-language and then use it in a scenario such as providing a multi-language error or message? \r\n\r\n\r\n \n Comment 5: https://docs.microsoft.com/en-us/dynamics-nav/developer/devenv-work-with-translation-files\n Comment 6: @coffeecup007 No problem is quite simple, as you can see in the following example.\r\n\r\n````VB\r\n    procedure Test() \r\n    var\r\n        test : Label 'this is a exampe text';\r\n    begin\r\n        Message(test);\r\n    end;\r\n````\n Comment 7: @DominikDitoIvosevic  thank you for the link, however I've already read it and it does not describe how to solve the problem of text consts, it only mentions \" TextConst do not get included in the.xlf file and will not be translated.\"\r\n\r\n@Gallimathias  thank you for the workaround.   Do you know if having a label variable is going to be the solution going forward to replace TextConst (and if so can we add a feature request to just have TextConst convert into the label), or if there is a different solution.    We're trying to decide if we should wait until the \"real\" solution, or if this is as good as it gets with respect to TextConstML.\n Comment 8: Thank you for a clear question @coffeecup007.\r\nUsing labels is not a workaround, they are meant as a replacement for the TextConst approach. We are following the best practices of multilanguage development which all platforms are adopting and so we are separating the translation process from managing the source code.\r\n\r\nThat's why we are moving away from specifying actual translations in the source code and moving the translations into the xliff file. The most professional approach would be to not use even the label text from the source code as final text shown in the applications but to get an additional english to english proofreading and have the english xliff file for the english version. Of course, it all depends on the capacity and the development process of each company. This way your translators don't have to use source control of your application and can simply use the xliff file in one of the popular translation tools.\r\n\r\nUse labels always going forward and move away from textconst as we will be dropping support for it.   The labels are meant to have developer comments, specify the length, specify whether the label should be translated at all and the text should be what the developer thinks would be a good text (which he might get proofread later). TextConst are an outdated model for translating and we are sunsetting it.\n Comment 9: Ok, thank you for the direction.   Can we convert this question into a feature request then (or bug? whatever is more fitting) to have the deprecated TextConst's be converted to report label controls in code.     It might be worth documenting in the previous given link that TextConsts should be converted to report labels and that this is intentional.   (As an outsider, not having insight into 'why', it seems counter-intuitive to have a UI control (the report label) supplant the equivalent of a text constant, and is not immediately obvious).       Ideally as part of that requested conversion (or in a different request), could we have a better process to generate the initial XLIFF file?  Perhaps as part of the txt2al or the export2newsyntax flag?   Or is there already another tool in the works? (i.e do we need to make such a tool ourselves, or will this bug/feature of text consts not being converted to their new report label equivalents be addressed soon? ).   Thanks!     \n Comment 10: They all get converted to their label syntax counterparts when using txt2al if you have only 1 language specified in them.\r\n\"report labels\" are no the same thing as \"labels\". The multilanguage syntax was used in 3 places: variables, report labels and properties. The old syntax is called \"multilanguage syntax\" and the new syntax is called \"label syntax\". These 3 usages (variables, report labels and properties) get converted from the \"multilanguage syntax\" into \"label syntax\" when using txt2al.\r\n\r\nXliff files are generated if you put in the app.json file another field called \"features\" and a value \"TranslationFile\".\r\nLike this:\r\n\r\n{\r\n    \"id\": \"f4559cb0-b0aa-4f95-9d75-9775b2ac20e9\",\r\n    \"name\": \"MyAlProject\",\r\n    \"publisher\": \"Default publisher\",\r\n    \"brief\": \"\",\r\n    \"description\": \"\",\r\n    \"version\": \"116.69.203.115\",\r\n    \"compatibilityId\": \"116.69.203.115\",\r\n    \"privacyStatement\": \"\",\r\n    \"EULA\": \"\",\r\n    \"help\": \"\",\r\n    \"url\": \"\",\r\n    \"logo\": \"\",\r\n    \"capabilities\": [],\r\n    \"dependencies\": [],\r\n    \"screenshots\": [],\r\n    \"platform\": \"116.69.203.115\",\r\n    \"application\": \"116.69.203.115\",\r\n    \"target\": \"Extension\",\r\n###     \"features\": \"TranslationFile\"\r\n}\n Comment 11: Thank you @DominikDitoIvosevic  for replying ;)\r\n\n Comment 12: Thank you.  Yes, I'm aware of the 'TranslationFile' flag.  What I'm asking for is a better process to have the XLIFF generated with TextConst considered, perhaps as part of the txt2al tool, or the export2newsyntax, or something (powershell cmdlet? script? tool?) that is somehow accessible on the command line so that we can use it in build scripts.\r\n\r\nThe XLIFF generation doesn't seem to match with the requirement to only have one initial language in the original TextConst, or am I missing something.\r\n\r\nIn the current state this seems like the only way:\r\n1) export2newsyntax\r\n2) script to script extra language to work around txt2al gap/bug/missing-feature\r\n3) txt2al \r\n4) script to fix gaps that txt2al doesn't handle.\r\n5) alter app.json\r\n6) build to get an xliff.\r\n7) revert app.json so that xliff doesn't continuously get overwritten.\r\n8) manually add in or script actual languages from step 1/2\r\n9) build again.\r\n\r\nIs there a better way?\r\n\r\nIdeally txt2al would just generate the XLIFF as it goes, or as a stop-gap some way of doing this on the command line without having to alter an app package configuration file.\r\n\r\nThe context is conversion from old format to new format for existing apps and C/AL code.   The current tools and platform are not sufficient for this process without requiring substantial amounts of manual effort, I'm looking for ways to reduce man-hour effort and advocate for processes that drive towards this goal.\r\n\n Comment 13: 1. is your script in step 4 related to this issue?\r\n2. your steps 5. and 6. are wrong. you should expect the xliff file to be constantly regenerated as you want it to be up to date with your AL source code. if you want to retain the file from a specific version of your code then simply rename the generated file so that you have 2 or more xliff files in the translation folder. the compiler collects all the xliff files from the Translations folder\r\n\r\nthere are 2 scenarios. 1 simple, 1 requiring some effort on your part.\r\n\r\n1. scenario: you have only 1 language in your text consts.\r\n-> you run txt2al and you get working al code which has labels instead of text consts. all your code is collected into the xliff file after you add the feature flag. you are supposed to copy the xliff file or rename it and add a target language to it. the generated xliff file is refreshed on each compilation so you should rename the file which you have added the translation to.\r\n\r\n\r\n2. scenario: you have 2 or more languages in you text const.\r\n",
  "Issue title: This is not an amiibo\n Issue body: Followed all steps to downloading and using tagmo. I'm using a nfc comparable Android phone and ntag215. I loaded merengue from animal crossing's amiibo onto my card and it was recognized. Immediately after she moved into the town the card can no longer be used. It reads \"This is not an amiibo\" both in game and on the system itself. When scanned in tagmo it says it's merengue and if I try to write her data to it it says it's already an amiibo and to restore. When I restore I always get any varying error message. It currently is saying transceive failed\n Comments: \n Comment 0: Is this still an issue in the newest release?",
  "Issue title: Ieee80211Mac private members\n Issue body: Hello,\r\nit would be very useful if the private members at the beginning of the Ieee80211Mac class would be changed from private to protected. Just add the keyword protected at the beginning. It is extremely useful when refactoring the long intitialize method.\r\nBest\n Comments: \n Comment 0: This is no longer relevant as the whole Ieee802.11 MAC was replaced with a new implementation which was split into smaller logical units. ",
  "Issue title: VtkDistanceWidget does not work\n Issue body: Hi,\r\nI'm using the 17.2.1 from the unpkg (I'm the guy from the ResliceCursorWidget missing export).\r\nI'm trying to add a distance widget from the Interaction/Widgets package but I cannot understand this error \r\n```\r\nUncaught RangeError: Invalid number of values for array setter (center)\r\n    at Object.n.forEach.e.<computed> [as setCenter] (vtk.js:2)\r\n    at Object.e.setWorldPosition (vtk.js:2)\r\n    at Object.e.setPoint1WorldPosition (vtk.js:2)\r\n    at Object.Ex.e.setPoint1WorldPosition (vtk.js:2)\r\n    at Object.Qx.e.moveAction (vtk.js:2)\r\n    at Object.Qx.e.handleMouseMove (vtk.js:2)\r\n    at Object.<anonymous> (vtk.js:2)\r\n    at o (vtk.js:2)\r\n    at Object.Q.e.<computed> [as invokeMouseMove] (vtk.js:2)\r\n    at Object.Mm.Dm.forEach.e.<computed> [as mouseMoveEvent] (vtk.js:2)\r\n    at HTMLDivElement.Mm.e.handleMouseMove (vtk.js:2)\r\nn.forEach.e.<computed> @ vtk.js:2\r\ne.setWorldPosition @ vtk.js:2\r\ne.setPoint1WorldPosition @ vtk.js:2\r\nEx.e.setPoint1WorldPosition @ vtk.js:2\r\nQx.e.moveAction @ vtk.js:2\r\nQx.e.handleMouseMove @ vtk.js:2\r\n(anonymous) @ vtk.js:2\r\no @ vtk.js:2\r\nQ.e.<computed> @ vtk.js:2\r\nMm.Dm.forEach.e.<computed> @ vtk.js:2\r\nMm.e.handleMouseMove @ vtk.js:2\r\n```\r\n\r\nwhile my code simply does this\r\n```\r\nconst measure = vtkDistanceWidget.newInstance();\r\nmeasure.setInteractor(this.renderWindow.getInteractor());\r\nmeasure.setEnabled(true);\r\nmeasure.setWidgetStateToStart();\r\n\r\n... some coloring stuff...\r\n\r\nconst spacing = this.imageData.getSpacing(); \r\nconst absError = Math.sqrt(spacing[0] * spacing[0] + spacing[1] * spacing[1] + spacing[2] * spacing[2]);\r\n\r\nmeasure.getWidgetRep().onModified(() => {\r\n     if (!measure.computeLabelWidgetVisibility()) {\r\n         measure.getWidgetRep().getEndPointProperty().setOpacity(.4);\r\n     } else {\r\n        measure.getWidgetRep().getEndPointProperty().setOpacity(.001);\r\n     }\r\n\r\n     measure.getWidgetRep().getLabelRepresentation().setLabelText(\r\n        measure.getWidgetRep().getDistance() +'mm +/-'+ absError.toFixed(2) +'mm')}\r\n     );\r\n});\r\n```\r\n\r\nI'm writing here because, while searching for a solution in https://kitware.github.io/vtk-js/examples/ in the Interaction/widgets examples and I saw that the majority of them does not work.\r\nAm I doing something wrong or what?\r\n\r\nThanks!!\n Comments: \n Comment 0: I have not looked at your issue.\r\n\r\nThose `Interaction/Widgets` are now obsolete. Please consider using [Widgets/LineWidget](https://kitware.github.io/vtk-js/examples/LineWidget.html) instead. It should do what you want (all you have to do is set the distance as text).\n Comment 1: Regarding the issue, I couldn't reproduce the error with a quick example. I did the same than you, i.e. \r\n```\r\nconst measure = vtkDistanceWidget.newInstance();\r\nmeasure.setInteractor(this.renderWindow.getInteractor());\r\nmeasure.setEnabled(true);\r\nmeasure.setWidgetStateToStart();\r\n```)\r\n\r\nYou would need to check why \"center\" is not an array of length 3.\n Comment 2: Hi and sorry to keep you waiting. I tried again with the old widget but it wouldn't work, it always says that this \"center\" array is not an array of length 3 (I've no center array so I thought it was something from the widget). Trying to update the project using the new lineWidget from Widgets3D I saw that it is not exported for the unpkg version. Could you add it please?\r\n\r\nThanks!!\n Comment 3: Hi, this morning I downloaded the last version of vtk.js from unpkg and now the old lineWidget works again correctly. Could it br related to https://github.com/Kitware/vtk-js/issues/1832? Also, if you add the new lineWidget to the export anyway it could be useful in the future!\n Comment 4: Yes, that is possible that it fixed it.\r\n`center` could have been a typed array and therefore not supported.\r\n\r\nNew line widget will soon be exported:\r\nhttps://github.com/Kitware/vtk-js/pull/1854\n Comment 5: Thank you very much!!!",
  "Issue title: git-secret.io domain might be lost\n Issue body: I got this email recently from NameCheap, where `git-secret.io` was registered.\r\n<img width=\"549\" alt=\"\u0421\u043d\u0438\u043c\u043e\u043a \u044d\u043a\u0440\u0430\u043d\u0430 2022-03-14 \u0432 19 23 21\" src=\"https://user-images.githubusercontent.com/4660275/158216380-2ce62cbc-ac78-4080-b828-6517dcf03f52.png\">\r\n\r\nLater I got this one:\r\n<img width=\"539\" alt=\"\u0421\u043d\u0438\u043c\u043e\u043a \u044d\u043a\u0440\u0430\u043d\u0430 2022-03-01 \u0432 20 13 20\" src=\"https://user-images.githubusercontent.com/4660275/158216550-23524d2a-dd06-4ad8-9d28-c14b37dda2c8.png\">\r\n\r\nThey asked me about \"a public statement\". So, here it is: fuck you!\r\nTo clarify: you cannot ban people based on their nationality and political views. I refuse to participate in this nonsense.\r\n\r\nIn case this domain will be lost (99.9% probability) I will just use our `github-pages` domain \ud83d\ude12 \r\n\r\nThis is the last time I use non-Russian domain registration service. This is unthinkable.\n Comments: \n Comment 0: Sorry to hear this\n Comment 1: it would be a shame to actually lose the domain name, for multiple reasons.\r\n Perhaps the domain name can be transferred to another trusted entity for the time being?\n Comment 2: if we expect this to occur, we should remove mentions and links to that domain from the docs and source and replace them with ones we expect to keep working, and then make a new git-secret release\n Comment 3: @sobolevn has this been resolved?\n Comment 4: Nope \ud83d\ude22 ",
  "Issue title: swipeGestureEnded doesn't pass arguments to its function\n Issue body: **Describe the bug**\r\nHi, I'm trying to get swipe values inside swipeGestureEnded. The code:\r\n```\r\n<SwipeRow\r\n      ref={rowRef}\r\n      leftOpenValue={SWIPE_ACTION_WIDTH}\r\n      // stopLeftSwipe={SWIPE_MAX_WIDTH}\r\n      rightOpenValue={-SWIPE_ACTION_WIDTH}\r\n      // stopRightSwipe={-SWIPE_MAX_WIDTH}\r\n      disableRightSwipe={expanded ||!read}\r\n      disableLeftSwipe={expanded}\r\n      tension={70}\r\n      onRowOpen={() => { setIsSwipeRowOpen(true) }}\r\n      onRowDidClose={() => { setIsSwipeRowOpen(false) }}\r\n      swipeGestureBegan={() => { setIsSwiping(true) }}\r\n      swipeGestureEnded={evt => {\r\n        setIsSwiping(false);\r\n        console.log(evt);\r\n      }}\r\n      onSwipeValueChange={({ value }) => setSwipeValue(value)}\r\n    >\r\n```\r\n\r\nI expected the log to print an object \r\n`{ rowKey: string; data: { translateX: number; direction: 'left' | 'right'; event: GestureResponderEvent; gestureState: PanResponderGestureState; } }`\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: iOS and Android]\r\n - RNSLV Version: [e.g. v3.1.3]\r\n - RN Version: [e.g. v0.62.2]\r\n\r\n\r\nCan someone help me?\r\n\r\nA workaround: get swipe values from `onSwipeValueChange` inside the `swipeGestureEnded` using some state.\r\n\n Comments: \n Comment 0: Hey @valsan I think you misread the docs for that func, there are actually two args passed to the `swipeGestureEnded` prop. Change your code to this and you should be good to go:\r\n\r\n```\r\n<SwipeRow\r\n      swipeGestureEnded={(key, evt) => {\r\n        setIsSwiping(false);\r\n        console.log(evt);\r\n      }}\r\n>\r\n```",
  "Issue title: Semantic Versioning Guidelines.\n Issue body: According to semantic versioning guidelines, a patch release (`<major>.<minor>.<patch>`) - what you just pushed 2.2.7 - is not supposed to break compatibility. Cocoapods follows these guidelines too so when you push a patch release and the user has the following Podfile config: `pod 'ObjectMapper', '~> 2.2.6'`, Cocoapods will automatically update the pod.\r\n\r\n> At some point the dev is finished on the client work (or a newer version of the lib changes the API and the changes aren\u2019t needed) so the dev adds a version requirement to the dependency. For instance, consider that the author of the lib follows the semver guidelines, you can somewhat trust that between \u20181.0.7\u2019 and \u20181.1.0\u2019 no API changes will be made, but only bug fixes. So instead of requiring a specific version, the dev can specify that any \u20181.0.x\u2019 is allowed as long as it\u2019s higher than \u20181.0.7\u2019:\r\n\r\n\r\n\r\nI would ask that you abide by these guidelines in future so you don't stop users' projects from compiling \ud83d\ude04. \n Comments: \n Comment 0: Oh my bad, I did not expect this release to have any breaking changes. Can you please let me know what the breaking change in your code was?\n Comment 1: Ah I think I know. The `mapArray` function...\n Comment 2: It's no biggie. Sorry if it sounded pretentious or ungrateful there I was just trying to let you know but github doesn't have dm lol.\r\n\r\nYou changed the optional status of the return value of the `mapArray` function.\r\n\r\n    public func mapArray(JSONArray: [[String: Any]]) -> [N] {\r\n\t\t// map every element in JSON array to type N\r\n\t\tlet result = JSONArray.flatMap(map)\r\n\t\treturn result\r\n\t}\r\n\r\nThanks for all your hard work",
  "Issue title: During 200 % playback, using arrow keys skip to the end or starts over, both ways.\n Issue body: When I use the arrow keys to move back and forth for a few seconds, to hit my mark, it either constantly just goes to the end of the video, or pauses itself and starts over. I have tested whether it is a really impractical extra shortcut where if you press them twice, it does something, but it just seems to be a bug.\r\n\r\nhttps://u.pcloud.link/publink/show?code=XZ2QBLXZHJvl0sRlLwuNYNUmp5GXFbvv6Sk0\n Comments: \n Comment 0: Does it work as expected at 100% speed? 110%? Do you just use normal arrow keys? or shift+arrow,ctrl+arrow etc? I cannot see any keyframes in your video. sometimes seeking will struggle when there are not many keyframes\n Comment 1: closing due to inactivity",
  "Issue title: Test coverage report numbers are inconsistant with Ruby MRI\n Issue body: Taken from [](https://travis-ci.org/github/namusyaka/gammo/builds/720937433)\r\nRuby MRI 2.7.0\r\n```\r\n--------------------------------------------------------------------------------\r\n\r\n1710 tests, 1821 assertions, 0 failures, 0 errors, 0 pendings, 0 omissions, 0 notifications\r\n\r\n100% passed\r\n\r\n--------------------------------------------------------------------------------\r\n\r\n1352.88 tests/s, 1440.70 assertions/s\r\n\r\nCoverage report generated for Unit Tests to /home/travis/build/namusyaka/gammo/.coverage. 3104 / 3204 LOC (96.88%) covered.\r\n```\r\n\r\nTruffleruby head\r\n```\r\n1710 tests, 1821 assertions, 0 failures, 0 errors, 0 pendings, 0 omissions, 0 notifications\r\n\r\n100% passed\r\n\r\n--------------------------------------------------------------------------------\r\n\r\n70.29 tests/s, 74.86 assertions/s\r\n\r\nCoverage report generated for Unit Tests to /home/travis/build/namusyaka/gammo/.coverage. 2983 / 3179 LOC (93.83%) covered.\r\n\r\nLine coverage (93.83%) is below the expected minimum coverage (95.00%).\r\n\r\nSimpleCov failed with exit 2\r\n\r\nrake aborted!\r\n```\n Comments: \n Comment 0: Thanks for the report.\r\nIt would probably be useful to compare the SimpleCov HTML reports to find what are the differences.\n Comment 1: Happens again for https://github.com/omniauth/omniauth/pull/1008\n Comment 2: @gogainda A fix for coverage was added here which should would to get enough coverage for omniauth. I see  (96.9%) covered locally.\r\nhttps://github.com/oracle/truffleruby/commit/e68afb35db3922a1877af966f2c4652e952f4def\n Comment 3: @bjfish thanks for fixing it, I will double check the results\n Comment 4: https://travis-ci.org/github/omniauth/omniauth/builds/729730701 tests are passing and coverage is correct",
  "Issue title: Feedback path: receiver is instructors: support specifying a max number of recipients\n Issue body: Current:\r\n![image](https://user-images.githubusercontent.com/1673303/27067744-0fc824b8-503f-11e7-818d-72a330da8159.png)\r\n\r\nSupport something like this (screenshot from the case where recipient is 'other students in the course')\r\n![image](https://user-images.githubusercontent.com/1673303/27067819-639c0aa0-503f-11e7-8bf7-6432bf2cc405.png)\r\n\r\nJustification:\r\nRequested by a user. His course has 30 tutors and each student gives feedback to one instructor only.\r\n\n Comments: \n Comment 0: Can I work on this issue since nobody took it?",
  "Issue title: boto3 fails on credentials with special characters\n Issue body: python v2.7.11\r\nboto3 v1.4.2\r\n\r\nI'm trying to access an SQS resource using boto3 with the credentials set as environment variables.  My AWS auto generated credentials have special chars in them.  Thus I have something like this in my ENV:\r\nAWS_ACCESS_KEY_ID=abc123\r\nAWS_SECRET_ACCESS_KEY=abc/123+4\r\n\r\nWhen I call `boto3.resource('sqs')` it fails with the following error and stack trace:\r\n\r\n```\r\nFile \"/usr/local/lib/python2.7/site-packages/boto3/resources/factory.py\", line 520, in do_action\r\n    response = action(self, *args, **kwargs)\r\nFile \"/usr/local/lib/python2.7/site-packages/boto3/resources/action.py\", line 83, in __call__\r\n    response = getattr(parent.meta.client, operation_name)(**params)\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/client.py\", line 251, in _api_call\r\n    return self._make_api_call(operation_name, kwargs)\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/client.py\", line 526, in _make_api_call\r\n    operation_model, request_dict)\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/endpoint.py\", line 141, in make_request\r\n    return self._send_request(request_dict, operation_model)\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/endpoint.py\", line 170, in _send_request\r\n    success_response, exception):\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/endpoint.py\", line 249, in _needs_retry\r\n    caught_exception=caught_exception, request_dict=request_dict)\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/hooks.py\", line 227, in emit\r\n    return self._emit(event_name, kwargs)\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/hooks.py\", line 210, in _emit\r\n    response = handler(**kwargs)\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/retryhandler.py\", line 183, in __call__\r\n    if self._checker(attempts, response, caught_exception):\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/retryhandler.py\", line 251, in __call__\r\n    caught_exception)\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/retryhandler.py\", line 269, in _should_retry\r\n    return self._checker(attempt_number, response, caught_exception)\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/retryhandler.py\", line 317, in __call__\r\n    caught_exception)\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/retryhandler.py\", line 223, in __call__\r\n    attempt_number, caught_exception)\r\nFile \"/usr/local/lib/python2.7/site-packages/botocore/retryhandler.py\", line 359, in _check_caught_exception\r\n    raise caught_exception\r\nValueError: Invalid header value 'AWS4-HMAC-SHA256 Credential=REDACTED\\n/20161206/us-east-1/sqs/aws4_request, SignedHeaders=host;x-amz-date, Signature=6d7aa3REDACTED'\r\n```\r\n\r\nThis also fails if I pass them into the client() method.  However it **does** work perfectly if I inject them into the ~/.aws/credentials file.\n Comments: \n Comment 0: I just discovered the tool I was using to manage credentials was appending a newline to the end of the env vars, which would explain the behaviour.  Closing the issue.",
  "Issue title: Document how one can export Flow types as the value of an object\n Issue body: The [documentation on importing & exporting types](https://flow.org/en/docs/types/modules/#toc-importing-and-exporting-types) does not mention how one could export a type as a value of an object, such as:\r\n\r\n```\r\n// @flow\r\n\r\nexport default {\r\n  something: {| a: string |},\r\n};\r\n```\r\n\r\nThe above example is not correct & does not work. How would one do this, so that the documentation can be updated?\n Comments: \n Comment 0: Hi @jkdf2 I don't think one can do this. Types and values cannot be mixed like this. It helps me to think about the difference when using the comment syntax because it makes it easier to see what info Flow uses vs what code actually runs in the browser. Everything that is a comment is additional information we give Flow to be able to run additional checks but at runtime, all of this is removed and only the non-commented code remains.\r\n\r\n````js\r\n/* 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 type T = number; */\r\nexport default /* 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 T */\r\n````\r\nThis would fail Flow and not run in a browser since `export default` alone is invalid JavaScript.\r\n\r\nSince this is something new users of Flow are also likely to struggle with, it might be helpful to add more detail about this in the docs, possibly in the introduction at https://flow.org/en/docs/getting-started/\r\n\n Comment 1: In the spirit of adding color, rather than making demands, this is something I've struggled with as well. The subtle difference between objects/interfaces and values proper makes it tough to move types across module boundaries; that, in turn, makes scaling Flow to larger code bases complex and messy.\r\n\r\nI'm willing to bet there are more elegant solutions, but the big Flow projects I've personally worked on have fallen into two buckets. Some had a flat, top-level `types` module, wherein lived all the things:\r\n\r\n```\r\nsrc\r\n\u2514\u2500\u2500 types\r\n    \u251c\u2500\u2500 post.js\r\n    \u251c\u2500\u2500 tag.js\r\n    \u251c\u2500\u2500 user.js\r\n    \u251c\u2500\u2500 whatever.js\r\n    \u251c\u2500\u2500 you-get-the-idea.js\r\n    \u2514\u2500\u2500...\r\n```\r\n\r\nOthers made their peace with type imports that reached across module boundaries:\r\n\r\n```js\r\nimport type { Post } from 'app/redux/posts/post-types'\r\nimport type { Tag } from 'app/redux/tags/tag-types'\r\n```\r\n\r\nSince it can't be namespaced and re-exported, the type winds up undermining its context: in the first case by straying outside of its boundary, in the second by bringing every consumer of the API inside.\r\n\r\nNot that it's dispositive, but the rather more lax treatment of exported and imported types in TypeScript makes it possible to cleanly expose a namespaced public type to the rest of the application. I hammered together [a quick example](https://codesandbox.io/s/ts-flow-modules-pfzun), loosely grounded in work I've done in the past to type Redux. The salient point is that all the `data` module's types are exported from `data`, so the interface isn't violated and the consumer doesn't need to hold knowledge about what's underneath it.\r\n\r\nI wouldn't presume to speak to whether TypeScript's export-it-all-and-let-god-sort-it-out approach makes it more or less sound, from the vantage point of someone designing a type system. From the vantage point of someone using one, though, it's a godsend.\r\n\r\nI'm curious whether others have worked on this problem. I like Flow a lot---hence the meandering stroll back into GitHub and Stack Overflow every few months, looking for an excuse to use it---and I'd be eager to find a better approach than those I've seen.\n Comment 2: I think @vicapow has answered the question sufficiently. The docs do go over exporting/importing types/variables.\r\n\r\nIf anyone thinks the docs are missing something can you please clearly describe what information you think should exist there and we can reopen with a PR. ",
  "Issue title: Hide splitter\n Issue body: I have 2 panes with vertical splitter. I have a toggle button to expand / restore first pane to full / original width. It does this by setting the splitpanes'size' prop. Works well. However I need to hide the splitter in the expanded state and show it in the restored state. Is there a way I can do this? Thanks.\n Comments: \n Comment 0: Hi @edbotdev, I would do this via CSS.\r\nPlease share a reproduction link so I can help you.\r\nPlease reopen if not solved.",
  "Issue title: error: LOOT operation \"sortPlugins\" failed: Failed to evaluate condition \"version(\"Unofficial Fallout 4 Patch.esp\", \"2.0.7\", >=) and not version(\"../Fallout4.exe\", \"116.69.203.115\", >=)\". Details: An error was encountered while reading the version fields of \"\n Issue body: ### Application error\n#### System\n| | |\n|------------ | -------------|\n|Platform | win32 10.0.17763  |\n|Architecture | x64 |\n|Application Version | 0.18.1 |\n|Process | renderer |\n#### Message\nLOOT operation \"sortPlugins\" failed: Failed to evaluate condition \"version(\"Unofficial Fallout 4 Patch.esp\", \"2.0.7\", >=) and not version(\"../Fallout4.exe\", \"116.69.203.115\", >=)\". Details: An error was encountered while reading the version fields of \"F:\\STEAM GAME\\FALLOUT 4\\Fallout 4\\Data\\../Fallout4.exe\": zero fill\n#### Title\n```\nLOOT operation failed\n```\n\n#### Context\n```\nInstalling = Nanosuit 6.2-7451-6-2\n```\n#### Stack\n```\nError: LOOT operation \"sortPlugins\" failed: Failed to evaluate condition \"version(\"Unofficial Fallout 4 Patch.esp\", \"2.0.7\", >=) and not version(\"../Fallout4.exe\", \"116.69.203.115\", >=)\". Details: An error was encountered while reading the version fields of \"F:\\STEAM GAME\\FALLOUT 4\\Fallout 4\\Data\\../Fallout4.exe\": zero fill\n    at c.handleResponse (C:\\Program Files\\Black Tree Gaming Ltd\\Vortex\\resources\\app.asar.unpacked\\bundledPlugins\\gamebryo-plugin-management\\index.js:39:66370)\n    at Socket.e.on.e (C:\\Program Files\\Black Tree Gaming Ltd\\Vortex\\resources\\app.asar.unpacked\\bundledPlugins\\gamebryo-plugin-management\\index.js:39:65143)\n    at Socket.emit (events.js:182:13)\n    at addChunk (_stream_readable.js:283:12)\n    at readableAddChunk (_stream_readable.js:264:11)\n    at Socket.Readable.push (_stream_readable.js:219:10)\n    at Pipe.onStreamRead [as onread] (internal/stream_base_commons.js:94:17)\n```\n \n\n \n Reported by: isx23\n Comments: \n Comment 0: duplicate of #3845 \n Comment 1: ### Application error\n#### System\n| | |\n|------------ | -------------|\n|Platform | win32 10.0.17763  |\n|Architecture | x64 |\n|Application Version | 0.18.4 |\n|Process | renderer |\n#### Message\nLOOT operation \"sortPlugins\" failed: Failed to evaluate condition \"version(\"Unofficial Fallout 4 Patch.esp\", \"2.0.7\", >=) and not version(\"../Fallout4.exe\", \"116.69.203.115\", >=)\". Details: An error was encountered while reading the version fields of \"C:\\games\\Fallout 4 GOTY\\Data\\../Fallout4.exe\": zero fill\n#### Title\n```\nLOOT operation failed\n```\n\n#### Details\n```\nFile:\tC:\\games\\Fallout 4 GOTY\\Fallout4.exe\nExists:\ttrue\nSize:\t78756864\nMD5:\ta5c9317cfa8a1bba49b69f5fbaf5fedc\nVersion:\t116.69.203.115\n```\n#### Stack\n```\nError: LOOT operation \"sortPlugins\" failed: Failed to evaluate condition \"version(\"Unofficial Fallout 4 Patch.esp\", \"2.0.7\", >=) and not version(\"../Fallout4.exe\", \"116.69.203.115\", >=)\". Details: An error was encountered while reading the version fields of \"C:\\games\\Fallout 4 GOTY\\Data\\../Fallout4.exe\": zero fill\n    at c.handleResponse (C:\\Program Files\\Black Tree Gaming Ltd\\Vortex\\resources\\app.asar.unpacked\\bundledPlugins\\gamebryo-plugin-management\\index.js:39:66483)\n    at Socket.e.on.e (C:\\Program Files\\Black Tree Gaming Ltd\\Vortex\\resources\\app.asar.unpacked\\bundledPlugins\\gamebryo-plugin-management\\index.js:39:65256)\n    at Socket.emit (events.js:182:13)\n    at addChunk (_stream_readable.js:283:12)\n    at readableAddChunk (_stream_readable.js:264:11)\n    at Socket.Readable.push (_stream_readable.js:219:10)\n    at Pipe.onStreamRead [as onread] (internal/stream_base_commons.js:94:17)\n```\n \n\n \n Reported by: ArawBeltane\n Comment 2: ### Application error\n#### System\n| | |\n|------------ | -------------|\n|Platform | win32 10.0.17763  |\n|Architecture | x64 |\n|Application Version | 0.18.5 |\n|Process | renderer |\n#### Message\nLOOT operation \"sortPlugins\" failed: Failed to evaluate condition \"version(\"Unofficial Fallout 4 Patch.esp\", \"2.0.7\", >=) and not version(\"../Fallout4.exe\", \"116.69.203.115\", >=)\". Details: An error was encountered while reading the version fields of \"D:\\Games\\Fallout 4\\Data\\../Fallout4.exe\": zero fill\n#### Title\n```\nLOOT operation failed\n```\n\n#### Details\n```\nFile:\tD:\\Games\\Fallout 4\\Fallout4.exe\nExists:\ttrue\nSize:\t78756864\nMD5:\ta5c9317cfa8a1bba49b69f5fbaf5fedc\nVersion:\t116.69.203.115\n```\n#### Stack\n```\nError: LOOT operation \"sortPlugins\" failed: Failed to evaluate condition \"version(\"Unofficial Fallout 4 Patch.esp\", \"2.0.7\", >=) and not version(\"../Fallout4.exe\", \"116.69.203.115\", >=)\". Details: An error was encountered while reading the version fields of \"D:\\Games\\Fallout 4\\Data\\../Fallout4.exe\": zero fill\n    at c.handleResponse (C:\\Program Files\\Black Tree Gaming Ltd\\Vortex\\resources\\app.asar.unpacked\\bundledPlugins\\gamebryo-plugin-management\\index.js:39:66483)\n    at Socket.e.on.e (C:\\Program Files\\Black Tree Gaming Ltd\\Vortex\\resources\\app.asar.unpacked\\bundledPlugins\\gamebryo-plugin-management\\index.js:39:65256)\n    at Socket.emit (events.js:182:13)\n    at addChunk (_stream_readable.js:283:12)\n    at readableAddChunk (_stream_readable.js:264:11)\n    at Socket.Readable.push (_stream_readable.js:219:10)\n    at Pipe.onStreamRead [as onread] (internal/stream_base_commons.js:94:17)\n```\n \n\n \n Reported by: nartkhor\n Comment 3: ### Application error\n#### System\n| | |\n|------------ | -------------|\n|Platform | win32 10.0.17763  |\n|Architecture | x64 |\n|Application Version | 0.18.5 |\n|Process | renderer |\n#### Message\nLOOT operation \"sortPlugins\" failed: Failed to evaluate condition \"version(\"Unofficial Fallout 4 Patch.esp\", \"2.0.7\", >=) and not version(\"../Fallout4.exe\", \"116.69.203.115\", >=)\". Details: An error was encountered while reading the version fields of \"D:\\Games\\Fallout 4\\Data\\../Fallout4.exe\": zero fill\n#### Title\n```\nLOOT operation failed\n```\n\n#### Details\n```\nFile:\tD:\\Games\\Fallout 4\\Fallout4.exe\nExists:\ttrue\nSize:\t78756864\nMD5:\ta5c9317cfa8a1bba49b69f5fbaf5fedc\nVersion:\t116.69.203.115\n```\n#### Stack\n```\nError: LOOT operation \"sortPlugins\" failed: Failed to evaluate condition \"version(\"Unofficial Fallout",
  "Issue title: Android Basics: change-app-theme\n Issue body: **URL of codelab**\r\nhttps://developer.android.com/codelabs/basic-android-kotlin-training-change-app-theme?continue=https%3A%2F%2Fdeveloper.android.com%2Fcourses%2Fpathways%2Fandroid-basics-kotlin-unit-2-pathway-2%23codelab-https%3A%2F%2Fdeveloper.android.com%2Fcodelabs%2Fbasic-android-kotlin-training-change-app-theme#2\r\n\r\n**In which task and step of the codelab can this issue be found?**\r\nAdd Material dependencies to your project\r\nStep 3\r\n\r\n**Describe the problem**\r\nBoth implementations are in the gradle when generating the empty activity project ('androidx.appcompat:appcompat:1.2.0' and 'com.google.android.material:material:1.2.0')\r\n\r\n**Steps to reproduce?**\r\nN/A\r\n\r\n**Versions**\r\n_Android Studio version:_ 4.1.2\r\n_API version of the emulator:_ N/A \r\n\r\n\r\n**Additional information**\r\n_Include screenshots if they would be useful in clarifying the problem._\r\n\n Comments: \n Comment 0: Thank you so much for reporting this issue. This is fixed and will be published.",
  "Issue title: XForceExchange - URL wrong cast\n Issue body: ## What happened\r\nXForceExchange URL analyzer cast special character into %xx characters. Then the api, is wrongly called. And an error is raised. \r\n\r\n## Environment\r\n1. OS: Ubuntu 20.0.4\r\n2. IntelOwl version: 3.3.2\r\n\r\n##  What did you expect to happen\r\nHaving an analysis for this : https://exchange.xforce.ibmcloud.com/url/http:~2F~2Fmoviesfoundonline.com\r\n\r\n## How to reproduce your issue\r\nStart an analysis on XForceExchangeAnalyser with an URL (like http://moviesfoundonline.com), the analysis will fail because the url is cast into special characters in string using the %xx escape \r\n## Error messages and logs\r\n404 Client Error: Not Found for url: https://api.xforce.ibmcloud.com/url/malware/http%3A%2F%2Fmoviesfoundonline.com\r\n\r\n\r\n## Why it happens\r\nI think that the issue comes from the [XForceExchangeAnalyzer](https://github.com/intelowlproject/IntelOwl/blob/master/api_app/analyzers_manager/observable_analyzers/xforce.py) at line 29, url is parsed using [quote_plus()](https://docs.python.org/3/library/urllib.parse.html#urllib.parse.quote_plus), thus it replace characters... \r\n\r\n\n Comments: \n Comment 0: thanks for reporting this. I checked and the error was the main URL that was missing the \"/api\" but still worked anyway sometimes....the right url is `\"https://api.xforce.ibmcloud.com/api\"`\r\nThe fix will be available next release.\n Comment 1: Are you sure it is not : https://exchange.xforce.ibmcloud.com/api/\r\nBecause in api.xforce.ibmcloud.com I have found nowhere in the documentation that missing /api. [Sample stays](https://api.xforce.ibmcloud.com/doc/#/URL/get_url__url_) : https://api.xforce.ibmcloud.com/url/www.ibm.com%2Fsmarterplanet in the docs\n Comment 2: @mlodic have you already done it or would you like help? \n Comment 3: done this but not released yet :P I'll plan a new release soon, please follow the project so you get the update!\n Comment 4: Has it changed? \r\n\r\n![image](https://user-images.githubusercontent.com/103488825/167794445-3e9f23a4-e9ef-4a24-82ea-d4b3f3ed4330.png)\r\n![image](https://user-images.githubusercontent.com/103488825/167794534-72c3942e-a43a-42b1-b79a-144a064ffafe.png)\r\n\r\nFollowing the actual xforce website API call should be like : \r\n# WWW\r\n`curl -X GET --header 'Accept: application/json' -u {API_KEY:API_PASSWORD} 'https://exchange.xforce.ibmcloud.com/api/url/www.moviesfoundonline.com'`\r\n\r\n# HTTP \r\n`curl -X GET --header 'Accept: application/json' -u {API_KEY:API_PASSWORD} 'https://exchange.xforce.ibmcloud.com/api/url/http://moviesfoundonline.com'`\n Comment 5: thanks for reporting this again!\r\n\r\nI am sad cause I tested that manually. I retried that now and you are right, it does not work. \ud83e\udd14 \r\n\r\nI followed their [docs](https://api.xforce.ibmcloud.com/doc):\r\n![image](https://user-images.githubusercontent.com/30625432/167802093-bfdaaf1c-1f33-44ae-91f0-0623537f7118.png)\r\n\r\nMeanwhile, if you want to fix it locally (to avoid waiting for the next release), you can just apply the modification you can find in this commit by calling `git checkout xforce_fix`, shut down your instance and rerun it with a local build `python3 start.py test down && python3 start.py test up --build -d`. I have also added a \"link\" to the web GUI in the resutls\n Comment 6: on a second thought, I think that it is normal behavior. It just means that that URL was not found in their DB.\r\n\r\nI should change the analyzer to do not fail in that case.\n Comment 7: If the result is 404, thanks to the new change in the branch `xforce_fix`, you will found a new key \"found\" that is set to False.\n Comment 8: Thanks a lot! \r\n\n Comment 9: consider this solved and shipped in the next release",
  "Issue title: Instance status page\n Issue body: ## Is your feature request related to a problem?\r\n\r\nWe currently have metrics.posthog.com, which offers crucial performance information, but is a separate solution. Otherwise we don't offer any metrics, which makes detecting and explaining PostHog instance problems more time-consuming for users and also for the core team.\r\n\r\n## Describe the solution you'd like\r\n\r\nPostHog could use an instance status-type page (accessible only to organization admins on Self-Hosted or `is_staff` users on Cloud [or `is_superuser`? this distinction is actually useless for us]). For example, we could easily show database statistics like numbers of rows or table sizes, Redis health, event ingestion load \u2013 essentially data that comes up useful when users ask about problems.\r\n\r\n## Describe alternatives you've considered\r\n\r\nTell users to investigate instance internals themselves.\r\n\r\n## Additional context\r\n\r\nThought of this when a user needed to know why their PostHog Docker container was taking up so much space. I've told them to query for table sizes:\r\n```SQL\r\nSELECT relname as \"table\", pg_size_pretty(pg_total_relation_size(relid)) AS \"size\" FROM pg_catalog.pg_statio_user_tables ORDER BY pg_total_relation_size(relid) DESC;\r\n```\r\nbut it'd be much simpler if this information was available in the UI.\r\n\r\n#### *Thank you* for your feature request \u2013 we love each and every one!\r\n\n Comments: \n Comment 0: The list of things we should include\r\n- Event table size (both in MB and [Approximate size](https://wiki.postgresql.org/wiki/Count_estimate))\r\n- Element table size (both in MB and [Approximate size](https://wiki.postgresql.org/wiki/Count_estimate))\r\n- Redis queue size\r\n- Possibly memory size of workers?\r\n- Number of events in last day/week\n Comment 1: Closed by #1875.",
  "Issue title: (tor-browser) Permission issues when installed to default location (lib\\tor-browser\\tools\\tor-browser)\n Issue body: Post install of tor-browser, when trying to run it gives the error:\r\n(title) Tor Browser profile Problem\r\n(text) Tor browser does not have permission to access the profile. Please adjust your file system permissions and try again.\r\n\r\n## Expected Behavior\r\nIt should have permissions to run for at least the user account that installed the package.\r\n\r\n## Current Behavior\r\nPackage installer account does not have permission to run the program and files need to manually have permissions changed to allow running of the program.\r\n\r\n## Possible Solution\r\nadd this to end of install script:\r\n\r\n```powershell\r\n# set NTFS modify file permissions to $toolsDir\\tor-browser\\ for user account that installed the package\r\n$WhoAmI=whoami\r\n$Acl = Get-Acl \"$toolsDir\\tor-browser\"\r\n$Ar = New-Object  system.security.accesscontrol.filesystemaccessrule($WhoAmI,\"Modify\",\"Allow\")\r\n$Acl.SetAccessRule($Ar)\r\nSet-Acl \"$toolsDir\\tor-browser\" $Acl\r\n```\r\n\r\n(I forked it but not sure how to submit/push it back)!\n Comments: \n Comment 0: I think I did the pull request right...\r\n\r\nhttps://github.com/chocolatey/chocolatey-coreteampackages/pull/832\r\n",
  "Issue title: \ud83d\udc51 [\u9700\u6c42]\u5730\u56fe\u4e2d\u628a\u6240\u6709\u7684\u7f29\u653e\u7981\u7528\u4e86\u9f20\u6807\u6837\u5f0f\u8fd8\u662f\u624b\u578b\uff0c\u6709\u914d\u7f6e\u8bbe\u7f6e\u5417\uff1f\u6216\u8005\u5e94\u8be5\u8fd9\u65f6\u5019\u662f\u9ed8\u8ba4\u6837\u5f0f\uff1f\n Issue body:![image](https://user-images.githubusercontent.com/38289190/181719047-cdd47012-ca48-4249-84e1-888c26bb3314.png)\r\n\r\n\u7f29\u653e\u914d\u7f6e\u90fd\u7981\u7528\u4e86\u3002\r\n\u5730\u56fe\u4e0a\u7684\u624b\u578b\u622a\u56fe\u4e0d\u51fa\u6765\uff0c\u53ef\u4ee5\u770b\u4e0b\u3002\r\n\n Comments: \n Comment 0: \u5730\u56fe\u4e0d\u652f\u6301\u7f29\u653e\uff0c\u4f46\u662f\u9f20\u6807\u6837\u5f0f\u662fgrab\u624b\u578b\uff0c\u771f\u7684\u975e\u5e38\u5947\u602a\n Comment 1: @bbhu-y \u624b\u578b\u662f dom \u5bb9\u5668\u4e0a\u9762\u8bbe\u7f6e\u90fd\uff0c\u9ed8\u8ba4\u90fd\u662f\u624b\u5f62\uff0c\u4fee\u6539 dom \u4e0a\u7684 CSS \u5c5e\u6027\n Comment 2:![image](https://user-images.githubusercontent.com/38289190/181748318-6dde0a9b-38b3-4cba-b593-72fd58b2c979.png)\r\n\r\n\r\n\u5e76\u4e0d\u751f\u6548~\u6211\u8bd5\u8fc7\u4e86\n Comment 3: @bbhu-y \u5bb9\u5668\u8bbe\u7f6e\u9519\u8bef\uff0c\u770b css \u6743\u91cd\u5728\u4e0a\u4e00\u5c42\u5bb9\u5668\u4e0a\r\n",
  "Issue title: Removing and/or renaming a k8s service break CIS\n Issue body: Title\r\nRemoving and/or renaming a k8s service exposed by CIS without prior removing the ingress break CIS\r\n\r\nDescription\r\nIf we remove a service exposed by CIS 2.0 without removing first the ingress, the CIS break and stops updating configuration in BigIP. We need to delete and re-deploy the Controller to start working again.\r\n\r\nActual Problem\r\nToday if we remove a service that is being referenced by an ingress, it simply break the controller. Every update done after this is not reflected in BigIP.\r\n\r\nSolution Proposed\r\nIf a service exposed by CIS ingress is removed, the controller should identify and remove configuration in BigIP as the service dont exist anymore.\r\n\r\nAlternatives\r\nWe need to take care and first delete the ingress and then delete/rename the service. This is impacting customer operations. \r\n\r\nImportant log from Controller\r\n\r\n2020/07/10 14:46:11 [ERROR] [AS3] Big-IP Responded with code: 422\r\n**2020/07/10 14:46:11 [ERROR] [AS3] Raw response from Big-IP: map[code:422 declarationFullId: errors:[/dict_AS3/Shared/ingress_10_138_0_4_80/pool: contains path to non-existent object ingress_dict_nginx] message:declaration is invalid]**\r\n2020/07/10 14:46:33 [INFO] [CORE] Port '8080' for service 'nginx' was not found.\r\n2020/07/10 14:46:33 [INFO] [CORE] Service 'nginx' has not been found.\n Comments: \n Comment 0: cisbot will assign the issue to one of the devs. \n @devs, use /jira for internal tracking.\n Comment 1: @rlombardi12 CIS has service informers which does exactly what you have asked for. I am surprised it is not doing the same. Do you have both service and ingress in the same namespace or different.\r\n\r\nI will try to reproduce the issue and get back to you.\n Comment 2: @veeramalla-f5 the test was done in the same namespace. You can easily reproduce it. Just remove the service prior the ingress and things start getting strange. Customer is complaining that this is impacting their operations.\n Comment 3: duplicate of https://github.com/F5Networks/k8s-bigip-ctlr/issues/1417\n Comment 4: @trinaths can you please close it as duplicate or assign it to someone else? Thanks \ud83d\udc4d\n Comment 5: duplicate of #1417 closing this issue.",
  "Issue title: Does not produced encryption\n Issue body: I knew it would work like most stuff on GitHub\n Comments: \n Comment 0: GTFO skids",
  "Issue title: [Feature Request] Amazon Echo Studio support?\n Issue body: Checking to see if there is an ETA. thx\n Comments: \n Comment 0: This issue has been marked stale automatically after no activity for the last 60 days.",
  "Issue title: Add ability to reconfigure mint rate\n Issue body: ## Problem to solve\r\n\r\nAs title\r\n\r\n## More details\r\n\r\n_Add any other notes or screenshots about the feature request here._\r\n\n Comments: \n Comment 0: Duplicate of https://github.com/jbx-protocol/juice-interface/issues/1217",
  "Issue title: solution for this please\n Issue body: [bodega] flutter pub get\r\nRunning \"flutter pub get\" in bodega...                          \r\n    Because bitsdojo_window >=0.0.6 depends on bitsdojo_window_windows ^0.0.2 which depends on win32 ^2.0.0, bitsdojo_window >=0.0.6 requires win32 ^2.0.0.\r\n\r\n\r\n(1) So, because shared_preferences_windows <0.0.3-nullsafety depends on path_provider_windows ^0.0.2 which depends on win32 ^1.7.1, bitsdojo_window >=0.0.6 is incompatible with shared_preferences_windows <0.0.3-nullsafety.\r\n\r\n\r\n    Because shared_preferences_windows >=0.0.3-nullsafety <2.0.0 depends on shared_preferences_platform_interface ^2.0.0-nullsafety and shared_preferences 0.5.12+4 depends on shared_preferences_platform_interface ^1.0.0, shared_preferences_windows >=0.0.3-nullsafety <2.0.0 is incompatible with shared_preferences 0.5.12+4.\r\n\r\n    And because shared_preferences 0.5.12+4 depends on shared_preferences_windows ^0.0.1, shared_preferences 0.5.12+4 requires shared_preferences_windows >=0.0.1 <0.0.3-nullsafety.\r\n\r\n    And because bitsdojo_window >=0.0.6 is incompatible with shared_preferences_windows <0.0.3-nullsafety (1), bitsdojo_window >=0.0.6 is incompatible with shared_preferences 0.5.12+4.\r\n\r\n    And because no versions of shared_preferences match >0.5.12+4 <0.6.0, bitsdojo_window >=0.0.6 is incompatible with shared_preferences ^0.5.12+4.\r\n\r\n    So, because bodega_flutter depends on both shared_preferences ^0.5.12+4 and bitsdojo_window ^0.0.6, version solving failed.\r\npub get failed (1;     So, because bodega_flutter depends on both shared_preferences ^0.5.12+4 and bitsdojo_window ^0.0.6, version solving failed.)\r\nexit code 1\r\n\n Comments: \n Comment 0: Try upgrading shared_preferences plugin to a newer version.\n Comment 1: Can you try upgrading shared_preferences to the latest version and let me know how that goes?\n Comment 2: We're also having this issue. Upgrading shared_preferences to any of the 2.0.0 versions, seems to just set off more cascades of errors. \r\n\r\n* it then goes on to compain about `path_provider` so I up that to 2.0, \r\n* which then leads to some complaint about `xdg_directories`, so we up that to 0.2.0, \r\n* then goes to `cached_network_image` blowing up. \r\n`Because no versions of cached_network_image match >2.5.0 and cached_network_image >=0.4.0-rc.1 <0.4.0 depends on flutter_cache_manager ^0.1.0-rc.1, cached_network_image >=0.4.0-rc.1 <0.4.0 or >2.5.0 requires flutter_cache_manager ^0.1.0-rc.1.`\r\n\r\nThis seems to end eventually in some sort of deadlock where cached_network_image  needs `path_provider: ^1.6.18` but all the others want `path_provider: ^2.0.0`.\r\n\r\nRemoving cached_network_image image, and everything actually builds!! Still not sure really what that was all about... I guess you upped your shared_prefs version which led to all of these down-stream upgrades required?\n Comment 3: same here!\n Comment 4: > [bodega] flutter pub get\r\n> Running \"flutter pub get\" in bodega...\r\n> Because bitsdojo_window >=0.0.6 depends on bitsdojo_window_windows ^0.0.2 which depends on win32 ^2.0.0, bitsdojo_window >=0.0.6 requires win32 ^2.0.0.\r\n> \r\n> (1) So, because shared_preferences_windows <0.0.3-nullsafety depends on path_provider_windows ^0.0.2 which depends on win32 ^1.7.1, bitsdojo_window >=0.0.6 is incompatible with shared_preferences_windows <0.0.3-nullsafety.\r\n> \r\n> ```\r\n> Because shared_preferences_windows >=0.0.3-nullsafety <2.0.0 depends on shared_preferences_platform_interface ^2.0.0-nullsafety and shared_preferences 0.5.12+4 depends on shared_preferences_platform_interface ^1.0.0, shared_preferences_windows >=0.0.3-nullsafety <2.0.0 is incompatible with shared_preferences 0.5.12+4.\r\n> \r\n> And because shared_preferences 0.5.12+4 depends on shared_preferences_windows ^0.0.1, shared_preferences 0.5.12+4 requires shared_preferences_windows >=0.0.1 <0.0.3-nullsafety.\r\n> \r\n> And because bitsdojo_window >=0.0.6 is incompatible with shared_preferences_windows <0.0.3-nullsafety (1), bitsdojo_window >=0.0.6 is incompatible with shared_preferences 0.5.12+4.\r\n> \r\n> And because no versions of shared_preferences match >0.5.12+4 <0.6.0, bitsdojo_window >=0.0.6 is incompatible with shared_preferences ^0.5.12+4.\r\n> \r\n> So, because bodega_flutter depends on both shared_preferences ^0.5.12+4 and bitsdojo_window ^0.0.6, version solving failed.\r\n> ```\r\n> \r\n> pub get failed (1; So, because bodega_flutter depends on both shared_preferences ^0.5.12+4 and bitsdojo_window ^0.0.6, version solving failed.)\r\n> exit code 1\r\n\r\nProblem Solved with Flutter v2.0.0 \u2714",
  "Issue title: Set location pretends to work, but upon starting, returns to default location.\n Issue body:![picture 1](https://cloud.githubusercontent.com/assets/11504592/17077319/54f62f3a-50cc-11e6-83d6-bd679e79c5b1.png)\r\n![picture 2](https://cloud.githubusercontent.com/assets/11504592/17077318/54f4b24a-50cc-11e6-8b51-5c9ded98fa01.png)\r\n\r\nReproduce: \r\nSet location anywhere (in this case random spot in Copenhagen)\r\nConsole says location is set correctly (see picture 1)\r\nStart bot\r\nBased on Pokestop name, bot starts in some sort of a default location, presumably London area (picture 2)\n Comments: \n Comment 0: Thanks for the report, the latest commit fixes this problem. If you are using Visual Studio to compile you should be able to download the source now and it will work, if you are using the compiled version release tomorrow morning I'll create a new release containing this change.\n Comment 1: Confirmed, fixed!",
  "Issue title: Race condition in `FlutterSurfaceManager`\n Issue body: There is still a race condition in `FlutterSurfaceManager`. It's quite very difficult to reproduce, but it is there and it happens as follow\r\n```\r\n1) Time 0, RasterThread SwapBuffers, schedules OnIdle (back buffer release) on MainThread at Time 1\r\n2) Time almost 1, RasterThread EnsureBackBuffer, schedules canceling OnIdle on MainThread\r\n3) Time 1, MainThread, OnIdle, release back buffer (scheduled in step 1)\r\n4) Time 1+, MainThread cancel scheduling OnIdle, but that already happened in step 3)\r\n5) Time 1+, RasterThread SwapBuffer, crash.\r\n```\r\n\r\nThe issue that in the delay between 2 (on raster thread) and 4 (on main thread) 3 happens.\r\n\r\nThe obvious solution is to use synchronized variable, i.e. `_renderInProgress`, set it to `YES` in `ensureBackBuffer`, clear after `SwapBuffers` completes and ignore `OnIdle` if `_renderInProgress` is `YES` (time between 2 and 4).\n Comments: \n Comment 0: The linked fix has landed. Closing.\n Comment 1: This thread has been automatically locked since there has not been any recent activity after it was closed. If you are still experiencing a similar issue, please open a new bug, including the output of `flutter doctor -v` and a minimal reproduction of the issue.",
  "Issue title: Add gzip compression\n Issue body: Add gzip compression feature for the build files.\n Comments: \n Comment 0: It probably won't be added, as most static servers have gzip capabilities. \r\nBut you can easily add this yourself by installing [compression-webpack-plugin](https://github.com/webpack-contrib/compression-webpack-plugin).",
  "Issue title: Can't connect to yahka with HomeKit.\n Issue body: HI ;) \r\n\r\ni'm using yahka for over 3 years now. It has alsways woking. since 2 month homekit displays a connection lost to all yahka controlled devices. Since then I can't established an connection to yahka with homekit anymore. \r\n\r\nI'm using the beta version since 13.1 does the binding only to ip6 and the beta seemes to fixed that. \r\n\r\nDetails: \r\n\r\nI have yahka and a Bridge configured as follows: \r\n\r\n![grafik](https://user-images.githubusercontent.com/12759988/160285227-2e395b63-3e2d-47f4-b861-8eae1825c42a.png)\r\n\r\nPlease note that i tried the legacy and current version of the Advertiser. \r\n\r\nIn Homekit I can see the adapter when I  try to add. It states, that the configuration may take some minutes. After that the connection state an error \"The device is not visisble\". \r\n\r\nWhen I Input the wrong passcode, then this is recordnized. So I assume that a network connection is established. \r\n\r\n> \r\n> \u00d4\u00c3\u00b2\u00a1\u0002 \u0004           \u0004 \u0001   \u0178N@b\u2020c\u000b N   N   \u00dc\u00a62\u0012\u00e9|\u00acI\u00db4\u00e6X\b E  @  @ @\u0006U\u0017\u00c0\u00a8\u00b2(\u00c0\u00a8\u00b2'\u00c3\u00e4\u0081a8H\u0178\u0007    \u00b0\u0002\u00ff\u00ff*\u00a4  \u0002\u0004\u0005\u00b4\u0001\u0003\u0003\u0006\u0001\u0001\b\r\n> \u0002f\u0007\u00bb    \u0004\u0002  \u0178N@b\u00e2c\u000b J   J   \u00acI\u00db4\u00e6X\u00dc\u00a62\u0012\u00e9|\b E  <  @ @\u0006U\u001b\u00c0\u00a8\u00b2'\u00c0\u00a8\u00b2(\u0081a\u00c3\u00e4\u0010\u00050\u000f8H\u0178\b\u00a0\u0012\u00fe\u02c6\u00e5\u00cf  \u0002\u0004\u0005\u00b4\u0004\u0002\b\r\n> \u20ac`\u00e5n\u0002f\u0007\u00bb\u0001\u0003\u0003\u0007\u0178N@b\u00fdt\u000b B   B   \u00dc\u00a62\u0012\u00e9|\u00acI\u00db4\u00e6X\b E  4  @ @\u0006U#\u00c0\u00a8\u00b2(\u00c0\u00a8\u00b2'\u00c3\u00e4\u0081a8H\u0178\b\u0010\u00050\u0010\u20ac\u0010\b\r\n> \u00bcn  \u0001\u0001\b\r\n> \u0002f\u0007\u00c2\u20ac`\u00e5n\u0178N@b\u00dfz\u000b \u00c5   \u00c5   \u00dc\u00a62\u0012\u00e9|\u00acI\u00db4\u00e6X\b E  \u00b7  @ @\u0006T\u00a0\u00c0\u00a8\u00b2(\u00c0\u00a8\u00b2'\u00c3\u00e4\u0081a8H\u0178\b\u0010\u00050\u0010\u20ac\u0018\b\r\n> \u000eU  \u0001\u0001\b\r\n> \u0002f\u0007\u00c2\u20ac`\u00e5nPOST /pair-setup HTTP/1.1\r\n> Host: Yahka\\0325151._hap._tcp.local\r\n> Content-Length: 6\r\n> Content-Type: application/pairing+tlv8\r\n> \r\n>  \u0001 \u0006\u0001\u0001\u0178N@b\u0010{\u000b B   B   \u00acI\u00db4\u00e6X\u00dc\u00a62\u0012\u00e9|\b E  4!&@ @\u00063\u00fd\u00c0\u00a8\u00b2'\u00c0\u00a8\u00b2(\u0081a\u00c3\u00e4\u0010\u00050\u00108H\u0178\u2039\u20ac\u0010\u0001\u00fd\u00e5\u00c7  \u0001\u0001\b\r\n> \u20ac`\u00e5t\u0002f\u0007\u00c2\u00a0N@b\u0019e\u0001 {\u0002  {\u0002  \u00acI\u00db4\u00e6X\u00dc\u00a62\u0012\u00e9|\b E \u0002m!'@ @\u00061\u00c3\u00c0\u00a8\u00b2'\u00c0\u00a8\u00b2(\u0081a\u00c3\u00e4\u0010\u00050\u00108H\u0178\u2039\u20ac\u0018\u0001\u00fd\u00e8   \u0001\u0001\b\r\n> \u20ac`\u00e6\u00c7\u0002f\u0007\u00c2HTTP/1.1 200 OK\r\n> Content-Type: application/pairing+tlv8\r\n> Date: Sun, 27 Mar 2022 11:46:40 GMT\r\n> Connection: keep-alive\r\n> Transfer-Encoding: chunked\r\n> \r\n\r\ntcpdum reveals at least a positiv communication. I'm hosting yahka on an ibroker-bian on a raspberry pi 6. \r\n\r\n```\r\nPlattform\r\n    linux\r\nModell\r\n    ARMv7 Processor rev 3 (v7l)\r\nNode.js\r\n    v17.6.0 \r\n\r\n```\r\n\r\nThere is also an test device configured. I deleted yahka and its data folder. \r\n\n Comments: \n Comment 0: @Marinek: did you find a solution? I'm desperately searching as well...",
  "Issue title: Change guard-for-in to allow also the prevention of the use of for-in loops in the code\n Issue body: **What version are you using?**\n2.3.0\n\n**What did you do?**\nWell it is not like I found an issue, more like I would like to add more options to the `guard-for-in` rule.. Currently the rule only prevents `for-in` loops that doesn't have an `if` condition in them.\n\nThis may help in not running over all the prototype chain, but doesn't solve the fact that a `for-in` loop [prevents the JIT optimization](https://github.com/petkaantonov/bluebird/wiki/Optimization-killers#5-for-in) for the entire function.\n\nThis could be a **major** code optimization booster in some cases!\n\n**What happened?**\nWell I don't have this option.\n\n**What did you expect to happen?**\nThe optimal solution would be to have 2 options for this rule:\n1. just like now - you must have an if condition in the rule\n2. **Prevent the use of `for-in` all together** - There are just too many cases that most `for-in` loops actually makes, that prevents ALL JIT optimization on the function that contains the `for-in` loop.\n   If you truly need to run on all the prototype chain of an object, [just create an **isolated** function that runs `for-in` and disable this rule specifically there](https://github.com/petkaantonov/bluebird/wiki/Optimization-killers#523-the-object-contains-enumerable-array-indices)..<br>\n   Probably most of the usages of the `for-in` loop only needs to run on the keys of the object and not really of all the chain, this rule could save a lot of optimization.\n\n Comments: \n Comment 0: +1\n Comment 1: I think using `ForInStatement` with [no-restricted-syntax](http://eslint.org/docs/rules/no-restricted-syntax) would address your suggestion. What do you think?\n Comment 2: Well I must say that I never saw this rule and now I'm in love with it!\n\nIn my opinion we should still modify the [guard-for-in](http://eslint.org/docs/rules/guard-for-in) rule to have this option since I look at eslint in a lot of cases as a guideline for good js. A lot of js developers doesn't know about this `for-in` limitation and are just harming their code.\n\nHaving the option to block this behavior in a rule dedicated to it sounds like good guidance to me..\nWhat do you think?\n\nIf we're not on the same page here it is OK by me to close this ticket since the `no-restriced-syntax` gives me the result I needed :-)\n\n Comment 3: We don't want to have overlapping rules in the core. Also `guard-for-in` is crafted to protect against this very specific scenario. Even its name implies that so I don't think we can add it there.\n\nI'm glad `no-restricted-syntax` solves your problem!\n",
  "Issue title: SQLite3 Foreign Keys support\n Issue body: For example, `tx_hash`, `block_index`.\n\n Comments: \n Comment 0: This'll soon be complete.\n",
  "Issue title: Websockets pub/sub\n Issue body: The user should have the ability to publish (and subscribe) all messages to a pub/sub service like Redis (or postgres).  This will allow for sockets on multiple servers scaled in parallel to still communicate with each other.\r\n\r\nAcceptance Criteria:\r\n\r\n- [ ] Socket messages should be published to a pubsub service\r\n- [ ] Amber servers should subscribe to pubsub service, and broadcast messages to sockets\n Comments: \n Comment 0: This is done",
  "Issue title: GlobalSearch custom js\n Issue body: Is there a way to customize globalSearch view? I would like to enhance it a little, for example add more columns other then 'name' in the search result. The reasin is that sometimes there are several results with same name and user can not understand which one needs. It would be interesting if we could specicify our customzed view for globalsearch somewhere in metadata or prefs.\n Comments: \n Comment 0: I don't know such. For such questions please use our forum: http://forum.espocrm.com/\r\nI'm only one who monitors github issues and do the most development work for EspoCRM. I'm really very busy everyday.\r\n",
  "Issue title: \u5efa\u8bae\u4f7f\u7528 chii \u8fdc\u7a0b\u8c03\u8bd5\u5668\u66ff\u6362 weinre\n Issue body: \u9879\u76ee\u5730\u5740\uff1ahttps://github.com/liriliri/chii\r\n\r\n\u76f8\u6bd4 weinre \u4f18\u70b9\uff1a\r\n1. \u4f7f\u7528\u6700\u65b0\u7684 Chrome DevTools \u66ff\u6362\u8001\u65e7 Web Inspector\uff0c\u4f7f\u7528\u4f53\u9a8c\u66f4\u597d\r\n2. \u6301\u7eed\u66f4\u65b0\u7ef4\u62a4\uff0cWeinre \u5df2\u4e0d\u518d\u66f4\u65b0\u7ef4\u62a4\n Comments: \n Comment 0: @surunzi \uff0c\u611f\u8c22\u5efa\u8bae\u3002\r\n\r\n\u8981\u7528\u5230 Chrome DevTools \u7684\u79fb\u52a8\u7aef\u6d4f\u89c8\u5668\u662f\u4e0d\u662f\u6709\u9650\u5236\uff1f \u6bd4\u5982 iOS Safari \u6216\u8005\u5fae\u4fe1\u5185\u7684 webview \u662f\u5426\u4e0d\u652f\u6301\uff1f\n Comment 1: \u79fb\u52a8\u7aef\u7684\u8bdd\u6ca1\u6709\u9650\u5236\uff0c\u4e0d\u8fc7\u662f\u65b0\u5199\u7684\uff0c\u6ca1\u6709\u7ecf\u8fc7\u5927\u91cf\u9a8c\u8bc1\uff0c\u53ef\u80fd\u6709 bug\uff0c\u7406\u8bba\u4e0a\u8ddf weinre \u4e00\u6837\u529f\u80fd\u662f\u6ca1\u95ee\u9898\u7684\u3002\r\nPC \u7aef\u7684\u8bdd\u9700\u8981\u4f7f\u7528\u6700\u65b0\u7684 chrome \u6d4f\u89c8\u5668\u8bbf\u95ee\u3002\n Comment 2: \u9996\u9875\u4e0a\u6709 demo\uff0c\u4f60\u53ef\u4ee5\u8bd5\u4e0b\u5728 safari \u548c\u5fae\u4fe1\u5185\u8bbf\u95ee\u3002\u4e0d\u8fc7\u7531\u4e8e Chrome DevTools \u6587\u4ef6\u591a\u52a0\u4e0b\u670d\u52a1\u5668\u5728\u56fd\u5916\uff0c\u53ef\u80fd demo \u8c03\u8bd5\u9875\u6253\u5f00\u4f1a\u6709\u70b9\u6162\u3002\n Comment 3: \ud83d\udc4d  \u786e\u5b9e\u4e0d\u9519\uff0c\u754c\u9762\u4f53\u9a8c\u597d\u5f88\u591a\n Comment 4: @wuchangming \u4f5c\u8005\u60a8\u597d\uff0c\u8bf7\u95ee\u901a\u8fc7\u600e\u6837\u7684\u64cd\u4f5c\u53ef\u4ee5\u66f4\u6362\u5230chii inspector\u5417\n Comment 5: mark",
  "Issue title: Server posta in arrivo marcato come \"draft\"\n Issue body: **Versioni coinvolte:**\r\n\r\n- [ ] v12\r\n\r\n**Passi per riprodurre:**\r\n\r\n1. Creare un nuovo server posta in ingresso (IMAP) e mettere la spunta su pec\r\n2. Inviare una mail non contenente fattura elettronica all'indirizzo pec in questione\r\n3. Attendere che il cron giri 6 volte\r\n\r\n**Comportamento osservato:**\r\n\r\nLa mail in questione viene letta multiple volte ma mai messa come letta, incrementando il counter `server.pec_error_count` fino a quando non \u00e8 maggiore di 5 (default del parametro `fetchmail.pec.max.retry`) e il server di posta viene marcato come \"draft\".\r\n\r\nDa quello che vedo nel codice, il cron ogni volta legger\u00e0 la mail non contenente la fattura ma non la marcher\u00e0 come letta (non arriva a linea 71 di `fetchmail.py`):\r\nhttps://github.com/OCA/l10n-italy/blob/3eb8b3c0fd9ad366ca2eaa0ef510ac7653e6df3d/l10n_it_fatturapa_pec/models/fetchmail.py#L50-L75\r\n\r\nQuando il cron di fetchmail \u00e8 girato 6 volte, il counter degli errori arriva a un numero maggiore di 5 e imposta il server a \"draft\":\r\nhttps://github.com/OCA/l10n-italy/blob/3eb8b3c0fd9ad366ca2eaa0ef510ac7653e6df3d/l10n_it_fatturapa_pec/models/fetchmail.py#L119-L131\r\n\r\nInoltre quando si prova a inviare una fattura elettronica, se il server di ricezione \u00e8 in \"draft\", le nuove fatture non possono essere inviate:\r\nhttps://github.com/OCA/l10n-italy/blob/db2245ba766d84735d5fbd3a7c6b4e6f45ad8f4c/l10n_it_fatturapa_pec/models/fatturapa_attachment_out.py#L51-L63\r\n\r\n**Comportamento atteso:**\r\n\r\nAvere una configurazione che permetta di leggere comunque email che non contengono informazioni relative alla fatturazione elettronica cos\u00ec da non bloccare il processo ogni volta che una mail non relativa a fatture elettroniche viene ricevuta sulla casella pec.\n Comments: \n Comment 0: Chiudo a fronte di https://github.com/OCA/l10n-italy/issues/2316#issuecomment-858707635",
  "Issue title: [M001193] Rep. Tom MacArthur\n Issue body: Newly elected to 114th congress\n Comments: \n Comment 0: tested and working",
  "Issue title: Asynch?\n Issue body: Hi-\r\n Was wondering if there's a way to do copy with a callback... I have text (json blob) generated by the server, is not precomputed. Did not see a way offhand.\r\nThanks,\r\nJeff\n Comments: \n Comment 0: It's actually impossible, sadly.  It's a security restriction enforced in Flash 10+, similar to how window.open works in click handlers (needs to be synchronous in response to the event, or else it's blocked).\n\nThe best you can do is try to do it quickly before the user clicks it by detecting a nearby cursor or a hover event, and ask them to click again if they did it too quickly.\n",
  "Issue title: Allow for setting distributed timeout for cases where there are long data preprocessing times.\n Issue body: ## \ud83d\ude80 Feature\r\n\r\nAllow for setting the torch.distributed timeout to your own custom timing. Currently it is at 30 minutes, but there are some cases where each node in distributed training have very long preprocessing times of the data that exceed 30 minutes. In my case I need to manually preprocess the data per node before launching a distributed job else it will timeout. Initially the processing was done after launching the distributed job, but once I acquired more data and have more complicated data processing pipelines, it went passed 30 minutes which would crash the job until it hit the max number of restarts.\r\n\r\n\n Comments: \n Comment 0: This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n\n Comment 1: Is this something that can't really be done easily since this isn't exposed by torchrun?\n Comment 2: I believe this is a duplicate of https://github.com/Lightning-AI/lightning/issues/13211. Which was implemented and will be available in PL 1.7",
  "Issue title: Loading the racial fonts?\n Issue body: Hi, I was just wondering if it would be possible to load the racial fonts into the Homebrewery? They're listed in this thread:\r\n\r\nhttps://www.reddit.com/r/DnD/comments/2jwsx2/dnd_and_other_script_font_collection/\r\n\r\nI was wanting to put something in draconic in one of my brews, and thought it would be really cool to be able to put it in there. I installed it myself and copied it into the homebrewery, but it switched it back to the normal font.\r\n\r\nThanks!\n Comments: \n Comment 0: Yup, you can do this. First the font has to be hosted somewhere (Dropbox might work as well), then [you load them in using CSS](https://css-tricks.com/snippets/css/using-font-face/) and use style tags.\r\n\r\n```html\r\n<style>\r\n@font-face {\r\n  font-family: 'Draconic';\r\n  src: url('path-to-font.woff') format('woff');\r\n}\r\n.draconic{\r\n  font-family : 'Draconic';\r\n}\r\n</style>\r\n\r\n\r\n<div class='draconic'>I am in Draconic now</div>\r\n\r\n```\n Comment 1: This is awesome, I really appreciate it!\n\nIf you don't mind, I've been working on this for a long time and I can't\nseem to get it to show up. Here's what I've got:\n\n<style>\n@font-face {\n  font-family: 'Draconic';\n  src: url('http://www.megafileupload.com/oj3Y/Iokharic.otf')\nformat('opentype');\n}\n.draconic{\n  font-family : 'Draconic';\n}\n</style>\n\n<div class='Draconic'>I am in Draconic now</div>\n\nI can't get a direct file link from Google Drive or Dropbox This is still\nshowing the text normally, so I'm not sure what to do from here. I tried\nchanging the font to a.woff type and leaving the format as 'woff,' but it\nwas still the same. Would you have any ideas of how to fix it? If you don't\nhave time that's fine, I'll keep working on it.\n\nOn Tue, Sep 13, 2016 at 10:29 AM, Scott Tolksdorf <lisaobrien@example.com>\nwrote:\n\n> Closed #193 <https://github.com/stolksdorf/homebrewery/issues/193>.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/stolksdorf/homebrewery/issues/193#event-787633992>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AQ3wq9GWUOKTpIfKdmgk0IhurGBj6Kkwks5qprNJgaJpZM4J7uxo>\n>.\n>\n\n Comment 2: Easy fixes.\r\n\r\nFirstly, capitalization matters. `<div class='Draconic'>I am in Draconic now</div>` should be `<div class='draconic'>I am in Draconic now</div>`\r\n\r\nSecondly, the megaupload link doesn't actually link to the font, it goes to a webpage where you can download it. I suggest using dropbox. In your Dropbox there should be a public folder, put the font in there, wait for it to sync and then right click and hit 'Copy public link'. Use that link in your brew.\r\n\r\nCheck it.\r\n\r\n![image](https://cloud.githubusercontent.com/assets/387742/18482980/4fe13da2-79b0-11e6-8453-7368230306dc.png)\r\n\n Comment 3: Wow awesome! Unfortunately, dropbox accounts created after 2012 don't have\na Public folder unless you pay for it. I'll have to find somewhere to host\nit, but I momentarily copied your link there and it worked. I really\nappreciate your help!\n\nOn Tue, Sep 13, 2016 at 12:48 PM, Scott Tolksdorf <lisaobrien@example.com>\nwrote:\n\n> Easy fixes.\n>\n> Firstly, capitalization matters. <div class='Draconic'>I am in Draconic\n> now</div> should be <div class='draconic'>I am in Draconic now</div>\n>\n> Secondly, the megaupload link doesn't actually link to the font, it goes\n> to a webpage where you can download it. I suggest using dropbox. In your\n> Dropbox there should be a public folder, put the font in there, wait for it\n> to sync and then right click and hit 'Copy public link'. Use that link in\n> your brew.\n>\n> Check it.\n>\n> [image: image]\n> <https://cloud.githubusercontent.com/assets/387742/18482980/4fe13da2-79b0-11e6-8453-7368230306dc.png>\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/stolksdorf/homebrewery/issues/193#issuecomment-246746471>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AQ3wq4UkkeruhZTQ0aBR3ahmecLDb4j_ks5qptPLgaJpZM4J7uxo>\n>.\n>\n",
  "Issue title: \ud83e\uddd0[\u95ee\u9898] \u6298\u7ebf\u56fe\u6570\u636e\u91cd\u53e0\uff0c\u662f\u5426\u6709\u4f18\u5316\u663e\u793a\u7684\u65b9\u6cd5\uff1f\n Issue body: ### \ud83e\uddd0 \u95ee\u9898\u63cf\u8ff0\r\n\u5f53\u7ebf\u6761\u6bd4\u8f83\u591a\u7684\u65f6\u5019\uff0c\u663e\u793a\u6570\u636e\u65f6\uff0c\u6570\u636e\u4f1a\u91cd\u53e0\uff0c\u5982\u4e0b\u6240\u793a\r\n![image](https://user-images.githubusercontent.com/30134533/100202655-92a8a080-2f3c-11eb-86ba-2377c2a51e25.png)\r\n\r\n\u67e5\u770b\u6587\u6863\uff0c\u6ca1\u6709\u627e\u5230\u5173\u4e8e\u4e8b\u4ef6\u7ed1\u5b9a\u7684\u5185\u5bb9\u3002\u5c1d\u8bd5\u4e86\u7528useRef\u6302\u8f7d\u5230\u56fe\u8868\u7684chartRef\u4e0a\uff0c\u4f46\u662f\u4e8b\u4ef6\u662f\u6574\u4e2a\u56fe\u8868\u7684\u4e8b\u4ef6\uff0c\u4e0d\u80fd\u5177\u4f53\u5230\u67d0\u4e2a\u7ebf\u6761\u4e0a\u3002\r\n\u662f\u5426\u6709\u4ec0\u4e48\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u9f20\u6807\u79fb\u52a8\u5230\u67d0\u6761\u7ebf\u4e0a\u65f6\uff0c\u624d\u663e\u793a\u5177\u4f53\u6570\u503c\uff1f\r\n\r\n### \ud83d\ude91 \u5176\u4ed6\u4fe1\u606f [\u5982\u622a\u56fe\u7b49\u5176\u4ed6\u4fe1\u606f\u53ef\u4ee5\u8d34\u5728\u8fd9\u91cc]\r\n\"@ant-design/charts\": \"^1.0.8\"\n Comments: \n Comment 0:   label: {\r\n         layout: [{ type: 'hide-overlap' }],\r\n      },\r\n\n Comment 1: \u4e8b\u4ef6\u7ed1\u5b9a\u53ef\u4ee5\u4f7f\u7528 element:click, label  \u53ef\u4ee5\u8bbe\u7f6e formatter \u7684 \uff0c \u6839\u636e\u60c5\u51b5\u81ea\u5df1\u5224\u65ad\u3002\n Comment 2: \u60a8\u597d\uff0c\u6211\u5c1d\u8bd5\u4e86\u7ed1\u5b9a\u4e8b\u4ef6\u7684\u65b9\u5f0f\u3002\u5f53\u9f20\u6807\u79fb\u52a8\u81f3\u67d0\u4e2a\u56fe\u4f8b\u4e0a\u65f6\uff0c\u624d\u663e\u793a\u6b64\u7c7b\u6570\u636e\u3002\r\n\u4f46\u662f\uff0c\u7ed1\u5b9a\u4e8b\u4ef6\u540e\uff0c\u6bcf\u6b21\u4e8b\u4ef6\u89e6\u53d1\u65f6\uff0c\u90fd\u4f1a\u91cd\u65b0\u5237\u65b0\u56fe\u8868\uff0c\u5bfc\u81f4\u5f53\u9690\u85cf\u67d0\u56fe\u4f8b\u540e\uff0c\u9f20\u6807\u79fb\u52a8\u81f3\u5176\u4ed6\u56fe\u4f8b\u65f6\uff0c\u9690\u85cf\u7684\u7ebf\u6761\u8fd8\u662f\u4f1a\u91cd\u65b0\u51fa\u73b0\u3002\r\n\u4ee3\u7801\u5728\u6b64\uff1ahttps://codesandbox.io/s/still-river-lrn8q?file=/src/demo.tsx\r\n\r\n\u8868\u73b0\u5982\u4e0b\uff1a\r\n![\u95ee\u9898](https://user-images.githubusercontent.com/30134533/100492547-42158b00-3168-11eb-9284-8acb1383342f.gif)\r\n\r\n\n Comment 3: > \u4e8b\u4ef6\u7ed1\u5b9a\u53ef\u4ee5\u4f7f\u7528 element:click, label \u53ef\u4ee5\u8bbe\u7f6e formatter \u7684 \uff0c \u6839\u636e\u60c5\u51b5\u81ea\u5df1\u5224\u65ad\u3002\r\n\r\n\u6211\u6309\u7167\u4e0a\u65b9\u8bf4\u660e\u7ed1\u5b9a\u4e86\u4e8b\u4ef6\uff0c\u4f46\u662f\u6bcf\u6b21\u4e8b\u4ef6\u89e6\u53d1\u65f6\uff0c\u90fd\u4f1a\u5237\u65b0\u56fe\u8868\uff0c\u5bfc\u81f4\u5df2\u9690\u85cf\u7684\u7ebf\u6761\u4e5f\u4f1a\u51fa\u73b0\uff0c\u8bf7\u95ee\u8fd9\u4e2a\u662fbug\u8fd8\u662f\u6211\u4f7f\u7528\u6709\u8bef\u5462\u2026\u6211\u662f\u6309\u5b98\u65b9\u6587\u6863\u6765\u5b9a\u4e49\u7684\u4e8b\u4ef6\n Comment 4: \u73b0\u5728\u7684\u66f4\u65b0\u786e\u5b9e\u4f1a\u76f4\u63a5\u91cd\u65b0\u6e32\u67d3\u56fe\u8868\uff0c\u6ca1\u6709\u4fdd\u5b58 legend \u9690\u85cf\u72b6\u6001\uff0c\u8fd9\u4e2a\u95ee\u9898\u5e94\u8be5\u8981\u5230 G2Plot \u5c42\u89e3\u51b3",
  "Issue title: Add Regex.escape\n Issue body: Say I have some string that I want to literally interpolate into a regex:\n\n``` elixir\nregex = %r/#{mysterious_string}.../\n```\n\nIf `mysterious_string` contains any regex ops, this will end up badly. Regex could have a function that would escape all regex characters to make the string match literally:\n\n``` elixir\nregex = %r/#{Regex.escape(mysterious_string)}.../\n```\n\n Comments: \n Comment 0: I have renamed it to `Regex.escape`, everything else, :+1:.\n\n Comment 1: As far as I can tell, Erlang does not provide such functionality.\n\nI'm marking this as _starter_. The algorithm itself is quite simple: scan through the string's characters and prepend a slash to each non-alphanumeric character. This follows from the following statement:\n\n> For example, if you want to match a \\* character, you write \\\\* in the pattern. This escaping action applies whether or not the following character would otherwise be interpreted as a metacharacter, so it is always safe to precede a non-alphanumeric with backslash to specify that it stands for itself. In particular, if you want to match a backslash, you write \\\\.\n\nHere's a reference implementation in [Python](http://svn.python.org/view/python/trunk/Lib/re.py?view=markup#l206).\n\nWe might also need to come up with a bunch of tests for various edge-cases (some tricky unicode chars? obscure metachars?).\n\nSee [this](http://www.erlang.org/documentation/doc-5.7.4/lib/stdlib-1.16.4/doc/html/regexp.html) and [this](http://www.erlang.org/doc/man/re.html) for the complete reference of regular expressions in Erlang.\n\n Comment 2: I'm taking this, but there's no need to escape every `[^\\w]`.\n\n Comment 3: Current implementation fails with the `x` option which ignores whitespace and `#`.\n\nTry\n\n```\n\"\\\\A  \\\\z\"   =~ %r/#{Regex.escape(\"\\\\A  \\\\z\")}/x\n# or\n\"\\t\\n\"   =~ %r/#{Regex.escape(\"\\t\\n\")}/x\n```\n\nwe need to either include all whitespace characters [defined in Unicode](http://en.wikipedia.org/wiki/Whitespace_character#Unicode), or escape all non-alphanumeric characters like was initially proposed, to future proof the implementation.\n\n Comment 4: @meh ^\n\n Comment 5: Patch incoming.\n",
  "Issue title: Fresh standalone install causes \"error no matches for kind Application\" \n Issue body: /kind bug\r\n\r\n**What steps did you take and what happened:**\r\nFresh install of tekton pipelines and then standalone kfp-tekton\r\n```kubectl apply -f https://storage.googleapis.com/tekton-releases/pipeline/previous/v0.16.3/release.yaml```\r\n```kubectl apply -f install/v0.4.0/kfp-tekton.yaml```\r\n\r\nResults (during kfp-tekton install):\r\n```\r\n...\r\ncondition.tekton.dev/super-condition created\r\npersistentvolumeclaim/minio-pvc created\r\npersistentvolumeclaim/mysql-pv-claim created\r\nerror: unable to recognize \"install/v0.4.0/kfp-tekton.yaml\": no matches for kind \"Application\" in version \"app.k8s.io/v1beta1\"\r\n```\r\n\r\nThis is fixed by running the kfp-tekton install again. \r\nIt seems to be the same issue as one they are having in: https://github.com/kubeflow/kubeflow/issues/2380\r\n\r\nIs this fixable or should we add this to the troubleshooting doc?\r\n\r\n**What did you expect to happen:**\r\n\r\n**Additional information:**\r\n[Miscellaneous information that will assist in solving the issue.]\r\n\r\n\r\n**Environment:**\r\n\r\n* Python Version (use `python --version`):\r\n* SDK Version: \r\n* Tekton Version (use `tkn version`):\r\n* Kubernetes Version (use `kubectl version`):\r\n* OS (e.g. from `/etc/os-release`):\r\n\n Comments: \n Comment 0: The crd should be created at the beginning of the kfp-tekton.yaml. Can you make sure the kubectl version matches with the k8s server version, then delete and rerun the `kubectl apply` command?\n Comment 1: encounter this issue today:\r\n```\r\npersistentvolumeclaim/mysql-pv-claim unchanged\r\nerror: unable to recognize \"install/v0.4.0/kfp-tekton.yaml\": no matches for kind \"Application\" in version \"app.k8s.io/v1beta1\"\r\n```\r\nkubectl version is matched:\r\n```\r\nroot@rentz1:/opt/kube/kfp-tekton# kc version\r\nClient Version: version.Info{Major:\"1\", Minor:\"19\", GitVersion:\"v1.19.0\", GitCommit:\"e19964183377d0ec2052d1f1fa930c4d7575bd50\", GitTreeState:\"clean\", BuildDate:\"2020-08-26T14:30:33Z\", GoVersion:\"go1.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\nServer Version: version.Info{Major:\"1\", Minor:\"19\", GitVersion:\"v1.19.1\", GitCommit:\"206bcadf021e76c27513500ca24182692aabd17e\", GitTreeState:\"clean\", BuildDate:\"2020-09-14T07:30:52Z\", GoVersion:\"go1.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n```\r\n\r\nworkaround by apply again\r\n\n Comment 2: OK, it looks like there's some race condition since the crd takes few second to register to the k8s api. We can follow the Knative approach to deploy the crd first, then deploy the cr few seconds after.\r\n",
  "Issue title: Save a result file\n Issue body: **Is your feature request related to a problem? Please describe.**\r\nThe service return blob-data of a file and I want to have a possibility to save the file. \r\n\r\nNow I look at raw data. \r\n\r\n![Screenshot from 2021-09-20 17-28-54](https://user-images.githubusercontent.com/19969187/134019990-4df3f289-1b50-4a37-8be7-084191c571bf.png)\r\n![Screenshot from 2021-09-20 17-28-55](https://user-images.githubusercontent.com/19969187/134019995-862cf603-1bdd-4a82-a394-7fb03d197ae6.png)\r\n\r\n**Describe the solution you'd like**\r\nAutomated request with a window dialog to save file (set a name, a path and format if it is possible).\r\n\r\n**Describe alternatives you've considered**\r\nNow I use Postman to save the result. Also I can use a browser, but it can make troubles with the request as POST and has parameters.\r\n\r\n![Screenshot from 2021-09-20 17-31-58](https://user-images.githubusercontent.com/19969187/134020564-89e362c0-10d0-4a73-8596-aa91e1ed5a0d.png)\r\n\r\nSometimes response data can be too much to show and the window can be frozen, so I want to save file without showing result.\r\n\r\nThank you.\n Comments: \n Comment 0: Hi @diosby, thanks for the feedback, will add to roadmap. \n Comment 1: I'd like to second this request. Thunder Client is such a great tool, but it is difficult to move away from Postman without the ability to download and save files.\n Comment 2: Hi guys, if possible I will include this for the next update \n Comment 3: This feature is now implemented in v1.11.0, The feature is still in BETA, so let me know if you have any issues\r\nhttps://github.com/rangav/thunder-client-support/releases/tag/v1.11.0\r\n\r\nplease let me know if any feedback\n Comment 4: This seems works well for my use cases. I think it's a better approach than in Postman since I no longer have to remember to send the request differently if I actually want the file (and often have to do it twice). Great job.\n Comment 5: Thanks @onmusic-development, glad you like the implementation \ud83d\ude42",
  "Issue title: freebayes calls SNP instead of INDEL\n Issue body: Hello,\r\nin my reference sequence there is a pattern 11 times TG followed by 7 times T. Now I have a sample which I already sequenced by sanger resulting in one allel with 11xTG/5xT and one with 12xTG/7xT.\r\n\r\nIf I have a look at the alignment file for my NGS analysis I can guess the same result. But freebayes says there are 11/12xTG (which is ok) and a SNP T>G which is not the same as a 2bp deletion. In contrast gatk's HaplotypeCaller have the correct result.\r\n\r\nI don't understand what freebayes is doing here. Are there any parameters with which I can influence the result. \r\n\r\nIn the attachment you can see the relevant position in igv. What more information can I provide to you?\r\n\r\nThanks a lot.\r\n\r\nfin swimmer\r\n\r\n![cftr](https://cloud.githubusercontent.com/assets/2164565/22061364/f2de2862-dd74-11e6-8fc4-fb8636faa43a.jpg)\r\n\n Comments: \n Comment 0: This issue is marked stale because it has been open 120 days with no activity. Remove stale label or comment or this will be closed in 5 days\n Comment 1: This issue was closed for lack of activity. Feel free to re-open if someone feels like working on it.",
  "Issue title: Ambiguous error message: \"Expected object but got object\" when passing an array\n Issue body: I got this error when accidentally passing an array in package.json. \r\n\r\nIt happens because the \"but got...\" uses `typeof value`, which returns \"object\" for arrays.\r\nMaybe instead of using \"typeof\" for the error message, using `Object.prototype.toString.call(value)` is better? or something else which would distinguish an array from an object..\r\n\r\nSounds like a small problem but it took me a while to find my package.json error, due to the unclear error message.\n Comments: \n Comment 0: Yeah, this is super annoying I agree.\n Comment 1: Landed in v1.0.3.",
  "Issue title: NPE in CapabilityDispatcher\n Issue body: This issue appears with the following mods on world load:\r\n**Forge:** 407-397-0304 (currently latest)\r\n**Custom NPCs:** 1.11.2(10may17) ([Download](https://minecraft.curseforge.com/projects/custom-npcs/files/2418212))\r\n**Wearable Backpacks:** 2.3.2 ([Download](https://github.com/copygirl/WearableBackpacks/releases/tag/v2.3.2))\r\n\r\nCustom NPCs issue reported [here](https://minecraft.curseforge.com/projects/custom-npcs/issues/1840).\r\n\r\n**Full crash log:** [Here](https://gist.github.com/copygirl/61846b9ff7a1b81ba609a487b64a100d)\r\n\r\n## Stacktrace\r\n```\r\njava.lang.NullPointerException: Ticking entity\r\n    at net.minecraftforge.common.capabilities.CapabilityDispatcher.getCapability(CapabilityDispatcher.java:108)\r\n    at net.minecraft.entity.Entity.getCapability(Entity.java:3037)\r\n    at net.minecraft.entity.EntityLivingBase.getCapability(EntityLivingBase.java:2859)\r\n    at net.minecraft.entity.player.EntityPlayer.getCapability(EntityPlayer.java:2636)\r\n    at net.mcft.copy.backpacks.ProxyCommon.onLivingUpdate(ProxyCommon.java:173)\r\n   ...\r\n```\r\n\r\n### Relevant code\r\n[CapabilityDispatcher.java:108](https://github.com/MinecraftForge/MinecraftForge/blob/c545b8ecd4e96107ccf134c8fd89906357d586ad/src/main/java/net/minecraftforge/common/capabilities/CapabilityDispatcher.java#L108)\r\n[ProxyCommon.java:173](https://github.com/copygirl/WearableBackpacks/blob/master/src/main/java/net/mcft/copy/backpacks/ProxyCommon.java#L173)\r\n(Custom NPCs is not open source?)\r\n\r\n## Other notes\r\nCould it be that Custom NPCs registers a `ICapabilityProvider` which is `null` or something causing it to be passed down there? Perhaps there should be a sanity check where the error might originate so the proper mod is being attributed to error instead of the one simply accessing capabilities?\n Comments: \n Comment 0: i did try it and yes it npes on world load \r\nthen i tried to put it in idea intellij added WB and CNPS (deodf using BON2) as a lib\r\nbut that works just fine :(\r\n\r\ncan this go wrong??\r\n`    public boolean hasCapability(Capability<?> capability, EnumFacing facing) {\r\n        return capability == MARKDATA_CAPABILITY;\r\n    }\r\n\r\n    public <T> T getCapability(Capability<T> capability, EnumFacing facing) {\r\n        return this.hasCapability(capability, facing)?this:null;\r\n    }`\n Comment 1: I've poked around the CNPS mod and can confirm that there is a case were it attaches a null `ICapabilityProvider` to entities using the `AttachCapabilitiesEvent`. That is the cause of the NPE in `CapabilityDispatcher`. Therefore, it is a mod issue. \r\n\r\nThe most Forge could do is catch and log attempts to add a null `ICapabilityProvider` in `AttachCapabilitiesEvent`. However, I don't think it is necessary as this looks to be an isolated (or rare) issue. Of course, Lex or another Forge dev have the final say on that. \n Comment 2: If you attach a null you're gunna make things explode.\r\nThis isn't on us to fix.",
  "Issue title: Issue with searchable PDF #1889 - Reopened\n Issue body: The fix for #1889 is incomplete without removing the following two lines from the function.\r\n\r\nif (!filename)\r\n    return false;\r\n\r\n\r\n_Originally posted by @FarhadKhalafi in https://github.com/tesseract-ocr/tesseract/issue_comments#issuecomment-423834649_\n Comments: \n Comment 0: duplicate #1889.",
  "Issue title: \ud83e\uddd0[\u95ee\u9898] \u5982\u4f55\u901a\u8fc7API\u8bbe\u7f6eProTable\u7684sorter\u53c2\u6570\uff1f\n Issue body: \u9700\u8981\u5728toolbar\u4e0a\u9762\u6dfb\u52a0\u4e00\u4e2a\u6309\u94ae\uff0c\u70b9\u51fb\u6309\u94ae\u54cd\u5e94\u4e0d\u540c\u7684\u641c\u7d22\u53c2\u6570\u4ee5\u53ca\u6392\u5e8f\u53c2\u6570\uff0c\u76ee\u524d\u901a\u8fc7formRef\u6765\u8bbe\u7f6e\u67e5\u8be2\u6761\u4ef6\uff0c\u4f46\u662fsort\u4e0d\u77e5\u9053\u5982\u4f55\u901a\u8fc7API\u8bbe\u7f6e\r\n\r\n\n Comments: \n Comment 0: https://ant.design/components/table-cn/#components-table-demo-reset-filter\r\n\r\n\u770b\u8fd9\u91cc\n Comment 1: Thanks",
  "Issue title: Jetty-12 EE10 Default Servlet \n Issue body: **Target Jetty version(s)**\r\n\r\nJetty-12\r\n\r\n**Enhancement Description**\r\n\r\nFix/implement the deficiencies of the ee10 DefaultServlet and ResourceHandler as identified by reviews of #8276: specifically:\r\n + undisable the `DefaultServletTest` and fix them\r\n + remove the Generic request/response abstraction\r\n + javadoc\r\n\n Comments: \n Comment 0: This is mostly done so far.\r\nMost of the remaining work is in the core `ResourceService`",
  "Issue title: Sucks not able to ping/command (recipient-unavailable)\n Issue body: **Describe the bug**\r\nI'm able to control my M80 Pro using the Ecovacs Home app but not using sucks (0.9.4). I tried with multiple sucks version, verified DNS redirect, etc. As everything is working from the Android app, I'm expecting sucks to be able to control it too\r\n\r\nP.S.: I also tried with your fork of sucks with the same result\r\n\r\nP.P.S.: There's no output from bumper when receiving the commands. When commands are sent from the Ecovacs Android App, this message appear (but command is executed by the deebot)\r\n[2020-01-01 08:44:24,447] 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 ERROR 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 boterror 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 Received Error from (116.69.203.115:11426 | samanthamiller@example.net/atom) - <root><iq samanthamiller@example.net/GLBe563fc4d' type='set' id='348'><query xmlns='com:ctl'><ctl id='05682664' ret='ok' errs='100'/></query></iq></root>\r\n\r\nThanks for your precious time\r\n\r\n\r\n**To Reproduce**\r\n1. sucks login\r\n2. sucks clean 10 (or any command)\r\n\r\nsucks output\r\n`sleekxmppfs.basexmpp WARNING  fulljid property deprecated. Use boundjid.resource\r\nperforming clean command\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/sucks\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"/usr/local/lib/python3.6/site-packages/click/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/click/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/usr/local/lib/python3.6/site-packages/click/core.py\", line 1164, in invoke\r\n    return _process_result(rv)\r\n  File \"/usr/local/lib/python3.6/site-packages/click/core.py\", line 1102, in _process_result\r\n    **ctx.params)\r\n  File \"/usr/local/lib/python3.6/site-packages/click/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/sucks/cli.py\", line 219, in run\r\n    vacbot.run(action.vac_command)\r\n  File \"/usr/local/lib/python3.6/site-packages/sucks/__init__.py\", line 416, in run\r\n    self.send_command(action.to_xml())\r\n  File \"/usr/local/lib/python3.6/site-packages/sucks/__init__.py\", line 413, in send_command\r\n    self.xmpp.send_command(xml, self._vacuum_address())\r\n  File \"/usr/local/lib/python3.6/site-packages/sucks/__init__.py\", line 482, in send_command\r\n    c.send()\r\n  File \"/usr/local/lib/python3.6/site-packages/sleekxmppfs/stanza/iq.py\", line 235, in send\r\n    raise IqError(result)\r\nsleekxmppfs.exceptions.IqError: <iq type=\"error\" to=\"samanthamiller@example.net/8e8e3189bdcd1e0e0c2a22dba210945b\" from=\"samanthamiller@example.net/atom\" id=\"b6ca5a49-1b5d-4308-9514-c470fe379d4d-3\"><error type=\"wait\" code=\"404\"><recipient-unavailable xmlns=\"urn:ietf:params:xml:ns:xmpp-stanzas\" /></error></iq>\r\n`\r\n\r\n\r\n**Expected behavior**\r\nDeebot should execute the command\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Desktop (please complete the following information):**\r\n - OS: Linux\r\n\r\n**Smartphone (please complete the following information):**\r\n - Device: Android\r\n\r\n**Vacuum (please complete the following information):**\r\n - Model: Deebot M80 Pro\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\n Comments: \n Comment 0: We may move this issue to [my fork of sucks](https://github.com/bmartin5692/sucks), but can you try the following with my fork:\r\n`sucks --debug charge`\n Comment 1: The \"issues\" feature is disabled on your fork of sucks, so I don't know if we can move it there?\r\nUsing debug, I figured out that Hassio (Home Assistant) which manages the Docker container as an addon, was not using the network DNS, but google's DNS so my custom redirect was not used.\r\n\r\nOnce that was fixed, I was able to use your fork of sucks (the original code returning an SSL error, which I believe is normal), but the only command the robot respond to is \"charge\" (But the command never finish once the robot is charging)\r\n\r\nWhen I try to run \"clean 10\", the script seems to work, waiting for 10min for the robot to finish cleaning, but the robot does nothing.\r\n\r\nBumper output when receiving commands (clean 10, charge, etc) from your fork of sucks:\r\n```\r\n[2020-01-01 23:08:22,813] 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 INFO 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 confserver 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 client with devid 1703b245b1523e6a00dbaa3d60874a56 attempting login\r\n[2020-01-01 23:08:25,349] 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 INFO 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 xmppserver 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 client authenticated fuid_tmpuser\r\n```\r\n\r\nBumper output when receiving commands (auto, charge, etc) from the official app:\r\n```\r\n2020-01-01 23:21:28,644] 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 INFO 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 xmppserver 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 client authenticated dg1rs5f944e6f28e\r\n[2020-01-01 23:21:33,988] 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 ERROR 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 boterror 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 Received Error from (116.69.203.115:11426 | samanthamiller@example.net/atom) - <root><iq samanthamiller@example.net/GLBe563fc4d' type='set' id='971'><query xmlns='com:ctl'><ctl id='40702592' ret='ok' errs='100'/></query></iq></root>\r\n[2020-01-01 23:21:33,996] 38d1:d2b4:3d06:83e8:96a5:8c2:893",
  "Issue title: Addition of a build system generator\n Issue body: I suggest to reuse a higher level build system than your current [small make file](https://github.com/ericfischer/datamaps/blob/09c6b67912d4840827bd8b01e6384d6942758f2e/Makefile#L1) so that powerful checks for software features will become easier.\n- [CMake](http://cmake.org/)\n- [Autotools](http://www.gnu.org/software/autoconf/#TOCintroduction)\n\n Comments: \n Comment 0: The Makefile is already more complicated than I want it to be, actually. I'd like to get rid of the pkg-config stuff and just say -lpng if I could get away with it.\n\n Comment 1: Are you interested in portable make files?\nHow do you think about to improve software portability by feature checks?\n\n Comment 2: No, I would in general like to depend only on facilities that exist on any reasonably modern Unix system.\n\n Comment 3: There are some variations to consider for implementation details to be safe...\n\n Comment 4: As far as I know, everything I am doing is platform-neutral for the platforms I am targeting.\n\n Comment 5: Does [a tool like \"autoscan\"](https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.69/html_node/autoscan-Invocation.html) show any software dependencies that you find worth for further considerations?\n\n Comment 6: +1",
  "Issue title: [REQUEST] Vim keys already included?\n Issue body: I know you already added hjkl navigation to bpytop. Is it missing or am i just too stupid to find out how to configure? \r\n\r\nAs an idea you may be able to get away with less requests like these if users could add their keybindings to the config file. Not sure how much time would go into implementing that but just a suggestion.\r\n\r\nHave to say that i really like this version. As much as i love python this kind of thing is better written in a lower level language.\n Comments: \n Comment 0: @jweckman \r\nI can't really say that I see much point in having \"vim keys\" in a program where you're not going to be switching between typing text and moving around especially often.\r\n\r\nI could possibly add the keybinds for `h j k l` in upper-case, that way you can toggle them with caps-lock. But I won't remove the already set default keybindings to accommodate a very small minority of users. You would also still have to use the arrow keys to move the cursor when editing text fields.\r\n\r\nAdding support for user customizable keybinds is no small task and isn't gonna be a high priority request right smithcynthia@example.org.\n Comment 1: Thanks for the reply. I was mainly wondering about the `h j k l` support :)\r\n\r\nThe reason why many of us are so annoying related to this detail is that it has become a core component of how we use our computers. It's not simply vim, its basically everything. Bash, zsh, tmux, less, psql, and even web browsers support the home row based navigation standard, which allows us to almost completely not use the arrow keys or the mouse for the most part. Introducing one of the core applications (yours is one of them) with arrow keys breaks the flow so badly that the slowness of bpytop becomes a significantly smaller issue.\r\n\r\nWhat i'm saying is that perhaps some of your biggest fans that are really into performance optimization are now missing out on this rewrite that you spent so much time on, with no clear reason since the support was already there in the earlier version.\r\n\r\nPersonally, i would recommend against caps-lock based support, since many keyboard driven users remap their escape key to caps-lock since it is used a lot more often.\r\n\r\nAgain, thank you so much for your work. I will be fine using bpytop but i wanted you to know that this feature would mean a lot to a lot of people and that it is significant enough that maybe someone who knows C would be happy to add full keyboard customization for you. I'm more of a Python/Rust guy so i could not help you at the smithcynthia@example.org.\r\n\r\n\n Comment 2: @jweckman @itaranto \r\nA toggle in the options for enabling Vim keys added in v1.0.15\n Comment 3: @aristocratos Holy cow that was fast. I only realized that you added it now because Brodie Robertson covered your application on youtube. Instantly had to install on my daily driver and reconfigure all my personal ansible scripts. Thanks!",
  "Issue title: Is it possible to enable support for web frameworks?\n Issue body: ### The use case you're trying to solve\r\n\r\nI'm trying to use GitHub actions to deploy my nextjs SSR app to firebase hosting. I understand in order to deploy a SSR app, I need to enable webframeworks with `firebase experiments:enable webframeworks` command.\r\n\r\n### Change to the action that would solve that use case\r\n\r\nIs this possible by adding a run: after uses: in the yml file?\r\n\r\n```\r\n- uses: FirebaseExtended/action-hosting-deploy@v0\r\n        run: firebase experiments:enable webframeworks\r\n        with:\r\n          repoToken: \"${{ secrets.GITHUB_TOKEN }}\"\r\n          firebaseServiceAccount: \"${{ secrets.FIREBASE_SERVICE_ACCOUNT_THECANNABISAPP_V2_DEV }}\"\r\n          channelId: live\r\n```\r\n\n Comments: \n Comment 0: NVM, I think I found a way to do this.\r\n\r\nI added a line above the action to install firebase and enabled web framework support.\r\n\r\n```\r\n- name: Install firebase and npm packages\r\n   run: install -g firebase-tools && firebase experiments:enable webframeworks\r\n- uses: FirebaseExtended/action-hosting-deploy@v0\r\n...\r\n```",
  "Issue title: Windows problem when try to complie peerflix\n Issue body: Hi, when im trying to complie \"peerflix\" project the complie stuck in  v8_base.vcxproj ->........\\build\\Release\\lib\\v8_base.lib, and dont do nothing, i do the same with \"torrent-stream\" stuck in  v8_base.vcxproj ->........\\build\\Release\\lib\\v8_base.lib too, what is happen? dont show any error or nothing\n\nI have been compiling the examples hellow world and works ok, i have phyton 7 and visual studio 2013\n\n Comments: \n Comment 0: Hi, thanks for reporting this issue however I'm unclear of what exactly your issue is. Please post screenshots or logs of output and relevant code so we can figure this out!\n\n Comment 1: Closing - abandoned ",
  "Issue title: Librdkafka fails to create thread on RHEL 8\n Issue body: Description\r\n===========\r\nBack Trace\r\n\r\n#0  0x00007ffff7833340 in thrd_create () from /usr/lib64/libpthread.so.0\r\n#1  0x00007ffff2193afe in rd_kafka_new (type=RD_KAFKA_CONSUMER, app_conf=0x894840, errstr=0x88c438 \"\",\r\n    errstr_size=512) at rdkafka.c:2179\r\n\r\n[New Thread 0x7ffff0ca3700 (LWP 31923)]\r\nrd_kafka_new (type=RD_KAFKA_CONSUMER, app_conf=0x894840, errstr=0x88c438 \"\", errstr_size=512) at rdkafka.c:2181\r\n2181                    rk->rk_init_wait_cnt--;\r\n(gdb) n\r\n2182                    ret_err = RD_KAFKA_RESP_ERR__CRIT_SYS_RESOURCE;\r\n(gdb) n\r\n2183                    ret_errno = errno;\r\n(gdb) n\r\n2184                    if (errstr)\r\n(gdb) n\r\n2185                            rd_snprintf(errstr, errstr_size,\r\n(gdb) n\r\n2188                    rd_kafka_wrunlock(rk);\r\n(gdb) p errstr\r\n$1 = 0x88c438 \"Failed to create thread: No such file or directory (2)\"\r\n(gdb)\r\n\r\nLibrdkafka is built with the following options\r\n./configure --enable-gssapi --enable-ssl --disable-optimization\r\n.........................\r\n.........................\r\nchecking for libpthread (by pkg-config)... failed\r\nchecking for libpthread (by compile)... ok (cached)\r\nchecking for c11threads (by pkg-config)... failed\r\nchecking for c11threads (by compile)... failed (disable)\r\n..................................\r\n..................................\r\n\r\n\r\nChecklist\r\n=========\r\n\r\n**IMPORTANT**: We will close issues where the checklist has not been completed.\r\n\r\nPlease provide the following information:\r\n\r\n - [x] librdkafka version (release number or git tag): `<latest>`\r\n - [ ] Operating system: `<RHEL 8>`\r\n - [ ] Critical issue\r\n\r\n\n Comments: \n Comment 0: I believe the error code is irrelevant (\"No such file or directory\") since the glibc thrd_create() does not set errno, looking at the manual page it seems the only failure it can return is thrd_nomem, which indicates that the current process has a too strict thread, memory or stack limit.\r\nAlso check `cat /proc/sys/kernel/threads-max`\n Comment 1: Todo: fix error string\n Comment 2: # cat /proc/sys/kernel/threads-max\r\n30015\r\n\n Comment 3: I noticed the same error message on Fedora 31 with librdkafka (0.11.6) from Fedora RPM repository (probably built without c11 thread support).  \r\n\r\nIn my case, an application is loading a plugin, which depends on librdkafka, using dlopen().  I discovered that the problem is caused by linker and multiple definitions of `thrd_create()` - one provided by libpthread and another by librdkafka. Since my application doesn't depend on librdkafka, the linker binds `thrd_create` to implementation provided by libpthread before startup of the app. So far, so good.\r\n\r\nHowever, when the plugin is later loaded (by `dlopen)` and `thrd_create` symbol required by librdkafka must be resolved again, the linker decides to use early used binding i.e. implementation from libpthread. Here is the problem: exact value of `thrd_success` is undefined by C11, however, for libpthread and GCC 9.2.1 `thrd_success` value is 0, but tinycthread.h defined `thrd_success` as 2 and `thrd_error` as 0. As the librdkafka was built against values from tinycthread, it was expecting value 2 on success, but implementation from libpthread returned 0 (on success).\r\n\r\n https://github.com/edenhill/librdkafka/blob/1f3f46b808efe712c6b894c7ad82c81f7406c522/src/tinycthread.h#L184\r\n\r\nI resolved this issue by RTLD_DEEPBIND flag of dlopen(). Nevertheless, I think the library should not redefine these common symbols. \n Comment 4: My application links to a static library of librdkafka. The static library is built without c11threads and employs TinyCThread as extensions to c11threads.\r\n\r\nStill the thrd_create call tries to execute libpthread implementation instead of TinyCThread implementation on RHEL8.\r\n\r\nAny equivalent of RTLD_DEEPBIND while doing static linking?\n Comment 5: Thanks for the root cause of this issue, @Lukas955 \r\nWill see what we can do about it.",
  "Issue title: Should we deprecate \"safe_mode\"?\n Issue body: The [docs](https://pythonhosted.org/Markdown/reference.html#safe_mode) have pointed to [Bleach](https://github.com/jsocol/bleach) as an alternative for same_mode for some time now. And I have been saying for even longer that safe_mode is not really \"safe\". Therefore, I would like to deprecate it and suggest Bleach be used in its stead. I **might** be inclined to replace it with a simple extension that does raw HTML escaping only -- it would make no claims about being \"safe\" -- but I don't really see the value when a much safer alternative exists in Bleach.\n\nAny thoughts and/or objections?\n\nOf course, we would issue a PendingDeprecationWarning first, followed by a DeprecationWarning in the next release -- so it won't go away immediately.\n\nOh, and I know a lot of people use this for comments, etc. As Markdown accepts **kwargs, people setting the `safe_mode` keyword would not get any error if support was simply removed. Suddenly, comments that have had potentially dangerous content will no longer be sanitized when they upgrade to the new Python-Markdown version. Therefore, when the feature is finally removed, I think we need to issue an Error `if'safe_mode' in kwargs.keys()`.\n\n Comments: \n Comment 0: Your logic seems very sound. I'm supportive. \n\n Comment 1: As a reminder to myself, we also need to deprecate support for positional args when we do this as'safe_mode' was one of the old positional args. See [`markdown/__init__.py L108`](https://github.com/waylan/Python-Markdown/blob/master/markdown/__init__.py#L108). We can't just take it out and keep the later positional args at their same position. Seeing that the current support is really just a hack for backward compatibility we should just deprecate it on the same timeline as safe_mode itself. The end result would be that `markdown.Markdown` and `markdown.markdown` would only accept `**kwargs`, but not `*args`.\n\nAlso, we need to deprecate the `html_replacement_text` keyword along with `safe_mode`.\n",
  "Issue title: Disable touchpad whilst typing does not work - Surface Pro 3 Issue body: Similar to [Issue 67](https://github.com/linux-surface/linux-surface/issues/67), despite having 'disable when typing' checked in KDE, the cursor will jump around when typing if I brush the touchpad. Note that I'm running with Wayland. `libinput show-devices` shows it should be enabled. Device: Microsoft Surface Type Cover Touchpad Kernel: /dev/input/event7 Group: 5 Seat: seat0, default Size: 98x50mm Capabilities: pointer gesture Tap-to-click: disabled Tap-and-drag: enabled Tap drag lock: disabled Left-handed: disabled Nat.scrolling: disabled Middle emulation: disabled Calibration: n/a Scroll methods: *two-finger edge Click methods: *button-areas clickfinger Disable-w-typing: enabled Accel profiles: none Rotation: n/a ### Environment <!--- Include as many relevant details about the environment you experienced the bug in --> - Hardware model: `Surface Pro 3` - Kernel version: ` Linux russh-Surface-Pro-3 5.13.13-surface #1 SMP Fri Sep 3 00:16:33 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux` - Distribution: KDE Neon <details><summary>`dmesg` output</summary> ``` [ 0.000000] microcode: microcode updated early to revision 0x26, date = 2019-11-12 [ 0.000000] Linux version 5.13.13-surface (root@28fce4bb2599) (gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0, GNU ld (GNU Binutils for Ubuntu) 2.34) #1 SMP Fri Sep 3 00:16:33 UTC 2021 [ 0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-5.13.13-surface root=UUID=71ab5e82-5214-427b-b9bd-137a083686c6 ro quiet splash net.ifnames=0 biosdevname=0 spectre_v2=off mem_sleep_default=s2idle intremap=no_x2apic_optout nox2apic iommu=soft vt.handoff=7 [ 0.000000] KERNEL supported cpus: [ 0.000000] Intel GenuineIntel [ 0.000000] AMD AuthenticAMD [ 0.000000] Hygon HygonGenuine [ 0.000000] Centaur CentaurHauls [ 0.000000] zhaoxin Shanghai [ 0.000000] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers' [ 0.000000] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers' [ 0.000000] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers' [ 0.000000] x86/fpu: xstate_offset[2]: 576, xstate_sizes[2]: 256 [ 0.000000] x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using'standard' format. [ 0.000000] BIOS-provided physical RAM map: [ 0.000000] BIOS-e820: [mem 0x0000000000000000-0x0000000000057fff] usable [ 0.000000] BIOS-e820: [mem 0x0000000000058000-0x0000000000058fff] reserved [ 0.000000] BIOS-e820: [mem 0x0000000000059000-0x000000000009dfff] usable [ 0.000000] BIOS-e820: [mem 0x000000000009e000-0x000000000009ffff] reserved [ 0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000aa376fff] usable [ 0.000000] BIOS-e820: [mem 0x00000000aa377000-0x00000000aa3f3fff] reserved [ 0.000000] BIOS-e820: [mem 0x00000000aa3f4000-0x00000000aa40afff] ACPI data [ 0.000000] BIOS-e820: [mem 0x00000000aa40b000-0x00000000abb54fff] ACPI NVS [ 0.000000] BIOS-e820: [mem 0x00000000abb55000-0x00000000abffefff] reserved [ 0.000000] BIOS-e820: [mem 0x00000000abfff000-0x00000000abffffff] usable [ 0.000000] BIOS-e820: [mem 0x00000000e0000000-0x00000000efffffff] reserved [ 0.000000] BIOS-e820: [mem 0x00000000fec00000-0x00000000fec00fff] reserved [ 0.000000] BIOS-e820: [mem 0x00000000fed00000-0x00000000fed03fff] reserved [ 0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved [ 0.000000] BIOS-e820: [mem 0x00000000fee00000-0x00000000feefffff] reserved [ 0.000000] BIOS-e820: [mem 0x00000000ff000000-0x00000000ffffffff] reserved [ 0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000014fdfffff] usable [ 0.000000] NX (Execute Disable) protection: active [ 0.000000] e820: update [mem 0xa7d64018-0xa7d74057] usable ==> usable [ 0.000000] e820: update [mem 0xa7d64018-0xa7d74057] usable ==> usable [ 0.000000] extended physical RAM map: [ 0.000000] reserve setup_data: [mem 0x0000000000000000-0x0000000000057fff] usable [ 0.000000] reserve setup_data: [mem 0x0000000000058000-0x0000000000058fff] reserved [ 0.000000] reserve setup_data: [mem 0x0000000000059000-0x000000000009dfff] usable [ 0.000000] reserve setup_data: [mem 0x000000000009e000-0x000000000009ffff] reserved [ 0.000000] reserve setup_data: [mem 0x0000000000100000-0x00000000a7d64017] usable [ 0.000000] reserve setup_data: [mem 0x00000000a7d64018-0x00000000a7d74057] usable [ 0.000000] reserve setup_data: [mem 0x00000000a7d74058-0x00000000aa376fff] usable [ 0.000000] reserve setup_data: [mem 0x00000000aa377000-0x00000000aa3f3fff] reserved [ 0.000000] reserve setup_data: [mem 0x00000000aa3f4000-0x00000000aa40afff] ACPI data [ 0.000000] reserve setup_data: [mem 0x00000000aa40b000-0x00000000abb54fff] ACPI NVS [ 0.000000] reserve setup_data: [mem 0x00000000abb55000-0x00000000abffefff] reserved [ 0.000000] reserve setup_data: [mem 0x00000000abfff000-0x00000000abffffff] usable [ 0.000000] reserve setup_data: [mem 0x00000000e0000000-0x00000000efffffff] reserved [ 0.000000] reserve setup_data: [mem 0x00000000fec00000-0x00000000fec00fff] reserved [ 0.000000] reserve setup_data: [mem 0x00000000fed00000-0x00000000fed03fff] reserved [ 0.000000] reserve setup_data: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved [ 0.000000] reserve setup_data: [mem 0x00000000fee00000-0x00000000feefffff] reserved [ 0.000000] reserve setup_data: [mem 0x00000000ff000000-0x00000000ffffffff] reserved [ 0.000000] reserve setup_data: [mem 0x0000000100000000-0x000000014fdfffff] usable [ 0.000000] efi: EFI v2.31 by American Megatrends [ 0.000000] efi: ESRT=0xabeb0c18 ACPI 2.0=0xaa3f8000 ACPI=0xaa3f8000 SMBIOS=0xabeaf018 MOKvar=0xa8b61000 [ 0.000000] SMBIOS 2.8 present. [ 0.000000] DMI: Microsoft Corporation Surface Pro 3/Surface Pro 3, BIOS 3.11.2650 04/30/2019 [ 0.000000] tsc: Fast TSC calibration using PIT [ 0.000000] tsc: Detected 2494.036 MHz processor [ 0.000073] e820: update [mem 0x00000000-0x00000fff] usable ==> reserved [ 0.000077] e820: remove [mem 0x000a0000-0x000fffff] usable [ 0.000087] last_pfn = 0x14fe00 max_arch_pfn = 0",
  "Issue title: Move Link element helper button\n Issue body: **Context**: In the editor, a button element includes a helper button floating below it (button itself is disabled so that users can select and transform it.)\r\n\r\n**Problem**: The helper falls behind tools and off the screen when moved too low on the page. \r\n\r\n**Solution**: Move the helper above the button when it is placed below a certain point (bottom quarter of page).\r\n\r\n![screenshot 2015-05-29 16 10 11](https://cloud.githubusercontent.com/assets/53411/7891876/145c35ea-061e-11e5-8a1f-187398b6b077.png)\r\n\n Comments: \n Comment 0: <a href=\"https://github.com/mozilla/webmaker-core/issues/155\"><img src=\"https://raw.githubusercontent.com/toolness/learning-issue-migrator/master/img/migrated.png\"></a>\nThis issue has been moved to https://github.com/mozilla/webmaker-core/issues/155.\nPlease don't comment on it here.",
  "Issue title: Add autopackage files for Linux\n Issue body: **Reported by takkaria on 21 Mar 2007 15:11 UTC**\nTo make building and installing easier for Linux people, put together an autopackage ([http://autopackage.org/]) file.  Probably relies on us having a working./configure.\n Comments: \n Comment 0: **Comment by arcum42\\@gmail.com on 22 Apr 2007 21:52 UTC**\nAs a note, this should supplement, not replace, other methods of Linux distribution. Autopackage is x86 only - it is partially broken on 64-bit systems, and will not work on other processors...\n Comment 1: **Comment by takkaria on 25 Apr 2007 17:43 UTC**\nAh.  Doesn't sound like such a good idea, then.  (It wasn't going to replace anything else anyway.)\n Comment 2: **Modified by takkaria on 3 Jun 2007 16:18 UTC**\n Comment 3: **Comment by magnate on 28 May 2009 17:23 UTC**\nNow that building a.deb is easy (and therefore an.rpm via alien), perhaps this is a wontfix?\n Comment 4: **Modified by magnate on 26 Jul 2009 18:24 UTC**\n Comment 5: **Comment by magnate on 26 Jul 2009 18:34 UTC**\nWill be closed once the.deb (and.rpm) files are building properly with --enable-gtk and --with-private-dirs.\n Comment 6: **Comment by magnate on 13 Jan 2010 11:06 UTC**\nOk, this is essentially done, without autopackage. A.deb can be built by anyone checking out git://git.debian.org/collab-maint/angband.git (don't forget to pull in all submodules), and turned into an rpm with alien. Between the two, most major Linux distros are supported I think. See also #1076 for the Gentoo ebuild. Other package formats should be accommodated on an as-needed basis (no requests on Oook during 2009 for anything other than deb/rpm). ",
  "Issue title: Support for IAM roles\n Issue body: It would be great if you supported IAM roles for s3 authentication \n\n Comments: \n Comment 0: I will second this.  It's a simple change that is supported by Fog\n\n Comment 1: Ok, so i've added some fixes for this, to my forked version.  https://github.com/jforest/backup\n\nI added the few bits I think are necessary, please let me know what you think.\n\nI've added use_iam_profile.   \n\n Comment 2: Submitted a pull request, #493 \n",
  "Issue title: Add simple info on markdown input elements\n Issue body: As mentioned in #127, users could use a simple \"how-to\" on writing markdown.\r\n\r\nMy proposal is to add an \"i\" button in the (lower) right corner that would show a small markdown cheat-sheet in a popover, similar to this:\r\n\r\n![image](https://cloud.githubusercontent.com/assets/4129927/25895326/b028af98-357f-11e7-96f7-678e5b9cff86.png)\r\n\r\nHow does that sound?\r\n\r\nP.S. Someone should come up with a list of what should actually go there. [This](http://daringfireball.net/projects/markdown/basics) or [this](https://bitbucket.org/tutorials/markdowndemo/overview) list might be good starting points.\n Comments: \n Comment 0: Good point, i guess we should have a short description directly inside the app and link to a more extensive documentation. \r\nSimilar to what Trello does:\r\n\r\n[Trello Markdown hints](https://cloud.githubusercontent.com/assets/3404133/26050419/d4081042-395e-11e7-9afd-b44315b846f8.png)\r\n\n Comment 1: I think that is the way to go, but it need to be hosted.\r\nNot sure if nexcloud has a help wiki like page, or somewhere to host this help if indeed external.\r\nOther option is just to provide a link to another markdown - related help, or even the help page of the actual script itself. \n Comment 2: @x9t9 We can just create a page on the github repo wiki for that.\n Comment 3: Sure, I can do that if needed. as long as I don't interfere with @pixelipo wip...\n Comment 4: After creating the page and while editing it I actually noticed that the wikipage would just result in duplicated content.\r\nI feel it is much better to just incorporate the (`_BLANK` ) link to https://markdown-it.github.io, which provides demo, a kind of playground, and a comprehensive list of all the supported features.\r\nThe only useful entry is the `known issues` reference to #127 and the cited solution.\r\nThis can also be places in a general `known-issues` page for deck. No need for a special markdown page.\r\nSo feel free to just delete the whole page.\n Comment 5: I'd prefer to still keep the wiki page and link to that, since we can then also mention plugins we use as it might come with #53 \r\n\r\nI did some further adjustments to that https://github.com/nextcloud/deck/wiki/Markdown-Help\r\nThanks for getting it started @x9t9 ",
  "Issue title: R\u952ebug\n Issue body: \u9020\u4e00\u5835\u5f88\u9ad8\u7684\u5899\uff0c\u7ad9\u5728\u5899\u89d2\uff0c\u89c6\u7ebf\u5bf9\u7740\u5899\u9876\u90e8\uff0c\u6309R\u952e\uff08\u672a\u5f00\u98de\u884c\u3001\u7a7f\u5899\uff09\uff0c\u7136\u540e\u4e00\u76f4\u98de\u5230\u5899\u7684\u9876\u90e8\uff0c\u5c31\u4f1a\u53d1\u73b0\u6389\u4e0d\u4e0b\u6765\u3002\n Comments: \n Comment 0:![bug](https://cloud.githubusercontent.com/assets/12978630/12070340/0b3104ec-b0a9-11e5-914b-bfd24da07786.png)\r\n\n Comment 1: \u8fd9\u662f\u7279\u6027\uff0cR\u952e\u6709\u98de\u884c\u529f\u80fd\u3002\u9876\u90e8\u6389\u4e0d\u4e0b\u6765\u8bf7\u786e\u5b9a\u4f7f\u7528\u7684\u662f0.4.10\u53ca\u4ee5\u4e0a\u7684\u6b63\u5f0f\u7248\n Comment 2: \u7ecf\u6d4b\u8bd5\uff0c0.4.10\u6b63\u5f0f\u7248\u6ca1\u6709\u51fa\u73b0\u6389\u4e0d\u4e0b\u6765\u7684\u95ee\u9898",
  "Issue title: DateTimePicker crashes Safari\n Issue body: In Safari, load the documentation page and click on the Date`TimePicker` input. It crashes the browser. It works fine on Chrome and Firefox, however.\r\n\r\nhttps://jquense.github.io/react-widgets/docs/#/datetime-picker?_k=sjwrwg\r\n\r\nI repro'd this on Mac Safari 10.0.3 and iOS 10.2.1\n Comments: \n Comment 0: ugh safari is the worst...why is it even allowing that. Can you try with the v4 beta's and see if it still occurs\n Comment 1: Seeing this as well. @jquense do you have any more details on what Safari is doing? I'd be happy to attempt to get this fixed and issue a PR if it's not already resolved in v4 betas. Thanks!\n Comment 2: I don't have specific insight other than it seems to crash when you click the calendar button. generally js crashes are due to infinite loops but I have why I'd get one in safari but not others \n Comment 3: I just checked this morning and the issue is no longer present. Given that yesterday was the start of DST it seems that could potentially be related. Maybe some bad date processing somewhere in Safari related to that?\n Comment 4: you're right. l.o.l.\n Comment 5: This appears to be happening again today for me.  Seems worth fixing if its broken at least once per year!",
  "Issue title: Missing index-setting 'index.cache.query.enable' when updating indexsettings\n Issue body: On the http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-shard-query-cache.html its describe the new settings for enable query cache, the settings is missing in the IUpdateSettingsRequest.\n\n Comments: \n Comment 0: closed by #1245 ",
  "Issue title:  undefined is not a function\n Issue body: Hi\n\nI'm getting an error on a new install, from what I can tell I have everything installed ok. Do you know what would cause this?\n\nHere is the error\n\n```\nTypeError: undefined is not a function\n    at http://dev.rvwd.com/js/angular-redactor.js:36:32\n    at http://ajax.googleapis.com/ajax/libs/angularjs/1.2.10/angular.min.js:113:78\n    at e (http://ajax.googleapis.com/ajax/libs/angularjs/1.2.10/angular.min.js:33:287)\n    at http://ajax.googleapis.com/ajax/libs/angularjs/1.2.10/angular.min.js:37:1 \n```\n\nIt seems to be this line\n\n```\n$timeout(function () {\n        editor = $_element.redactor(options);\n        ngModel.$render();\n      });\n```\n\n Comments: \n Comment 0: I just tried again with your demo after installing angular and redactor via bower and I received the same error\n\n Comment 1: What version of redactor are you using?\n\n Comment 2: I'm going to close this, unless there is a known bug.\n\n Comment 3: Why did you close this @TylerGarlick? I'm getting the same error.\n\nIf I change line 43 from...\n\n```\neditor = $_element.redactor(options);\n```\n\nto \n\n```\neditor = $('textarea').redactor(options);\n```\n\n...I don't receive the error. Obviously this makes the directive pointless, but I'm just trying to show that there seems to be a bug.\n\n Comment 4: I'll take a look into it, sorry I thought you all resolved it.\n\n Comment 5: No worries. I actually just jumped on this issue because I was getting the same error. \n\nThanks for looking into it. \n\n Comment 6: What version of redactor are you all using?\n\n Comment 7: I'm using 8.2.2. I wanted to try it out before buying it and that's the version available in bower. \n\nIf I use the version from Redactor's example pages (`http://imperavi.com/js/redactor/redactor.js`), I get the same error\n\n Comment 8: It looks like someone else was having the same issue in https://github.com/TylerGarlick/angular-redactor/issues/7. \n\nIf I change `$_element` to `$($_element)`, it works fine. Perhaps something in `angular.element` changed, which is what broke it again. I'm using Angular v1.3.0-build.3001+sha.d2f8f25\n\n Comment 9: There definitely is an issue with 8.2.2 on bower, but I can't duplicate the undefined issue. It seems there is a digest issue going on in that version.\n\nI did verify that these versions work below\n\nAngularJS Versions\n- 1.3.0-beta.18\n- 1.3.0-build.3001+sha.d2f8f25\n- 1.2.2\n\nRedactor \n- 9.2.5\n- 9.2.6 \n\nCan someone who's getting this issue give me a complete code sample so I can replicate.  I may not spend a lot of time on this sense radactor is paid and they are on version 9.2.6, but I'll do what I can.\n\n Comment 10: I had the same problem and I solved it by loading jQuery before angular and redactor.\n\n Comment 11: Sorry I've been MIA from this. I managed to get this working on mine, but it was so long ago I'm not sure what I changed. I'm at work at the moment so I don't have much time. Here is my updated directive, likely hacked and smashed together.\n\n```\n  angular.module('angular-redactor', [])\n   .directive(\"redactor\", ['$timeout', function ($timeout) {\n\nreturn {\n      require: \"ngModel\",\n      link: function($scope, elem, attrs, controller) {\n          controller.$render = function() {\n              elem = $(elem);\n\n              var updateModel = function updateModel(value) {\n                scope.$apply(function () {\n                  ngModel.$setViewValue(value);\n                });\n              };\n\n              var options = {\n                changeCallback: function() {\n                      $scope.$apply( controller.$setViewValue(elem.val()) );\n                  }\n              };\n\n              var additionalOptions = $scope.redactorOptions;\n\n              var editor;\n\n              angular.extend(options, additionalOptions);\n\n              // put in timeout to avoid $digest collision.  call render() to\n              // set the initial value.\n              $timeout(function () {\n                editor = elem.redactor(options);\n              });\n\n          };\n      }\n  };\n\n}]);\n```\n\n Comment 12: It seems to work fine with the latest version of redactor and a current\nversion of this directive, as long as you include everything. ;)\nOn Sep 2, 2014 8:27 AM, \"Adam Greer\" thomasjordan@example.com wrote:\n\n> Sorry I've been MIA from this. I managed to get this working on mine, but\n> it was so long ago I'm not sure what I changed. I'm at work at the moment\n> so I don't have much time. Here is my updated directive, likely hacked and\n> smashed together.\n> \n>   angular.module('angular-redactor', [])\n>    .directive(\"redactor\", ['$timeout', function ($timeout) {\n> \n> return {\n>       require: \"ngModel\",\n>       link: function($scope, elem, attrs, controller) {\n>           controller.$render = function() {\n>               elem = $(elem);\n> \n> ```\n>           var updateModel = function updateModel(value) {\n>             scope.$apply(function () {\n>               ngModel.$setViewValue(value);\n>             });\n>           };\n> \n>           var options = {\n>             changeCallback: function() {\n>                   $scope.$apply( controller.$setViewValue(elem.val()) );\n>               }\n>           };\n> \n>           var additionalOptions = $scope.redactorOptions;\n> \n>           var editor;\n> \n>           angular.extend(options, additionalOptions);\n> \n>           // put in timeout to avoid $digest collision.  call render() to\n>           // set the initial value.\n>           $timeout(function () {\n>             editor = elem.redactor(options);\n>           });\n> \n>       };\n>   }\n> ```\n> \n>   };\n> \n> }]);\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/TylerGarlick/angular-redactor/issues/11#issuecomment-54168817\n>.\n\n Comment 13: Well Im facing this same issue at the moment and Im using bower to download the lib as well! Its actually intermittent! Sometimes, the editor loads fine, other times it gives me this error. Help?\n\nOh and my jQuery is being loaded before any other lib, so I dont think that should cause a problem.\n\n Comment 14: I don't believe the bower version is current, you'll probably need to try\nagain with the purchased version and its most recent update.\n\nOn Tue, Oct 28, 2014 at 6:52 AM, Shashanka Nataraj <thomasjordan@example.com\n\n> wrote:\n> \n> Well Im facing this same issue at the moment and Im using bower to\n> download the lib as well! Its actually intermittent! Sometimes, the editor\n> loads fine, other times it gives me this error. Help?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/TylerGarlick/angular-redactor/issues/11#issuecomment-60757816\n>.\n\n Comment 15: @Rosseyn Is right. I bought the cheapest version and it works fine with this library.\n\n Comment 16: I am seeing this as well. As a temporary fix I used `$($_element)` in place of `$_element`.\n\n Comment 17: I figured my issue out. Unrelated to this issue. It seems to be working properly now for me. \n\n Comment 18: getting same:\r\n\r\n`\r\nTypeError: undefined is not a function\r\n    at angular-redactor.js:55\r\n    at angular.js:16223\r\n    at completeOutstandingRequest (angular.js:4905)\r\n    at angular.js:5285angular.js:11607 (anonymous function)angular.js:8557 $getangular.js:16226 (anonymous function)angular.js:4905 completeOutstandingRequestangular.js:5285 (anonymous function)\r\n`",
  "Issue title: [BUG] why i don't get qr code\n Issue body:![image](https://user-images.githubusercontent.com/80480704/155874014-46365977-3a81-4d84-b649-838bf16eff58.png)\r\n\n Comments: \n Comment 0: you need to share code, cant say anything without seeing the code \n Comment 1: > you need to share code, cant say anything without seeing the code\r\n![carbon (2)](https://user-images.githubusercontent.com/80480704/155880896-e27af564-7373-43eb-bc66-62af3e0cfe1e.png)\r\n\r\n\n Comment 2: >![image](https://user-images.githubusercontent.com/80480704/155874014-46365977-3a81-4d84-b649-838bf16eff58.png)\r\n\r\nnpm i qrcode-terminal \n Comment 3: This issue is stale because it has been open 6 days with no activity. Remove the stale label or comment or this will be closed in 2 days",
  "Issue title: Liquid Supplier Pipe - Forestry\n Issue body: A system of a Liquid Supplier Pipe, Liquid Provider Pipe and a Carpenter will request fluid, even if the Carpenter is full, so the fluid is wasted. (tested with water)\nThe Carpenter is filled by this pipe. With IC2exp machines this setup works fine.\nForestry 116.69.203.115\nIC2x b288\nLP b73\n\n Comments: \n Comment 0: It is more that there will be a specifically sized liquid buffer which\ndoesn't exist in ic2. No liquid is destroyed. (worst case scenario is that\nit will bounce off a full inventory if other liquid somehow ends up in\nthere, invalidating the request while it is on route.\n\nOn Tue, Nov 12, 2013 at 2:51 PM, Marcus Ullrich anthony05@example.org:\n\n> A system of a Liquid Supplier Pipe, Liquid Provider Pipe and a Carpenter\n> will request fluid, even if the Carpenter is full, so the fluid is wasted.\n> (tested with water)\n> The Carpenter is filled by this pipe. With IC2exp machines this setup\n> works fine.\n> Forestry 116.69.203.115\n> IC2x b288\n> LP b73\n> \n> \u2014\n> Reply to this email directly or view it on GitHubhttps://github.com/RS485/LogisticsPipes-Dev/issues/216\n>.\n\n## \n\n\u201cGetting information off the Internet is like taking a drink from a fire\nhydrant.\u201d\n_\u2013 Mitchell Kapor_\n\n Comment 1: I think, I don't understand your comment. IC2 machines also have an internal buffer. If this is full, the Supplier Pipe stops requesting. At the Carpenter it is still requesting liquid. First the Carpenter is filled, then the pipe at the Carpenter is filled with water (inblock with the Crapenter), then the (placed) pipe Block besides the Carpenter is filled, and after this, the Pipe is still requesting water and the incoming items are animated as they where thrown to the ground, if they were normal items.\n\n Comment 2: if you try to supply more than the internal capacity then it will overflow\nand destroy the liquid; make sure that the supplier is not requesting more\nthan the buffer size.\n\nif it persists, could you post a sscreenshot of your setup here so we can\nsee what you are doing.\n\nfinally, you if you put a sink on the source then any extra over-flow can\nbounce off a full inventory, and then get sunk somewhere (like what happens\nwith items)\n\nOn Tue, Nov 12, 2013 at 3:25 PM, Marcus Ullrich anthony05@example.org:\n\n> I think, I don't understand your comment. IC2 machines also have an\n> internal buffer. If this is full, the Supplier Pipe stops requesting. At\n> the Carpenter it is still requesting liquid. First the Carpenter is filled,\n> then the pipe at the Carpenter is filled with water (inblock with the\n> Crapenter), then the (placed) pipe Block besides the Carpenter is filled,\n> and after this, the Pipe is still requesting water and the incoming items\n> are animated as they where thrown to the ground, if they were normal items.\n> \n> \u2014\n> Reply to this email directly or view it on GitHubhttps://github.com/RS485/LogisticsPipes-Dev/issues/216#issuecomment-28269264\n>.\n\n## \n\n\u201cGetting information off the Internet is like taking a drink from a fire\nhydrant.\u201d\n_\u2013 Mitchell Kapor_\n\n Comment 3: The Carpenter can hold 10 Buckets, I want to keep it 1 Bucket.\nAfter this Bucket, the pipe still requests water from the provider.\n\nI\n![2013-11-12_07 40 58](https://f.cloud.github.com/assets/2853451/1519590/0d5d2c8c-4b66-11e3-8c88-26ae3f2ce1a5.png)\n![2013-11-12_07 41 16](https://f.cloud.github.com/assets/2853451/1519591/0d5e1bce-4b66-11e3-84b4-cbae1fdead96.png)\n![2013-11-12_07 41 46](https://f.cloud.github.com/assets/2853451/1519592/0d5f2d8e-4b66-11e3-8753-756b4d1aa658.png)\n![2013-11-12_07 42 46](https://f.cloud.github.com/assets/2853451/1519593/0d6085c6-4b66-11e3-8dff-f5efdcf6ff94.png)\n![2013-11-12_07 44 23](https://f.cloud.github.com/assets/2853451/1519594/0d618764-4b66-11e3-8474-d749a0a8d09a.png)\n![2013-11-12_07 41 23](https://f.cloud.github.com/assets/2853451/1519595/0d62ec12-4b66-11e3-96fb-a1ac2902bbfe.png)\n\n Comment 4: OK I found the problem. The carpenter doesn't return it's internal tanks when you ask for them. We could fix that with a special proxy for forestry's carpenter. Question is, if this should be consisted a forestry bug. \n\n Comment 5: I created an issue at Forestrys bugtracking: https://bitbucket.org/sengir/forestry/issue/650/liquid-supplier-pipe-forestrys-internal\n\n Comment 6: If this doesn't get fixed from forestrys side, we probably should fix that from our side, at test for so long, till sengir get's time to fix this.\nSo i'm going to need a list of all things inside forestry, that have a tank and doesn't work with the supplier pipe, so i don't have to do this again and again.\n\n Comment 7: Every Forestry block with a tank is affected: Analyzer, Biogas Engine, Biogenerator, Bottler, Carpenter, Fermenter, Moister an the Still.\n\nWhile testing I mentioned another issue: The Forestry Analyzer can only accept liquid honey. But for example you can request water with a connected pipe to it. The Analyzer won't fill up with water, but the pipe do. So the pipe will be blocked to request other fluids. (You have to break and replace it)\nIt may be good, that the SupplierPipes only request fluids, if the connected machine can handle this fluid. I don't know, if the ForestryAPI have an interface for this, but if it's possible an implementaion may be great.\n\n Comment 8: Says resolved on the forestry side. Can you confirm that?\n\n Comment 9: to confirm it they have to implement it in LP first\n\n Comment 10: still existing with \nforestry 116.69.203.115\nand LP build 80\n\n Comment 11: you'll have to wait for at least build 81 (the next one) to confirm it, forestry added a method that enables mods to ask for liquid levels in the tank of the machine, LP now has to use them\n\n Comment 12: If forestry uses the standard forge method like it should, than LP don't need to update. And the update fpr forestry isn't available. The issue was closed yesterday and the forestry version 116.69.203.115 is from Nov 07. So you will have to wait to test.\n\n Comment 13: ah, cause it worked i knew one had to be updated but it is somehing added so i guessed LP had to implement it. wrong gues\n\n Comment 14: It works with the new forestry update :)\n",
  "Issue title: Autoscroll when new message is sent\n Issue body: Is there an option to have the message feed scroll when you send a new message? Right now it doesn't show messages I sent when I mouse over and scroll down manually. Works fine for incoming messages.\n Comments: \n Comment 0: Same here and it happens on incoming messages as well. I've tried to get a pattern but it's kind of random. But I've noticed that I get two messages at once many times (incoming messages), and (not always) it's printed on screen my message when i write two messages one after the other. Hope this helps",
  "Issue title: i18n guidelines\n Issue body: Hi Tom,\n\nI want to translate this resource to pt-BR, do you have any guideline for that to be integrated with your rep?\n\n Comments: \n Comment 0: Awesome, [added a note about translations](https://github.com/tmcw/mapschool/blob/gh-pages/CONTRIBUTING.md#translation) with a first approach to try, but open to any better ways to do it that still keep it simple!\n\n Comment 1: Great, thanks a lot for this resource. You think it would be ok to republish on our project, [Geojournalism Handbook](http://geojournalism.oeco.org.br/)?\n\n Comment 2: Absolutely, go for it!\n\n Comment 3: Cool, ping back if there's anything to add in terms of translations.\n",
  "Issue title: \u770b\u4e0d\u5230\u4ef7\u683c\n Issue body: \u4ee3\u7801\u5b9e\u4f8b\r\n```\r\nconst trackEcommerce = ({id, name, category, price, position, screenName, action}) => {\r\n    console.log(id, name, category, price, position, screenName, action)\r\n    const HitBuilders = ga.HitBuilders;  \r\n    const Product = ga.Product;\r\n    const ProductAction = ga.ProductAction;  \r\n\r\n    const product =  new Product()\r\n                       .setId(id)\r\n                       .setName(name)\r\n                       .setCategory(category)\r\n                       .setPrice(price)\r\n\t\t\t\t\t\t\t\t\t\t\t\t.setCustomDimension(1, \"Member\"); \r\n\t\t\t\t\t\t\t\t\t\t\t\t//.setPosition(position)\r\n\t\tconst productAction = new ProductAction(ProductAction[action])\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.setTransactionRevenue(price) // \u3010\u91cd\u8981\u3011\u8fd9\u4e2a\u662f\u8ba2\u5355\u603b\u4ef7\uff0c\u5305\u542b\u4e86 \u7a0e\u8d39 \u548c \u8fd0\u8d39\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.setTransactionTax(0)\r\n    \t\t\t\t\t\t\t\t\t\t\t\t\t.setTransactionShipping(0);\r\n    const builder = new HitBuilders.ScreenViewBuilder()\r\n                       .addProduct(product)\r\n                       .setProductAction(productAction);\r\n    getApp().getTracker().setScreenName(screenName).set(\"&cu\", \"CNY\").send(builder.build());    \r\n\r\n}\r\n```\r\n\r\n### \u4ef7\u683c\u8fd9\u4e00\u5217\u4e00\u76f4\u662f0\uff0c\u662f\u4ee3\u7801\u6709\u95ee\u9898\u5417\uff1f\u8fd8\u662fGA\u6709\u95ee\u9898\uff1f\r\n<img width=\"1287\" alt=\"screen shot 2018-07-11 at 3 08 52 pm\" src=\"https://user-images.githubusercontent.com/12168865/42555957-9759f8e4-851c-11e8-8ef3-42d140d04ec0.png\">\r\n\n Comments: \n Comment 0: \u8fd9\u662f\u6700\u8fd1\u5728\u4e00\u4e2a\u5c0f\u7a0b\u5e8f\u4e2d\u4f7f\u7528\u7684\u4ee3\u7801\u7247\u6bb5\uff0c\u4f60\u53c2\u8003\u4e00\u4e0b\r\n\r\n\r\n```javascript \r\n// \u5f53\u524d\u4ea7\u54c1\u5217\u8868\u9875\u540d\u5b57\r\nconst EA_PRODUCT_LIST = '\u73ab\u7470\u82b1\u5e97'\r\n\r\n// \u7edf\u8ba1\u4ea7\u54c1\u5c55\u793a\r\n      const builder = new HitBuilders.ScreenViewBuilder()\r\n   \r\n       ///////////////// \u5982\u679c\u5217\u8868\u5c55\u793a\u591a\u4e2a\u4ea7\u54c1\uff0c\u8fd9\u91cc\u5f00\u59cb\u5faa\u73af ///////////\r\n       // \u5b9a\u4e49\u4ea7\u54c1\r\n        const product = new Product()\r\n         .setId(`P${product_id}SKU${sku_id}`)\r\n         .setName(`${item.name}`)\r\n         .setPrice(item.price)\r\n         .setQuantity(1)\r\n         .setCategory('\u73ab\u7470\u82b1')\r\n         .setBrand('APP\u540d\u5b57')\r\n         .setPosition(1) // \u5217\u8868\u4e2d\u7684\u4f4d\u7f6e\uff0c\u4ece1\u5f00\u59cb\r\n\r\n\r\n      const productAction = new ProductAction(ProductAction.ACTION_DETAIL)\r\n         .setProductActionList(EA_PRODUCT_LIST)\r\n        builder.addImpression(product, EA_PRODUCT_LIST)\r\n         .addProduct(product)\r\n         .setProductAction(productAction)\r\n\r\n        ///////////////// \u5982\u679c\u591a\u4e2a\u4ea7\u54c1\uff0c\u8fd9\u91cc\u7ed3\u675f\u5faa\u73af /////////////////\r\n\r\n// \u53d1\u9001\u6570\u636e\r\n const t = getTracker()\r\n      t.setScreenName('/pages/index/rose-shop')\r\n      t.send(builder.build())\r\n\r\n\r\n//.................\r\n\r\n\r\n// \u4ea7\u54c1\u70b9\u51fb\r\nconst productAction = new ProductAction(ProductAction.ACTION_CLICK)\r\n           .setProductActionList(EA_PRODUCT_LIST)\r\n          const builder = new HitBuilders.EventBuilder()\r\n           .addProduct(product)\r\n           .setProductAction(productAction)\r\n           .setCategory('\u8d2d\u4e70\u73ab\u7470\u82b1')\r\n           .setAction('\u70b9\u51fb\u8d2d\u4e70')\r\n\r\n          getTracker().send(builder.build())\r\n\r\n//........................\r\n\r\n\r\n\r\n// \u52a0\u5165\u8d2d\u7269\u8f66\uff08\u6216\u8fdb\u884c\u8ba2\u5355\u751f\u6210\uff09\r\n const productAction = new ProductAction(ProductAction.ACTION_ADD)\r\n           .setProductActionList(EA_PRODUCT_LIST)\r\n          const builder = new HitBuilders.EventBuilder()\r\n           .addProduct(product)\r\n           .setProductAction(productAction)\r\n           .setCategory('\u8d2d\u4e70\u73ab\u7470\u82b1')\r\n           .setAction('\u70b9\u51fb\u8d2d\u4e70')\r\n\r\n          getTracker().send(builder.build())\r\n\r\n//.............................\r\n\r\n\r\n// \u5f00\u59cb\u5fae\u4fe1\u652f\u4ed8\r\nconst productAction = new ProductAction(ProductAction.ACTION_CHECKOUT)\r\n             .setProductActionList(EA_PRODUCT_LIST)\r\n             .setCheckoutStep(1)\r\n             .setCheckoutOptions('\u5fae\u4fe1\u652f\u4ed8')\r\n            const builder = new HitBuilders.EventBuilder()\r\n             .addProduct(product)\r\n             .setProductAction(productAction)\r\n             .setCategory('\u8d2d\u4e70\u73ab\u7470\u82b1')\r\n             .setAction('\u652f\u4ed8\u65b9\u5f0f')\r\n             .setLabel('\u5fae\u4fe1\u652f\u4ed8')\r\n\r\n            getTracker().send(builder.build())\r\n\r\n// \u652f\u4ed8\u6210\u529f\u4e4b\u540e\r\nconst productAction = new ProductAction(ProductAction.ACTION_PURCHASE)\r\n             .setProductActionList(EA_PRODUCT_LIST)\r\n             .setTransactionId(`O${order_id}`)\r\n             .setTransactionAffiliation('\u73ab\u7470\u82b1\u5e97')\r\n             .setTransactionRevenue(item.price * 1) // \u3010\u91cd\u8981\u3011\u8fd9\u4e2a\u662f\u8ba2\u5355\u603b\u4ef7\uff0c\u5305\u542b\u4e86 \u7a0e\u8d39 \u548c \u8fd0\u8d39\r\n             .setTransactionTax(0)\r\n             .setTransactionShipping(0)\r\n\r\n            const builder = new HitBuilders.EventBuilder()\r\n             .addProduct(product)\r\n             .setProductAction(productAction)\r\n             .setCategory('\u8d2d\u4e70\u73ab\u7470\u82b1')\r\n             .setAction('\u652f\u4ed8')\r\n\r\n            getTracker().send(builder.build())\r\n```\n Comment 1: \u53e6\u5916\u8fd9\u4e2a\u62a5\u8868\u6570\u636e\u4f1a\u5ef6\u8fdf\u597d\u51e0\u5206\u949f\uff0c\u4f60\u6700\u65b0\u7684\u6d4b\u8bd5\u6570\u636e\u9700\u8981\u8fc7\u51e0\u5206\u949f\u624d\u80fd\u770b\u5230\n Comment 2: \u53ef\u4ee5\u4e86\uff0c\u8c22\u8c22\u3002",
  "Issue title: [Feature] Implement DSC Resource for active and configured VMKernel dump file on the VMHost\n Issue body: DSC Resource that modifies the active and configured VMKernel dump file on the VMHost.\n Comments: \n Comment 0: VMHostVMKernelActiveDumpFile DSC Resource was implemented via PR #236. Closing the issue.",
  "Issue title: interface\n Issue body: _From [snipert...@gmail.com](https://code.google.com/u/101869750767225947958/) on January 21, 2012 21:16:44_\n\nWhat steps will reproduce the problem? 1.\u0417\u0430\u043f\u0443\u0441\u043a \u043f\u0440\u043e\u0438\u0433\u0440\u044b\u0432\u0430\u0442\u0435\u043b\u044f)\n\n\u0412\u0430\u0448\u0430 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0430 \u043c\u043d\u0435 \u043e\u0447\u0435\u043d\u044c \u043d\u0440\u0430\u0432\u0438\u0442\u0441\u044f,\u0442\u0430\u043a\u043e\u0439 \u0448\u0438\u0440\u0438\u043a\u0438\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u043e\u043d\u0430\u043b \u0432 Windows-\u043f\u043b\u0435\u0435\u0440\u0430\u0445 \u0440\u0435\u0434\u043e\u043a. \u0423\u0434\u0430\u0447\u0438 \u0432\u0430\u043c \u0432 \u0440\u0430\u0437\u0432\u0438\u0442\u0438\u0438,\u0431\u0443\u0434\u0443 \u0432\u0435\u0440\u043d\u044b\u043c \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u043c \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u044b :) \n\n\u0415\u0441\u0442\u044c \u0437\u0430\u043c\u0435\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441\u0443,\u043d\u0430\u0434\u0435\u044e\u0441\u044c \u044d\u0442\u043e \u043d\u0435 \u043d\u0430\u0432\u0441\u0435\u0433\u0434\u0430)\n\n**Attachment:** [11111.png](http://code.google.com/p/clementine-player/issues/detail?id=2643)\n\n_Original issue: http://code.google.com/p/clementine-player/issues/detail?id=2643_\n\n Comments: \n Comment 0: _From [john.maguire](https://code.google.com/u/john.maguire/) on January 21, 2012 14:05:06_\n\nWe don't speak Russian.\n\n**Status:** Invalid  \n",
  "Issue title: False positive\n Issue body: As an example I have a key in my doku repo, but it's invalid. (and I mentioned it).\r\nNow I get a false positive alert.\r\n\r\nPlease provide details how to handle this when using gg-shield to avoid false positives.\n Comments: \n Comment 0: You can put the false positive key in the.gitguardian.yaml under `matches-ignore`. You can have more details [here](https://github.com/GitGuardian/gg-shield#configuration).\r\n\r\nDon't hesitate if you have more questions\r\n\r\n",
  "Issue title: Still support rfcn?\n Issue body: It seems rfcn has been removed to another code file,and I cannot find any trained model or model config file in this repro to re-produce rfcn?Could you provide more details about this part?Thanks\n Comments: \n Comment 0: Any response\n Comment 1: I also want to know if there is any plan for rfcn? Thanks.",
  "Issue title: Sequential type annotations should have blank space between them.\n Issue body: \r\n```elm\r\nencode : Stats -> Json.Encode.Value\r\ndecoder : Json.Decode.Decoder Stats\r\n```\r\nshould format with two blank lines in between.\n Comments: \n Comment 0: Might have been fixed by d63a2f728c89ee0e6d7fed2b9ead4afb47248793.\n Comment 1: Backfilled tests in c1fead4.",
  "Issue title: Need help\n Issue body: Hello everyone,\r\n\r\nUntill few days, my Requestrr bot don't reply in Discord :( I check discord settings and Radarr settings and test are OK.\r\n\r\nI found this in logs but I don't know what to do : \r\n\r\n`[2021-10-05 19:06:00 +02:00] [0   /            ] [Crit ] There was an error registering application commands\r\nDSharpPlus.Exceptions.UnauthorizedException: Unauthorized: 403\r\nat DSharpPlus.Net.DiscordApiClient.BulkOverwriteGuildApplicationCommandsAsync(UInt64 application_id, UInt64 guild_id, IEnumerable`1 commands)`\r\n\r\nExeption seem like to come from DSharpPlus to communicate with Discord but i'm stuck, someone could help me?\n Comments: \n Comment 0: I would recommend that you check this out first:\r\n\r\n__**Here's what's changed**__\r\n\r\nThe bot is now using slash commands `/` the old way of using commands with the prefix `!` is gone.\r\n\r\n__**How do I correctly migrate my bot?**__\r\n\r\nFirst update your bot to the latest version.\r\n\r\nThen kick the bot from your server(s), go in Requestrr's web portal in the Chat Client page and re-invite your bot to your servers using the **COPY LINK** button to get your new link.\r\n\r\nOnce its inside your server(s), restart it then you should be good to go\n Comment 1: Love you, kicked him and added him again : work perfectly! :)",
  "Issue title: Example issue\n Issue body: Hello!\r\n\r\nI'm trying to run the example dashboard script but I keep getting the following error, any suggestions? Thanks!\r\n\r\n```\r\nTylers-iMac:dashboard tyleryouschak$ node server.js \r\n/Users/tyleryouschak/Desktop/GPS.js/examples/dashboard/server.js:14\r\n  parser: SerialPort.parsers.readline('\\r\\n')\r\n                             ^\r\n\r\nTypeError: SerialPort.parsers.readline is not a function\r\n    at Object.<anonymous> (/Users/tyleryouschak/Desktop/GPS.js/examples/dashboard/server.js:14:30)\r\n    at Module._compile (module.js:569:30)\r\n    at Object.Module._extensions..js (module.js:580:10)\r\n    at Module.load (module.js:503:32)\r\n    at tryModuleLoad (module.js:466:12)\r\n    at Function.Module._load (module.js:458:3)\r\n    at Function.Module.runMain (module.js:605:10)\r\n    at startup (bootstrap_node.js:158:16)\r\n    at bootstrap_node.js:575:3\r\n```\n Comments: \n Comment 0: Hmm, I should version-pin serialport. Seems you need to update it.\n Comment 1: I've done some investigating and I found that locking serial port to 4.0.7 works great. They must have changed some things in 5.0.0.\r\n\r\n```\"serialport\": \"^4.0.7\",```\r\n\r\nAlso, I'm wanting to use your GPS.js library in an Electron app - do you expect that this should work?\n Comment 2: Oh, you're right. I'll check out what's new. Thanks!\r\n\r\nIt should work with electron without any problems. Only thing you need to do is set up the callbacks.\n Comment 3: Okay awesome. Will let you know how it works or if I run into any issues. I will close this issue for now.\n Comment 4: Ahh, they changed the parsers to be stream transforms now.\n Comment 5: Give me 10min, I'll update the examples to make them work with serialport v5\n Comment 6: Okay, thats fine! Thanks for looking into it also!\r\n\r\nI'm about to step out of the office for a few hours, but will be back later.\n Comment 7: Okay, done :)",
  "Issue title: Drop shadow on moving object\n Issue body: I'm unable to get drop shadows to appear on moving objects. I've added in the filter size script.\r\n```\r\n filterSize: {\r\n                    width: '600%',\r\n                    height: '600%',\r\n                    x: '-200%',\r\n                    y: '-200%',\r\n                },\r\n            },\r\n```\r\n\r\n\r\nThe drops shadows appear on the objects when they are static but disappear once they start to move. The then reappear when the object stops.\r\n\r\nIs there any know fix for this.\r\n\r\nThank you!\r\n\r\n\n Comments: \n Comment 0: hi, can you share a link with your implementation? Also what browser are you testing it on?\n Comment 1: Hey there!\r\n\r\nHere's a link to my Ae file along with a demo. https://drive.google.com/drive/folders/1luGAujyL72Izx6tj4Nxxz72E-tlpciKO?usp=sharing\r\n\r\nCurrently the drop shadows work fine in Chrome but they do not work in Fire fox.\r\n\r\nThank you!\n Comment 2: Hi @bodymovin just wondering if you may have had a chance to take a look into this. I've got a client I'm working with and I'm wondering if I should find another solution.\r\n\r\nThanks so much!\n Comment 3: sorry about the delay. Unfortunately this seems like a glitch from Firefox, and my attempts to solve it haven't succeeded.\n Comment 4: Hey no worries! I ended up using a png and it actually improved the performance of the animation across most browsers so it's kind a win lol. Thanks for trying!",
  "Issue title: fingerprintable options on subsystem dependencies of earlier upstream v1 tasks don't invalidate downstream v1 tasks\n Issue body: See https://github.com/pantsbuild/pants/issues/7417#issuecomment-475485698. Changes in fingerprintable subsystem dependency option values in the native backend compile and link tasks will invalidate those tasks, but won't invalidate the `python_dist()` building task, which will happily use stale cached results.\r\n\r\nOne easy way to solve this might be to make each Task's `.fingerprint` mix in the hash of all subsystem dependencies of all tasks producing any products which the current Task uses (with e.g. `round_manager.require(<product>)` or `round_manager.optional_data(<product>)`, etc).\n Comments: \n Comment 0: This is probably better done by porting the native backend to v2 as described in #7136.",
  "Issue title: [SearchProfiler] Sharded Index renders weirdly and with React errors\n Issue body: **Kibana version:**\r\nMaster as of `06df2b0db6`\r\n\r\n**Describe the bug:**\r\n\r\nIn SearchProfiler on multiple shards index renders weirdly and causes React errors to be logged to browser console.\r\n\r\n**Steps to reproduce:**\r\n1. Follow the setup instructions for the Console commands on this issue: https://github.com/elastic/kibana/pull/57402\r\n2. Navigate to SearchProfiler\r\n3. Run the default query\r\n4. You should see something like in the screenshot\r\n\r\n**Console commands:**\r\n\r\n\r\n**Expected behavior:**\r\n\r\nSearchProfiler shards should render slightly further apart (visually) and there should not be any console errors.\r\n\r\n**Screenshots (if relevant):**\r\n\r\n<img width=\"1937\" alt=\"Screenshot 2020-02-13 at 13 33 52\" src=\"https://user-images.githubusercontent.com/8155004/74436353-944e1f80-4e66-11ea-92d5-951efbb825e1.png\">\r\n\n Comments: \n Comment 0: Pinging @elastic/es-ui (Team:Elasticsearch UI)",
  "Issue title: useLayoutEffect\n Issue body: I am using this hook for determining if a user is on a mobile or desktop device, and to conditionally expand or collapse a menu. I am using a `useLayoutEffect` hook for setting state based on the `useMedia` hook, but this hook uses `useEffect`, which causes another render and for the UI to flash into place on the second render, immediately after. I've tried switching the defaultState, but that just moves the problem to the other match case.\r\n\r\nHow do you feel about a second export that uses `useLayoutEffect` so consumers can choose which type of effect they would like to use?\n Comments: \n Comment 0: I'm more than happy to submit a PR with a `useMediaLayout` (or something similar) named export that uses `useLayoutEffect` if that seems okay.\n Comment 1: Does it make sense to only have `useLayoutEffect`? Or are there cases where `useEffect` if preferable for this hook?\n Comment 2: >... if that seems okay.\r\n\r\nThat would be great, I'm just thinking if we can just replace `useEffect` with `useLayoutEffect`.\n Comment 3: There are probably cases for both. For my uses, I feel like I would only use a layout effect, but there are a ton of media queries, I doubt all need to be run synchronously.\n Comment 4: OK, then we can create `useMediaLayout`.\n Comment 5: Maybe something like this:\r\n\r\n```js\r\nconst useMedia = createUseMedia(useEffect);\r\nconst useMediaLayout = createUseMedia(useLayoutEffect);\r\n```\n Comment 6: Oh yeah, nice! I'll give that a go and submit a PR.\n Comment 7: Thanks for adding this, it should be in `1.3.0` now.",
  "Issue title: Get & Set Failing After Error Cascade\n Issue body: Aloha!\r\n\r\n### The Problem\r\nUnder certain loads and after long up-times, we've begun seeing a curious error during addorset (Reproduced at the end).\r\nThis is accompanied by a much higher number of errors for Gets (Reproduced at the end) that are roughly identical, though we do use get far more than set.\r\n\r\n### Additional\r\nOnce a client becomes symptomatic, it rapidly begins throwing these errors on most or all operations. Bouncing that client causes another client to become symptomatic in a similar way, which may be a red herring but was interesting enough to bear mention.\r\n\r\nWe currently use only one multiplexer, which seems like a possible cause, but before we refactor, I thought I'd check in. Our application is pretty much pure C#. We are seeing time-outs as well, during symptomatic periods. My assumption is that [StackExchange.Redis/ConnectionMultiplexer.cs#L2601](https://github.com/StackExchange/StackExchange.Redis/blob/master/src/StackExchange.Redis/ConnectionMultiplexer.cs#L2601) is the top level call in the multiplexer for the error, given that 2622 is part of error handling deferral. \r\n\r\n### Set Error:\r\n```\r\nREDACTED REDIS AddOrSet Failure on key REDACTED\r\n    StackExchange.Redis.RedisConnectionException: Failed to write ---> System.InvalidOperationException: Concurrent reads or writes are not supported.\r\n       at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n       at System.IO.Pipelines.PipeCompletion.ThrowLatchedException()\r\n       at System.IO.Pipelines.Pipe.GetFlushResult(FlushResult& result)\r\n       at System.IO.Pipelines.Pipe.PrepareFlush(CompletionData& completionData, ValueTask`1& result, CancellationToken cancellationToken)\r\n       at System.IO.Pipelines.Pipe.FlushAsync(CancellationToken cancellationToken)\r\n       at System.IO.Pipelines.Pipe.DefaultPipeWriter.FlushAsync(CancellationToken cancellationToken)\r\n       at Pipelines.Sockets.Unofficial.SocketConnection.WrappedWriter.FlushAsync(CancellationToken cancellationToken) in /_/src/Pipelines.Sockets.Unofficial/SocketConnection.cs:line 434\r\n       at StackExchange.Redis.PhysicalConnection.FlushAsync(Boolean throwOnFailure) in /_/src/StackExchange.Redis/PhysicalConnection.cs:line 907\r\n       at StackExchange.Redis.PhysicalBridge.ProcessBacklog() in /_/src/StackExchange.Redis/PhysicalBridge.cs:line 889\r\n       --- End of inner exception stack trace ---\r\n       at StackExchange.Redis.ConnectionMultiplexer.ExecuteSyncImpl[T](Message message, ResultProcessor`1 processor, ServerEndPoint server) in /_/src/StackExchange.Redis/ConnectionMultiplexer.cs:line 2622\r\n       at StackExchange.Redis.RedisBase.ExecuteSync[T](Message message, ResultProcessor`1 processor, ServerEndPoint server) in /_/src/StackExchange.Redis/RedisBase.cs:line 54\r\n```\r\n\r\n### Get Error:\r\n```\r\nREDACTED REDIS GetAsync Failure on key REDACTED\r\n    StackExchange.Redis.RedisConnectionException: Failed to write ---> System.InvalidOperationException: Concurrent reads or writes are not supported.\r\n       at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n       at System.IO.Pipelines.PipeCompletion.ThrowLatchedException()\r\n       at System.IO.Pipelines.Pipe.GetFlushResult(FlushResult& result)\r\n       at System.IO.Pipelines.Pipe.PrepareFlush(CompletionData& completionData, ValueTask`1& result, CancellationToken cancellationToken)\r\n       at System.IO.Pipelines.Pipe.FlushAsync(CancellationToken cancellationToken)\r\n       at System.IO.Pipelines.Pipe.DefaultPipeWriter.FlushAsync(CancellationToken cancellationToken)\r\n       at Pipelines.Sockets.Unofficial.SocketConnection.WrappedWriter.FlushAsync(CancellationToken cancellationToken) in //src/Pipelines.Sockets.Unofficial/SocketConnection.cs:line 434\r\n       at StackExchange.Redis.PhysicalConnection.FlushAsync(Boolean throwOnFailure) in //src/StackExchange.Redis/PhysicalConnection.cs:line 907\r\n       at StackExchange.Redis.PhysicalBridge.WriteMessageTakingWriteLockAsync(PhysicalConnection physical, Message message) in /_/src/StackExchange.Redis/PhysicalBridge.cs:line 987\r\n       --- End of inner exception stack trace ---\r\n       at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n       at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n```\r\n\n Comments: \n Comment 0: If the timeout errors would be helpful, I can provide them too. Redacting them is more timestaking, and I wanted to get this up.\n Comment 1: That's... very curious; the stack trace gives me a lot of context here - I\ncan see somehow we're attempting concurrent IO from flushbacklog. Is this\nrepeatable? I'm trying to think of there's anything I can do to directly\nrepro it\n\nOn Sat, 18 Apr 2020, 01:26 JKurzer, <patriciakeller@example.com> wrote:\n\n> If the timeout errors would be helpful, I can provide them too. Redacting\n> them is more timestaking, and I wanted to get this up.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/StackExchange/StackExchange.Redis/issues/1438#issuecomment-615520687>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAAEHMCRSDD554CN7DGIT5LRNDXULANCNFSM4MLDWLWA>\n>.\n>\n\n Comment 2: FYI - we have a customer getting this problem on version 116.69.203.115891.  I will see if we can any details on how to reproduce this...\n Comment 3: We are also on v: 116.69.203.115891. Our repro is inconsistent at best, and only occurs after a soak under production load levels. Unfortunately, we can't go live until I have a clean line to resolve. It does seem likely that this is happening during.net threadpool exhaustion.\r\n\r\nWe are also seeing fairly regular time-outs (reproduced at the end) from symptomatic machines prior to and during the fatal cascade. I believe this is an orthogonal issue, but I mention it for completeness. These appear to be both due to and causing the threadpool exhaustion, as indicated in WORKER. Our redis metrics and slowlog do not report issues.\r\n\r\n### Timeout Error:\r\n```\r\nREDIS GetAsync Failure on key REDACTED\r\n    StackExchange.Redis.RedisTimeoutException: The timeout was reached before the message could be written to the output buffer, and it was not sent, command=GET,\r\ntimeout: 5000, outbound: 9293KiB, inbound: 0KiB, next: SETEX REDACTED, inst: 20, qu: 192, qs: 14, aw: True, bw: RecordingTimeout, rs: ReadAsync, ws: Flushed, in: 0, in-pipe: 0, out-pipe: 243792,\r\nserverEndpoint: 116.69.203.115:6001, mc: 1/1/0, mgr: 9 of 10 available, clientName: REDACTED, PerfCounterHelperkeyHashSlot: 11679, IOCP: (Busy=1,Free=999,Min=24,Max=1000), WORKER: (Busy=56,Free=32711,Min=24,Max=32767),\r\nv: 116.69.203.115891 (Please take a look at this article for some common client-side issues that can cause timeouts: https://stackexchange.github.io/StackExchange.Redis/Timeouts)\r\n       at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n       at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n       at REDACTED.Engine.Common.Caching.RedisCache.GetAsync()\r\n```\n Comment 4: I may have a small additional lead. We're seeing another form of the same error, much rarer but a bit more informative maybe, since it shows what's happening to the task.\r\n\r\n```\r\nUnobserved Task Exception caught, sender is System.Threading.Tasks.Task1[StackExchange",
  "Issue title: AppVeyor for Windows builds\n Issue body: Travis CI doesn't support Windows builds. However, there is [AppVeyor](https://www.appveyor.com/) which, just like Travis CI, is free for OSS software and provides VMs for Windows. Adding AppVeyor is the next step to 1) test TinySpline on Windows and 2) deploy releases to services like pypi.\n Comments: \n Comment 0: Fixed with: #106",
  "Issue title: Integrate KernelUtils into Kernel\n Issue body: `KernelUtils` provide a set of methods for creating specific kernels. Those static methods should instead be moved to the `Kernel` class itself.\r\n\r\nThis change is part of the API review (see issue #11)\n Comments: \n Comment 0: Done as of commit 140d063ac425bb441a353cacaa9750ef2736ccf2.",
  "Issue title: use yargs\n Issue body: It would be good to use an arguments library. I'm currently thinking http://yargs.js.org/. It has a @types/yargs. https://github.com/yargs/yargs\r\n\r\nAnother stage could be full configuration through something like https://github.com/indexzero/nconf. It uses yargs for its command line processing\r\n\r\n\n Comments: \n Comment 0: Looks nice! Fable 0.7 used [command-line-args](https://www.npmjs.com/package/command-line-args) directly from TS. It can be [configured with a simple pojo object](https://github.com/fable-compiler/Fable/blob/b89698206160acae01fcf35ae889844ee97ff513/src/fable/Fable.Client.Node/ts/options.ts#L14-L41).\n Comment 1: I got both command-line-args and yargs working with Fable. I like yargs a whole lot more. It is 100 times more popular in downloads stats and github stars.",
  "Issue title: Very slow installer\n Issue body: This is just an observation. The installer takes a very long time. Like 20-30 minutes. Nothing I ever install in VS takes that long. I guess it is what it is. I am surprised an extension takes that long to install. It makes me want to install it after work hours.\n Comments: \n Comment 0: That is not something I have observed.  Wonder why. Maybe you can share some logs?",
  "Issue title: Style/FormatStringToken with --disable-uncorrectable can't handle multiline strings\n Issue body: ## Expected behavior\r\n\r\nWhen rubocop disable statement via `--auto-correct --disable-uncorrectable` is added, it should handle multiline strings.\r\n\r\n## Actual behavior\r\n\r\nIt does not handle multiline strings and adds the `# rubocop:disable Style/FormatStringToken` in a place, where it breaks the code.\r\n\r\n## Steps to reproduce the problem\r\n\r\nFor this code in `foo.rb`\r\n```\r\n puts format('loaded %d references in'\\\r\n       '%.1f ms (%.1fms per ref)', 10, 100, 10)\r\n```\r\nThen execute the cop\r\n```\r\nrubocop foo.rb --auto-correct --disable-uncorrectable --only 'Style/FormatStringToken'\r\n```\r\nResult\r\n```\r\n puts format('loaded %d references in'\\ # rubocop:disable Style/FormatStringToken\r\n       '%.1f ms (%.1fms per ref)', 10, 100, 10)\r\n```\r\nThis leads to a syntax error\r\n```\r\n$ ruby foo.rb \r\nfoo.rb:1: syntax error, unexpected escaped space, expecting ')'\r\n...t('loaded %d references in'\\ # rubocop:disable Style/Forma...\r\nfoo.rb:2: syntax error, unexpected ',', expecting end-of-input\r\n...    '%.1f ms (%.1fms per ref)', 10, 100, 10)\r\n```\r\n\r\n\r\n## RuboCop version\r\n```\r\n0.73.0 (using Parser 116.69.203.115, running on ruby 2.6.2 x86_64-darwin18)\r\n```\r\n\n Comments: \n Comment 0: This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contribution and understanding!\n\n Comment 1: This is still an issue.\n Comment 2: The problem in the description can not be reproduced in newer versions of RuboCop. After the PR #7409 the `Style/FormatStringToken` cop no longer detects offenses in strings that are split into multiple lines with backslashes.\r\n\r\nIs there another cop where the same problem can be reproduced, or should we fix `Style/FormatStringToken`? Cc: @buehmann \n Comment 3: This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contribution and understanding!\n\n Comment 4: This issues been automatically closed due to lack of activity. Feel free to re-open it if you ever come back to it.\n",
  "Issue title: _autoprefixerPrefix error with node v7\n Issue body:  Cannot read property '_autoprefixerPrefix' of undefined\r\nThis error occurs with Node v7.10.0. With node v6 everything works fine\r\n\r\n\r\n\n Comments: \n Comment 0: Version 2 now supports PostCSS 6. Would you try again?\n Comment 1: Seems it is still not fixed for me.\r\nI updated package.json, deleted npm, reinstalled modules and error still exists.\r\n(There was deprecation warning about Node.raws it was fixed after update)\r\n\r\nI use Node v7 if it matters\n Comment 2: Thanks for the update. I\u2019m wondering if it\u2019s another plugin in your stack. What other plugins are you using? I only ask because this project does not use Autoprefixer, and your error indicates something with Autoprefixer.\n Comment 3: I'm using only postcss-normalize and autoprefixer.\r\nI made a little test. This is strange, but everything works fine, if normalize goes after autoprefixer.\r\nBut if normalize goes first, error occurs.\r\nLike this:\r\n```\r\n.pipe(postcss([\r\n    postcssNormalize(),\r\n    autoprefixer()\r\n]))\r\n```\n Comment 4: Testing this now.\n Comment 5: @jonathantneal what I should test? `master`?\n Comment 6: This should be resoled in 2.0.1.\r\n\r\nTest: https://github.com/jonathantneal/postcss-tests/blob/master/postcss-normalize-test-00\r\n\r\nTest Plugins: https://github.com/jonathantneal/postcss-tests/blob/master/postcss-normalize-test-00/test.js#L8-L9\n Comment 7: Thanks for fast fix, everything works now",
  "Issue title: Nested keyframe animations behaving erratically\n Issue body: Congrats on the great work, loving react-spring \ud83d\udcaf \r\n\r\nI have come across an issue trying to nest some keyframe animations.\r\n\r\nI wanted to smoothly open up some vertical space before fading in the target element. Then have that element smoothly adjust it's height to accommodate a child item (e.g. button), and fade in that item only when the space is created.\r\n\r\nhttps://codesandbox.io/s/61wo67o6mr\r\n\r\nIt actually ended up being worse when I tried to isolate it in the sandbox above. In my project the button does display fine, it's just that the parent element has a fixed height so doesn't accomodate the new child item. Looking into it, the parent element initially transitions open, gets it's height set to auto once it has opened fully, but then the height is set to a fixed value when the component later updates to accomodate the new child item.\r\n\r\nAny help much appreciated - perhaps I am going about this the wrong way?\r\n\r\n\r\n\n Comments: \n Comment 0: I see, this could be tough to fix on my side. 'auto' isn't straight forward, we have to measure out a frame with height set to auto, remember the value and then animate there, when it's all done the animated height is replaced with 'auto' again. That of course makes the animation volatile as nested stuff can grow larger/smaller after the initial measurement, it also makes the animation async, which explains the weird skipping that sometimes happens.\r\n\r\nIf i was you i'd use 'auto' for sure-cases, where you know that nothing inside will stretch or shrink. In cases where that can happen, better measure out yourself using react-measure and give spring proper values instead of auto.\r\n\r\nPS. i made a lib myself that's prone to little hickups: https://github.com/drcmda/react-animated-tree\r\nYou can see it if you open something within and then open/collapse on the parent real quick. To reduce the impact i made the animations quicker and gave it a minimal threshold so that the animation completes with less precision:\r\n\r\n```jsx\r\nconfig={{\r\n           ...config.default,\r\n            restSpeedThreshold: 1,\r\n            restDisplacementThreshold: 0.01,\r\n          }}\r\n```\r\n\r\nIf you're interested, this is the mix-in that realizes auto: https://github.com/drcmda/react-spring/blob/master/src/targets/web/fix-auto.js\r\n\r\nMaybe you can see some obvious solution in there. Like i said, it basically detects if you use auto, then renders a full frame with position set to absolute and visibility: hidden, then measures out bounds with the hellish dom api, and in a next frame tells spring the target height/width so that the animation can start.",
  "Issue title: Pass by reference in IPropertyManager38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5setProperty(string, T)\n Issue body: The code for `IPropertyManager38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5setProperty(const string&, const T)` should accept the value by reference rather than by value. This will stop a potential truncation error which may be what is breaking polymorphism.\n\n Comments: \n Comment 0: This issue was originally [trac ticket 1311](http://trac.mantidproject.org/mantid/ticket/1311)\n",
  "Issue title: Tracking issue occurs when both controllers vibrate\n Issue body: I don't know how to explain it, but whenever something occurs in-game that would cause both of my controllers to vibrate, such as using the bow and arrow, or using the climbeymotion keys to climb walls and use the jump boots, my hands dislodge and fly away from my body. As soon as I end the action that's causing the vibration, my hands snap back to where they should be, and while they're glitching out, the tracking is generally laggy and stutters, aside from the displacement.\r\n\r\nNote: I am using an Oculus Rift S, and my game is slightly modded. The mods are as follows:\r\n![image](https://user-images.githubusercontent.com/37159882/103249797-e6911580-493e-11eb-8523-fee157e2891c.png)\r\n\n Comments: \n Comment 0: Sounds like a problem with the controllers. You should contact Oculus about this. As a temporary workaround you could unbind the haptics in the SteamVR controller bindings menu.\n Comment 1: Looks like you aren't the only one with this problem.\r\nhttps://forums.oculusvr.com/community/discussion/84375/rift-s-controllers-lose-tracking-with-vibration-strong-haptic-feedback\r\nhttps://www.reddit.com/r/oculus/comments/citwkw/rift_s_controllers_lose_tracking_when_they_vibrate/\r\n\r\nThere's some seemingly magic fixes in those threads you could try. The most consistent one seems to be using a different USB port (if your motherboard has both USB 3.0 and 3.1 or something like that).\n Comment 2: Thanks so much for the swift response. Switching out the USB port fixed the issue. I'll close this issue now.",
  "Issue title: Can't instal Internet Hosting Tool\n Issue body: I'm trying to install the Internet Hosting Tool, but there is a problem in the middle of installation that says \"Service (MISS) failed to start. Verify that you have sufficient privilege to start system services.\"\r\n\r\nI'm on Windows 10 Home. I tried running as administrator with no success.\r\n\r\nThis is the log:\r\n\r\n> [248C:43D4][2022-01-20T04:18:07]i001: Burn v116.69.203.11518, Windows v10.0 (Build 19043: Service Pack 0), path: C:\\Users\\...\\AppData\\Local\\Temp\\{1B09EC0F-BD2D-44E0-9FFB-16C5EB6DA22B}\\.cr\\InternetHostingToolSetup-v5.5.2.exe\r\n[248C:43D4][2022-01-20T04:18:07]i009: Command Line: '-burn.clean.room=E:\\Users\\...\\Downloads\\InternetHostingToolSetup-v5.5.2.exe -burn.filehandle.attached=672 -burn.filehandle.self=704'\r\n[248C:43D4][2022-01-20T04:18:07]i000: Setting string variable 'WixBundleOriginalSource' to value 'E:\\Users\\...\\Downloads\\InternetHostingToolSetup-v5.5.2.exe'\r\n[248C:43D4][2022-01-20T04:18:07]i000: Setting string variable 'WixBundleOriginalSourceFolder' to value 'E:\\Users\\...\\Downloads\\'\r\n[248C:43D4][2022-01-20T04:18:07]i000: Setting string variable 'WixBundleLog' to value 'C:\\Users\\...\\AppData\\Local\\Temp\\Moonlight_Internet_Hosting_Tool_20220120041807.log'\r\n[248C:43D4][2022-01-20T04:18:07]i000: Setting string variable 'WixBundleName' to value 'Moonlight Internet Hosting Tool'\r\n[248C:43D4][2022-01-20T04:18:07]i000: Setting string variable 'WixBundleManufacturer' to value 'Moonlight Game Streaming Project'\r\n[248C:4620][2022-01-20T04:18:07]i000: Setting numeric variable 'WixStdBALanguageId' to value 1033\r\n[248C:4620][2022-01-20T04:18:07]i000: Setting version variable 'WixBundleFileVersion' to value '116.69.203.115'\r\n[248C:43D4][2022-01-20T04:18:07]i100: Detect begin, 3 packages\r\n[248C:43D4][2022-01-20T04:18:07]i000: Setting version variable 'VCREDIST_142_x86' to value '14.29.30133.0'\r\n[248C:43D4][2022-01-20T04:18:07]i052: Condition 'VCREDIST_142_x86 >= v14.28.29334' evaluates to true.\r\n[248C:43D4][2022-01-20T04:18:07]i101: Detected package: Microsoft_Visual_C___2015_2019_Redistributable___x86, state: Present, cached: None\r\n[248C:43D4][2022-01-20T04:18:07]i101: Detected package: mish, state: Absent, cached: None\r\n[248C:43D4][2022-01-20T04:18:07]i101: Detected package: GSv6FwdSetup_2.5.2.msi, state: Absent, cached: None\r\n[248C:43D4][2022-01-20T04:18:07]i199: Detect complete, result: 0x0\r\n[248C:4620][2022-01-20T04:18:08]i000: Setting numeric variable 'EulaAcceptCheckbox' to value 1\r\n[248C:43D4][2022-01-20T04:18:08]i200: Plan begin, 3 packages, action: Install\r\n[248C:43D4][2022-01-20T04:18:08]w321: Skipping dependency registration on package with no dependency providers: Microsoft_Visual_C___2015_2019_Redistributable___x86\r\n[248C:43D4][2022-01-20T04:18:08]i000: Setting string variable 'WixBundleRollbackLog_mish' to value 'C:\\Users\\...\\AppData\\Local\\Temp\\Moonlight_Internet_Hosting_Tool_20220120041807_000_mish_rollback.log'\r\n[248C:43D4][2022-01-20T04:18:08]i000: Setting string variable 'WixBundleLog_mish' to value 'C:\\Users\\...\\AppData\\Local\\Temp\\Moonlight_Internet_Hosting_Tool_20220120041807_000_mish.log'\r\n[248C:43D4][2022-01-20T04:18:08]i000: Setting string variable 'WixBundleRollbackLog_GSv6FwdSetup_2.5.2.msi' to value 'C:\\Users\\...\\AppData\\Local\\Temp\\Moonlight_Internet_Hosting_Tool_20220120041807_001_GSv6FwdSetup_2.5.2.msi_rollback.log'\r\n[248C:43D4][2022-01-20T04:18:08]i000: Setting string variable 'WixBundleLog_GSv6FwdSetup_2.5.2.msi' to value 'C:\\Users\\...\\AppData\\Local\\Temp\\Moonlight_Internet_Hosting_Tool_20220120041807_001_GSv6FwdSetup_2.5.2.msi.log'\r\n[248C:43D4][2022-01-20T04:18:08]i201: Planned package: Microsoft_Visual_C___2015_2019_Redistributable___x86, state: Present, default requested: Present, ba requested: Present, execute: None, rollback: None, cache: No, uncache: No, dependency: None\r\n[248C:43D4][2022-01-20T04:18:08]i201: Planned package: mish, state: Absent, default requested: Present, ba requested: Present, execute: Install, rollback: Uninstall, cache: Yes, uncache: No, dependency: Register\r\n[248C:43D4][2022-01-20T04:18:08]i201: Planned package: GSv6FwdSetup_2.5.2.msi, state: Absent, default requested: Present, ba requested: Present, execute: Install, rollback: Uninstall, cache: Yes, uncache: No, dependency: Register\r\n[248C:43D4][2022-01-20T04:18:08]i299: Plan complete, result: 0x0\r\n[248C:43D4][2022-01-20T04:18:08]i300: Apply begin\r\n[248C:43D4][2022-01-20T04:18:08]i010: Launching elevated engine process.\r\n[248C:43D4][2022-01-20T04:18:09]i011: Launched elevated engine process.\r\n[248C:43D4][2022-01-20T04:18:10]i012: Connected to elevated engine.\r\n[0D74:29C4][2022-01-20T04:18:10]i358: Pausing automatic updates.\r\n[0D74:29C4][2022-01-20T04:18:10]i359: Paused automatic updates.\r\n[0D74:29C4][2022-01-20T04:18:10]i360: Creating a system restore point.\r\n[0D74:29C4][2022-01-20T04:18:10]i361: Created a system restore point.\r\n[0D74:29C4][2022-01-20T04:18:10]i370: Session begin, registration key: SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\{93eb5670-efb1-4b20-9704-9956fbc2d2fd}, options: 0x7, disable resume: No\r\n",
  "Issue title: duplicate variable-definition in generated code (golang)\n Issue body: It seems that after the merge of PR #518 the variable `i` is defined multiple times (once per map-field) which results in a compiler error.\r\nHere's the line causing the issue: https://github.com/envoyproxy/protoc-gen-validate/pull/518/files#diff-f8225a1531f2fe61141b5466d79ef77ce6910263343191fe1f4c6fdc0ef9035fR41\r\n\r\nHere's a sample of the generated code:\r\n```golang\r\nfunc (m *ErrorCounter) validate(all bool) error {\r\n\tsorted_keys := make([]string, len(m.GetCounts()))\r\n\ti := 0\r\n\t//...\r\n\r\n\tsorted_keys := make([]string, len(m.GetComponents()))\r\n\ti := 0\r\n        //...\r\n```\r\n\r\n@akonradi can you confirm this issue?\n Comments: \n Comment 0: Looks like when I added the sorting, I forgot to put the definitions for\nthose temporaries inside local scopes. The fix should be simple, I'll have\nit out in a few hours.\n\n-Alex\n\nOn Mon, Sep 27, 2021, 4:51 AM Florian Purchess ***@***.***>\nwrote:\n\n> It seems that after the merge of PR #518\n> <https://github.com/envoyproxy/protoc-gen-validate/pull/518> the variable\n> i is defined multiple times (once per map-field) which results in a\n> compiler error.\n> Here's the line causing the issue:\n> https://github.com/envoyproxy/protoc-gen-validate/pull/518/files#diff-f8225a1531f2fe61141b5466d79ef77ce6910263343191fe1f4c6fdc0ef9035fR41\n>\n> Here's a sample of the generated code:\n>\n> func (m *ErrorCounter) validate(all bool) error {\n> \tsorted_keys := make([]string, len(m.GetCounts()))\n> \ti := 0\n> \t//...\n>\n> \tsorted_keys := make([]string, len(m.GetComponents()))\n> \ti := 0\n>         //...\n>\n> @akonradi <https://github.com/akonradi> can you confirm this issue?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/envoyproxy/protoc-gen-validate/issues/521>, or\n> unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAWWJKDI3OQYURKRXUDKKI3UEAWALANCNFSM5E2ANLOQ>\n>.\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n>\n\n Comment 1: @akonradi thanks for your super quick response!",
  "Issue title: Native epoll transport should honor AUTO_READ flag\n Issue body: ### Expected behavior\r\nData should only be read when requested, if AUTO_READ option is set to false  \r\n### Actual behavior\r\nWhen using Epoll transport, netty calls handler's channelRead0 without requesting read, even if AUTO_READ option is set to false. NIO Transport on the other hand works as expected.\r\nThis could be a problem if you are acting as a proxy. \r\n### Steps to reproduce\r\nThis is reproducible using small sized data I could reproduce it starting from 1 byte till 150k. Client must close connection as soon as done writing. Here are some settings I used.\r\n\r\n1) SO_RCVBUF option was not set, although setting it didn't help.\r\n2) AUTO_READ false\r\n3) TCP_NODELAY false\r\n4) SO_REUSEADDR true \r\n5) cat /proc/sys/net/ipv4/tcp_rmem\r\n4096\t87380\t6291456\r\n6) /proc/sys/net/ipv4/tcp_wmem\r\n4096\t16384\t4194304\r\n\r\nThis could help generating test data quickly:\r\ncp some_large_file 10k_file\r\ntruncate -s 10240 10k_file\r\nnc host port < 10k_file\r\n\r\n### Netty version\r\n4.1.6.Final\r\n### JVM version \r\njava version \"1.8.0_65\"\r\nJava(TM) SE Runtime Environment (build 1.8.0_65-b17)\r\nJava HotSpot(TM) 64-Bit Server VM (build 25.65-b01, mixed mode)\r\n### OS version \r\nLinux 4.8.15-300.fc25.x86_64 \r\nx86_64 x86_64 x86_64 GNU/Linux\r\n\n Comments: \n Comment 0: may be you should use Epoll level trigger, default Epoll Mode is edge trigger,  [see this](https://github.com/netty/netty/blob/4.1/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollChannelConfig.java#L127)\n Comment 1: Setting LEVEL_TRIGGERED bootstrap option did not help. \n Comment 2: > Client must close connection as soon as done writing.\r\n\r\nIIRC if we get a EPOLLRDHUP then we must read until we get a socket error for stream sockets [1] while in ET mode as we may not be notified of activity on that FD again. This may not be necessary in LT mode, and especially if NIO transport is still able to deliver all data. I will need to investigate more.\r\n\r\n[1] https://github.com/netty/netty/blob/4.1/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollRecvByteAllocatorHandle.java#L57",
  "Issue title: fold_map_collect\n Issue body: Would something like a `fold_map_collect` be of interest for inclusion into itertools?\r\n\r\n```rust\r\ntrait IteratorExt: Iterator {\r\n    fn fold_map_collect<C, B, M, F>(self, init: B, mut f: F) -> (B, C)\r\n    where\r\n        F: FnMut(B, Sel38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5Item) -> (B, M),\r\n        C: Default + Extend<M>,\r\n        Self: Sized,\r\n    {\r\n        let mut c = <C as Default>38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5ult();\r\n        let mut init = init;\r\n        match self.size_hint() {\r\n            (_, Some(upper)) => c.extend_reserve(upper),\r\n            (lower, None) => c.extend_reserve(lower),\r\n        }\r\n        for item in self {\r\n            let (new_init, mapped) = f(init, item);\r\n            init = new_init;\r\n            c.extend_one(mapped);\r\n        }\r\n        (init, c)\r\n    }\r\n}\r\n\r\nimpl<T: Iterator> IteratorExt for T {}\r\n```\r\n\r\nExample usage:\r\n\r\n```rust\r\nlet (width, grid) =\r\n    st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5io38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5stdin()\r\n       .lock()\r\n       .lines()\r\n       .fold_map_collect(0usize, |max_width, line| {\r\n            let (line_width, line) = line.unwrap().chars().enumerate().fold(\r\n                (0usize, 0u64), // (character count, encoded line)\r\n                |(count, line), (idx, chr)| {\r\n                    (\r\n                        count + 1,\r\n                        match chr {\r\n                            '.' => line,\r\n                            '#' => line | (1u64 << idx),\r\n                            _ => panic!(\"invalid grid line\"),\r\n                        },\r\n                    )\r\n                },\r\n            );\r\n            (cmp38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5max(line_width, max_width), line)\r\n        });\r\n```\r\n\r\nThe name is bikesheddable.\n Comments: \n Comment 0: My default instinct here is that combining this many different things is the wrong way to go.\r\n\r\nThis gives me a big of a `scan` vibe?  Is there a way to make an additional accessor on that?  Or a different kind of adapter that doesn't need to include the `collect` stuff too?\n Comment 1: > This gives me a big of a scan vibe? Is there a way to make an additional accessor on that?\r\n\r\nYou mean something like `scanl 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 (a -> b -> a) -> a -> [b] -> [a]`? That wouldn't work because I need both the accumulator *and* mapped items returned. Both types might differ so it also not possible to just add the accumulator into the returned list.\r\n\r\n> Or a different kind of adapter that doesn't need to include the collect stuff too?\r\n\r\nI have though about this but can't find a way because fold and map are quite \u201cdifferent\u201d in terms of execution (lazy and eager evaluation. This pattern requires eager evaluation though).`std` does include `unzip` but using that isn't \"zero-cost\" (because then I'd have to store the fold values for each entry and then stored them in a container, followed by the operation i want to do, eg. `max`).\r\n\r\nI mean another thing you can do is just introduce a local and update the local each time you are trying to do your fold computation. But perhaps this is the more elegant solution to do this? (That would be unsatisfying.)\n Comment 2: Can't you just use an external variable with `map` and `collect`?\r\n\r\n```rust\r\nlet mut max_width = 0usize;\r\nlet grid =\r\n    st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5io38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5stdin()\r\n       .lock()\r\n       .lines()\r\n       .map(|line| {\r\n            let (line_width, line) = line.unwrap().chars().enumerate().fold(\r\n                (0usize, 0u64), // (character count, encoded line)\r\n                |(count, line), (idx, chr)| {\r\n                    (\r\n                        count + 1,\r\n                        match chr {\r\n                            '.' => line,\r\n                            '#' => line | (1u64 << idx),\r\n                            _ => panic!(\"invalid grid line\"),\r\n                        },\r\n                    )\r\n                },\r\n            );\r\n            max_width = cmp38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5max(line_width, max_width);\r\n            line\r\n        })\r\n       .collect();\r\n```\n Comment 3: @SkiFire13 Well, yeh that would be possible, but I thought it would be nice to avoid state mutation ala Iterator38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5old, but I guess this is such a niche case, it\u2019d be much more readable with state mutation.",
  "Issue title: (node) warning: possible EventEmitter memory leak detected. 11 listeners added. Use emitter.setMaxListeners() to increase limit.\n Issue body: Hi,\n\nI am using Pool node-mysql 2.5.4 with express.js to query a database with connectionLimit=10.\n\nand when I get around 12-16 connections (checking using ''netstat -an | grep 116.69.203.115._3306._ESTABLISHED | wc -l\") when many clients are connected, I get this message: \"(node) warning: possible EventEmitter memory leak detected. 11 listeners added. Use emitter.setMaxListeners() to increase limit.\". I have set req.setMaxListeners(0); ( http://nodejs.org/docs/latest/api/events.html#events_emitter_setmaxlisteners_n) in express request method, but still no effect.\n\nI have three questions:\n1. with connectionLimit=10, what is truly means? Does it limit the no. of current sessions to 10 max? That doesn't seem to be the case, because I see 12-16 connections on port 3306 (sometimes 18)\n1. also, what is the recommended connectionLimit?\n2. Is there a way to avoid that warning message?\n\nThanks\n\n Comments: \n Comment 0: Can you point to what line in the source of this module is generating that message?\n Comment 1: Here is the trace...  i think its the line: /apps/clink-prod/clink/ndt/node_modules/mysql/lib/protocol/Protocol.js:271:23\r\n\r\n(node) warning: possible EventEmitter memory leak detected. 11 listeners added. Use emitter.setMaxListeners() to increase limit.\r\nTrace\r\n    at Pool.addListener (events.js:160:15)\r\n    at MySqlClient.runQry (/apps/clink-prod/clink/ndt/modules/mysql_client.js:63:15)\r\n    at MySqlClient.getBundleNameByAssocIntfId [as getIntfBundleAssoc] (/apps/clink-prod/clink/ndt/modules/mysql_client.js:155:10)\r\n    at /apps/clink-prod/clink/ndt/nwmap/app.js:229:19\r\n    at runQryCb (/apps/clink-prod/clink/ndt/modules/mysql_client.js:104:20)\r\n    at Query._callback (/apps/clink-prod/clink/ndt/modules/mysql_client.js:79:20)\r\n    at Query.Sequence.end (/apps/clink-prod/clink/ndt/node_modules/mysql/lib/protocol/sequences/Sequence.js:96:24)\r\n    at Query._handleFinalResultPacket (/apps/clink-prod/clink/ndt/node_modules/mysql/lib/protocol/sequences/Query.js:143:8)\r\n    at Query.EofPacket (/apps/clink-prod/clink/ndt/node_modules/mysql/lib/protocol/sequences/Query.js:127:8)\r\n    at Protocol._parsePacket (/apps/clink-prod/clink/ndt/node_modules/mysql/lib/protocol/Protocol.js:271:23)\r\n\r\n\n Comment 2: Your trace shows it's caused by whatever code you have at /apps/clink-prod/clink/ndt/modules/mysql_client.js:63:15\n Comment 3: well, thats just the beginning trace... i don't have anything related to eventemitter in my code. i am just calling mysql lib in express.js, but not closing the pool ever. may be due to that?\n\n Comment 4: Van you paste that file of yours I referenced?\n\n Comment 5: In think its this line...\r\n```javascript\r\n    this.pool.on('enqueue', function () {\r\n```\r\n\r\nI have removed some company specific stuff from the code, but here is the generic code...\r\n\r\n```javascript\r\n/**\r\n * mysql_client\r\n */\r\n\r\n// Import modules\r\nvar mysql = require('mysql');\r\nvar path = require('path');\r\nvar fs = require('fs');\r\nvar async = require('async');\r\n\r\n// Export module with Namespace\r\nvar mysqlc = exports;\r\n\r\n// Constants\r\nvar DEFAULT_MYSQL_PORT = 3306;\r\nvar DEFAULT_AUTOCOMMIT = false;\r\nvar DEFAULT_CONNLIMIT = 10;\r\n\r\n/**\r\n * MySQL Class Wrapper\r\n * @param {string} user: user of database account\r\n * @param {string} password: password for database account\r\n * @param {string} database: database name\r\n * @param {string} host: hostname of server\r\n * @param {string} port: port of server\r\n * @param {boolean} autocommit: autocommit\r\n * @return {object} object\r\n */\r\nmysqlc.MySqlClient = function MySqlClient(connProp) {\r\n    \"use strict\";\r\n    this.user = connProp.user;\r\n    this.password = connProp.password;\r\n    this.database = connProp.database;\r\n    this.host = connProp.host;\r\n    this.port = connProp.port || DEFAULT_MYSQL_PORT;\r\n    this.autocommit = connProp.autocommit || DEFAULT_AUTOCOMMIT;\r\n    this.connectionLimit = connProp.connectionLimit || DEFAULT_CONNLIMIT\r\n    this.pool = null;\r\n    \r\n    this.connProp = {\r\n            connectionLimit : this.connectionLimit,\r\n            host            : this.host,\r\n            port            : this.port,\r\n            user            : this.user,\r\n            password        : this.password,\r\n            database        : this.database\r\n    };\r\n}\r\n\r\n\r\nmysqlc.MySqlClient.prototype.runQry = function runQry(qry, args, callback) {\r\n    this.pool.on('enqueue', function () {\r\n        console.error('runQry-Waiting for available connection slot-ERROR');\r\n        return callback('pool-not-empty');\r\n    });\r\n    console.log('running mysql qry:', qry);\r\n    this.pool.getConnection(function(err, connection) {\r\n        if (err) {\r\n            console.error('runQry-cannot getConnection ERROR:', err);\r\n            return callback(err);\r\n        }\r\n        connection.query(qry, args, function(err, rows) {\r\n            if (err) {\r\n                console.error('runQry-cannot run qry ERROR:', err);\r\n                return callback(err);\r\n            }\r\n            connection.release();\r\n            return callback(null, rows);\r\n        });\r\n    });\r\n};\r\n\r\nmysqlc.MySqlClient.prototype.connect = function connect(callback) {\r\n    var pool = mysql.createPool(this.connProp);\r\n    this.pool = pool;\r\n    \r\n    // verify connection\r\n    pool.getConnection(function(err, connection) {\r\n        console.log('connecting mysql');\r\n        if (err) {\r\n            console.error('ERROR connecting to mysql server with connProp:', this.connProp);\r\n            return callback(err);\r\n        }\r\n        connection.release();\r\n        return callback(null);\r\n    });\r\n};\r\n\r\nmysqlc.MySqlClient.prototype.disconnect = function disconnect(callback) {\r\n    var pool = this.pool;\r\n    pool.getConnection(function(err, connection) {\r\n        console.log('disconnecting mysql');\r\n        if (err) {\r\n            console.error('ERROR disconnecting to mysql server with connProp:', this.connProp);\r\n            return callback(err);\r\n        }\r\n        connection.release();\r\n        pool.end();\r\n        return callback(null);\r\n    });\r\n}\r\n\r\n```\n Comment 6: Thanks! So the bug is in your code there. Every call made to runQry has the same pool (this is fine), but you add a listener on it every time. You only need to make 11 calls and you get that warning. You just need to stop adding the same listener over and over again.\r\n\r\nIn fact, it seems like all you're trying to do is make it an error for getConnect to queue; there is an option that will do this for you.\n Comment 7: oh.. that makes sense.. in that case, i should simply add the enqueue listener in connect function. thanks a lot :+1: \n Comment 8: No problem!\n",
  "Issue title: BibUpload: --append only new fields\n Issue body: Originally on 2013-03-28\n\nIn most typical scenarios it is practically unseen that a record has two identical metadata fields. \n\nIn order to simplify workflows where some fields are being `--append`ed it is proposed to add a new flag (e.g. `--only-new-fields`) e.g. to BibUpload CLI that will ensure only new fields (i.e. fields that have at least a difference in a given subfield) are going to be appended.\n\nTwo fields are considered identical if their sorted subfields are identical one-by-one.\n\n Comments: \n Comment 0: Originally on 2014-01-06\n\nI think it can be generally useful to have a check for duplicated fields and not allow them unless an option `--allow-duplicated-fields` has been specified.  Even for non-append modes.  Though such a check would take some extra time, so perhaps make it the other way round via an optional `--ignore-duplicated-fields` that would trigger the check.\n\n Comment 1: Originally on 2014-01-29\n\nSo in principle, if a workflow generates duplicate fields via `replace`/`correct`/`insert`, then IMHO it's really broken :-)\n\nOn the other hand it's very complex to implement a workflow that uses `append` and avoids creating duplicate fields.\n\nSince creating duplicate fields is really a non-feature\u2122 I think I'm going to simply perform the check just during append mode.\n\n Comment 2: Originally on 2014-01-29\n\nAvailable at [sam/1440-bibupload-no-duplicate](http://invenio-software.org/repo/personal/invenio-sam/log/?h=1440-bibupload-no-duplicate).\n\n Comment 3: Originally on 2014-01-30\n\nOK, this should do for the vast majority of use cases indeed.\n\n Comment 4: Originally on 2014-01-30\n\nIn c22accb7d80dfaf84127cff458b1bfb739861635:\n\n```\n#CommitTicketReference repository=\"invenio\" revision=\"c22accb7d80dfaf84127cff458b1bfb739861635\"\nBibUpload: --append only new fields\n\n- When bibupload --append mode is used never create\n  duplicate fields. Two fields are considered identical\n  if they have the same indicators and exactly the same\n  subfields in the same order.\n  (closes #1440)\n\nReported-by: Florian Schwennsen <jelliott@example.net>\nSigned-off-by: Samuele Kaplun <jelliott@example.net>\nTested-by: Tibor Simko <jelliott@example.net>\n```\n",
  "Issue title: Notes on Compact Block getdata fallback responses\n Issue body: This came up at a meeting a while back, but I realized it was never materially written down anywhere.\r\n\r\nCompact Block high-bandwidth processing can fall back to getdatas when the client belives a short id collision may have occurred (among a few other cases). In such cases, we are required to wait until we have verified the full block before we can respond to the getdata request (hence the few awkward ActivateBestChain calls in net_processing). However, in case we find the block to be invalid (or decide its actually not our best-chain-candidate due to some race receiving another block in parallel) we will simply leave the getdata unresponded to. This will result in us eventually getting disconnected for stalling.\r\n\r\nIt is important to note that, were an attacker able to generate a block which, when relayed, would cause getdata fallbacks on an invalid block, such an attacker would be able to cause massive disconnections across the network, especially targeting mining nodes or other nodes which receive blocks particularly fastly. I do not believe such creation is currently possible, but definitely could be bad if we did something dumb like fixing the nonce in the future.\r\n\r\nDuring the meeting we discussed using the existing NOTFOUND message for block requests as well, which seemed to have some level of support (or a BLOCK_NOTFOUND or whathaveyou) and using that to allow peers to simply reject providing a block without being disconnected as a staller.\n Comments: \n Comment 0: It appears this might still be a potential issue in 24.0rc1 and master.\r\n\r\nIIUC when node A detects a short id collision on a compact block it will request the full block from node B with a `getdata`:\r\n\r\nhttps://github.com/bitcoin/bitcoin/blob/def75f0fb51b2d2d54cd4d772cf54d45b0fa5ae8/src/net_processing.cpp#L4195-L4201\r\n\r\n If node B has in the meantime determined that block to be invalid after validation (or re-orged it) then the following clause will execute causing node B to never respond to the `getdata` request for the block:\r\n\r\nhttps://github.com/bitcoin/bitcoin/blob/def75f0fb51b2d2d54cd4d772cf54d45b0fa5ae8/src/net_processing.cpp#L2106-L2109\r\n\r\nOne thing that is not immediately clear to me is where node A marks B for disconnection in the case a `getdata` is not responded to; is this still how the P2P protocol works internally?\r\n\r\nIf the disconnection is still a prospect, it does seem that using the `NOTFOUND` message is the approach that makes the most sense, and avoids having to add a new message.",
  "Issue title: catkin build issue on raspberry pi 4\n Issue body: Hi, i have a problem on Raspberry Pi4 4 G RAM  trying to follow this tutorial https://ros-planning.github.io/moveit_tutorials/doc/getting_started/getting_started.htm i get to the Build your catkin workspace and at the execution of :\r\n$catkin build \r\neverything is hungs out on make 14% of moveit_tutorials, not only terminal, but Raspberry is not reacting on anything, so i have to powerdown it not really greacefuly.\r\nAny idea what could be a problem?\r\n\r\n* Operating System: `ubuntu 18.04 bionic 64bit (installed image), but the uname -a show Linux ubuntu 4.19.83-22 aarch64`\r\n* Python Version: 2.7.15+\r\n* Version of catkin_tools: catkin_tools 0.4.5\r\n* ROS Distro: `melodic`\n Comments: \n Comment 0: This is not a problem with `catkin_tools`.\r\n\r\nThe Pi just doesn't have the resources to compile something as extensive as MoveIt with anything more than a single job. It would fail with a regular parallel `make` build as well.\r\n\r\nAdd `-j1` to your `catkin build` invocation and enable swap. That should give you a chance to build MoveIt successfully.\r\n\r\nPlease note that there should be binary packages for MoveIt provided for Ubuntu Bionic by the ROS buildfarm. That would remove the need to build things from source.\r\n\n Comment 1: Thanks a lot for the suggestion, setting the swap to 2 Gb and putting -j1 as a parameter make it work.",
  "Issue title: Add Two Factor Auth\n Issue body: #### :rotating_light: MIGRATED FROM REQUESTS.GETDIRECTUS.COM :rotating_light: \r\n\r\n\r\n\r\n# Two Factor Auth Option\r\n### :+1: = 1\r\n*Created 5 months ago by @benhaynes*\r\n \r\n\r\n\r\n-----\r\n### @benhaynes \u2013 :+1: (5 months ago)\r\nIn 7.x\r\n\r\n\n Comments: \n Comment 0: This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n",
  "Issue title: [Feature] [Deeprun Tram] Weird Behavior\n Issue body: The deeprun tram movement starts to the opposite side and than bounces back to the correct side. If you are in the \"first\" node (the one closest to your destination) you will be moved back to the last-node place and hit the wall, staying at same city you were. It's REALLY hard to explain, better someone go see it for yourself.\n3 \"nodes\" (i.e seats) leave Stormwind and only 2 arrive to ironforge (the object itself, is missing).\nBasically, the entire train is messed up!\n\nAlso noticed that only 1 train is active instead of 2. the other train just moves out of the map.\n\nspecial thanks goes to Malcret for pointing out on this issue\n\n Comments: \n Comment 0: i fixed it\n",
  "Issue title: Is it possible to transfer proxy to another vds without secret change?\n Issue body: Hello. Is it possible to transfer proxy to another vds without secret change?\n Comments: \n Comment 0: Yes. I migrate every day. With tha same -p  -H -S -P keys it will be completely identical. You also do not need register new host in the MTProxy Admin Bot. Just set -P key value and enjoy. ",
  "Issue title: Cloud Run support\n Issue body: <!--- Please leave this line, it helps our automation: [issue-type:enhancement] --->\r\n<!--- Please keep this note for the community --->\r\n\r\n### Community Note\r\n\r\n* Please vote on this issue by adding a \ud83d\udc4d [reaction](https://blog.github.com/2016-03-10-add-reactions-to-pull-requests-issues-and-comments/) to the original issue to help the community and maintainers prioritize this request\r\n* Please do not leave \"+1\" or \"me too\" comments, they generate extra noise for issue followers and do not help prioritize the request\r\n* If you are interested in working on this issue or have submitted a pull request, please leave a comment. If the issue is assigned to the \"modular-magician\" user, it is either in the process of being autogenerated, or is planned to be autogenerated soon. If the issue is assigned to a user, that user is claiming responsibility for the issue. If the issue is assigned to \"hashibot\", a community member has claimed the issue already.\r\n\r\n<!--- Thank you for keeping this note for the community --->\r\n\r\n### Description\r\n\r\nIs there a plan to implement GCP's new \"cloud run\" functionality? \r\n\r\n### New or Affected Resource(s)\r\n\r\n<!--- Please list the new or affected resources and data sources. --->\r\n\r\n* google_cloud_run\r\n\r\n### Potential Terraform Configuration\r\n\r\n<!--- Information about code formatting: https://help.github.com/articles/basic-writing-and-formatting-syntax/#quoting-code --->\r\n\r\n```tf\r\n# Propose what you think the configuration to take advantage of this feature should look like.\r\n# We may not use it verbatim, but it's helpful in understanding your intent.\r\nresource \"google_cloud_run\" \"example\" {\r\n  container    = \"us.gcr.io/project/service@sha256:fff\"\r\n  service_name = \"some-service\"\r\n}\r\n```\r\n\r\n\n Comments: \n Comment 0: also: i would be happy to attempt implementing this \n Comment 1: we are always open to community contributions! as a side note, we generally are trying to develop new resources via our autogeneration repo, https://github.com/GoogleCloudPlatform/magic-modules\n Comment 2: @emilymye thank you! started working on PR here: https://github.com/GoogleCloudPlatform/magic-modules/pull/1643\n Comment 3: @emilymye I'm currently stuck on the API calls to the Cloud Run REST API. they are all returning 400, even simple GET/list operations. Googling did not yield anything helpful. I even tried setting the default region for my project. Here's the comment: https://github.com/GoogleCloudPlatform/magic-modules/pull/1643#issuecomment-483665744 any thoughts on this, or where i can go for help with this? \n Comment 4: @quinn My understanding is that the `namespaces.*` endpoints listed are a side effect of the object model that CloudRun is built on and they are not actually valid or updatable resources. The `projects.locations.*` endpoints should have the real resources. I have been told there is work in progress to get those removed from the docs.\r\n\r\nThat being said the `locations.services` object is unfortunately much more complex than the namespaces one. Thank you for tackling this, but we've been building tools to generate the api definition from complex upstream discovery docs so I can take this over from here.\n Comment 5: @chrisst thanks for the update! looking forward to this being available \n Comment 6: What is the current ETA/current progress on this module? Thoroughly looking forward to integrating with this! @chrisst\n Comment 7: I've implemented this locally. Happy to help whoever is working on PR for this.\n Comment 8: Quick update on this. I've been talking with the Cloud Run team and have found that while the Cloud Run product is in `beta` our support of it would required using `alpha` KNative apis. Part of the proposal for the KNative `v1beta1` is an overhaul of the object structure that the API will accept, for more details check out [KNative's latest release](https://github.com/knative/serving/releases/tag/v0.6.0) which explains the beta proposal.\r\n\r\nWe do not want to release a Terraform resource that will have to change within months of its release or one that relies on alpha apis that are still stabilizing. Additionally we strive to not introduce intentional breaking changes to our `beta` provider. So we have decided to wait until the API hits `v1beta1` before releasing official support for Cloud Run. This should be happening soon, but feel free to track https://github.com/knative/serving for more precision. \r\n\r\nThe code in the linked PR is currently functional and tested against the `alpha` APIs so those who are interested are welcome to pull it locally and use it to prototype or build against. Once `v1beta1` is available I'll be updating the resource but hopefully it will remain very similar.\n Comment 9: @chrisst, is the new 0.7.0 release of KNative/serving the one we've been waiting for? It looks like `v1beta1` APIs are present now \ud83d\ude04  \r\n\r\nhttps://github.com/knative/serving/releases/tag/v0.7.0\n Comment 10: @sheepsteak yup that's the one! Once the Cloud Run API's migrate to the `v1beta1` Knative APIs then we'll be able to launch Terraform support.\n Comment 11: The cloudrun REST API hasn't been released at `v1beta1` yet, however they have updated the `v1alpha1` endpoints to accept and respond with the beta object models. I've updated our mappings to use those so it looks and feels \"beta-y\" even though it's using alpha endpoints under the hood. I don't have an estimate for when the beta endpoints will ship but I've been told the models _shouldn't_ be changing between now and then. \r\nGiven the above I'm planning on shipping the Terraform support for this in the next release and I'm calling it a \"betpha\" so use with good judgement. We will update the resource when the beta apis ship.\n Comment 12: With the initial release of `google_cloud_run_service` resource type, there seems to be a few things still missing and I'm wondering if this is a Terraform module limit or API limit. Two I've hit are assigning service account and IAM roles. Am I just missing something here?\n Comment 13: I'm going to lock this issue because it has been closed for _30 days_ \u23f3. This helps our maintainers find and focus on the active issues.\n\nIf you feel this issue should be reopened, we encourage creating a new issue linking back to this one for added context. If you feel I made an error \ud83e\udd16 \ud83d\ude49 , please reach out to my human friends \ud83d\udc49  bfriedman@example.com. Thanks!\n",
  "Issue title: Plugin Java package names should adhere to Java package naming convention\n Issue body: Namely, we should remove the underscores (which are only recommended as workarounds to special cases, such as avoiding reserved words).\r\n\r\nhttps://docs.oracle.com/javase/tutorial/java/package/namingpkgs.html\r\n\r\nThis is the Java equivalent of https://github.com/flutter/flutter/issues/10073\r\n\r\n@mravn-google @goderbauer @collinjackson \n Comments: \n Comment 0: Underscores are also used instead of hyphens, which is the rule we're following. We could remove them, but I prefer leaving it up to the user.\n Comment 1: That's only recommended when you're required to do so to avoid a hyphen that exists in your internet domain or a leading number or the like.  By default, they recommend using all lowercase with no underscores -- the list of examples in the [Java 8 spec](http://docs.oracle.com/javase/specs/jls/se8/html/jls-6.html#jls-6.1) shows this:\r\n\r\n```\r\ncom.nighthacks.java.jag.scrabble\r\norg.openjdk.tools.compiler\r\nnet.jcip.annotations\r\nedu.cmu.cs.bovik.cheese\r\ngov.whitehouse.socks.mousefinder\r\n```\r\n\r\nI agree that this isn't imperative, but why not publish idiomatic Java?  I think not doing so causes Java developers to give pause (if only for a second), and not in a good way.  e.g. internally in Google, they explicitly call out that underscores are not allowed in package names in their [style guide](http://goto.google.com/java-package-names).\n Comment 2: Please e-mail flutter-dev warning about this change a little while before landing it. Please ask for feedback saying whether it's going to be a problem.\n Comment 3: Removing the underscores from package names in the new project / new plugin templates seems like an easy win because it has no effect on existing apps. We already did this for internal plugins and TBH it was kind of annoying to remember when to remove underscores and when to keep them, but I can see the advantages of being idiomatic.\r\n\r\nHopefully existing plugins can be converted over without breaking anyone if they don't expose any public APIs that clients are supposed to call.\r\n\r\nAgree that we should give flutter-dev a heads up before making the change.\n Comment 4: https://groups.google.com/forum/#!topic/flutter-dev/52UuFHCDLMA\n Comment 5: I did not see any issues raised on Todd's post. @tvolkert @collinjackson either of you looking at this refactoring?\n Comment 6: Seems like we should go ahead with it. @tvolkert did you want to take this one?\n Comment 7: Yep\n Comment 8: This thread has been automatically locked since there has not been any recent activity after it was closed. If you are still experiencing a similar issue, please open a new bug, including the output of `flutter doctor -v` and a minimal reproduction of the issue.",
  "Issue title: add more products to e2e fixtures data.\n Issue body: add more products to e2e fixtures data.\n\n---\nhttps://github.com/woocommerce/woocommerce-gutenberg-products-block/blob/9b71de027f5251c26b87071f39c390163c5cb48b/tests/e2e-tests/fixtures/fixture-loaders.js#L108-L119\n---\n###### :rocket: This issue was generated by the [automations bot](https://github.com/woocommerce/automations) based on a `todo` comment in 9b71de027f5251c26b87071f39c390163c5cb48b when #2548 was merged. cc @senadir\n Comments: \n Comment 0: This issue has been marked as `stale` because it has not seen any activity within the past 60 days. Remove the `stale` label or post a comment, otherwise it will be closed in 10 days.\n Comment 1: This issue has been marked as `stale` because it has not seen any activity within the past 60 days. Our team uses this tool to help surface issues for review. If you are the author of the issue there's no need to comment as it will be looked at. \n\n###### Internal: After 10 days with no activity this issue will be automatically be closed.\n Comment 2: Not very tangible issues, we will add more products when we need them in other tests.",
  "Issue title: R48 introduced regression in expr for YUV420P8 clips\n Issue body: I've run into a bug with R48 that seems to trace back to expr. Essentially, expr produces a green clip, instead of black and white, for YUV420 clips. The bit-depth of the clip doesn't seem to matter.\r\n\r\nThe following script can reproduce it on my ubuntu18.04 machine using an AMD Phenom 1090t. Either uncommenting the SetMaxCPU or switching to the default (RGB) clip produces a black clip. Otherwise the output is green:\r\n\r\n```\r\nimport vapoursynth as vs\r\ncore = vs.get_core()\r\n#core.std.SetMaxCPU(\"none\")\r\n\r\n#clp  = core.std.BlankClip()\r\nclp  = core.std.BlankClip(format=vs.YUV420P8)\r\nclp1 = clp\r\n\r\nexpr = 'x 3 + y < x 3 + x 3 - y > x 3 - y??'\r\nclp = core.std.Expr([clp1, clp], expr=[expr])\r\n\r\nclp.set_output()\r\n```\r\nThis results in corrupt output for QTGMC, as expr is used to process the input for motion compensation functions. Thanks to HolyWu, I can work around it by setting core.std.SetMaxCPU(\"none\"). I did not have this issue with R47.2, and can also work around by rolling back.\r\n\r\nLet me know if I can provide anything else to assist in debugging.\n Comments: \n Comment 0: I can't reproduce. Does this happen on other CPUs?\n Comment 1: Also can't reproduce it here using vdub2 to view the output.\n Comment 2: I attempted to run VMs on virtualbox with different cpu_profiles to emulate other CPUs without success, meaning the VMs won't load.\r\n\r\nIs there anything else I can provide you folks with to assist in debugging?\r\n\r\nIs this a case of an older CPU introducing irregularities?\n Comment 3: Do you not have access to any other CPUs than Phenom? For example, Core 2, i3;/5/7, etc. And are you using a 32-bit or 64-bit build?\n Comment 4: Reproduced on x64 kubuntu running in a VM.\n Comment 5: @chriskretler more details please, reproduction is really spurious\n Comment 6: @myrsloik I'm happy to provide more. Do you want environmental information, or more information on the test case?\n Comment 7: The following steps can assist in reproducing the issue and ultimately fixing it:\r\n\r\n(1) Sharing your VapourSynth binary (libvapoursynth.so). Please share unstripped binaries.\r\n(2) If unsuccessful, we may need remote access to your computer to reproduce the issue.\n Comment 8: The requested file can be found here:\r\nhttps://www.dropbox.com/s/nkvnlti0oztj3ff/libvapoursynth.so?dl=0\r\n\r\nFor what it's worth, I can create an environment that reproduces the error via the vagrant environment as defined here:\r\n\r\nhttps://github.com/chriskretler/vsynth-env-provisioning\r\n\r\n\n Comment 9: I tried to use your binary but still could not reproduce on my system.\n Comment 10: Arggh, you're right. That was a 47.2 binary.\r\n\r\nI've rebuilt R48 and uploaded the binary to dropbox. It is available via the same link.\n Comment 11: I tried with the new binary. It is R48, but I still can't reproduce the issue. I ran the script in the OP and the chroma planes are 0x80 as one would expect.\n Comment 12: Given that setting:\r\n\r\ncore.std.SetMaxCPU(\"none\")\r\n\r\neliminates the issue for me, I'm comfortable assuming I am seeing this due to my older CPU.\r\n\r\nOne last question: what version of zimg are you running?\n Comment 13: I used the Git master of zimg, but it is not relevant to your script, since only BlankClip and Expr are invoked. Even if the issue is specific to your CPU, we do want to understand the root cause. Does the green clip reproduce 100% for you?\n Comment 14: Ahah, found the bug. Fix is checked into master.\n Comment 15: That's great news sekrit. Thank you for sticking with it.\n Comment 16: I will test soon.\n Comment 17: Confirmed fixed in master. Thank you for your diligence sekrit.",
  "Issue title: this is the original week 7 source\n Issue body: not joking this time here is:\r\nhttps://app.mediafire.com/2zapi57wt4r65\n Comments: \n Comment 0: Hey bro this is PC games \n Comment 1: Can you upload this file in mega? I doin't have mediafire pro\n Comment 2: Ok\n Comment 3: @Kffwlp\r\nThis will take too long but ok\n Comment 4: > @kffwlp\r\n> This will take too long but ok\r\nSorry bro error upload week7\r\n",
  "Issue title: \u5173\u4e8e \u5934\u50cf\u548c\u6635\u79f0 \u5237\u65b0\u540e \u4e0d\u663e\u793a\u7684\u4e00\u70b9\u7591\u95ee\n Issue body: \u4f60\u597d\uff0c\u6211\u662f\u540e\u7aef\u7684\u7ae5\u978b\uff0c\u5bf9\u524d\u7aef\u4e0d\u662f\u5f88\u4e86\u89e3\uff0c\u671b\u591a\u5305\u6db5\u3002\r\n\u95ee\u9898\uff1a\u63a5\u53e3\u90fd\u5df2\u7ecf\u548c\u670d\u52a1\u7aef\u4ea4\u4e92\u4e86\uff0c\u5728\u767b\u5f55\u540e\u4fdd\u5b58\u4e86\u5934\u50cf\u548c\u6635\u79f0\uff0c\r\n```\r\ncommit('SET_NAME', { name: data.info.name, welcome: welcome() })\r\ncommit('SET_AVATAR', data.info.avatar)\r\n```\r\n\u7136\u540e\u5237\u65b0\u5c31\u4e0d\u663e\u793a\u4e86\uff0c\u4e4b\u524d\u4e5f\u77e5\u9053\uff0c\u8fd9\u4e2a\u95ee\u9898\u7684\u5b58\u5728\uff0c\u6240\u4ee5\u6211\u5c31\u5e72\u8106\u7528localStorage\u6765\u5b58\uff0c\u7a81\u7136\u60f3\u5230\uff0c\u89d2\u8272\u6743\u9650\u4e5f\u662f\u7528 ```commit``` \u5f62\u5f0f\u6765\u4fdd\u5b58\u7684\uff0c\u6211\u662f\u4e0d\u662f\u4e5f\u8981\u7528localStorage\u6765\u5b58\u5462\uff1f\u7591\u60d1\u7684\u662f\u6211\u770b\u6f14\u793a\u7ad9\uff0c\u767b\u5f55\u540e\u5237\u65b0\uff0c\u90fd\u662f\u6b63\u5e38\u7684\u3002\n Comments: \n Comment 0: \u91cd\u8981\u7684\u6570\u636e\uff0c\u9690\u79c1\u6570\u636e\u7b49\u3002\u4e0d\u63a8\u8350\u5f80 localStorage \u50a8\u5b58\uff0c\u5e94\u5f53\u76f4\u63a5\u653e\u5728 Vuex(\u5185\u5b58) \u4e2d\u6bd4\u8f83\u4fdd\u9669\u3002\r\n\r\n\u53e6\u5916\uff0c\u5237\u65b0\u4e0d\u80fd\u663e\u793a\uff0c\u8003\u8651\u770b\u4e00\u4e0b\u8def\u7531\u5b88\u536b\u6709\u4e00\u4e2a\u5224\u65ad\u662f\u5426\u767b\u5f55\uff0c\u6709\u767b\u5f55\u4f1a\u53bb\u8bf7\u6c42\u4e00\u6b21\u7528\u6237\u4fe1\u606f\uff0c\u91cd\u65b0\u521d\u59cb\u5316\u5230 Vuex \u3002\u5982\u679c\u4f60\u6ca1\u5bf9\u8fd9\u4e00\u5757\u5904\u7406\u4fdd\u5b58\u5934\u50cf\uff0c\u90a3\u4e48\u5237\u65b0\u540e\uff0c\u4e22\u5931\u5c31\u5c5e\u4e8e\u6b63\u5e38\u60c5\u51b5\u4e86\n Comment 1: \u8c22\u8c22\uff0c\u660e\u767d\u4e86\u3002",
  "Issue title: After Upgrade to 4.2: Unhandled rejection Error: Unknown XML-RPC tag 'H1'\n Issue body: After upgrading to 4.2, I get for one of my pools this message and all objects from this pools are missing.\r\n\r\nThe pool christinebrown@example.com (016).\r\n\r\nFollowing is the traceback:\r\n\r\nUnhandled rejection Error: Unknown XML-RPC tag 'H1'\r\n    at [object Object].Deserializer.onError (/srv/xoa/xo-server/node_modules/xen-api/node_modules/xmlrpc/lib/deserializer.js:109:20)\r\n    at [object Object].Deserializer.onClosetag (/srv/xoa/xo-server/node_modules/xen-api/node_modules/xmlrpc/lib/deserializer.js:202:14)\r\n    at Object.me._parser.(anonymous function) [as onclosetag] (/srv/xoa/xo-server/node_modules/xen-api/node_modules/xmlrpc/node_modules/sax/lib/sax.js:245:15)\r\n    at emit (/srv/xoa/xo-server/node_modules/xen-api/node_modules/xmlrpc/node_modules/sax/lib/sax.js:615:33)\r\n    at emitNode (/srv/xoa/xo-server/node_modules/xen-api/node_modules/xmlrpc/node_modules/sax/lib/sax.js:620:3)\r\n    at closeTag (/srv/xoa/xo-server/node_modules/xen-api/node_modules/xmlrpc/node_modules/sax/lib/sax.js:861:5)\r\n    at Object.write (/srv/xoa/xo-server/node_modules/xen-api/node_modules/xmlrpc/node_modules/sax/lib/sax.js:1294:29)\r\n    at SAXStream.write (/srv/xoa/xo-server/node_modules/xen-api/node_modules/xmlrpc/node_modules/sax/lib/sax.js:227:16)\r\n    at Client.<anonymous> (/srv/xoa/xo-server/node_modules/xen-api/node_modules/xmlrpc/lib/client.js:109:14)\r\n    at Client.methodCall (/srv/xoa/xo-server/node_modules/xen-api/node_modules/xmlrpc/lib/client.js:106:27)\r\n    at Client.tryCatcher (/srv/xoa/xo-server/node_modules/bluebird/js/main/util.js:24:31)\r\n    at Xapi._rawCall (/srv/xoa/xo-server/node_modules/xen-api/src/index.js:382:17)\r\n    at Xapi._transportCall (/srv/xoa/xo-server/node_modules/xen-api/src/index.js:350:17)\r\n    at Async._schedule (/srv/xoa/xo-server/node_modules/bluebird/js/main/schedule.js:11:53)\r\n    at Async._queueTick (/srv/xoa/xo-server/node_modules/bluebird/js/main/async.js:200:14)\r\n    at AsyncSettlePromises [as settlePromises] (/srv/xoa/xo-server/node_modules/bluebird/js/main/async.js:127:10)\r\n\r\n\r\n\n Comments: \n Comment 0: It looks like it did get a valid XML-RPC response, are you sure about the server's address?\n Comment 1: After a restart toolstack it works again, should have taken this into account before writing.\r\n\r\nThanks!",
  "Issue title: Converting Date to ISO with Timezone\n Issue body: Currently the **oj.IntlConverterUtils** does not provide a way to convert a Date Object to timestamp as per my use-case I have to take users input as a Date and then pass it as a Timestamp to REST API.\n Comments: \n Comment 0: Hi Ankit,  \r\n\r\nThere really isn't any such thing as a timestamp in JavaScript.  This is not something that JET would provide. It's a basic functionality of JavaScript itself.  I recommend looking at something like this Stackoverflow thread to understand how to best get what would be considered a timestamp in JavaScript.\r\nhttp://stackoverflow.com/questions/221294/how-do-you-get-a-timestamp-in-javascript",
  "Issue title: [Cosmos v4] Evaluate declared but unused member variables\n Issue body: Following class member variables are declared but never used:\r\n\r\nhttps://github.com/Azure/azure-sdk-for-java/blob/1300def7a6c810eb0b9f3a9fe175316e7f4f98f7/sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/RxDocumentServiceRequest.java#L44\r\n\r\nhttps://github.com/Azure/azure-sdk-for-java/blob/1300def7a6c810eb0b9f3a9fe175316e7f4f98f7/sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/directconnectivity/AddressResolver.java#L325\r\n\r\nhttps://github.com/Azure/azure-sdk-for-java/blob/1300def7a6c810eb0b9f3a9fe175316e7f4f98f7/sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/directconnectivity/GlobalAddressResolver.java#L44\r\n\r\nhttps://github.com/Azure/azure-sdk-for-java/blob/1300def7a6c810eb0b9f3a9fe175316e7f4f98f7/sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/directconnectivity/GlobalAddressResolver.java#L45\r\n\n Comments: \n Comment 0: private volatile String resourceFullName;  -> Does not use in SDK anymore\nprivate GatewayAddressCache gatewayAddressCache;   -> Does not use in SDK anymore\nprivate AddressResolver addressResolver;  -> Does not use in SDK anymore\n\n\n Comment 1: PR has merged.",
  "Issue title: Error running Keras notebook\n Issue body: I am trying to run the CIFAR10 Keras notebook [here](https://github.com/awslabs/amazon-sagemaker-examples/blob/mvs-keras-notebook/sagemaker-python-sdk/tensorflow_keras_cifar10/tensorflow_keras_CIFAR10.ipynb) on SageMaker, but I run into the following error when I try to create the training job:\r\n\r\n```\r\nValueError: Error training sagemaker-tensorflow-2018-07-04-02-30-42-260: Failed Reason: AlgorithmError: uncaught exception during training: 'Sequential' object has no attribute 'train_function'\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/container_support/training.py\", line 36, in start\r\n    fw.train()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tf_container/train_entry_point.py\", line 164, in train\r\n    train_wrapper.train()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tf_container/trainer.py\", line 69, in train\r\n    estimator = self._build_estimator(run_config=run_config)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tf_container/trainer.py\", line 96, in _build_estimator\r\n    return tf.keras.estimator.model_to_estimator(keras_model=model, config=run_config)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py\", line 504, in model_to_estimator\r\n    keras_weights)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py\", line 415, in _save_first_checkpoint\r\n    if not model.train_function:\n Comments: \n Comment 0: This seems to be a problem with Tensorflow and not SageMaker in particular. I found a relevant issue in the Tensorflow repo [here](https://github.com/tensorflow/tensorflow/issues/20552), so I will close this issue and follow that one.",
  "Issue title: start problem for signed apks\n Issue body: Hello,\r\nI have a problem, when starting of the Appium on real device.\r\n\r\nI faced with this Error after click Start Sessions.\r\n\r\nError\r\nAn unknown server-side error occurred while processing the command. Original error: Error executing adbExec. Original error: 'Command 'C:\\Users\\25200038\\AppData\\Local\\Android\\Sdk\\platform-tools\\adb.exe -P 5037 -s TQC000200003470401 install -r 'C:\\Program Files\\Appium\\resources\\app\\node_modules\\appium\\node_modules\\appium-uiautomator2-server\\apks\\appium-uiautomator2-server-v4.21.1.apk'' exited with code 1'; Stderr: 'adb: failed to install C:\\Program Files\\Appium\\resources\\app\\node_modules\\appium\\node_modules\\appium-uiautomator2-server\\apks\\appium-uiautomator2-server-v4.21.1.apk: Failure [INSTALL_FAILED_VERIFICATION_FAILURE]'; Code: '1'\r\n\r\nMy real device doesn't accept unsigned apk files or something because of security.\r\nWhen I realized that, I just signed all of the files below to solve the problem.\r\n\r\n settings_apk-debug.apk\r\n app-debug-androidTest.apk, \r\n appium-uiautomator2-server-debug-androidTest.apk\r\n appium-uiautomator2-server-v4.21.1.apk\r\nand then, I replaced them with the unsigned ones. After that I wrote 'adb install' on Windows Power Shell to check them if they were correct or not.\r\n\r\nThe Windows Power Shell showed me :\r\n\r\n  ''Performing Streamed Install\r\n  Success''\r\nI thought 'this time I succeed on it.' But it was not happened.\r\nWhen I clicked Start Session with correct information which Appium need ( deviceName, appActivity, appPackage, platformName).\r\nSame Error occurred again.\r\n\r\nError\r\nAn unknown server-side error occurred while processing the command. Original error: Error executing adbExec. Original error: 'Command 'C:\\Users\\25200038\\AppData\\Local\\Android\\Sdk\\platform-tools\\adb.exe -P 5037 -s TQC000200003470401 install -r 'C:\\Program Files\\Appium\\resources\\app\\node_modules\\appium\\node_modules\\appium-uiautomator2-server\\apks\\appium-uiautomator2-server-v4.21.1.apk'' exited with code 1'; Stderr: 'adb: failed to install C:\\Program Files\\Appium\\resources\\app\\node_modules\\appium\\node_modules\\appium-uiautomator2-server\\apks\\appium-uiautomator2-server-v4.21.1.apk: Failure [INSTALL_FAILED_VERIFICATION_FAILURE]'; Code: '1'\r\n\r\nLike I didn't sign any apk. or I didn't change anything.\r\nAfter got the same error I checked the Windows Power Shell to see the differences. I faced with the same failed massage at the beginning.\r\nI realized that Appium change the signed files with the beginning ones. It replaced files with the unsigned ones.\r\nIt didn't let me make some changings.\r\nI don't know why?????\r\n\r\nHOW CAN I F\u0130X TH\u0130S PROBLEM?\r\nIS THERE ANYONE COME ACROSS A PROBLEM L\u0130KE THAT?\r\n\r\nscreenshots below, \r\n\r\n![screen1](https://user-images.githubusercontent.com/87432156/126942771-034104a4-c4e2-45c9-a87c-2eac6e6bbf04.png)\r\n![screen2](https://user-images.githubusercontent.com/87432156/126942775-7b722f3e-73b7-4d85-9f70-e0ba4cb56a18.png)\r\n\r\n\n Comments: \n Comment 0: Appium usually re-sign the apk by https://github.com/appium/appium-adb/tree/master/keys by default for Android.\r\n`'appium:noSign': true` capability skips it.\n Comment 1: Just to add on the above: `noSign` option works for the application under test only. In order to keep server binaries with their original signature you could preinstall them on the device manually and set the `skipServerInstallation` capability to `true`.\n Comment 2: Closed as not an issue",
  "Issue title: Node-gyp Build fails when trying to install meanjs{ yo meanjs }\n Issue body: I have a build error running node-gyp please let me now how can I solve this.\r\n\r\n```\r\n`Error: Command failed: cd startApp && npm install\r\nnpm WARN deprecated brittanyjones@example.com: Package renamed to phantomjs-prebuilt. Please update 'phantomjs' package references\r\n to 'phantomjs-prebuilt'\r\nnpm WARN deprecated brittanyjones@example.com: Grunt needs your help! See https://github.com/gruntjs/grunt/issues/1403.\r\nnpm WARN deprecated brittanyjones@example.com: graceful-fs version 3 and before will fail on newer node releases. Please update\r\nto graceful-fs@^4.0.0 as soon as possible.\r\nnpm WARN deprecated brittanyjones@example.com: graceful-fs version 3 and before will fail on newer node releases. Please update\r\nto graceful-fs@^4.0.0 as soon as possible.\r\nnpm WARN deprecated brittanyjones@example.com: lodash@<3.0.0 is no longer maintained. Upgrade to lodash@^4.0.0.\r\nnpm WARN deprecated brittanyjones@example.com: graceful-fs version 3 and before will fail on newer node releases. Please update\r\nto graceful-fs@^4.0.0 as soon as possible.\r\nnpm WARN deprecated brittanyjones@example.com: this package has been reintegrated into npm and is now out of date with respect to np\r\nm\r\nnpm WARN prefer global brittanyjones@example.com should be installed with -g\r\nnpm WARN prefer global brittanyjones@example.com should be installed with -g\r\nnpm WARN prefer global brittanyjones@example.com should be installed with -g\r\ngyp ERR! build error\r\ngyp ERR! stack Error: `msbuild` failed with exit code: 1\r\ngyp ERR! stack     at ChildProcess.onExit (C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\node-gyp\\lib\\build.js:2\r\n76:23)\r\ngyp ERR! stack     at emitTwo (events.js:100:13)\r\ngyp ERR! stack     at ChildProcess.emit (events.js:185:7)\r\ngyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:204:12)\r\ngyp ERR! System Windows_NT 10.0.10586\r\ngyp ERR! command \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Program Files\\\\nodejs\\\\node_modules\\\\npm\\\\node_modules\\\\node\r\n-gyp\\\\bin\\\\node-gyp.js\" \"rebuild\"\r\ngyp ERR! cwd C:\\Users\\rigel\\Documents\\MEANJSProjects\\startApp\\node_modules\\bufferutil\r\ngyp ERR! node -v v5.9.1\r\ngyp ERR! node-gyp -v v3.3.1\r\ngyp ERR! not ok\r\nnpm WARN install:brittanyjones@example.com brittanyjones@example.com install: `node-gyp rebuild`\r\nnpm WARN install:brittanyjones@example.com Exit status 1\r\ngyp ERR! build error\r\ngyp ERR! stack Error: `msbuild` failed with exit code: 1\r\ngyp ERR! stack     at ChildProcess.onExit (C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\node-gyp\\lib\\build.js:2\r\n76:23)\r\ngyp ERR! stack     at emitTwo (events.js:100:13)\r\ngyp ERR! stack     at ChildProcess.emit (events.js:185:7)\r\ngyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:204:12)\r\ngyp ERR! System Windows_NT 10.0.10586\r\ngyp ERR! command \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Program Files\\\\nodejs\\\\node_modules\\\\npm\\\\node_modules\\\\node\r\n-gyp\\\\bin\\\\node-gyp.js\" \"rebuild\"\r\ngyp ERR! cwd C:\\Users\\rigel\\Documents\\MEANJSProjects\\startApp\\node_modules\\utf-8-validate\r\ngyp ERR! node -v v5.9.1\r\ngyp ERR! node-gyp -v v3.3.1\r\ngyp ERR! not ok\r\nnpm WARN install:brittanyjones@example.com brittanyjones@example.com install: `node-gyp rebuild`\r\nnpm WARN install:brittanyjones@example.com Exit status 1\r\ngyp ERR! build error\r\ngyp ERR! stack Error: `msbuild` failed with exit code: 1\r\ngyp ERR! stack     at ChildProcess.onExit (C:\\Users\\rigel\\Documents\\MEANJSProjects\\startApp\\node_modules\\node-gyp\\lib\\bu\r\nild.js:276:23)\r\ngyp ERR! stack     at emitTwo (events.js:100:13)\r\ngyp ERR! stack     at ChildProcess.emit (events.js:185:7)\r\ngyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:204:12)\r\ngyp ERR! System Windows_NT 10.0.10586\r\ngyp ERR! command \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\rigel\\\\Documents\\\\MEANJSProjects\\\\startApp\\\\node_modu\r\nles\\\\node-gyp\\\\bin\\\\node-gyp.js\" \"build\" \"--fallback-to-build\" \"--module=C:\\\\Users\\\\rigel\\\\Documents\\\\MEANJSProjects\\\\st\r\nartApp\\\\node_modules\\\\v8-debug\\\\build\\\\debug\\\\v0.4.6\\\\node-v47-win32-x64\\\\debug.node\" \"--module_name=debug\" \"--module_pa\r\nth=C:\\\\Users\\\\rigel\\\\Documents\\\\MEANJSProjects\\\\startApp\\\\node_modules\\\\v8-debug\\\\build\\\\debug\\\\v0.4.6\\\\node-v47-win32-x\r\n64\"\r\ngyp ERR! cwd C:\\Users\\rigel\\Documents\\MEANJSProjects\\startApp\\node_modules\\v8-debug\r\ngyp ERR! node -v v5.9.1\r\ngyp ERR! node-gyp -v v3.3.1\r\ngyp ERR! not ok\r\nnode-pre-gyp ERR! build error\r\nnode-pre-gyp ERR! stack Error: Failed to execute 'C:\\Program Files\\nodejs\\node.exe C:\\Users\\rigel\\Documents\\MEANJSProjec\r\nts\\startApp\\node_modules\\node-gyp\\bin\\node-gyp.js build --fallback-to-build --module=C:\\Users\\rigel\\Documents\\MEANJSProj\r\nects\\startApp\\node_modules\\v8-debug\\build\\debug\\v0.4.6\\node-v47-win32-x64\\debug.node --module_name=debug --module_path=C\r\n:\\Users\\rigel\\Documents\\MEANJSProjects\\startApp\\node_modules\\v8-debug\\build\\debug\\v0.4.6\\node-v47-win32-x64' (1)\r\nnode-pre-gyp ERR! stack     at ChildProcess.<anonymous> (C:\\Users\\rigel\\Documents\\MEANJSProjects\\startApp\\node_modules\\v\r\n8-debug\\node_modules\\node-pre-gyp\\lib\\util\\compile.js:83:29)\r\nnode-pre-gyp ERR! stack     at emitTwo (events.js:100:13)\r\nnode-pre-gyp ERR! stack     at ChildProcess.emit (events.js:185:7)\r\nnode-pre-gyp ERR! stack     at maybeClose (internal/child_process.js:850:16)\r\nnode-pre-gyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:215:5)\r\nnode-pre-gyp ERR! System Windows_NT 10.0.10586\r\nnode-pre-gyp ERR! command \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\rigel\\\\Documents\\\\MEANJSProjects\\\\startApp\\\\\r\nnode",
  "Issue title: Installer will create a folder named `~` under home directory\n Issue body: ## Expected behavior, english is recommend\r\nA directory named `~` will be created under home directory during installation.\r\n\r\n## Environment Information\r\n- OS: Mac OS X\r\n- vim version:\r\n- neovim version: 0.17\r\n\r\n## The reproduce ways from Vim starting (Required!)\r\n```\r\ncurl -sLf https://spacevim.org/install.sh | bash\r\n```\r\n\r\n## Output of the \":message\" command, and \":echo SpaceVim#logger#viewLog()\"\r\nA directory named `~` will be created under home directory.  The content of this directory looks like:\r\n```\r\n~/~/.cache/vimfilesrepos/github.com/Shougo/dein.vim\r\n```\r\n\r\nplease post log below, if you want me reproduce your issue quickly, post your custom config here will be better.\r\n\r\n\n Comments: \n Comment 0: oh, it is a bug, will check it tonight.\n Comment 1: @cjppku I can not reproduce it, what is your custom conifg, and \r\nwhat is the result of \r\n`:echo g:spacevim_plugin_bundle_dir`\n Comment 2: i had met the same bug,but i haven't take it in my heart ago.\n Comment 3: but I can not reproduce it, does it happend with default config?\n Comment 4: yes,probably the default config,my home dir also have the ~ directory \n Comment 5: do you me `/home/root/~/`?\n Comment 6: /home/leon/~ \r\n\r\n\r\n\r\n\r\n\r\n\n Comment 7: can you delete it, and with default config, will this dir be created again?\n Comment 8: it disapperead\n Comment 9: I think it should be fixed in master. ",
  "Issue title: How to deploy to something other than Netlify or GitHub pages?\n Issue body: I have a hosting account I want to use, and I know how to FTP stuff, but simply uploading my 11ty folder doesn't do what I expected.  I can open the homepage, but all links are dead, there is no css, js and no images. My existing blog is hand written static html and works just fine on that server.\r\n\r\nI am entirely new to SSG's and I must be misunderstanding something very basic. I have found nothing in 11ty docs to shed light - they are perhaps not (yet) very beginner-friendly.\r\n\r\nIn short: How do I deploy my site with everything working as well as it does locally?\n Comments: \n Comment 0: Hi, @HagelBagel! Welcome to Eleventy! Do you have a link to a repository to share? I can take a look.\n Comment 1: How do you build the site? (what command)\r\nHow do you synch the output folder?\r\n\r\nThat's why services like Netlify, [ZEIT Now](https://zeit.co), or [buddy.works](https://buddy.works) (if you need to automate FTP deployments) exist, that deployment step should be set up and automated. \r\n\r\n\n Comment 2: @reubenlillie Here's my repo: [https://github.com/HagelBagel/11ty-test-blog](url)\r\n@DirtyF: For building: \"npx eleventy\". I am not sure what you mean by synching the output folder? Like automated deployment? I only tried regular ol' FTP.\n Comment 3: When you run `npx eleventy` it will generate an output directory (by default called `_site`). You need to put the content of that directory onto a webserver (e.g. using FTPS). That's what is called \u201edeployment\u201d (= transferring files from where they were generated to the machine which shall serve them)\n Comment 4: For example, I am using Uberspace and build the files there locally before copying the output directory onto the document root defined with Apache.\n Comment 5: @HagelBagel FWIW your site is deploying fine on Netlify: https://5e7cb5f8578654018cf1420b--sleepy-carson-e1b1e4.netlify.com\n Comment 6: Hi @Ryuno-Ki  - that's exactly what I have been doing: simply copying the files to my server. But perhaps something is going wrong in that process. \r\n@DirtyF: thanks for testing!\r\nIt's probably just a dumb mistake I'm making - at it again ;-)\n Comment 7: @HagelBagel Would you be able to share a link to the server you're FTPing it to? This way we could check the links.\r\n\r\n> I can open the homepage, but all links are dead, there is no css, js and no images.\r\n\r\nIf I understand you correctly, this is your main problem (not the upload).\n Comment 8: So: I think I nailed it now. Turns out I hadn't put things in the root, but one folder down (doh). Then I had some paths without trailing slashes: /about instead of /about/. Finally, I had folders with title-case: \"About\", but the corresponding paths were lower-case: /about/. All these things fixed, it finally works: [http://chfrom.dk/](http://chfrom.dk/)\r\nSo, not one - but several mistakes. Learned a lot from this one. Thanks to all of you - I'm closing this one down. :-)\n Comment 9: Hooray!\r\n\r\nWill you blog in Danish or English? In any case, don't forget to generate a RSS feed :-)\n Comment 10: I will be writing in English, but I will probably put my old site back up while I work on this new 11ty thing of wonder, adding RSS and all kinds of goodies ;-)\n Comment 11: [Microformats](https://indieweb.org/microformats) *_\\*\r\n\r\nOkay, I'll keep an eye on the site then :-)\n Comment 12: Hello, so I need help for something similar, on my localhost, the 11ty site works fine but I can't upload it to the current shared hosting that my client uses as in the _site folder, all links become it own directories and this breaks the page (i.e: products.html to product > index.html)\r\n\r\nSo how should I fix this? I see many people just say upload your _site to your FTP root directory but this will just result in broken pages cause of the \"product > index.html\" thing.\r\n\r\n\n Comment 13: Hi Omar!\r\nIt looks like you're having the same problems I had. I did figure it out and wrote about it [here:](http://chfrom.dk/posts/2020/portfolio-remake-with-eleventy/). Maybe it will help you too. Read from \"Getting Started\" and down...hope it helps! :-)\n Comment 14: @omartan I created a basic example at https://github.com/pdehaan/11ty-permalinks\r\n\r\nThe /src/ directory has all of my source files (.liquid, global _data files, etc), and the /www/ directory has all the generated output so you can see the final folder structure.\r\nThe /src/about.liquid file specifies an explicit permalink of \"/about.html\", and the /src/home.liquid file specifies a permalink of \"/\" (which will be written to /www/index.html).\r\n\r\nDepending on how many files you have in your site, it might be easier to specify explicit `permalink` fields in your frontmatter. If you have dozens-hundreds of pages, we might be able to figure out some [directory data file](https://www.11ty.dev/docs/data-template-dir/#example-apply-a-default-layout-to-multiple-templates) solution.\n Comment 15: @pdehaan, how do you link other pages then? \r\nas I see `{{ page.url }}` which returns the current page url, which is fine, but what about linking to other pages like \r\n`<a href=\"/about/\">About</a>`?\n Comment 16: @pdehaan okay, I'm getting close but here's what I notice, so in `home.liquid`,\r\n\r\nTo link to the about page, I need to manually change from `<a href=\"\\about\\\">About</a>` to `<a href=\"about.html\">About</a>` correct?\r\n\r\nbut I have another page in a loop uses something like `{{ page.url }}` which will always return `\\about.html`, so how do I get rid of that `\\`? \r\n\r\n\r\n\n Comment 17: @omartan Not sure if you maybe want to start a new GitHub issue and post a link to your repo. I don't know why your links would be `<a href=\"\\about\\\">About</a>` if you're setting the `permalink` in the front-matter for that file, unless the links were manually set to that in the content somewhere.\r\n\r\nI'm also curious where you are deploying this and why it wouldn't work with a leading \"/\"; unless your final folder isn't in the root directory of the URL. But if that is the case, maybe we can just set [`pathPrefix`](https://www.11ty.dev/docs/config/#deploy-to-a-subdirectory-with-a-path-prefix) in your.eleventy.js config file to whatever your final URL structure would be.\r\n\r\n```js\r\n  return {\r\n    dir: {\r\n      input: \"src\",\r\n      output: \"www\",\r\n    },\r\n    pathPrefix: \"/~your-prefix-dir-here/\",\r\n  };\r\n```\r\n\r\nIf that doesn't solve it, then we can try writing a custom 11ty filter to strip leading `/` characters should work (although it might need some additional checks and logic to cover cases where people write [protocol-less URLs](https://www.paulirish.com/2010/the-protocol-relative-url/) like //google.com/foo/bar).\r\n\r\nBut this should work for a very simple use case:\r\n```js\r\n  eleventyConfig.addFilter(\"stripLeadingSlash\", (urlPath = \"\") =>\r\n    urlPath.startsWith(\"/\")? urlPath.slice(1) : urlPath\r\n  );\r\n```\r\n\n Comment 18: Hey @pdehaan, thanks for that answer. I think I made a typo and let me better phrase sentence, so based on the sample you given there's 2 files, index/home and about, let say I want to create a link from home to about, how do I get doing about that as if I were to go the default \r\n\r\nhome.liquid\r\n```<a href = \"/about/\">About</a>```\r\n\r\nthe output will be\r\n\r\nindex.html\r\n```<a href=\"/about/\">About</a>```\r\n\r\nwhich will result in a broken link if I were to open the index.html file directly as the url technically need to be",
  "Issue title: Native FFmpeg broken\n Issue body: When I execute `ffmpeg` and `ffprobe`, I get the following errors:\r\n```\r\nFailed loading ffmpeg from ffmpeg.framework/ffmpeg, cause = (null)\r\nFailed loading ffprobe from ffprobe.framework/ffprobe, cause = (null)\r\n```\r\n\r\nI would love to be able to use the native version of FFmpeg instead of the webAssembly one, but it doesn\u2019t seem to work on a-shell 1.8.1.\n Comments: \n Comment 0: Hi, \r\nthis has happened in the past with other users and other commands. It seems to be an issue with iOS security. Rebooting the device and / or re-installing a-Shell could fix it. \n Comment 1: Reinstalling did the trick for now. Thanks for the help!",
  "Issue title: Custom query fields\n Issue body: First, I just tried this library, and this is just amazing. Really nice work!\r\n\r\nI've been thinking that it would be nice to have some form of custom fields available. For example, you might want to filter on user's full name when you have first_name and last_name in the model, or you might want to filter on some aggregate (say, num_books >= 10).\r\n\r\nIt seems this would require changes to both the schema and build_filter parts. I'll probably write a quick hack for this so that it's possible to check what exactly this requires.\n Comments: \n Comment 0: I got similar feature requests from other people as well, and I personally think this could be a powerful feature if implemented properly. I've looked through your PR, and the idea of extracting DjangoQLField seems to be promising. I'd like to play with your version a little bit, maybe try some variants for the API.\r\n\r\nthank you for contributing!\n Comment 1: The DjangoQLField approach is very likely a good solution on high level. Moving a bit more logic to DjangoQLField from schema would likely make it even more powerful. As an example, it would be nice that you could use the display value of a field's choices in the search string, and then convert that to the internal representation. This should be doable by an ui_to_internal(value) method of DjangoQLField.\r\n\r\nNow, the actual implementation I wrote will probably need a bit more tuning. I believe it would be better to have something like DjangoQLField, and then Int, String, Boolean,... fields subclassing the DjangoQLField. Now, things like schema.validate() could be implemented as a high level validator in schema.validate(), and then field type specific validation would be done by calling field.validate().\n Comment 2: alright, version 0.8.0 is out, with [Custom Search Fields](https://github.com/ivelum/djangoql#custom-search-fields)\r\n\r\nThis is based on many of your ideas and your PR, I just explored the concept further and provided ability for users to perform fully custom lookups. From my perspective it covers majority of use cases that users may want, but that would be great to hear your thoughts too. I'm closing this for now, but if you think that the problem is not resolved well enough - please feel free to re-open it.\r\n\r\nthanks again for contributing!\n Comment 3: Thanks, that was fast!\r\n\r\nI have one idea for this still... add a method of something like `Field.participate_in_query(self, queryset, path, operator, value)`. The method returns a queryset, and shouldn't call filter() or exclude() on the queryset.\r\n\r\nThe idea would be that this method is called *only* if the field is used as part of the query. A common use case would be doing an annotation to the query. It would be better to do the annotation only when the field is used in the query, instead of doing it always in admin's get_queryset().\r\n\r\nThere are some advantages doing it this way. First, if you have multiple fields requiring annotations, then the queryset can become quite heavy even if you don't need all of the annotations. Still, this would allow one to use djangoql searches on any queryset, without the need to add annotations to the query manually. Finally, if you use the new Exists expression from Django 1.11, and the user's query is something like commented_since_days=3, your implementation could look like this:\r\n```\r\nn_days_ago = timezone.now() - timedelta(days=3)\r\nrecent_comments = Comment.objects.filter(\r\n    post=OuterRef('pk'),\r\n    created_at__gte=n_days_ago,\r\n)\r\nqs = qs.annotate(commented_since_days=Exists(recent_comments))\r\nqs.filter(commented_since_days=True)\r\n```\r\ndoing this without access to the queryset is impossible, as the annotation is dynamic. With the proposed addition it should be possible to do this type of query.\n Comment 4: Good catch about avoiding unnecessary annotations when a field is not used in the query. Let's re-open this",
  "Issue title: Can remotedb be used to serve rpcs\n Issue body: I noticed there is a new `--remotedb` argument in cli, and found the PR https://github.com/ethereum/go-ethereum/pull/24836\r\n\r\nI'm quite interested in this idea of remotedb, because I'm looking for a way to scale my geth rpc service without too much additional storage costs, and remotedb looks a perfect solution for that. Though due to lack of documents I'm not sure if remotedb can be used in that way.\r\n\r\n\n Comments: \n Comment 0: As of now it's not possible to serve RPC using remotedb. If your goal is to have one master node and a few slave nodes, you can try the light-client approach here. In the gist I use the tracing API, but it could work for other methods too.\r\n\r\nhttps://gist.github.com/s1na/ab834d1af2c91b3f67ee9ea692efdf55",
  "Issue title: bug: doesn't support my company's proprietary package manager\n Issue body: hi please add support for our in-house, private package manager by hashing all file names in the root dir\n Comments: \n Comment 0: +1\n Comment 1: Does it support unicorns? If yes, PR welcome!",
  "Issue title: HTML attributes are not reactive when store is set through a client plugin\n Issue body: _I'm new to Nuxt.js so I might be missing something basic here, but I've looked everywhere and I believe it's a bug._\r\n\r\n```\r\n// index.vue\r\n\r\n<template>\r\n  <p :title=\"name\">{{ name }}</p>\r\n</template>\r\n\r\n<script>\r\nexport default {\r\n  computed: {\r\n    name() {\r\n      return this.$store.state.user.name;\r\n    }\r\n  }\r\n};\r\n</script>\r\n```\r\nTitle does not match the text:\r\n![image](https://user-images.githubusercontent.com/2454954/122878745-4999bd00-d362-11eb-90c6-bacd02047290.png)\r\n\r\n```\r\n// store/index.js\r\n\r\nexport default {\r\n  actions: {\r\n    async nuxtClientInit({ commit }) {\r\n      commit(\"user/set\", { name: \"Rick Sanchez\" });\r\n    }\r\n  }\r\n};\r\n```\r\n```\r\n// store/user.js\r\n\r\nexport const state = () => ({\r\n  name: \"Morty Smith\"\r\n});\r\n\r\nexport const mutations = {\r\n  set(state, user) {\r\n    state.name = user.name;\r\n  }\r\n};\r\n\r\n```\r\n\r\n\r\n\r\n### Versions\r\n\r\n- nuxt: v2.15.7\r\n- node: v14.16.0\r\n\r\n### Reproduction\r\nCheck out: [CodeSandbox](https://codesandbox.io/s/pensive-lake-q6yd8)\r\n\r\n\r\n\n Comments: \n Comment 0: Hi @ronenteva, this seems a problem related to Vue core. This issue might help you https://github.com/vuejs/vue/issues/7063\n\nBasically the workaround is to put a ref on the element.\n Comment 1: Thanks for your contribution to Nuxt!\nThis issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.\nIf you would like this issue to remain open:\n\n 1. Verify that you can still reproduce the issue in the latest version of nuxt-edge\n 1. Comment the steps to reproduce it\n\nIssues that are labeled as `pending` will not be automatically marked as stale.\n",
  "Issue title: Homebrew \u955c\u50cf\u4f7f\u7528\u5e2e\u52a9 \u5730\u5740\u914d\u7f6e\u9519\u8bef\n Issue body: \u5e2e\u52a9\u4e2d\u8bbe\u7f6eremote\u5730\u5740\u4e3a\uff1a\r\n`git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/brew.git`\r\n`git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew-core.git`\r\n`git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew-science.git`\r\n`git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew-python.git`\r\n\r\n\u5b9e\u9645\u5e94\u8be5\u4e3a\uff1a\r\n`git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/homebrew/brew.git`\r\n`git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/homebrew/homebrew-core.git`\r\n`git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/homebrew/homebrew-science.git`\r\n`git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/homebrew/homebrew-python.git`\n Comments: \n Comment 0: \u6211\u8bd5\u4e86\u4e00\u4e0b `https://mirrors.tuna.tsinghua.edu.cn/git/homebrew-python.git` \u8fd9\u4e2a\u5730\u5740\u53ef\u4ee5 clone \u4e0b\u6765\u5440\u2026\u2026\r\n\r\n\u4f60\u5199\u7684\u5730\u5740\u662f\u65e7\u955c\u50cf\uff0c\u4e00\u4e2a\u6708\u6ca1\u66f4\u65b0\u4e86\u2026\u2026 \u6211\u5fd8\u4e86\u5220\r\n\r\n\r\n\r\n\n Comment 1: \u6211\u6839\u636e\u73b0\u5728\u7684\u60c5\u51b5\u66f4\u65b0\u4e86\u4e00\u4e0b\uff0chttps://mirrors.tuna.tsinghua.edu.cn/help/homebrew/ \u518d\u8bd5\u8bd5\uff1f\n Comment 2: \u6211\u8bd5\u8bd5\r\n\n Comment 3: `git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git`\r\n\u8fd9\u4e2a\u5728fetch\u7684\u65f6\u5019\u62a5\u9519\uff1a\r\n```\r\nerror: inflate: data stream error (invalid distance too far back)\r\nfatal: pack has bad object at offset 32330497: inflate returned -3\r\nerror: Unable to find efc271f683e8d00ebf62cfcc1f928c1291f8fd36 under https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\r\nCannot obtain needed object efc271f683e8d00ebf62cfcc1f928c1291f8fd36\r\nerror: fetch failed.\r\n```\r\n\r\n\u96be\u9053\u662f\u6211homebrew\u7684\u95ee\u9898\uff1f\n Comment 4: 2333\uff0c\u600e\u4e48404\u4e86\uff0c\u5927\u9e70\u4f60\u5728\u7ef4\u62a4\u4e48\uff1f\n Comment 5: \u6211\u76f4\u63a5 git clone \u662f\u53ef\u4ee5\u7684\u2026\u2026 \u96be\u9053\u8ddf\u5386\u53f2\u6709\u5173\u7cfb\uff1f\r\n404 \u662f\u628a\u90a3\u4e2a\u65e7\u7684\u5220\u4e86\uff0c\u73b0\u5728\u6240\u6709 git \u955c\u50cf\u90fd\u5728\u53e6\u4e00\u53f0\u673a\u5668\u4e0a \n Comment 6: \u73b0\u5728\u53ef\u4ee5\u4e86\uff0c\u5e94\u8be5\u4fee\u590d\u4e86\u3002\u591a\u8c22\u5927\u9e70\u3002",
  "Issue title: How to set axis limit?\n Issue body: Hello,\r\n\r\nI want to set the axis limit for the plot of `evo_traj`. I tried to add `ax.set_xlim(right=5)` in [here](https://github.com/MichaelGrupp/evo/blob/051e5bf63195172af58dc8256cc71618f079f224/evo/tools/plot.py#L324), but it didn't work.\r\n\r\nCould you please provide a qucik code to set axis limit? Thanks a lot.\n Comments: \n Comment 0: You might find help here: https://stackoverflow.com/questions/17734587/why-is-set-xlim-not-setting-the-x-limits-in-my-figure\r\n\r\n\n Comment 1: @MichaelGrupp\r\nThank you for your advice.\r\nThis [answer](https://stackoverflow.com/a/59884328/11157926) solves my problem.",
  "Issue title: No response frome button view reminders\n Issue body: I install v0.2.5 in MM v5.10, when I add a remind, the view reminders button in post message has no response. The issue is similar with #93 \n Comments: \n Comment 0: Confirmed, thank you @tgly307!  I will get to this asap.  :)\n Comment 1: @tgly307 the problem should be fixed in 0.2.6\r\nhttps://github.com/scottleedavis/mattermost-plugin-remind/releases/tag/v0.2.6\n Comment 2: @scottleedavis thanks a lot!\r\nI have test v0.2.6 on MM 5.11, it works fine.\r\nI will close this issue.",
  "Issue title: Broken link release notes\n Issue body: The following link is broken in\r\nhttps://github.com/opencobra/cobrapy/blob/devel/release-notes/0.6.0.md\r\n\r\nObjectives can now easily be made quite advanced by simply crafting the right expression and assigning this as usual to model.objective, see the --> contraints and objectives notebook <--. \r\nhttp://cobrapy.readthedocs.io/en/latest/constraints_objective.html\n Comments: \n Comment 0: Fixed\n Comment 1: Great. Thanks a lot.",
  "Issue title: [Python]Import amalgamation/python/mxnet_predict API and MXNet Causing Core Dump\n Issue body: `\r\n# coding=utf-8\r\nimport sys, os\r\ncurr_path = os.path.dirname(os.path.abspath(os.path.expanduser(__file__)))\r\nsys.path.append(\"/home/liang/frankwang/mxnet/amalgamation/python/\")\r\nsys.path.append(\"/home/liang/frankwang/mxnet/python/\")\r\n\r\nfrom mxnet_predict import Predictor, load_ndarray_file\r\nimport mxnet as mx\r\nimport numpy as np\r\nimport cv2\r\nimport os\r\n`\r\n\r\nIt seems that if I import both of mxnet_predict and mxnet, a core dump happened:\r\n\r\n`\r\n[15:48:36] /home/liang/frankwang/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:48:36] /home/liang/frankwang/mxnet/dmlc-core/include/dmlc/./././any.h:264: Check failed: type_->ptype_info == &typeid(T) The stored type mismatch stored=N4nnvm5OpMapISt8functionIFSt6vectorISsSaISsEERKNS_9NodeAttrsEEEEE requested=N4nnvm5OpMapISt8functionIFSt6vectorISsSaISsEERKNS_9NodeAttrsEEEEE\r\n\r\nStack trace returned 55 entries:\r\n[bt] (0) /home/liang/anaconda2/envs/frankwang-cv/lib/python2.7/site-packages/mxnet-0.9.3-py2.7-linux-x86_64.egg/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x29) [0x7f7425dcf0e9]\r\n[bt] (1) /home/liang/anaconda2/envs/frankwang-cv/lib/python2.7/site-packages/mxnet-0.9.3-py2.7-linux-x86_64.egg/mxnet/libmxnet.so(_ZZN4nnvm2Op8set_attrISt8functionIFSt6vectorISsSaISsEERKNS_9NodeAttrsEEEEERS0_RKSsRKT_iENKUlPN4dmlc3anyEE_clESJ_+0x1ef) [0x7f7425e7b03f]\r\n[bt] (2) /home/liang/anaconda2/envs/frankwang-cv/lib/python2.7/site-packages/mxnet-0.9.3-py2.7-linux-x86_64.egg/mxnet/libmxnet.so(_ZN4nnvm2Op8set_attrISt8functionIFSt6vectorISsSaISsEERKNS_9NodeAttrsEEEEERS0_RKSsRKT_i+0x11e) [0x7f7425dd2e3e]\r\n[bt] (3) /home/liang/anaconda2/envs/frankwang-cv/lib/python2.7/site-packages/mxnet-0.9.3-py2.7-linux-x86_64.egg/mxnet/libmxnet.so(+0x575f76) [0x7f7425cd7f76]\r\n[bt] (4) /lib64/ld-linux-x86-64.so.2(+0xf3a3) [0x7f746d2473a3]\r\n[bt] (5) /lib64/ld-linux-x86-64.so.2(+0x13ab6) [0x7f746d24bab6]\r\n[bt] (6) /lib64/ld-linux-x86-64.so.2(+0xf1b4) [0x7f746d2471b4]\r\n[bt] (7) /lib64/ld-linux-x86-64.so.2(+0x131ab) [0x7f746d24b1ab]\r\n[bt] (8) /lib64/libdl.so.2(+0x102b) [0x7f746ca1f02b]\r\n[bt] (9) /lib64/ld-linux-x86-64.so.2(+0xf1b4) [0x7f746d2471b4]\r\n[bt] (10) /lib64/libdl.so.2(+0x162d) [0x7f746ca1f62d]\r\n[bt] (11) /lib64/libdl.so.2(dlopen+0x31) [0x7f746ca1f0c1]\r\n[bt] (12) /home/liang/anaconda2/envs/frankwang-cv/lib/python2.7/lib-dynload/_ctypes.so(+0x10b2c) [0x7f7465816b2c]\r\n[bt] (13) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x8942) [0x7f746cf3b5a2]\r\n[bt] (14) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(PyEval_EvalCodeEx+0x89e) [0x7f746cf3c1ce]\r\n[bt] (15) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(+0x797e1) [0x7f746ceb77e1]\r\n[bt] (16) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(PyObject_Call+0x53) [0x7f746ce87dc3]\r\n[bt] (17) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(+0x5c54f) [0x7f746ce9a54f]\r\n[bt] (18) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(PyObject_Call+0x53) [0x7f746ce87dc3]\r\n[bt] (19) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(+0xb6910) [0x7f746cef4910]\r\n[bt] (20) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(+0xad328) [0x7f746ceeb328]\r\n[bt] (21) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(PyObject_Call+0x53) [0x7f746ce87dc3]\r\n[bt] (22) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x6a67) [0x7f746cf396c7]\r\n[bt] (23) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(PyEval_EvalCodeEx+0x89e) [0x7f746cf3c1ce]\r\n[bt] (24) /home/liang/anaconda2/envs/frankwang-cv/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x8596) [0x7f746cf3b1f6]\r\n[bt] (",
  "Issue title: Can't use container exec on container groups with multiple containers\n Issue body: If you attempt to use `az container exec` in 2.0.30 on a container group with multiple containers, you get an error saying `--container-name` is required even if you supply it:\r\n\r\n```\r\naz container exec -g $resourceGroup -n $containerGroupName --container-name \"front-end\" `\r\n    --exec-command \"/bin/bash\"\r\n--container-name required when container group has more than one container.\r\n```\r\n\r\nLooks like the logic in this `if` statement doesn't account for the situation when there are multiple containers and the container name has been supplied:\r\nhttps://github.com/Azure/azure-cli/blob/5f1a9c621bfc8b15b17f53399e37e43a8c55aa4c/src/command_modules/azure-cli-container/azure/cli/command_modules/container/custom.py#L261\n Comments: \n Comment 0: This was fixed in PR #5927 and will be in the next release.",
  "Issue title: Font/Background Color in Code Blocks\n Issue body: Is there a way to change these? When I paste a simple text, it is too unreadable IMO and I'd like the text to be white if possible.\n Comments: \n Comment 0: the styling for the code blocks is in `_sass/uno.scss` around line 1020\r\n`code {\r\n\tpadding:.1em.4em;\r\n\tbackground: #e8f2fb;\r\n\tborder: 1px solid #c9e1f6;\r\n\tborder-radius: 3px;\r\n\tfont-family: Consolas, Menlo, Monaco, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace, serif;\r\n\tfont-size:.85em; }`",
  "Issue title: Link uploaded image to media, and respect image_default_link_type when adding images\n Issue body: ### Expected behavior\r\n\r\nWhen inserting an image through the app's editor, it should be possible to \"link to media\" like in Gutenberg. Also, the setting `image_default_link_type` from options.php should be respected.\r\n\r\n### Actual behavior\r\n\r\nApp only allows to enter a URL manually. `image_default_link_type` gets ignored.\r\n\r\n##### Tested on [device], Android [version], WPAndroid [version]\r\n\r\nDevice: Oneplus 9 Pro\r\nAndroid: 11\r\nWPAndroid: 17.3-rc-1\r\n\n Comments: \n Comment 0: \n<!--\n  2 failure:  Please add a type..., Please add a feat...\n  0 warning: \n  \n  \n  DangerID: danger-id-Peril;\n-->\n\n<table>\n  <thead>\n    <tr>\n      <th width=\"50\"></th>\n      <th width=\"100%\" data-danger-table=\"true\">Fails</th>\n    </tr>\n  </thead>\n  <tbody><tr>\n      <td>:no_entry_sign:</td>\n      <td>\n\n  Please add a type label to this issue. e.g. '[Type] Enhancement'\n  </td>\n    </tr>\n  \n<tr>\n      <td>:no_entry_sign:</td>\n      <td>Please add a feature label to this issue. e.g. 'Stats'</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n\n<p align=\"right\">\n  Generated by :no_entry_sign: <a href=\"https://danger.systems/js\">dangerJS</a>\n</p>\n\n Comment 1: I cannot add a label, as I'm not a contributor, could anyone with appropriate permission please add a `[Type] Enhancement` Label? Thanks!",
  "Issue title: Linking post page\n Issue body: skylos wrote:\n\n\"Is there a way to connect the blog sections among the sites?\n\nI mean linking the \u2018Posts page\u2019 set from the Reading Settings.\n\nSettings >> Reading Settings >> Front page displays,\nFront page (works, as it\u2019s the root directory)\n&\nPosts page (does not work \u2013 redirects to main page).\n\nUsing MSLS 0.95 and WP 3.3RC2\"\n\n Comments: \n Comment 0: Seems that it works now.\n",
  "Issue title: auto-conversion from protobuf schema to capnproto shema\n Issue body: Is there any existing tool to do such auto-conversion? \n Comments: \n Comment 0: Not that I know of, sorry.",
  "Issue title: Unable to get Terraform completions\n Issue body: I am trying to get completions from [vim-terraform-completion](https://github.com/juliosueiras/vim-terraform-completion) working with the `omni` source, but I cannot get it to work.\r\n\r\nIt seems related to the trigger pattern, so I tried to create a small `coc-terraform` extension simular to what you created for `coc-vimtex`. Yet it will never autoload (I have to enable the extention using `:CocList` > `extentions`) and then it will still not trigger completions \ud83d\ude1e \r\n\r\nCould you maybe have a quick look and tell me what I'm doing wrong? If we get it working that it would also be nice to move (or just create) the plugin under your Github org.\r\n\r\nThanks! \n Comments: \n Comment 0: I don't have time for it, you can debug it in Chrome https://github.com/neoclide/coc.nvim/wiki/Debug-coc.nvim\n Comment 1: \ud83d\ude1e\n Comment 2: I fully understand and appreciate that you don't have time to help debug/fix everything, but at least some pointers would be really, really helpful for me to know where to look at.\r\n\r\nAs you can see by the extension I tried to create, I did invest some time to try and figure things out myself before creating this issue. But as I'm stuck right now and as I'm not a typescript/javascript developer, the page you linked to isn't helpful if I don't know what to look for or what to debug.\r\n\r\nTo recap, I have two issues:\r\n\r\n1. The plugin doesn't enable automatically when opening a file with the registered extension\r\n2. It seems the pattern used as the trigger isn't working as expected\r\n\r\nIf you could only give a few pointers (examples, links to docs or just links to the relevant source code that is responsible for these parts) that would at least give me a point were I could start writing some `console.error` lines in order to try and understand how it should work and what goes wrong in my case.\r\n\r\nHope you can find a minute to unblock me. Thanks...\r\n\r\n\n Comment 3: > The plugin doesn't enable automatically when opening a file with the registered extension.\r\n\r\nIt's controlled by `activationEvents` in package.json.\r\n\r\n> It seems the pattern used as the trigger isn't working as expected\r\n\r\nIt's problem of your `pattern`, checkout RegExp docs of javascript and test it out in console or your browser or node REPL.\n Comment 4: Thanks for the pointers! I'm going to have another look \ud83d\udc4d \n Comment 5: @svanharmelen Did you manage to get it to work? \n Comment 6: No, I didn't follow up on it and now use https://github.com/juliosueiras/terraform-lsp which works reasonably...\n Comment 7: Yes, found that last night too. Thanks!",
  "Issue title: Typo manual 2.17 section 20.2\n Issue body: #### Summary:\r\nPlease provide a short summary (no more than a sentence or two).\r\n\r\nreal[] x_i should be int[] x_i\r\n#### Description:\r\nDescribe the issue as clearly as possible.\r\nThere is a typo showing code that won't work. This would be obvious to anyone who knew anything about these issues, but I didn't and it took me a lot of work and some guessing to get it. This was complicated by the fact that the error message wasn't very clear. Anyway, the manual has two lines in a row starting with real[], and the second one should be int[]. \r\n\r\n#### Reproducible Steps:\r\nPlease report steps to reproduce the issue. If it's not possible to reproduce, please include a description of how you discovered the issue.\r\nCopied the code exactly, just changing the function for z to the one I wanted. Kept getting an error message about the signature. Wasn't sure what to make of it. Finally guessed that this was a typo, made the change I suggest above, and it worked,\r\nIf you have a reproducible example, please include it.\r\n\r\n\r\n#### Current Output:\r\nIf applicable, any relevant output from RStan.\r\n\r\n\r\n#### Expected Output:\r\nIf applicable, the output you expected from RStan.\r\n\r\n\r\n#### RStan Version:\r\nThe version of RStan you are running (e.g., from `packageVersion(\"rstan\")`)\r\n2.17.3\r\n#### R Version:\r\nThe version of R you are running (e.g., from `R.version.string`)\r\n\r\n#### Operating System:\r\nYour operating system (e.g., OS X 10.11.3)\r\nMac High Sierra 10.13.3\n Comments: \n Comment 0: We track issues with the manual here:\r\n\r\nhttps://github.com/stan-dev/stan/issues/2437#issuecomment-371829107\r\n\r\nI copied your issue over to a comment with a citation and am closing this issue.",
  "Issue title: \u5f15\u5165ant design\u4e4b\u540e\uff0c\u9875\u9762\u52a0\u8f7d\u53d8\u6162\n Issue body: \u6211\u662f\u5728\u4e00\u4e2a\u5df2\u7ecfreact+koa+webpack\u642d\u5efa\u597d\u7684\u9879\u76ee\u4e4b\u540e\u5f15\u5165ant design \uff0c\u6211\u901a\u8fc7npm install antd --save\u5b89\u88c5\u4f9d\u8d56\u4e4b\u540e\uff0c\u901a\u8fc7import { Tabs, Card, Select, Input } from 'antd';\u5bfc\u5165\uff0c\u4f46\u662f\u53d1\u73b0\u5bfc\u5165\u4e4b\u540e\u9875\u9762\u52a0\u8f7d\u7684\u7279\u522b\u6162\uff0c\u6c42\u95ee\u5927\u795e\u662f\u4ec0\u4e48\u539f\u56e0\u3002\n Comments: \n Comment 0: Hello @lixiang-king, your issue has been closed because it does not conform to our issue requirements. Please use the [Issue Helper](http://new-issue.ant.design?repo=ant-design) to create an issue, thank you!\n Comment 1: \nIt will be better to write your issue/comment in English, so more people can understand you.\n And this means that more people can help you or benefit from your issue/comment.\n See: https://github.com/ant-design/ant-design/issues/4897",
  "Issue title: How do I compile it?\n Issue body: I downloaded and opened the folder in Visual Studio, but, when I click compile, it doesn't work, I try to run, but nothing...\n Comments: \n Comment 0: Can you provide more details, please?\n Comment 1:![IMG_20191215_100231](https://user-images.githubusercontent.com/9298580/70859277-26e34880-1f22-11ea-871a-1faba173899c.jpg)\r\n\n Comment 2: I have Visual Studio 2019 and.Net Framework installed, but when i download the ZIP archive and opened the Visual Studio, i push in Build in VS and the console show ERROR all time.\n Comment 3: What is this error or errors?\n Comment 4: 1>------ Build started: Project: UnityDarkSkin.Lib, Configuration: Debug|AnyCPU ------\r\n  UnityDarkSkin.Lib -> C:\\Users\\Jormun\\Desktop\\UnityDarkSkin-master\\UnityDarkSkin.Lib\\bin\\Debug\\UnityDarkSkin.Lib.dll\r\n2>------ Build started: Project: UnityDarkSkin, Configuration: Debug|AnyCPU ------\r\n3>------ Build started: Project: UnityDarkSkin.App, Configuration: Debug|AnyCPU ------\r\n  UnityDarkSkin -> C:\\Users\\Jormun\\Desktop\\UnityDarkSkin-master\\UnityDarkSkin\\bin\\Debug\\Unity Dark Skin Console.exe\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\Bin\\Microsoft.Common.CurrentVersion.targets(2106,5): warning MSB3245: Could not resolve this reference. Could not locate the assembly \"Microsoft.WindowsAPICodePack, Version=116.69.203.115, Culture=neutral, PublicKeyToken=8985beaab7ea3f04, processorArchitecture=MSIL\". Check to make sure the assembly exists on disk. If this reference is required by your code, you may get compilation errors.\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\Bin\\Microsoft.Common.CurrentVersion.targets(2106,5): warning MSB3245: Could not resolve this reference. Could not locate the assembly \"Microsoft.WindowsAPICodePack.Shell, Version=116.69.203.115, Culture=neutral, PublicKeyToken=8985beaab7ea3f04, processorArchitecture=MSIL\". Check to make sure the assembly exists on disk. If this reference is required by your code, you may get compilation errors.\r\nC:\\Users\\Jormun\\Desktop\\UnityDarkSkin-master\\UnityDarkSkin.App\\Core\\IOHelper.cs(7,17,7,35): error CS0234: The type or namespace name 'WindowsAPICodePack' does not exist in the namespace 'Microsoft' (are you missing an assembly reference?)\r\nC:\\Users\\Jormun\\Desktop\\UnityDarkSkin-master\\UnityDarkSkin.App\\Core\\IOHelper.cs(29,39,29,59): error CS0246: The type or namespace name 'CommonOpenFileDialog' could not be found (are you missing a using directive or an assembly reference?)\r\n========== Build: 2 succeeded, 1 failed, 0 up-to-date, 0 skipped ==========\n Comment 5: You need manually install WindowsAPICodePack into project, using NuGet package manager:\r\nhttps://www.nuget.org/packages/Microsoft-WindowsAPICodePack-Core/\r\nhttps://www.nuget.org/packages/Microsoft-WindowsAPICodePack-Shell/\r\n\r\nTutorial how to use NuGet: https://dzone.com/articles/install-nuget-packages-in-visual-studio (pic related)\r\n\r\n![Install NuGet packages in Visual Studio5](https://user-images.githubusercontent.com/9298580/70870035-d8748f00-1f9f-11ea-8a6f-cc3a29cf2635.png)\r\n![Install NuGet packages in Visual Studio4](https://user-images.githubusercontent.com/9298580/70870036-d8748f00-1f9f-11ea-9c01-e7c23bc51d9d.png)\r\n\n Comment 6: Thanks now it works perfectly.",
  "Issue title: bug in cse when applying it to a list of long expressions?\n Issue body: @isuruf \r\nlooking at #1338  it seems that this issue popped up already a while ago, but \r\nsince i am currently using the latest dev-version  (116.69.203.115.g398a3f3) i think \r\nthis fix is already implemented in my version.\r\n\r\nhowever, while trying to implement the new symengine-cse functionality \r\n(whose existence i greatly appreciate) i unfortunately found that there seems to be \r\nsome problems remaining when applying cse to lists of large expressions.\r\n\r\nsince i can not directly isolate the problem, i wrote the following minimal example\r\nto show what's happening:\r\n\r\ntxt-file with a list of trigonometric polynomials: [asdf.txt](https://github.com/symengine/symengine/files/1414175/asdf.txt)\r\n\r\n```python\r\nimport numpy as np\r\nfrom symengine import var, cse, sympify, Lambdify\r\nfrom sympy import cse as sympy_cse\r\n\r\n# read list of functions\r\nwith open('PATH TO asdf.txt FILE', 'r') as text_file:\r\n        asdf = text_file.read().splitlines()\r\n\r\n# initialize symbols used in asdf.txt\r\ntheta_0 = var('theta_0')\r\n# convert asdf to symengine expressions\r\nfunlist = sympify(asdf)\r\n# generate a function to directly evaluate the expressions provided in asdf.txt\r\nfuneval = Lambdify(theta_0, funlist)\r\n\r\n# use symengine to perform cse\r\nrepl_symeng, fun_symeng = cse(funlist)\r\n\r\n# use sympy to perform cse\r\nrepl_sympy, fun_sympy = sympy_cse(funlist)\r\n\r\n\r\n# undo symengine cse\r\nnewfun_symeng = fun_symeng\r\nfor n, _ in enumerate(fun_symeng):\r\n    for i in range(len(repl_symeng)):\r\n        newfun_symeng[n] = newfun_symeng[n].xreplace(dict(repl_symeng)) \r\n# generate a function to check for consistency before and after cse\r\nsymeng_funeval = Lambdify(theta_0, newfun_symeng)\r\n\r\n# undo sympy cse\r\nnewfun_sympy = fun_sympy\r\nfor n, _ in enumerate(fun_sympy):\r\n    for i in range(len(repl_sympy)):\r\n        newfun_sympy[n] = newfun_sympy[n].xreplace(dict(repl_sympy)) \r\n# generate a function to check for consistency before and after cse\r\nsympy_funeval = Lambdify(theta_0, newfun_sympy)\r\n\r\n\r\n# calculate the difference before and after cse\r\n# (supposed to be 0.0)\r\ndiff = [(funeval(.5) - sympy_funeval(.5)),\r\n        (funeval(.5) - symeng_funeval(.5))\r\n        ]\r\n\r\n# print the differences\r\nfor i, j in np.array(diff).T:\r\n    print('sympy:', i,'  symeng:', j)\r\n```\r\n\r\nalternatively you can execute this to see the problem symbolically...\r\n\r\n```python\r\nfrom sympy import simplify\r\n\r\ntest = [0]*len(newfun_symeng)\r\nfor i, nf in enumerate(newfun_symeng):\r\n    test[i] = simplify(nf - funlist[i])\r\n\r\n```\r\n**cse of individual list elements:**\r\n...since i already digged a little bit into the problem:\r\napplying cse to each expression individually yields reasonable numerical errors\r\n(sympy still succeeds here and gives exactly 0.0 which i also don't fully get...\r\nis this due to the *c <-> python* conversion of symengine?)\r\n\r\n```python\r\nfor N in range(len(funlist)): \r\n    # generate a function to directly evaluate the N'th expression\r\n    funeval = Lambdify(theta_0, funlist[N])\r\n    # use symengine to perform cse of the N'th expression\r\n    repl_symeng, fun_symeng = cse([funlist[N]])\r\n    \r\n    # undo symengine cse\r\n    newfun_symeng = fun_symeng\r\n    for n, _ in enumerate(fun_symeng):\r\n        for i in range(len(repl_symeng)):\r\n            newfun_symeng[n] = newfun_symeng[n].xreplace(dict(repl_symeng)) \r\n    # generate a function to check for consistency before and after cse\r\n    symeng_funeval = Lambdify(theta_0, newfun_symeng)\r\n    \r\n    print((funeval(.5) - symeng_funeval(.5)))\r\n\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\n Comments: \n Comment 0: `116.69.203.115.g398a3f3` is 23 days old and the PR was merged 21 days ago.\n Comment 1: thanks for the quick reply... that is very good to hear!\r\ni updated symengine yesterday via ` conda install -c symengine/label/dev symengine `\r\nwhat would be the correct way to get a version that includes #1338?\r\n\n Comment 2: @raphaelquast, send a PR like https://github.com/symengine/python-symengine-feedstock/pull/3/files\n Comment 3: @raphaelquast, can you check whether this is fixed or not?\n Comment 4: @iusuruf i did some tests and i can confirm that the behavior of Lambdify and cse is now as expected.\r\nThank you very much for this!\r\n\r\nHowever, the behaviour of LambdifyCSE is still not as expected as can also be seen by running the code in my last comment on symengine/symengine.py#174\r\n\r\nThere might be an error concerning the newly introduced \"order\"-parameter within `LambdifyCSE`\r\nwich can directly be seen by using higher-dimensional input arguments in the above tests as:\r\n\r\n\r\ntxt-file with a list of trigonometric polynomials: [asdf.txt](https://github.com/symengine/symengine/files/1414175/asdf.txt)\r\n```python\r\n\r\nfrom symengine import var, sympify, Lambdify, LambdifyCSE\r\n\r\n# read list of functions\r\nwith open('PATH TO asdf.txt FILE', 'r') as text_file:\r\n        asdf = text_file.read().splitlines()\r\n\r\n# initialize symbols used in asdf.txt\r\ntheta_0 = var('theta_0')\r\n# convert asdf to symengine expressions\r\nfunlist = sympify(asdf)\r\n# generate a function to directly evaluate the expressions provided in asdf.txt\r\nfuneval = Lambdify(theta_0, funlist)\r\n\r\nfuneval = Lambdify(theta_0, funlist, order='F')\r\nfuneval([.4,.5]) \r\n# yealds correct result\r\n\r\nfuneval_CSE = LambdifyCSE(theta_0, funlist, order='F')\r\nfuneval_CSE([.4,.5]) \r\n# ValueError: all the input array dimensions except for the concatenation axis must match exactly\r\n\r\n\r\nfuneval_CSE = LambdifyCSE(theta_0, funlist, order='C')\r\nfuneval_CSE([.4,.5]).T\r\n# yields same result as funeval([.4,.5]) \r\n\r\n```\r\n\r\n\r\nFurthermore (in a different piece of code) even if i provide `order = 'F'` as an argument\r\nto `LambdifyCSE`, I get the error:  `ValueError: C order implies.....`\r\n\r\n\r\nI think this issue can be closed since the issue of LambdifyCSE certainly is not an issue of the\r\ncse functionality used (which is still sympy.cse from the docstring) as the numerical values are correct\r\nand just the shape of the input- and output- arrays is different.\r\n\r\nShould I add this comment to symengine/symengine.py#174 where it would fit better to the discussion? \r\n",
  "Issue title: Specify email address in LoginWith \n Issue body: Hi,\r\n\r\nwhen login with an OpenID provider for the first time, I would like to set email without triggering email verification.\r\nIndeed, `email` is already verified by upstream OpenID provider. \r\n\r\nWe could modify the `loginWith` method :\r\n```\r\nParseUser.loginWith(String provider, AuthData authData, {String email});\r\n```\r\n\r\nThat way, `email` is set during the `POST /parse/users`, and email verification is not triggered.\r\n\r\nAny thoughts about that?\n Comments: \n Comment 0: # In Parse Server REST GUIDE\r\nthere are two methods to register user with third party provider:\r\n\r\n## POST /parse/user\r\nSending only authData in body request, this will create a new user with random username, random password. Other user's properties are ignored.\r\n\r\n## POST /parse/user\r\nSendind json body containing user's properties AND authData property, this will create a new user linked to third party provider, setting all properties set in json body into user's record.\r\n\r\n### Example:\r\n\r\n**Register only with AutData:**\r\n\r\n**Request**\r\n```\r\ncurl --request POST \\\r\n  --url https://{parseServerUrl}/parse/users \\\r\n  --header 'Content-Type: application/json' \\\r\n  --header 'X-Parse-Application-Id: {appId}' \\\r\n  --data '{\"authData\":{\"provider\":{\"access_token\":\"accessToken\",\"id\":\"id\",\"id_token\":\"id_token\"}}}'\r\n```\r\n**Result**\r\ncreated user as json:\r\n```json\r\n{\r\n\"objectId\":\"objectId\",\r\n\"username\":\"generated\",\r\n\"password\":\"*********\",\r\n\"email\": \"undefined\",\r\n\"authData\":{\"authData\":{\"provider\":{\"access_token\":\"accessToken\",\"id\":\"id\",\"id_token\":\"id_token\"}}},\r\n\"emailVerified\": \"undefined\",\r\n\"updatedAt\": \"....\",\r\n\"createdAt\": \".....\",\r\n\"ACL\": \"....\"\r\n}\r\n```\r\n\r\n**Register AutData and User properties:**\r\n\r\n**Request**\r\n```curl\r\ncurl --request POST \\\r\n  --url https://{parseServerUrl}/parse/users \\\r\n  --header 'Content-Type: application/json' \\\r\n  --header 'X-Parse-Application-Id: {appId}' \\\r\n  --data '{\r\n\"username\":\"username\",\r\n\"password\":\"password\",\r\n\t\"email\": \"abigail50@example.org\",\r\n\t\"authData\":{\"google\": {\"access_token\":\"accessToken\", \"id\":\"id\", \"id_token\": \"idToken\"}}\r\n}'\r\n```\r\n**Result**\r\ncreated user as json:\r\n```json\r\n{\r\n\"objectId\":\"objectId\",\r\n\"username\":\"username\",\r\n\"password\":\"*********\",\r\n\"email\": \"abigail50@example.org\",\r\n\"authData\":{\"google\": {\"access_token\":\"accessToken\", \"id\":\"id\", \"id_token\": \"idToken\"}},\r\n\"emailVerified\": \"undefined\",\r\n\"updatedAt\": \"....\",\r\n\"createdAt\": \".....\",\r\n\"ACL\": \"....\"\r\n}\r\n```\r\n\r\n# In Parse SDK \r\n\r\nIn dart/flutter SDK, only **Register with AutData** is possible.\r\nIt can be a problem. In our app, we need to set user's email from google or facebook.\r\nTo do that, we update the user setting email BUT this trigger emailVerification (and we don't want verification for user from third party providers).\r\n\r\nTo respect REST guide, i think we must do something like this:\r\n\r\nParseUser38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5loginWith\r\nShould take an optional params {String email, String username, String password};\r\nThen create a new user with ParseUser.createUser(username, password, email);\r\n\r\nParseUser38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5_loginWith\r\nShould send in body request toJson() and authData, not only authData.\r\n\r\nI'm testing it on our fork, we will do a PR when it's ok for us.\n Comment 1: We are closing issues that have been open for a long time without activity. \r\nThis will make it easier to organize things from now on.\r\nIf the problem persists, please open a new issue.\r\nThanks.\n Comment 2: loginWith('facebook', authData) also gives me an error: `Facebook auth is invalid for this user`. What should I do? I am using the latest version of parse_server_flutter\n Comment 3: The problem is not in the package. \r\n\r\nAndroid or iOS project?\r\n\r\n it is some wrong or not done configuration in the Back4app or in your project.\r\n\r\ncheck all configurations. \n Comment 4: \r\nThe problem is not in the package.\r\n\r\nAndroid or iOS project?\r\n\r\nit is some wrong or not done configuration in the Back4app or in your project.\r\n\r\ncheck all configurations.\n Comment 5: Yes. I think the problem is in back4app loginWith. As far as i know, all\nconfiguration are correct. Their support team is unresponsive at the moment\n\nOn Sat, Aug 14, 2021, 11:59 PM Rodrigo de Souza Marques <\n***@***.***> wrote:\n\n> The problem is not in the package.\n>\n> Android or iOS project?\n>\n> it is some wrong or not done configuration in the Back4app or in your\n> project.\n>\n> check all configurations.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/parse-community/Parse-SDK-Flutter/issues/506#issuecomment-898911723>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AK27WTV5ZN4DJUOBM4OVJALT42HHHANCNFSM4TUS5OZQ>\n>.\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>\n>.\n>\n\n Comment 6: I have two projects set up with Facebook in Back4app working (including the one in the guide)\r\n\r\nDelete Facebook App Id and add again.\r\n\r\nRetest.",
  "Issue title: Bug: the text on image  sliders are synchronized\n Issue body: When you click  text `111` it should trigger `this.yoyo` but it triggers `this.yoyo2`.\r\n\r\nWhen you click  text `222` it should trigger `this.yoyo2` but it triggers `this.yoyo`.\r\n\r\nStrange bug~~ please fix it thank you.\r\n\r\n\r\n\r\n    class App extends React.Component {\r\n\r\n        yoyo() {\r\n          console.log(\"111\")\r\n        }\r\n        yoyo2() {\r\n          console.log(\"222\")\r\n        }\r\n        render() {\r\n\r\n            var settings = {\r\n\r\n            }\r\n\r\n            return (\r\n                  <Slider {...settings} className=\"slider-portal-container\">\r\n                    <div>\r\n                      <h3\u3000className=\"slider-portal-text\" onClick={this.yoyo}>111</h3>\r\n                      <img className=\"slider-portal-img\" src=\"img/slides/slide_1.jpg\" />\r\n                    </div>\r\n\r\n                    <div>\r\n                      <h3\u3000className=\"slider-portal-text\" onClick={this.yoyo2}>222</h3>\r\n\r\n                      <img className=\"slider-portal-img\" src=\"img/slides/slide_2.jpg\" />\r\n                    </div>\r\n                  </Slider>\r\n            )\r\n        }\r\n    }\r\n\r\n\n Comments: \n Comment 0: It could be problem with your css",
  "Issue title: Provide option to export as beamer pdf using pandoc.\n Issue body: In order to enable this option, I need to follow the guidelines for slide formatting in `pandoc`. Here are the key things\nto do in order to make `slidify` decks pandoc compatible\n1. Remove class definitions from slide separators.\n2. Download and replace online images with local images.\n3. Remove content with `iframe`, `script` etc.\n\n Comments: \n Comment 0: Here are some ideas.\n\n``` R\npandoc <- function(..., path = 'pandoc', cmdOnly = FALSE){\n  xargs <- list(...)\n  nxargs <- names(xargs)\n  nxargs <-ifelse(nxargs == \"\", \"\", sprintf(\"--%s=\", nxargs))\n  xcmd  <- paste(sprintf('%s%s', nxargs, xargs), collapse = \" \")\n  if (!cmdOnly) {\n    system(sprintf('%s %s', path, xcmd))\n  } else {\n    xcmd\n  }\n}\n```\n\n``` R\npandoc(write = \"beamer\", \"SLIDES.txt\", output = 'example9.pdf', \n  cmdOnly = FALSE, variable=\"theme:CambridgeUS\")\n```\n",
  "Issue title: demo.js fails on io.js 1.2\n Issue body: Here's my process\r\n\r\n```bash\r\ngit clone davidwagner@example.com:letsencrypt/node-acme.git\r\npushd node-acme\r\nnpm install\r\nnode demo.js\r\n```\r\n\r\nTested working with v0.10.36\r\n\r\nTesting FAILing with v1.2.0\r\n\r\nTests FAIL on both\r\n\r\n```bash\r\nnpm install -g mocha\r\nmocha tests/basic.js\r\n```\r\n\r\n(I'm assuming that's how mocha tests are meant to be run?)\n Comments: \n Comment 0: ```\r\nServer listening on port 4000\r\n~~~> HTTP REQUEST\r\n       Method: POST\r\n       URL: https://localhost:4000/acme/new-authz\r\n       Body: {\"header\":{\"alg\":\"RS256\",\"jwk\":{\"kty\":\"RSA\",\"n\":\"nxX955SBd2WgcG1hthy4zRniGdeJzAlJHgqGzAP7NX9PMfY8H_l2NVWGeWRKaNzV9gVMBO7TC-xTNHNK72AAdqZDNAUDNqQyAwf4EBYUxm5Ymfa8vp9ggXslS5k8ch7NLsZIQJAACCdBSs8XT_S9AqWqNddf5bQN_HOkT3ZBIcKTv7nR0owHzp2zx4_ioVQjSWVYX3jz0Nlg2ZkdaQ9OLfrSkQeFHKnL1Qu2UY_vh4Xe5QNAZ4DEvDzcprmRouS8KfCALojpERNjVoZ3XBamscsppxus6QkzcLkGe3oJRq1KlvV5hZGlQyG3v0iGprtORHX4Ll27vvUHVFWCZQQ07Q\",\"e\":\"AQAB\"}},\"protected\":\"eyJub25jZSI6Ik5sUUZIbWhrZFZEaTV3SzBBblNfT2cifQ\",\"payload\":\"eyJpZGVudGlmaWVyIjp7InR5cGUiOiJkbnMiLCJ2YWx1ZSI6ImxvY2FsaG9zdCJ9fQ\",\"signature\":\"eAjFufvxKN_S0_qPP7hhzTb4Cu42Y9jPJz_niMw7Ml-3RMxg2FTcOmZA_f6wzR1AUjjz-uOWNgPjZ8Ym1z1953Jns0u2aH7KcCMZYxCAPoTRKChCizn_gH2UvwAC4UEapcezXGdRTIczrwnuDt2HlW_tPTTM0lpRDIcGbC-e-k8yzGnt7_HX-QbZTjsHd_av661pq9C3969POLX_tZqxkA_8FhKB9sXJ2uXuBvnrDDF0M6pvPoqgw3CU5GEqYWJTPMBhyQ5hZHwf40afhvx5NQ72yIGdVyptv4FLiFj3aV_STmWzAUUqK8wHdLb6IfhOMjFMIjzdeq6Mc6Z4h9KNUw\"}\r\nevents.js:125\r\n      throw er; // Unhandled 'error' event\r\n            ^\r\nError: socket hang up\r\n    at createHangUpError (_http_client.js:192:15)\r\n    at TLSSocket.socketOnEnd (_http_client.js:270:23)\r\n    at emitNone (events.js:70:20)\r\n    at TLSSocket.emit (events.js:147:7)\r\n    at _stream_readable.js:891:16\r\n    at process._tickCallback (node.js:337:11)\r\n```\n Comment 1: Also fails with node v0.12\n Comment 2: @bifurcation, take a look?\r\n\r\n@coolaj86, just to set expectations correctly, this is a proof of concept implementation and is likely to be spottily maintained. The official client that we plan to launch is at https://github.com/letsencrypt/lets-encrypt-preview. That said, we're happy to accept pull requests on this one since it's useful to have multiple implementations, and some people may want a node version.\n Comment 3: I want the node version.\r\n\r\nI'm working on a home cloud that I'd like to release the same day that Let's Encrypt launches in hopes of being the \"first secure home cloud\", so you'll be seeing more of me. :-D\n Comment 4: Pleased to meet you, and glad Let's Encrypt will help you achieve your goals! You may also be interested to know that the latest version of the server-side software is at https://github.com/letsencrypt/boulder and we keep a generally up-to-date live testing davidwagner@example.com (only accessible by ACME protocol, doesn't serve anything meaningful to web clients). So if you want to test code against that you are welcome to.\n Comment 5: Thanks @jsha! And who do I tell when www.letsencrypt-demo.org appears to be borked? I just ran the demo.js and swapped the local server for the \"real\" one https://github.com/letsencrypt/node-acme/blob/master/demo.js#L5, but here's what I get:\r\n\r\n```\r\n~~~> HTTP REQUEST\r\n       Method: POST\r\n       URL: https://www.letsencrypt-demo.org/acme/new-authz\r\n       Body: {\"header\":{\"alg\":\"RS256\",\"jwk\":{\"kty\":\"RSA\",\"n\":\"4mNUFBI2Xdo_iOyAI4eT7vdtnuhhqshAtuH5M5Xw-7wk5fAzph2mhWN-Q0emEX6hTw8NhhngVQzMJyQiiFIP1NdWzYmBQZ7-5tfqnOIkMmlQmPF1xnPMTRkPSOAZBROBlj8wry8m_uMfIFFozR54lVJ4yMWq9V8Igq7wiOMmg5qezCoGNrfg2lCv3dx9MgKLNb1twzFW0GrrD7_1bys_ZnoDd2ZtCR553pIr-qLYNZugtRyP98fF1fEthZXJ8MYdcNulcUUTBTBoYjRpmO9xX3cZOw2QY5z2ezZM2Wtl1Y0XYtplF1psi_MUYntr817NzCdGHLkQXBlbr21i4fivYQ\",\"e\":\"AQAB\"}},\"protected\":\"eyJub25jZSI6ImVUYW1kaHFLZUljQ1hnc0VCSG9Kd3cifQ\",\"payload\":\"eyJpZGVudGlmaWVyIjp7InR5cGUiOiJkbnMiLCJ2YWx1ZSI6ImxvY2FsaG9zdCJ9fQ\",\"signature\":\"lYD31y8Uko_e-sT_vBWDGF3IBlF6Mk3lKuyfXOnEaGhXk7jelVTUE8XGK9zH-_3hnDM34ulgzxuBbZfgrCyIFqOOZU8nPBS97-kGz9E7Rejic8REFtJG0l36Yy55BxY_wvfhJmBCP_IE-O1Qufer7Se5tJoaWt2_MtI6Z3UNmvm4W5xFSAq3k7tDxt0ydq8wca3qmjrqbYhUiWaSKXKiOsEXyFa29Vce9RZtREls1FPFK1bTNUXKcUX-TqWuKe-PgKSfI2y2a2B12sdo4cIoagdxmuzGwX6OzYb0D5rsk2yY0rnXjFcKuXI7W4QOJMaVF07MbhUkEJxyrUL_EsrZFw\"}\r\n<~~~ HTTP RESPONSE\r\n       Code: 502\r\n       Header: {\"server\":\"nginx/1.4.6 (Ubuntu)\",\"date\":\"Thu, 19 Feb 2015 04:37:17 GMT\",\"content-type\":\"text/html\",\"content-length",
  "Issue title: Weekly Update - July 8th, 2016\n Issue body: https://nodejs.org/en/blog/weekly-updates/weekly-update.2016-07-08/\r\n\r\nhttps://github.com/nodejs/nodejs.org/blob/master/locale/en/blog/weekly-updates/weekly-update.2016-07-08.md\n Comments: \n Comment 0: Closed via #392.",
  "Issue title: docker-standard Cannot connect to the Docker daemon at unix:///var/run/docker.sock.\n Issue body: \r\nI create a vsts-agent container with command:\r\n```\r\n  docker run \\\r\n  -e VSTS_ACCOUNT=... \\\r\n  -e VSTS_TOKEN=.... \\\r\n  -e VSTS_AGENT='$(hostname)-agent' \\\r\n  -e VSTS_POOL=docker \\\r\n  -e VSTS_WORK='/var/vsts/$VSTS_AGENT' \\\r\n  -v /var/vsts:/var/vsts \\\r\n  --restart=always \\\r\n  -d \\\r\n  -it microsoft/vsts-agent:ubuntu-16.04-docker-17.06.0-ce-standard\r\n```\r\nbut when I build an image use this agent,I got some error:\r\n```\r\n2018-04-17T13:53:02.3856500Z ##[section]Starting: Build an image\r\n2018-04-17T13:53:02.4097938Z ==============================================================================\r\n2018-04-17T13:53:02.4110018Z Task         : Docker\r\n2018-04-17T13:53:02.4122104Z Description  : Build, tag, push, or run Docker images, or run a Docker command. Task can be used with Docker or Azure Container registry.\r\n2018-04-17T13:53:02.4134161Z Version      : 0.3.11\r\n2018-04-17T13:53:02.4145990Z Author       : Microsoft Corporation\r\n2018-04-17T13:53:02.4157924Z Help         : [More Information](https://go.microsoft.com/fwlink/?linkid=848006)\r\n2018-04-17T13:53:02.4170025Z ==============================================================================\r\n2018-04-17T13:53:02.8690020Z eb9326ac-2bf6-4dd2-bb4a-a9bab2fa565f exists true\r\n2018-04-17T13:53:03.0318911Z [command]/usr/local/bin/docker build -f /var/vsts/8e5a00f65bff-agent/1/s/WebApplication2/Dockerfile -t 116.69.203.115/demo/ddemo:0.03 -t 116.69.203.115/demo/ddemo /var/vsts/8e5a00f65bff-agent/1/s/WebApplication2\r\n2018-04-17T13:53:03.0334993Z Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\r\n2018-04-17T13:53:03.0420223Z ##[error]Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\r\n2018-04-17T13:53:03.0472064Z ##[error]/usr/local/bin/docker failed with return code: 1\r\n2018-04-17T13:53:03.0709145Z ##[section]Finishing: Build an image\r\n\r\n```\r\n\r\nsomeone kown why?\n Comments: \n Comment 0: @dakale  bingo, thanks\n Comment 1: What is the volume mapping if running on a Windows host?",
  "Issue title: Prevent the deselection\n Issue body: It would be great if I could prevent deselect when I click on an already selected option.\r\n\r\nNew prop\r\n```js\r\ndeselectSelectedOption: {\r\n      type: String,\r\n      default: true\r\n },\r\n```\r\nused in\r\n```js\r\nconst isSelected = this.isSelected(option)\r\n\r\nif (isSelected && deselectSelectedOption) {\r\n     if (key!== 'Tab') this.removeElement(option)\r\n     return\r\n}\r\n```\r\n\n Comments: \n Comment 0: Sorry but there are no plans to introduce such a change. You can control which options you select or deselect by using the corresponding events instead of relying on v-model or at input event. Please take a look at the docs.\n Comment 1: @shentao  - Could you give some insight on how allowEmpty should work? \"Allows to remove all selected values. Otherwise one must be left selected.\" -- But when I select already selected value it sets v-model to null or undefined... isn't this contradicting the documentation?\r\n\r\n\r\n",
  "Issue title: Tasmota 6.5.0 cannot connect to WLAN after LED strip is toggled\n Issue body: ### BUG DESCRIPTION\r\n\r\nTasmota 6.5.0 cannot connect to WLAN after LED strip is toggled\r\n\r\n### REQUESTED INFORMATION\r\n\r\n- [x] Read the [Contributing Guide and Policy](https://github.com/arendst/Sonoff-Tasmota/blob/development/CONTRIBUTING.md) and [the Code of Conduct](https://github.com/arendst/Sonoff-Tasmota/blob/development/CODE_OF_CONDUCT.md)\r\n- [x] Searched the problem in issues (https://github.com/arendst/Sonoff-Tasmota/issues)\r\n- [x] Searched the problem in the wiki (https://github.com/arendst/Sonoff-Tasmota/wiki/Troubleshooting)\r\n- [x] Searched the problem in the forum (https://groups.google.com/d/forum/sonoffusers)\r\n- [ ] Searched the problem in the chat (https://discord.gg/Ks2Kzd4)\r\n- [x] Device used (i.e. Sonoff Basic) : NodeMCU 1.0\r\n- [x] Tasmota binary firmware version number used : sonoff.bin 6.5.0 from GitHub Releases\r\n- [ ] Development IDE - Compiler / Upload tools used : ____ / ____\r\n- [ ] Provide the output of command ``status 0`` :\r\n\r\n\r\n### TO REPRODUCE\r\n\r\n```\r\nme@host:~$ sudo chmod a+rwx /dev/ttyUSB0 ;  sudo '/home/me/Downloads/esptool-2.6/esptool.py' --chip esp8266 --port /dev/ttyUSB0 erase_flash\r\n\r\nme@host:~$ sudo chmod a+rwx /dev/ttyUSB0 ;  sudo '/home/me/Downloads/esptool-2.6/esptool.py' --chip esp8266 --port /dev/ttyUSB0 write_flash 0x00000 '/home/me/Downloads/sonoff.bin'\r\n\r\nsonoff-XXXX access point is visible, I can connect to it, do a network scan, enter my credentials, click Save\r\n\r\nESP reboots, connects to the WLAN\r\n\r\nAfter resetting, Serial port says\r\n\r\n00:00:00 Project sonoff Sonoff Version 6.5.0(release-sonoff)-2_3_0\r\n00:00:00 WIF: Connecting to AP1 h48 in mode 11N as sonoff-XXXX...\r\n00:00:05 WIF: Connected\r\n00:00:05 HTP: Web server active on sonoff-4090 with IP address 192.168.XXX.XXX\r\n\r\nIn the web interface, I select Configuration -> Configure Module -> Generic(18), click Save\r\n\r\nAfter resetting, Serial port says\r\n\r\n00:00:00 Project sonoff Sonoff Version 6.5.0(release-sonoff)-2_3_0\r\n00:00:00 WIF: Connecting to AP1 h48 in mode 11N as sonoff-XXXX...\r\n00:00:05 WIF: Connected\r\n00:00:05 HTP: Web server active on sonoff-4090 with IP address 192.168.XXX.XXX\r\nIn the web interface, I select Configuration -> Configure Module -> D2 GPIO4 -> WS2812 (7), click Save\r\n\r\nAfter resetting, Serial port says\r\n\r\n00:00:00 Project sonoff Sonoff Version 6.5.0(release-sonoff)-2_3_0\r\n00:00:00 WIF: Connecting to AP1 h48 in mode 11N as sonoff-4090...\r\n00:00:05 WIF: Connected\r\n00:00:05 HTP: Web server active on sonoff-4090 with IP address 116.69.203.115\r\nIn the web interface, I click \"Toggle\"\r\n\r\n11:01:06 WIF: Connecting to AP1 h48 in mode 11N as sonoff-4090...\r\n11:01:13 WIF: Connect failed as AP cannot be reached\r\n11:01:13 WIF: Connecting to AP1 h48 in mode 11N as sonoff-4090...\r\n11:01:20 WIF: Connect failed as AP cannot be reached\r\n11:01:21 WIF: Connect failed as AP cannot be reached\r\n11:01:21 WIF: Connecting to AP1 h48 in mode 11N as sonoff-4090...\r\n\r\nFrom thereon, it does not connect to WLAN anymore. Also not after resetting\r\n\r\nAt this point, I can only revive functionality by\r\n\r\nme@host:~$ sudo chmod a+rwx /dev/ttyUSB0 ;  sudo '/home/me/Downloads/esptool-2.6/esptool.py' --chip esp8266 --port /dev/ttyUSB0 erase_flash\r\n\r\nand reflashing new firmware.\r\n```\n Comments: \n Comment 0: could be power issue. What if you disconnect the strip and reboot? Still no wlan?\n Comment 1: Yes, the same happens when the strip is not stacy51@example.org.\n Comment 2: Please post `status 0`\n Comment 3: 22:05:35 RSL: stat/sonoff/STATUS = {\"Status\":{\"Module\":52,\"FriendlyName\":[\"Sonoff\"],\"Topic\":\"sonoff\",\"ButtonTopic\":\"0\",\"Power\":0,\"PowerOnState\":3,\"LedState\":1,\"SaveData\":1,\"SaveState\":1,\"SwitchTopic\":\"0\",\"SwitchMode\":[0,0,0,0,0,0,0,0],\"ButtonRetain\":0,\"SwitchRetain\":0,\"SensorRetain\":0,\"PowerRetain\":1}}\r\n22:05:35 RSL: stat/sonoff/STATUS1 = {\"StatusPRM\":{\"Baudrate\":115200,\"GroupTopic\":\"sonoffs\",\"OtaUrl\":\"http://thehackbox.org/tasmota/release/sonoff.bin\",\"RestartReason\":\"Software/System restart\",\"Uptime\":\"0T00:04:00\",\"StartupUTC\":\"2019-05-18T21:01:35\",\"Sleep\":50,\"CfgHolder\":4617,\"BootCount\":4,\"SaveCount\":19,\"SaveAddress\":\"F9000\"}}\r\n22:05:35 RSL: stat/sonoff/STATUS2 = {\"StatusFWR\":{\"Version\":\"6.5.0(sonoff)\",\"BuildDateTime\":\"2019-03-24T13:45:27\",\"Boot\":4,\"Core\":\"2_3_0\",\"SDK\":\"1.5.3(aec24ac9)\"}}\r\n22:05:35 RSL: stat/sonoff/STATUS3 = {\"StatusLOG\":{\"SerialLog\":2,\"WebLog\":2,\"SysLog\":0,\"LogHost\":\"\",\"LogPort\":514,\"SSId\":[\"h48\",\"\"],\"TelePeriod\":300,\"Resolution\":\"558180C0\",\"SetOption\":[\"00008029\",\"280500000100000000000000000000000000\",\"00000000\"]}}\r\n22:05:35 RSL: stat/sonoff/STATUS4 = {\"StatusMEM\":{\"ProgramSize\":447,\"Free\":556,\"Heap\":20,\"ProgramFlashSize\":1024,\"FlashSize\":1024,\"FlashChipId\":\"144051\",\"FlashMode\":3,\"Features\":[\"00000809\",\"0F402390\",\"00048000\",\"00000096\",\"000000C0\"]}}\r\n22:05:35 RSL: stat/sonoff/STATUS5 = {\"StatusNET\":{\"Hostname\":\"sonoff-2246\",\"IPAddress\":\"192.168.XXX.XXX\",\"Gateway\":\"116.69.203.115\",\"Subnetmask\":\"116.69.203.115\",\"DNSServer\":\"192.168.XXX.XXX\",\"Mac\":\"60:01:94:XX:XX:XX\",\"Webserver\":2,\"WifiConfig\":2}}\r\n22:05:35 RSL: stat/sonoff/STATUS6 = {\"StatusMQT\":{\"MqttHost\":\"\",\"MqttPort\":1883,\"MqttClientMask\":\"DVES_%06X\",\"MqttClient\":\"DVES_XXXXXX\",\"MqttUser\":\"DVES_USER\",\"MqttCount\":0,\"MAX_PACKET_SIZE\":1000,\"KEEPALIVE\":15}}\r\n22:05:35 RSL: stat/sonoff/STATUS7 = {\"StatusTIM\":{\"UTC\":\"Sat May 18 21:05:35 2019\",\"Local\":\"Sat May 18 22:05:35 2019\",\"StartDST\":\"Sun Mar 31 02:00:00 2019\",\"EndDST\":\"Sun Oct 27 03:00:00 2019\",\"Timezone\":\"+01:00\",\"Sunrise\":\"05:04\",\"Sunset\":\"20:28\"}}\r\n22:05:35 RSL: stat/sonoff/STATUS9 = {\"StatusPTH\":{\"PowerDelta\":80,\"PowerLow\":0,\"PowerHigh\":0,\"",
  "Issue title: Python 3.9.3 : \"TypeError: Multiple inheritance with NamedTuple is not supported\"\n Issue body: Hello,\r\n\r\nI'm using Python 3.9.3 on ArchLinux and launching snscrape is met with the following:\r\n\r\n`Traceback (most recent call last):\r\n  File \"/usr/bin/snscrape\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/lib/python3.9/site-packages/snscrape/cli.py\", line 224, in main\r\n    args = parse_args()\r\n  File \"/usr/lib/python3.9/site-packages/snscrape/cli.py\", line 159, in parse_args\r\n    import snscrape.modules\r\n  File \"/usr/lib/python3.9/site-packages/snscrape/modules/__init__.py\", line 15, in <module>\r\n    _import_modules()\r\n  File \"/usr/lib/python3.9/site-packages/snscrape/modules/__init__.py\", line 12, in _import_modules\r\n    module = importlib.import_module(moduleName)\r\n  File \"/usr/lib/python3.9/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/usr/lib/python3.9/site-packages/snscrape/modules/telegram.py\", line 12, in <module>\r\n    class TelegramPost(typing.NamedTuple, snscrape.base.Item):\r\n  File \"/usr/lib/python3.9/typing.py\", line 1881, in _namedtuple_mro_entries\r\n    raise TypeError(\"Multiple inheritance with NamedTuple is not supported\")\r\nTypeError: Multiple inheritance with NamedTuple is not supported`\r\n\r\nAdding the \"-vv\" and \"--dump-locals\" switches does not change this output. By searching the web it seems this is an issue with modules not supporting python 3.9, can you confirm? Any quick workaround, or is my only option a venv on python 3.8?\r\n\r\nThanks a lot!\n Comments: \n Comment 0: Duplicate of #111\r\n\r\nThis is fixed in the development version. The release 0.3.4 does indeed not support Python 3.9. I hope to find some time soon to finish a few loose ends and release a new version. Until then, you can either use the dev version or the release with Python 3.6 to 3.8.",
  "Issue title: Polygon holes filling is tricky\n Issue body: It seems that adding **-Ph** to headers is not enough. It needs that the hole polygon has an orientation contrary to its parent. But that's not all, if origin is not at LowerLeft (for rectangles) wholes are painted too regardless if its orientation.\r\n\r\n```\r\ncat << EOF > quads.dat\r\n> -Gred CCW\r\n0  0\r\n5  0\r\n5  10\r\n0  10\r\n0  0\r\n> -Ph  CW\r\n2  1\r\n2  3\r\n4  3\r\n4  1\r\n2  1\r\n> -Ph  CCW\r\n2  4\r\n4  4\r\n4  6\r\n2  6\r\n2  4\r\n> -Ph CCW origin TopLeft\r\n2  9\r\n2  7\r\n4  7\r\n4  9\r\n2  9\r\n> CW -Gblue\r\n5  0\r\n5  10\r\n10 10\r\n10 0\r\n5  0\r\n> -Ph  CW\r\n7  1\r\n7  3\r\n9  3\r\n9  1\r\n7  1\r\n> -Ph  CCW\r\n7  4\r\n9  4\r\n9  6\r\n7  6\r\n7  4\r\nEOF\r\ngmt plot quads.dat -JX12c -Ba2f1WSen -R-0.5/10.5/-0.5/10.5 -Gred -W1p -png map\r\n```\r\n![map](https://user-images.githubusercontent.com/537321/79698965-397cde00-8284-11ea-8875-b8645a86655c.png)\r\n\n Comments: \n Comment 0: Yes, I think that is true.  Software that writes polygons with holes will ensure the orientation is consistent (e.g., inside is to the left as you walk around the perimeter).  I am pretty sure shapefiles do this correctly.   We do not reverse holes as we assume they are placed correctly.  if you ensure this orientation, does it then work?\n Comment 1: Curiously there was a thread in GDAL list about holes and Even said that GDAL does not care about the parent-child orietation. And PostGIS doesn't care either (and plots holes correctly).\r\n\r\nBut aside from the orientation there seems to be another issue that looks like a bug. Third square on reds should be transparent bit it's not because origin is not the same (TopLeft instead of BottomLeft).\n Comment 2: The 3rd square is CCW like the parent so no hole.\n Comment 3: If we must, we have code in gmtspatial to determine handedness and could reverse holes etc.\n Comment 4: True about 3rd. I got lost with so many looks at the Clock.\r\nI thought on that ``gmtspatial`` option. Worth trying (at polygon plotting time) though I'm curious in what will happen from Julia.  The thing is, for those cases, from Julia I don't make a copy of data coming from GMT, just a direct memory access. Don't remember what happens when same data is sent back to GMT and it changes it because of bad handedness (kind of 1D transpose).\n Comment 5: It seems we can bury something deep in gmt_geo_polygons.  It plots the parent polygon (the usual case is to plot a single polygon), but then we loop over all the holds that might follow.  I think we can (a) detect that there are holes, (b) then determine the handedness of the parent, and (c) get handedness of each hold and reverse if matches the parent.  I will give that a try.",
  "Issue title: ErrorException with message 'Unbinding $this of closure is deprecated' On php7.4\n Issue body:![image](https://user-images.githubusercontent.com/20262949/70022607-b5c19e00-15cf-11ea-9009-bfee599bf016.png)\r\n\n Comments: \n Comment 0: I'm not able to reproduce this, and I can't tell from current code where we might be causing it. Do you mind pasting the output of `composer info`? That might help track it down.\n Comment 1: ```\r\nvagrant@homestead:~/code/school$ composer info\r\nbarryvdh/laravel-ide-helper           v2.6.5     Laravel IDE Helper, generates correct PHPDocs for all Facade classes, to improve auto-completion.\r\nbarryvdh/reflection-docblock          v2.0.6\r\ncomposer/ca-bundle                    1.2.4      Lets you find a path to the system CA bundle, and includes a fallback to the Mozilla CA bundle.\r\ncomposer/composer                     1.9.1      Composer helps you declare, manage and install dependencies of PHP projects. It ensures you have the right stack everywhere.\r\ncomposer/semver                       1.5.0      Semver library that offers utilities, version constraint parsing and validation.\r\ncomposer/spdx-licenses                1.5.2      SPDX licenses list and validation library.\r\ncomposer/xdebug-handler               1.4.0      Restarts a process without Xdebug.\r\ndnoegel/php-xdg-base-dir              0.1        implementation of xdg base directory specification for php\r\ndoctrine/cache                        1.10.0     PHP Doctrine Cache library is a popular cache implementation that supports many different drivers such as redis, memcache, apc, mongodb...\r\ndoctrine/dbal                         v2.10.0    Powerful PHP database abstraction layer (DBAL) with many features for database schema introspection and management.\r\ndoctrine/event-manager                1.1.0      The Doctrine Event Manager is a simple PHP event system that was built to be used with the various Doctrine projects.\r\ndoctrine/inflector                    1.3.1      Common String Manipulations with regard to casing and singular/plural rules.\r\ndoctrine/instantiator                 1.3.0      A small, lightweight utility to instantiate objects in PHP without invoking their constructors\r\ndoctrine/lexer                        1.2.0      PHP Doctrine Lexer parser library that can be used in Top-Down, Recursive Descent Parsers.\r\ndragonmantank/cron-expression         v2.3.0     CRON for PHP: Calculate the next or previous run date and determine if a CRON expression is due\r\negulias/email-validator               2.1.11     A library for validating emails against several RFCs\r\nerusev/parsedown                      1.7.3      Parser for Markdown.\r\nfacade/flare-client-php               1.3.0      Send PHP errors to Flare\r\nfacade/ignition                       1.13.0     A beautiful error page for Laravel applications.\r\nfacade/ignition-contracts             1.0.0      Solution contracts for Ignition\r\nfideloper/proxy                       4.2.1      Set trusted proxies for Laravel\r\nfilp/whoops                           2.5.0      php error handling for cool kids\r\nfzaninotto/faker                      v1.9.0     Faker is a PHP library that generates fake data for you.\r\nhamcrest/hamcrest-php                 v2.0.0     This is the PHP port of Hamcrest Matchers\r\njakub-onderka/php-console-color       v0.2\r\njakub-onderka/php-console-highlighter v0.4       Highlight PHP code in terminal\r\njustinrainbow/json-schema             5.2.9      A library to validate a json schema.\r\nlaravel/framework                     v6.6.0     The Laravel Framework.\r\nlaravel/telescope                     v2.1       An elegant debug assistant for the Laravel framework.\r\nlaravel/tinker                        v2.0.0     Powerful REPL for the Laravel framework.\r\nlcobucci/jwt                          3.3.1      A simple library to work with JSON Web Token and JSON Web Signature\r\nleague/flysystem                      1.0.57     Filesystem abstraction: Many filesystems, one API.\r\nmockery/mockery                       1.3.0      Mockery is a simple yet flexible PHP mock object framework\r\nmonolog/monolog                       2.0.1      Sends your logs to files, sockets, inboxes, databases and various web services\r\nmoontoast/math                        1.1.2      A mathematics library, providing functionality for large numbers\r\nmyclabs/deep-copy                     1.9.3      Create deep copies (clones) of your objects\r\nnamshi/jose                           7.2.3      JSON Object Signing and Encryption library for PHP.\r\nnesbot/carbon                         2.27.0     An API extension for DateTime that supports 281 different languages.\r\nnikic/php-parser                      v4.3.0     A PHP parser written in PHP\r\nnunomaduro/collision                  v3.0.1     Cli error handling for console/command-line PHP applications.\r\nopis/closure                          3.5.1      A library that can be used to serialize closures (anonymous functions) and arbitrary objects.\r\nparagonie/random_compat               v9.99.99   PHP 5.x polyfill for random_bytes() and random_int() from PHP 7\r\nphar-io/manifest                      1.0.3      Component for reading phar.io manifest information from a PHP Archive (PHAR)\r\nphar-io/version                       2.0.1      Library for handling version information and constraints\r\nphpdocumentor/reflection-common       2.0.0      Common reflection classes used by phpdocumentor to reflect the code structure\r\nphpdocumentor/reflection-docblock     4.3.2      With this component, a library can provide support for annotations via DocBlocks or otherwise retrieve information that is embedded in a...\r\nphpdocumentor/type-resolver           1.0.1      A PSR-5 based resolver of Class names, Types and Structural Element Names\r\nphpoption/phpoption                   1.6.0      Option Type for PHP\r\nphpspec/prophecy                      1.9.0      Highly opinionated mocking framework for PHP 5.3+\r\nphpunit/php-code-coverage             7.0.10     Library that provides collection, processing, and rendering functionality for PHP code coverage information.\r\nphpunit/php-file-iterator             2.0.2      FilterIterator implementation that filters files based on a list of suffixes.\r\nphpunit/php-text-template             1.2.1      Simple template engine.\r\nphpunit/php-timer                     2.1.2      Utility class for timing\r\nphpunit/php-token-stream              3.1.1      Wrapper around PHP's tokenizer extension.\r\nphpunit/phpunit                       8.4.3      The PHP Unit Testing framework.\r\npsr/container                         1.0.0      Common Container Interface (PHP FIG PSR-11)\r\npsr/log                               1.1.2      Common interface for logging libraries\r\npsr/simple-cache                      1.0.1      Common interfaces for simple caching\r\npsy/psysh                             v0.9.11    An interactive shell for modern PHP.\r\nramsey/uuid                           3.9.1      Formerly rhumsaa/uuid. A PHP 5.4+ library for generating RFC 4122 version 1, 3, 4, and 5 universally unique identifiers (UUID).\r\nscrivo/highlight.php                  v116.69.203.115 Server side syntax highlighter that supports 185 languages. It's a PHP port of highlight.js\r\nsebastian/code-unit-reverse-lookup    1.0.1      Looks up which function or method a line of code belongs to\r\nsebastian/comparator                  3.0.2      Provides the functionality to compare PHP values for equality\r\nsebastian/diff                        3.0.2      Diff implementation\r\nsebastian/environment                 4.2.3      Provides functionality to handle HHVM/PHP environments\r\nsebastian/exporter                    3.1.2      Provides the functionality to export PHP variables for visualization\r\nsebastian/global-state                3.0.0      Snapshotting of global state\r\nsebastian/object-enumerator           3.0.3      Traverses array structures and object graphs to enumerate all referenced objects\r\nsebastian/object-reflector",
  "Issue title: how to make two columns as default sorting columns in primeng datatable\n Issue body: how to make two columns as default sorting columns in primeng datatable\r\n<p-dataTable [value]=\"itemList\" [emptyMessage]=\"itemErrorMessage\" scrollable=\"true\"\t\r\n\t\t[rows]=\"50\" [rowsPerPageOptions]=\"[50, 75, 100]\" [pageLinks]=\"3\" [multiSortMeta]=\"[{field: 'createDate', order: -1}, {field: 'ID', order: -1}]\"\r\n\t\t[paginator]=\"itemList.length > 50\" [responsive]=\"true\" [scrollHeight]=\"scrollableValue\" sortMode=\"multiple\" (onSort)=\"changeSort($event)\">\r\nAnyone help me!!!!!!!!!\n Comments: \n Comment 0: Please use forum for support requests, you need to use multiSortMeta, documentation has information already.",
  "Issue title: Manually scanning app data\n Issue body: Since this app exists I always had the problem that after running `occ preview:pre-generate` my photos still seemed to load very slowly (via the gallery app and the Android app). During this time the CPU load on the server was also quite high, as if the previews were created for the first time.\r\n\r\nIf i opened the folder in the browser via the files app all previews loaded fast and CPU load was low -> pregenerated previews were used I guess.\r\nI always assumed that this behaviour was normal and my server simply didn't have enough resources to show the previews quickly.\r\n\r\nHowever, now I found a workaround:\r\n\r\nI run `occ file:scan-app-data` after `occ preview:pre-generate` everything is fast and CPU load stays relatively low. My Nextcloud and the Android app are now finally usable to watch large photo collections (>200GB) :tada: :smile: \r\n\r\nTherefore I have updated my cron job to:\r\n```\r\n0    6    *    *   * php -f /var/www/html/occ preview:pre-generate\r\n0    7    *    *   * php -f /var/www/html/occ file:scan-app-data\r\n```\r\n\r\nIs this behaviour excpected? Maybe someone can reproduce this too?\r\nIs it a good idead to run `occ file:scan-app-data` regularly or are the any downsides?\n Comments: \n Comment 0: Is there any update on this?\r\nI tried to run `occ file:scan-app-data` and my database size increased by 20%. Even after running `occ file:cleanup` it returned that there are no orphaned files.\r\n\r\nI never added anything manually to my Nextcloud so surely all those new entries must come from this app.",
  "Issue title: reports of crashes when importing wallet backup while blockchain is not re-synced\n Issue body: and people don't realize your balance won't show, etc. need to address this\n\n Comments: \n Comment 0: Related to: #514\n\n Comment 1: How can we fix this?  I suggest on mainnet, disallow importing wallet backups when the chain is out of date until the crashing and UI issues are resolved.\n\nWe need to investigate the crashes.  I'm thinking I'll try to see if I can reproduce the crash with testnet or unit tests.\n\n Comment 2: I'm not sure exactly what this issue is referring to, but there was a bug of about this vintage where importing a wallet while syncing crashed.  This was caused by:\n- wallet starts to run.  after some time, it calls 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5yield() to allow other tasks to run\n- a new block comes in from the network.  \n- chain_db notifies wallet that there's a new block\n- wallet starts scanning the new block, not realizing it was already in the process of scanning.\n\nf80db8fb4ac358038d40cd7a70d102c841608639 and 570869a3789109471bea77878eac3e5926ef8aa3 may be fixes for the crash (although I seem to recall Dan L had a hand in the fix).\n\nI don't have a clue about the \"and people don't realize your balance won't show\" part of this issue though.\n\n Comment 3: The only way to deal with balances not showing during syncing is to move to a thin-client style architecture where your balances and keys are stored on a server for you somewhere. I'd say that's not a serious issue for full nodes.\n\n Comment 4: Okay.  I think this issue is closeable, then.\n",
  "Issue title: Questions about purpose\n Issue body: Forgive me if this is the wrong place to ask..\r\n\r\nI've not quite wrapped by head around the purpose of this project. Is the purpose to replace the stream deck software? (Or do both work together?) I understand that installation the stream deck software is a requirement for this software - but does it need to be running?  If it is a replacement then would that mean that I lose the screen timeout and folder functionality?\r\n\r\nWhat I was hoping that with this software was a couple of things that the out-of-the-box software cannot do. Specifically:\r\n\r\n1. Change button images and functionality dynamically (meaning... on the click of a button I want to launch a program, and then reset the button to a disabled state. In the disabled state another button click would be ignored.\r\n2. Display a status (meaning... every few seconds some program I would write would change the button to display a status [CPU temperature perhaps])\r\n3. Move the position of the up-one-folder button (or change it to a set of buttons that can cycle through different modes)\r\n4. Change the display based on a custom event fired from some software I would write\r\n\r\nI hope that makes since. Thank you!\n Comments: \n Comment 0: Hi there,\r\n\r\nThis is a common question. You can find the answer you're looking for right at the top of our [README](https://github.com/Lange/node-elgato-stream-deck/blob/master/README.md):\r\n\r\n> \u2757 Please note that `node-elgato-stream-deck` is NOT a standalone application. It is not something you download and run on its own. It is not an alternative to the [official Stream Deck program provided by Elgato](https://www.elgato.com/en/gaming/downloads). Instead, `node-elgato-stream-deck` is a code library, which developers can use to make their own applications which interface with the Stream Deck.\r\n\n Comment 1: I've [updated the README](https://github.com/Lange/node-elgato-stream-deck/commit/2b979931c81736daa8469b603795d7abc7d8d377) to further clarify this, as it seems like a number of people are finding this library on google and mistakenly thinking it is a standalone replacement for the official Stream Desk software.\r\n\r\nI apologize for any frustration you may have experienced while figuring out what this library is and is not. If it's any consolation, you are not the first person to have this happen:\r\n\r\n- https://github.com/Lange/node-elgato-stream-deck/issues/44\r\n- https://github.com/Lange/node-elgato-stream-deck/issues/33\r\n",
  "Issue title: warning when creating a module in namespace \"ceylon\" or \"java\"\n Issue body: The spec reserves these namespaces. If we don't want everyone to go calling their modules \"ceylon\", we should explicitly discourage them from doing it. (And in the IDE, the New Ceylon Module wizard should give the same warning.)\n\n Comments: \n Comment 0: Done.\n\n Comment 1: It should be possible to disable the warning though. It is annoying to open up the sdk module an get the warnings on module and package files, fully knowing that in this particular case the warning is wrong. \n",
  "Issue title: ERROR   General  (kmer_coverage_model.cpp   : 187) Invalid kmer coverage histogram, make sure that the coverage is indeed uniform\n Issue body: ### Description of bug\n\n== Error ==  system call for: \"['/gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/spades-core', '/gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.spades/K99/configs/config.info']\" finished abnormally, OS return value: 21\n\n### spades.log\n\n\r\n== Warning ==  No assembly mode was specified! If you intend to assemble high-coverage multi-cell/isolate data, use '--isolate' option.\r\n\r\n\r\nCommand line:./spades.py\t-o\t/gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.spades\t-t\t24\t-m\t20\t-k\t99,111,127\t-1\t/gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.S24_DKDL210000040-1a_HFL3FCCX2_L6_1_forward_paired.fq.gz.SSU.1.fq\t-2\t/gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.S24_DKDL210000040-1a_HFL3FCCX2_L6_1_forward_paired.fq.gz.SSU.2.fq\t\r\n\r\nSystem information:\r\n  SPAdes version: 3.15.3\r\n  Python version: 2.7.5\r\n  OS: Linux-3.10.0-1160.45.1.el7.x86_64-x86_64-with-redhat-7.9-Nitrogen\r\n\r\nOutput dir: /gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.spades\r\nMode: read error correction and assembling\r\nDebug mode is turned OFF\r\n\r\nDataset parameters:\r\n  Standard mode\r\n  For multi-cell/isolate data we recommend to use '--isolate' option; for single-cell MDA data use '--sc'; for metagenomic data use '--meta'; for RNA-Seq use '--rna'.\r\n  Reads:\r\n    Library number: 1, library type: paired-end\r\n      orientation: fr\r\n      left reads: ['/gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.S24_DKDL210000040-1a_HFL3FCCX2_L6_1_forward_paired.fq.gz.SSU.1.fq']\r\n      right reads: ['/gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.S24_DKDL210000040-1a_HFL3FCCX2_L6_1_forward_paired.fq.gz.SSU.2.fq']\r\n      interlaced reads: not specified\r\n      single reads: not specified\r\n      merged reads: not specified\r\nRead error correction parameters:\r\n  Iterations: 1\r\n  PHRED offset will be auto-detected\r\n  Corrected reads will be compressed\r\nAssembly parameters:\r\n  k: [99, 111, 127]\r\n  Repeat resolution is enabled\r\n  Mismatch careful mode is turned OFF\r\n  MismatchCorrector will be SKIPPED\r\n  Coverage cutoff is turned OFF\r\nOther parameters:\r\n  Dir for temp files: /gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.spades/tmp\r\n  Threads: 24\r\n  Memory limit (in Gb): 20\r\n\r\n\r\n======= SPAdes pipeline started. Log can be found here: /gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.spades/spades.log\r\n\r\n/gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.S24_DKDL210000040-1a_HFL3FCCX2_L6_1_forward_paired.fq.gz.SSU.2.fq: max reads length: 150\r\n/gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.S24_DKDL210000040-1a_HFL3FCCX2_L6_1_forward_paired.fq.gz.SSU.1.fq: max reads length: 150\r\n\r\nReads length: 150\r\n\r\n\r\n===== Before start started. \r\n\r\n\r\n===== Read error correction started. \r\n\r\n\r\n===== Read error correction started. \r\n\r\n\r\n== Running: /gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/spades-hammer /gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.spades/corrected/configs/config.info\r\n\r\n  0:00:00.000     1M / 11M   INFO    General                 (main.cpp                  :  75)   Starting BayesHammer, built from N/A, git revision N/A\r\n  0:00:00.004     1M / 11M   INFO    General                 (main.cpp                  :  76)   Loading config from /gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.spades/corrected/configs/config.info\r\n  0:00:00.008     1M / 11M   INFO    General                 (main.cpp                  :  78)   Maximum # of threads to use (adjusted due to OMP capabilities): 24\r\n  0:00:00.011     1M / 11M   INFO    General                 (memory_limit.cpp          :  48)   Memory limit set to 20 Gb\r\n  0:00:00.015     1M / 11M   INFO    General                 (main.cpp                  :  86)   Trying to determine PHRED offset\r\n  0:00:00.020     1M / 11M   INFO    General                 (main.cpp                  :  92)   Determined value is 33\r\n  0:00:00.022     1M / 11M   INFO    General                 (hammer_tools.cpp          :  38)   Hamming graph threshold tau=1, k=21, subkmer positions = [ 0 10 ]\r\n  0:00:00.026     1M / 11M   INFO    General                 (main.cpp                  : 113)   Size of aux. kmer data 24 bytes\r\n     === ITERATION 0 begins ===\r\n  0:00:00.030     1M / 11M   INFO    General                 (kmer_index_builder.hpp    : 243)   Splitting kmer instances into 16 files using 24 threads. This might take a while.\r\n  0:00:00.035     1M / 11M   INFO    General                 (file_limit.hpp            :  32)   Open file limit set to 1024\r\n  0:00:00.039     1M / 11M   INFO    General                 (kmer_splitter.hpp         :  93)   Memory available for splitting buffers: 0.277776 Gb\r\n  0:00:00.043     1M / 11M   INFO    General                 (kmer_splitter.hpp         : 101)   Using cell size of 2330156\r\n  0:00:00.179  7681M / 7681M INFO   K-mer Splitting          (kmer_data.cpp             :  97)   Processing /gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.S24_DKDL210000040-1a_HFL3FCCX2_L6_1_forward_paired.fq.gz.SSU.1.fq\r\n  0:00:00.214  7681M / 7681M INFO   K-mer Splitting          (kmer_data.cpp             :  97)   Processing /gpfs0/biores/users/tarun/miniconda3/envs/pf/bin/S24.S24_DKDL210000040-1a_HFL3FCCX2_L6_1_forward_paired.fq.gz.SSU.2.fq\r\n  0:00:00.257  7681M / 7681M INFO   K-mer Splitting          (kmer_data.cpp             : 112)   Total 3370 reads processed\r\n  0:00:00.261",
  "Issue title: Downloading ryan75@example.net%\n Issue body: I wanted to try Legendary but every game i install gets ryan75@example.net%. \r\ni get the error: {FileWorker}} WARNIGNG: Writer queue empty!\r\n\r\ncan someone help me? that wil be amazing.\r\n\r\nrunning:\r\nOS: Pop!_os 20.04\r\nKernel: 5.4.0-7642-generi\n Comments: \n Comment 0: What game are you installing?\r\n\r\nTry running `legendary -v install <your app name> --dlm-debug` and then share that log on pastebin/github gists or whatever. That will include debug information to help me figure this out. Also make sure you're on the latest version.\n Comment 1: On Mon, Sep 07, 2020 at 05:21:29PM -0700, Rodney wrote:\n> What game are you installing?\n> \n> Try running `legendary -v install <your app name> --dlm-debug` and then share that log on pastebin/github gists or whatever. That will include debug information to help me figure this out. Also make sure you're on the latest version.\n> \n> -- \n> You are receiving this because you authored the thread.\n> Reply to this email directly or view it on GitHub:\n> https://github.com/derrod/legendary/issues/92#issuecomment-688551508\n\n\nThe game im installing is Just cause 4 (Kakopo).\nI used legendary -v install kakopo --dlm-debug.\n\n\nthis is the output: \n[LGDLFS] DEBUG: Failed to load installed game data: FileNotFoundError(2, 'No such file or directory')\n[Core] INFO: Trying to re-use existing login session...\n[Core] DEBUG: Set locale to en-US\n[cli] INFO: Preparing download...\n[LGDLFS] DEBUG: Failed to load installed game data: FileNotFoundError(2, 'No such file or directory')\n[Core] DEBUG: Downloading manifest from https://download.epicgames.com/Builds/Org/o-7petn7mrlk8g86ktqm7uglcr7lfaja/64943f5c28484fcaa462c4c134f81b61/default/YVSFhrTIwcpAbOGpJ0irAt1fqimZXw.manifest?Policy=eyJTdGF0ZW1lbnQiOiBbeyJSZXNvdXJjZSI6IipCdWlsZHMvT3JnL28tN3BldG43bXJsazhnODZrdHFtN3VnbGNyN2xmYWphLzY0OTQzZjVjMjg0ODRmY2FhNDYyYzRjMTM0ZjgxYjYxL2RlZmF1bHQvWVZTRmhyVEl3Y3BBYk9HcEowaXJBdDFmcWltWlh3Lm1hbmlmZXN0IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNTk5NTU3MDkzfSwiSXBBZGRyZXNzIjp7IkFXUzpTb3VyY2VJcCI6IjAuMC4wLjAvMCJ9fX1dfQ__&Signature=H4uSd7x1dGfjt2uqpwyDPqnSEYyCkP3Qixc9Cs8ep8wfIEa1sbjdnt4Ie6HTYES50cyPrJgtcheIjoBJha8oYboXJ3J1jaaln1fcPUgVmJ09YanY--5CaZBEmdLEJVES50atBmXK-0TZgzhEOnOAjmmlOL3pxWWprCVRu90sM4WG07UXKuNqO4-bwAYxfTRJvHIo3rgfSwaPOeme9MJeqd7vldZgN4eeEyqOUVbb6jU9~ulvaQqLR-f9SX-mFMu2fOnRKeYic6EOivIe6clMyTSvSm-Ofa8KbVwUXTovhX9pn2Kd2B4nTPtrKcQUyfhOpDpCNGFH92-nUZaehn9ang__&Key-Pair-Id=APKAI5CNFPJPTPYZISXQ...\n[Core] INFO: Parsing game manifest...\n[Core] DEBUG: Base urls: ['https://download.epicgames.com/Builds/Org/o-7petn7mrlk8g86ktqm7uglcr7lfaja/64943f5c28484fcaa462c4c134f81b61/default', 'https://download2.epicgames.com/Builds/Org/o-7petn7mrlk8g86ktqm7uglcr7lfaja/64943f5c28484fcaa462c4c134f81b61/default', 'https://download3.epicgames.com/Builds/Org/o-7petn7mrlk8g86ktqm7uglcr7lfaja/64943f5c28484fcaa462c4c134f81b61/default', 'https://download4.epicgames.com/Builds/Org/o-7petn7mrlk8g86ktqm7uglcr7lfaja/64943f5c28484fcaa462c4c134f81b61/default', 'https://epicgames-download1.akamaized.net/Builds/Org/o-7petn7mrlk8g86ktqm7uglcr7lfaja/64943f5c28484fcaa462c4c134f81b61/default']\n\nI hope this is enough information.\n\nThanks.\n\n\n Comment 2: No, please post the *full* output.",
  "Issue title: File Preview is Locking the File Preventing Moving Operation\n Issue body: ### Microsoft PowerToys version\n\n0.56.1\n\n### Running as admin\n\n- [X] Yes\n\n### Area(s) with issue?\n\nDeveloper file preview\n\n### Steps to reproduce\n\nOpen 2 different windows explorer windows (eg c:\\project1  & c:\\project2)\r\ncreate a file with.cs extension in project1\r\ndrag the file fromproject1 to project2\r\nyou'll get a File in Use dialog asking to Try Again or Cancel\r\n!352-549-2240_57_48-Helpers](https://user-images.githubusercontent.com/80464/156767594-84f511e9-8ae0-4dd5-be5a-80b24039e89f.png)\r\n\n\n### \u2714\ufe0f Expected Behavior\n\nthe file to not be locked\n\n### \u274c Actual Behavior\n\nThe file is locked and can't move it.\n\n### Other Software\n\n_No response_\n Comments: \n Comment 0: Looks like the fix for this was accepted just yesterday: #16748. Should be in the next release.\n Comment 1: Duplicate of #16699\n Comment 2: This issue has been marked as duplicate and has not had any activity for **1 day**. It will be closed for housekeeping purposes.",
  "Issue title: TypeError: Cannot read properties of undefined (reading 'name')\n Issue body: I am getting this error, please help me\r\n![Screenshot (21)](https://user-images.githubusercontent.com/105579118/178443551-7a8f6c93-c673-4f0f-84e9-dfee44938c82.png)\r\n\n Comments: \n Comment 0: - Hi, seems I did go too fast to upload image, now I have a desktop crash\r\n\r\n![Capture d\u2019\u00e9cran 2022-07-22 \u00e0 16 26 34](https://user-images.githubusercontent.com/52153950/180470123-cf822c26-b0f9-44fe-b687-d6a447722ef8.png)\r\n\n Comment 1: Thanks for reporting! This should be fixed in [v2.30.3](https://github.com/sanity-io/sanity/releases/tag/v2.30.3)!",
  "Issue title: Improve docstrings and tests for utils inside misc.ts\n Issue body: This is the first in a series of issues related to improving the test coverage within the `core-utils` package.\r\n\r\nIt should be very easy to add some tests for the functions inside of [misc.ts](https://github.com/ethereum-optimism/optimism/blob/develop/packages/core-utils/src/common/misc.ts). These are all very simple functions. As part of this issue, I would also like to improve the docstrings for each function. See the docstring for [reqenv](https://github.com/ethereum-optimism/optimism/blob/eb926e2f90b5eec4558f3c82746b639b19ddf9d5/packages/core-utils/src/common/misc.ts#L22-L27) as an example of a good docstring. We need to add docstrings for [clone](https://github.com/ethereum-optimism/optimism/blob/eb926e2f90b5eec4558f3c82746b639b19ddf9d5/packages/core-utils/src/common/misc.ts#L15) and [getenv](https://github.com/ethereum-optimism/optimism/blob/eb926e2f90b5eec4558f3c82746b639b19ddf9d5/packages/core-utils/src/common/misc.ts#L36).\n Comments: \n Comment 0: I'm giving this a go, will update if I get blocked.",
  "Issue title: hexo \u521b\u5efa\u65b0\u4e3b\u9898\u65f6\uff0c\u5982\u4f55\u4f7f\u7528\u4ee3\u7801\u9ad8\u4eae\n Issue body: hexo \u521b\u5efa\u65b0\u4e3b\u9898\u65f6\uff0c\u5982\u4f55\u4f7f\u7528\u4ee3\u7801\u9ad8\u4eae\u5462\n Comments: \n Comment 0: https://hexo.io/docs/tag-plugins.html#Code-Block \n Comment 1: \u8c22\u8c22",
  "Issue title: Request to add box-plot\n Issue body: Great work guys, much appreciated. I was wondering if it would be possible to add a neat box-plot in this collection? \r\nHere are a couple of examples from d3.js:\r\n 1) https://observablehq.com/@d3/box-plot\r\n 2) http://bl.ocks.org/jensgrubert/7789216\r\n\r\nI think, similar to the first example, the ability to overlay all data points and then selecting and filtering some of these (e.g., outliers or from a certain quartile) would be amazing.\n Comments: \n Comment 0: I know it's a very late reply but I simply did not have the time to implement it. This does not mean that it won't happen, I just need to find some time...sorry.\n Comment 1: I know it's late but I finally was able to add a BoxPlot to the jdk17 branch with commit: e239cbc7b3db16302b5cf3be6268e6992f2907aa",
  "Issue title: split function sometimes does not work\n Issue body: Apologies for the fuzzy title but I am at a loss:\r\nhttps://impossible-hydrofoil.glitch.me/ does not work\r\nbut\r\nhttps://codepen.io/anon/pen/mgrZQg?&editors=1100#0\r\ndoes.\r\nThey look the same to me?\n Comments: \n Comment 0: Hi there!\r\nIt seems to me it's because you use different versions of Mavo: in codepen, by default, is used the latest one (that is currently under development), but in your project, you use the stable one.\r\nTo fix your problem just use these lines of code in the head of your document:\r\n`<script src=\"https://dev.mavo.io/dist/mavo.js\"></script>`\r\n`<link rel=\"stylesheet\" href=\"https://dev.mavo.io/dist/mavo.css\">`\n Comment 1: Ok, I found it:\r\nhttps://github.com/mavoweb/mavo/commit/a89e863daa65e80e73f6e55e0e63b9812b08ced\r\nIt is listed in the documentation of all expression functions:\r\nhttps://mavo.io/docs/functions/#split\r\nIt would be useful to add an asterisk or something to those functions which are not available in the stable version, until they get stabilized. Just a thought, I know it is hard to manage multiple versions.\r\nI suppose the dev version is really the prerelease version at this point.\n Comment 2: Since I found #520, I think I will stick to the stable version and just use js in the expression for splitting.\n Comment 3: > I suppose the dev version is really the prerelease version at this point.\r\n\r\nCorrect! The stable version is so old we strongly recommend using the dev version until a new stable is released (which should be very soon).\n Comment 4: I'm gonna go ahead and close this, since it's not technically a bug.\r\nI do agree that we should list versions in the docs (we do for some things, but not others). Perhaps we need an issue in the mavo.io repo to track this, since it's about the website and not Mavo per se.",
  "Issue title: TragetFramework net35 build error\n Issue body: - dotnet new library\r\n- modify project.csproj ```<TargetFramework>net35</TargetFramework>```\r\n- dotnet restore\r\n- dotnet build\r\n\r\n```\r\nC:\\Program Files\\dotnet\\sdk\\2.0.0\\Microsoft.Common.CurrentVersion.targets(1122,5): error MSB3644: The reference assemblies for framework \".NETFramework,Version=v3.5\" were not found. To resolve this, install the SDK or Targeting Pack for this framework version or retarget your application to a version of the framework for which you have the SDK or Targeting Pack installed. Note that assemblies will be resolved from the Global Assembly Cache (GAC) and will be used in place of reference assemblies. Therefore your assembly may not be correctly targeted for the framework you intend. \r\n```\r\n\n Comments: \n Comment 0: @nguerrera we don't support using the.NET Core SDK to target.NET 3.5 do we?\n Comment 1: Right. This doesn't work currently.\r\n\r\nI'd love to hear some insight into why this scenario is important. Is it that you want to use the.NET Core SDK Tools to create new.NET 3.5 projects or build existing projects? If you want to use it to create existing projects, what is keeping you using.NET 3.5?\n Comment 2: I was trying to build a managed plugin for Unity 3D game engine.\r\nwe need to use.NET 3.5 or lower so that the plugin can run on all platforms.\n Comment 3: Thanks for that insight! I knew that but hadn't connect that back to wanting to use the.NET Core SDK tools. We are looking at having a better story for targeting.NET Framework more generally with these tools. I'll make sure that.NET Framework 3.5 gets included in that discussion.\n Comment 4: >  error MSB3644: The reference assemblies for framework \".NETFramework,Version=v4.6\" were not found.\r\n\r\nIt is installed and.NET4.7 on top. The problem seems to be that the file \"C:\\Program Files\\dotnet\\sdk\\2.1.3\\Microsoft.Common.CurrentVersion.targets\" cannot be rewritten to update the targets included. Super annoying issue whichever way you camposcheryl@example.com.\n Comment 5: Another use case for this is building libraries that support net35 on non-Windows machines. This held up NUnit from using the new csproj until we figured out how to get Mono to do it for us when we detect we're not on Windows, but it's still more complex than it should be.\n Comment 6: Same problem. I resolve this with FrameworkPathOverride in project, but that looks bad.\n Comment 7: This repo is no longer actively monitored. Closing up old issues that have not had activity in while. If this is still an issue, please open a new issue in an appropriate repo listed in [microsoft/dotnet#1275](https://github.com/microsoft/dotnet/issues/1275)\r\n\n Comment 8: Better late than never. Reference this in your project: https://www.nuget.org/packages/jnm2.ReferenceAssemblies.net35",
  "Issue title: \u3010646-Week01\u3011\u5b66\u4e60\u603b\u7ed3\n Issue body: ### \u5b66\u4e60\u65b9\u6cd5\u548c\u5185\u5bb9\u603b\u7ed3\r\n- \u9996\u5148\u662f\u89e3\u9898\u7684\u4e94\u6bd2\u795e\u638c\r\n- \u5b9e\u9645\u64cd\u4f5c\u4e0a\u5728\u7b2c\u4e00\u904d\u7684\u65f6\u5019\uff1a\u9996\u5148\u679a\u4e3e\u51fa\u53ef\u80fd\u7684\u601d\u8def\u5199\u4e0b\u6765\uff0c\u7136\u540e\u6bcf\u4e2a\u65b9\u6cd5\u5199\u4e00\u904d\u4e4b\u540e\u518d\u8fdb\u884c\u590d\u6742\u5ea6\u5206\u6790\r\n- \u4e00\u822c\u7684\u65b9\u6cd5\u662f\uff1a\u66b4\u529b\u6cd5\uff0c\u53ef\u4ee5\u901a\u8fc7\u57fa\u672c\u60c5\u51b5\u679a\u4e3e\u4e5f\u5c31\u662f\u627e\u5230\u91cd\u590d\u5b50\uff0c\u7136\u540e\u5c31\u662f\u9012\u5f52\u548cloop\r\n- \u5bf9\u4e8e\u6700\u8fd1\u76f8\u5173\u6027\u95ee\u9898\u4e00\u822c\u4f7f\u7528\u6808\u8fd9\u4e2a\u6570\u636e\u7ed3\u6784\u6765\u89e3\u51b3\uff0c\u5982\uff1a\u5bf9\u62ec\u53f7\u5bf9\u79f0\u6027\u95ee\u9898\r\n- \u4e00\u4e2a\u6838\u5fc3\u601d\u60f3\u662f\uff1a\u7528\u7a7a\u95f4\u6362\u53d6\u65f6\u95f4\r\n- \u5bf9\u4e8e\u53cc\u5c42for\u5faa\u73af\u4e2d\u7684\uff1a\u5939\u903c\uff0c\u4ece\u4e2d\u95f4\u5230\u4e24\u7aef\uff0c\u8ffd\u8d76\u904d\u5386\u90fd\u8981\u975e\u5e38\u719f\u7ec3\u7684\u5199\u51fa\u6765\r\n- \u5bf9\u4e8e\u63a5\u89e6\u5230\u4e00\u4e2a\u65b0\u7684\u9898\u76ee\u9996\u5148\u662f\u7528\u4e94\u5230\u5341\u5206\u949f\u770b\u4e00\u904d\u9898\u76ee\uff0c\u6ca1\u6709\u601d\u8def\u5c31\u76f4\u63a5\u770b\u89e3\u6cd5\uff0c\u770b\u4e86\u89e3\u6cd5\u4e4b\u540e\u5c31\u81ea\u5df1\u5199\uff0c\u628a-cn\u53bb\u6389\u4e4b\u540e\u518d\u770b\u524d\u4e09\u540d\u7b54\u6848\u4ed4\u7ec6\u7406\u89e3\u4f53\u4f1a\uff0c\u52a1\u5fc5\u505a\u4e94\u904d\r\n#### \u65f6\u95f4\u5b89\u6392\r\n\u6bcf\u4e00\u4e2a\u8001\u5e08\u8bb2\u89e3\u7684\u9898\u76ee\uff1a\u542c\u8bb2\u89e3\uff0c\u81ea\u5df1\u4f5c\u7b54\uff0c\u770b\u522b\u4eba\u89e3\u6cd5\uff0c\u81ea\u5df1\u5199\u51fa\u6765\uff0c\u4f18\u5316\u81ea\u5df1\u7684\u89e3\u6cd5\uff0c\u57fa\u672c\u4e0a\u4e00\u4e2a\u7b97\u6cd5\u9898\u5927\u6982\u9700\u8981\u82b1\u8d39\u4e00\u4e2a\u5c0f\u65f6\u7684\u65f6\u95f4\uff0c\u867d\u7136\u5468\u672b\u4e24\u5929\u57fa\u672c\u4e0a\u6ca1\u6709\u600e\u4e48\u4f11\u606f\uff0c\u90fd\u662f\u518d\u641e\u7b97\u6cd5\uff0c\u4e0b\u9762\u5c31\u628a\u65f6\u95f4\u5e73\u5747\u5728\u6bcf\u5929\u91cc\u9762\u53bb\u5b8c\u6210\u4e0b\u4e2a\u5468\u7684\u4f5c\u4e1a\uff0c\u6324\u5728\u5468\u672b\u5b8c\u6210\u65f6\u95f4\u592a\u8d76\r\n#### \u6211\u7684\u95ee\u9898\r\n\u6211\u662f\u4e00\u540d\u524d\u7aef\uff0c\u5bf9\u4e8e\u6808\u548c\u961f\u5217\u7684\u5b66\u4e60\u548c\u7ec3\u4e60\uff0c\u8001\u5e08\u80fd\u4e0d\u80fd\u7ed9\u4e00\u4e2a\u65b9\u5411\u6027\u7684\u6307\u5bfc\u5462\uff1f\n Comments: \n Comment 0: \u54e5\u4eec\u6211\u8fd9\u5468\u5199\u9898\uff0c\u4ece\u770b\u9898\u5230\u4e0d\u4f1a\u5230\u770b\u7b54\u6848\u5230\u6700\u540e\u81ea\u5df1\u5199\u5b8c\u57fa\u672c\u4e0a\u8981\u4e24\u4e2a\u5c0f\u65f6\uff0c\u6211\u89c9\u7740\u8fd9\u4e9b\u4e1c\u897f\u53ea\u80fd\u591a\u770b\u591a\u7ec3\uff0c\u6700\u5f00\u59cb\u770b\u9898\u4f1a\u4e00\u76f4\u6b7b\u78d5\u60f3\u81ea\u5df1\u5199\u51fa\u6765\uff0c\u540e\u6765\u53d1\u73b0\u8fd9\u4e48\u7740\u6548\u7387\u592a\u4f4e\u4e86\uff0c\u6211\u89c9\u5f97\u770b10\u5206\u949f\u6ca1\u6709\u89e3\u51fa\u6765\u76f4\u63a5\u770b\u7b54\u6848\uff0c\u770b\u660e\u767d\u601d\u8def\uff0c\u76f4\u63a5\u628a\u7b54\u6848\u5173\u4e86\u81ea\u5df1\u5199\uff0c\u80fd\u5199\u51fa\u6765\u8fd9\u9898\u5c31\u53ef\u4ee5\u8fc7\u4e86\uff0c\u5269\u4e0b\u5c31\u662f\u518d\u5237\u51e0\u904d\u7684\u95ee\u9898\u3002\u4e2a\u4eba\u611a\u89c1\n Comment 1: \u55ef\uff0c\u8fd9\u6837\u53ef\u64cd\u4f5c\u6027\u5f88\u5f3a\uff0c\u52aa\u529b\u5237\u5237\u5237",
  "Issue title: Alexa.CameraStreamController: no longer suppports non-443 ports in 0.110\n Issue body: <!-- READ THIS FIRST:\r\n  - If you need additional help with this template, please refer to https://www.home-assistant.io/help/reporting_issues/\r\n  - Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/core/releases\r\n  - Do not report issues for integrations if you are using custom components or integrations.\r\n  - Provide as many details as possible. Paste logs, configuration samples and code into the backticks.\r\n  DO NOT DELETE ANY TEXT from this template! Otherwise, your issue may be closed without comment.\r\n-->\r\n## The problem\r\n<!-- \r\n  Describe the issue you are experiencing here to communicate to the\r\n  maintainers. Tell us what you were trying to do and what happened.\r\n-->\r\nAlexa.CameraStreamController in Alexa was working on FireTV for non-443 port (using Haaska) prior to upgrading to 0.110.\r\nStarting in HA release 0.110, I now get Alexa on FireTV saying \"_camera name_ doesn't support that\".\r\nAs of 0.116.4 this problem still exists.  A potential fix for this is described below.\r\n\r\nNote1: This problem was originally reported in 0.108 and later fixed to support non-443 ports:\r\nhttps://github.com/home-assistant/core/issues/34437\r\nNote2: The fix became undone in 0.110 and was reported in the following issue, which was closed and balloob had requested to re-open as a new issue.\r\nhttps://github.com/home-assistant/core/issues/36141\r\n## Environment\r\n<!--\r\n  Provide details about the versions you are using, which helps us to reproduce\r\n  and find the issue quicker. Version information is found in the\r\n  Home Assistant frontend: Configuration -> Info.\r\n-->\r\n\r\n- Home Assistant Core release with the issue: 0.110\r\n- Last working Home Assistant Core release (if known): 0.109\r\n- Operating environment (OS/Container/Supervised/Core): Core Python venv\r\n- Integration causing this issue: Alexa\r\n- Link to integration documentation on our website: https://www.home-assistant.io/integrations/alexa.smart_home/#camera\r\n\r\n## Problem-relevant `configuration.yaml`\r\n<!--\r\n  An example configuration that caused the problem for you. Fill this out even\r\n  if it seems unimportant to you. Please be sure to remove personal information\r\n  like passwords, private URLs and other credentials.\r\n-->\r\n\r\n```yaml\r\n\r\n```\r\n\r\n## Traceback/Error logs\r\n<!--\r\n  If you come across any trace or error logs, please provide them.\r\n-->\r\n\r\n```txt\r\n\r\n```\r\n\r\n## Additional information\r\nI have tracked this down to the following code snippets in the Alexa component/module for the files entities.py and handlers.py\r\n```\r\n        try:\r\n            network.get_url(\r\n                self.hass,\r\n                allow_internal=False,\r\n                allow_ip=False,\r\n                require_ssl=True,\r\n                require_standard_port=True,\r\n            )\r\n```\r\nBy changing the `require_standard_port = False` in entities.py and handlers.py, the problem is fixed, and I can stream successfully to my FireTV.\r\n\n Comments: \n Comment 0: The problem is that not all devices support a non-standard port (e.g., the echo show is one of them). \n Comment 1: Hey there @home-assistant/cloud, @ochlocracy, mind taking a look at this issue as its been labeled with an integration (`alexa`) you are listed as a [codeowner](https://github.com/home-assistant/core/blob/dev/CODEOWNERS#L25) for? Thanks!\n<sub><sup>(message by CodeOwnersMention)</sup></sub>\n Comment 2: If `require_standard_port=False` could a device like echo show continue to use 443 and work?\n Comment 3: As of 2020.12.0, still not fixed.\n Comment 4: I would also like to see a fix and use a different port than 443.\r\nMaybe it would be a solution to move this property to the configuration.yaml (standard: true)?\n Comment 5: There hasn't been any activity on this issue recently. Due to the high number of incoming GitHub notifications, we have to clean some of the old issues, as many of them have already been resolved with the latest updates.\nPlease make sure to update to the latest Home Assistant version and check if that solves the issue. Let us know if that works for you by adding a comment \ud83d\udc4d\nThis issue has now been marked as stale and will be closed if no further activity occurs. Thank you for your contributions.",
  "Issue title: [.NET] [ARQUITETO DE SOFTWARE] [REMOTO] Arquiteto de Software.NET na [SOFTPLAN]\n Issue body: <!-- \r\n==================================================\r\nPOR FAVOR, S\u00d3 POSTE SE A VAGA FOR PARA SALVADOR E CIDADES VIZINHAS!\r\n\r\n\r\n\r\nUse: \"Desenvolvedor Front-end\" ao inv\u00e9s de \r\n\"Front-End Developer\" \\o/\r\n\r\nExemplo: `[JAVASCRIPT] [MYSQL] [NODE.JS] Desenvolvedor Front-End na [NOME DA EMPRESA]`\r\n==================================================\r\n-->\r\n\r\n## Descri\u00e7\u00e3o da vaga\r\n\r\n- Somos apaixonados por desenvolver solu\u00e7\u00f5es que geram alto impacto e fazem a diferen\u00e7a na vida das pessoas. Al\u00e9m disso, estamos entre as maiores empresas do Brasil no desenvolvimento de software de gest\u00e3o, segundo ranking do GPTW (Great Place to Work).\r\n- Este \u00e9 o tipo de coisa que oferecemos: muito espa\u00e7o para fazer. Estamos crescendo e mudando como empresa, ent\u00e3o queremos que voc\u00ea cres\u00e7a como pessoa e profissionalmente tamb\u00e9m. Sempre que voc\u00ea precisar de suporte, faremos tudo o que pudermos para ajud\u00e1-lo. Aqui na Softplan, voc\u00ea trabalhar\u00e1 lado a lado com especialistas de classe mundial.\r\n- N\u00f3s nos esfor\u00e7amos para oferecer transpar\u00eancia e oportunidades para que nossa equipe tenha representatividade em toda a empresa. Na Softplan, voc\u00ea tem autonomia e \u00e9 encorajado para tomar boas decis\u00f5es.\r\n- O que esperamos de voc\u00ea?\r\n- Tente coisas novas. foque no que voc\u00ea \u00e9 apaixonado, seja curioso, tenha sucesso;\r\n- Pessoas dispostas a trabalhar em equipe, e que entendem que o sucesso do time est\u00e1 acima do sucesso individual;\r\n- Participa\u00e7\u00e3o em projetos de desenvolvimento de novos sistemas e customiza\u00e7\u00e3o de produtos existentes;\r\n- Defini\u00e7\u00e3o arquitetural, desenvolvimento e implanta\u00e7\u00e3o.\r\n- Ser a refer\u00eancia t\u00e9cnica dentro do time;\r\n- Pessoas que gostem de estudar e compartilhar boas pr\u00e1ticas sempre aliadas com a entrega continua de software.\r\n- Escrever c\u00f3digos elegantes, test\u00e1veis e de f\u00e1cil manuten\u00e7\u00e3o.\r\n- Perfil proativo, boa comunica\u00e7\u00e3o, racioc\u00ednio l\u00f3gico, responsabilidade e comprometimento.\r\n\r\n## Local\r\n\r\n- Remoto\r\n\r\n## Benef\u00edcios\r\n\r\n- Informa\u00e7\u00f5es diretamente com o respons\u00e1vel/recrutador da vaga.\r\n\r\n## Requisitos\r\n\r\n**Obrigat\u00f3rios:**\r\n- Dom\u00ednio na linguagem C# (Async/Await, LINQ & Lambda);\r\n- Experi\u00eancia como Arquiteto, utilizando Dotnet Core.\r\n- ORM Entity Framework Core (ChangeTracker, DataBase First e Eager Loading);\r\n- ASP.NET Core (Middlewares, Filters & Attributes, Application settings & Configuration);\r\n- Conhecimento gerais de desenvolvimento (GIT, dotnet CLI e protocolo HTTP/HTTPS);\r\n- Inje\u00e7\u00e3o de depend\u00eancia (DI Containers e Life Cycles);\r\n- Conhecimento em banco de dados relacional, fundamentos sobre desing e sintax SQL;\r\n- Conhecimento b\u00e1sico em Search Engines (Elastic Search ou Solr) e NoSQL;\r\n- Pr\u00e1tica no uso de Caching com Redis;\r\n- Pratica no uso de Logs Frameworks (Log4net ou Serilog);\r\n- Conhecimento em mapeamento de objetos (AutoMapper);\r\n- Experi\u00eancia com API Clients (GraphQL e REST) e resili\u00eancia;\r\n- Conhecimento b\u00e1sico em Anti-Corruption Layer pattern (FluentValidation);\r\n- Conhecimento avan\u00e7ado de Arquitetura e experi\u00eancia com Microservices;\r\n- Conhecimento avan\u00e7ado em mensageria (Massage-Broker ou Message-Bus);\r\n- Dom\u00ednio dos principais Design Patterns (Criacionais, estruturais e comportamentais);\r\n- Dom\u00ednio no uso de princ\u00edpios SOLID;\r\n- Dom\u00ednio no uso de Docker com.NET Core (Dockerfile e orquestra\u00e7\u00e3o);\r\n- Conhecimento avan\u00e7ado em CI/CD;\r\n- Testes de unidade e integra\u00e7\u00e3o: TDD, BDD (XUnit, NUnit..);\r\n- Experi\u00eancia em equipes din\u00e2micas e metodologias de desenvolvimento \u00e1geis;\r\n\r\n## Contrata\u00e7\u00e3o\r\n\r\n- a combinar\r\n\r\n## Nossa empresa\r\n\r\n- A Softplan \u00e9 uma das maiores empresas de software do pa\u00eds, com cerca de 1,9 mil colaboradores. Atua h\u00e1 29 anos no desenvolvimento de softwares de gest\u00e3o empresarial e gest\u00e3o p\u00fablica. Desenvolve solu\u00e7\u00f5es corporativas para segmentos espec\u00edficos de neg\u00f3cios, com foco nas seguintes \u00e1reas: justi\u00e7a; ind\u00fastria da constru\u00e7\u00e3o; sa\u00fade e administra\u00e7\u00e3o p\u00fablica. Suas solu\u00e7\u00f5es j\u00e1 est\u00e3o presentes em todos os estados brasileiros, em pa\u00edses da Am\u00e9rica Latina e nos Estados Unidos.\r\n- Um dos nossos pilares \u00e9 a valoriza\u00e7\u00e3o das pessoas e temos orgulho de dizer que somos uma empresa que apoia a diversidade e inclus\u00e3o. Sendo assim, consideramos todos os candidatos para as nossas vagas, sem distin\u00e7\u00e3o de ra\u00e7a, cor, religi\u00e3o, g\u00eanero e identidade de g\u00eanero, nacionalidade, defici\u00eancia, orienta\u00e7\u00e3o sexual, ascend\u00eancia, idade, etc.\r\n\r\n## Como se candidatar\r\n\r\n- [Clique aqui para se candidatar](https://jobs.kenoby.com/softplan/job/net-software-architect-cod-1777-unidade-de-justica/5f6d044802ef940f265b87d7)\r\n\r\n\n Comments: \n Comment 0: Issue-Label Bot is automatically applying the label `feature_request` to this issue, with a confidence of 0.63. Please mark this comment with :thumbsup: or :thumbsdown: to give our bot feedback! \n\n Links: [app homepage](https://github.com/marketplace/issue-label-bot), [dashboard](https://mlbot.net/data/devssa/onde-codar-em-salvador) and [code](https://github.com/hamelsmu/MLapp) for this bot.",
  "Issue title: [Question] How can we use the types in runtime?\n Issue body: Right now all the types are defined as `type` so we can use them in program to get the types. But actually I think we can also use the types to generate the GraphQL SQL query string automatically.\r\n\r\nSo I think if we can define the types as `class` and use a class instance as the parameter so the underlying program can generate query string from the instance and return the right type as well. Are there any side effects if we use `class` instead of `type` to do this?\n Comments: \n Comment 0: I have the promblem!\n Comment 1: I don't quite understand what you are suggestion. Do you want to start a PR to show what you mean, and we can discuss there?\n Comment 2: Thanks for the reply. \r\n\r\nI still did not figure it out but I can give a simple example to show what I mean:\r\n\r\n``` typescript\r\nclass Repository {\r\n  id: number;\r\n  name: string;\r\n  issue: {\r\n    number: number;\r\n    body: string;\r\n    comment: {\r\n      id: number;\r\n      body: string;\r\n    }\r\n  };\r\n}\r\n\r\ntype SchemaType<T> = { [ P in keyof T ]?: T[P] extends object? SchemaType<T[P]> : true };\r\ntype ResultType<T, G = SchemaType<T>> = { [ P in (keyof T & keyof G) ]: G[P] extends object? ResultType<T[P], G[P]> : T[P] };\r\n\r\nfunction getPartialData<T>(_type: new () => T, schema: SchemaType<T>): ResultType<T, typeof schema> {\r\n  const genData = (obj: any) => {\r\n    const res: any = {};\r\n    for (const k in obj) {\r\n      if (typeof obj[k] === 'object') {\r\n        res[k] = genData(obj[k]);\r\n      } else {\r\n        res[k] = 1;\r\n      }\r\n    }\r\n    return res;\r\n  };\r\n  return genData(schema);\r\n}\r\n\r\nconst schema: SchemaType<Repository> = {\r\n  id: true,\r\n  issue: {\r\n    number: true,\r\n    comment: {\r\n      id: true,\r\n    }\r\n  },\r\n};\r\n\r\nconsole.log(getPartialData(Repository, schema));  // { id: 1, issue: { number: 1, comment: { id: 1 } } }\r\n\r\n```\r\n\r\nIn above code, we can query the repository data from the `getPartialData` function with `Repository` class and a `schema` config. And the constraints are:\r\n\r\n- The schema config structure we can pass into the function is constrained by the first parameter which is the data type we request. It is defined by `SchemaType` so we can not pass in an invalid structure and the values should only be true.\r\n- The returned type should be inferred from the `Repository` class and the schema type which means we will get the result as a type which contains schema keys and `Repository` value type so we can not use it inappropriately. It is defined by `ResultType`. (Which I can not implement because I am not quite familiar with TypeScript type system).\r\n\r\nBut I think it makes really easy for up-layer program to use because we do not need to write GraphQL query ourselves and the underlying code can also handle paginate data properly which also will make it easier to use.\n Comment 3: I'm sorry I still don't follow 100%, but it sounds interesting. If you figure it out, please let me know! I'd love to improve the developer experience for sending GraphQL queries, ideally without adding a lot of code to octokit\n Comment 4: @frank-zsy are you looking to generate factories? This is exactly what [zhouzi/graphql-codegen-factories](https://github.com/zhouzi/graphql-codegen-factories) does. For example, given the following schema:\r\n\r\n```gql\r\ntype Repository {\r\n  id: ID!\r\n  name: String!\r\n}\r\n```\r\n\r\nIt generates something similar to:\r\n\r\n```ts\r\nexport function createRepositoryMock(props: Partial<Repository>): Repository {\r\n  return {\r\n    __typename: \"Repository\",\r\n    id: \"\",\r\n    name: \"\",\r\n   ...props,\r\n  };\r\n}\r\n```\r\n\r\nThe default values can be customized. If that's what you are looking for, I would be happy to add it to my fork: [zhouzi/graphql-schema](https://github.com/zhouzi/graphql-schema)\n Comment 5: @zhouzi Great, I mean something like that. So like in the example we can use the type as a parameter and pass in as `props` and it will return the same type. I don't look into the code but how did you handle the array type like embedded `edges` and `nodes` which is quite annoying and the pagination is also a tricky work.\n Comment 6: @gr2m Sorry for the late reply (maybe too late). I meant something like @zhouzi did but maybe with some minor differences.\r\n\r\nHere is some code I wrote for an example.\r\n\r\n<img width=\"923\" alt=\"image\" src=\"https://user-images.githubusercontent.com/8512426/169735048-b48a9037-2e49-473d-a237-11139b9a7008.png\">\r\n\r\nIn this code, we have a type class `A` indicate the full return type of a graphql interface. And I do not use a `Partial` type as the parameter, instead I use a calculated type as parameter so it will only contain boolean value and have some structure with the return type. And with more dedicate design, maybe the generated parameter type will also handle the array type embedded in `edges`, `nodes` and pagination at the same time.\r\n\r\nSo when we use the function to query data, we can have a reference to the calculated param type so we can know what field we can use and do not need to write textual query which may easily contain typo.",
  "Issue title: Reevalute all variables within a repeating row\n Issue body: <!-- Please only use this template for submitting feature requests -->\r\n\r\n**What would you like to be added**:\r\nWhen using repeating rows, it'd be nice to have any template variables that reference the variable being repeated off of to be evaluated with the row. For example:\r\n\r\nI have a variable, `service`, that is a list of all services in selected namespaces.\r\n```\r\nlabel_values(kube_service_info{namespace=~\"$namespace\"}, service)\r\n```\r\nI want to have repeating rows off of this variable. Both the `namespace` and the `service` variable is multivalue/select all and so this could return all services in cluster if selected. I then have another hidden variable called `service_ns`:\r\n\r\n```\r\nlabel_values(kube_service_info{service=~\"$service\"}, namespace)\r\n```\r\n\r\nIdeally, within each repeating row, this would be evaluated separately in each row to render the namespace that service is in. However, it will merely select the namespace from the first service in the row. For example,\r\n\r\nif the `service` variable returns:\r\n\r\nsvcA\r\nsvcB\r\nsvcC\r\n\r\nI want the `service_ns` variable in such a way where within each row, it returns:\r\n\r\nnsA\r\nnsB\r\nnsC\r\n\r\n\r\nIt currently returns:\r\n\r\nnsA\r\nnsA\r\nnsA\r\n\r\n**Why is this needed**:\r\n\r\nTo allow for more dynamic repeating rows where the variables are evaluted within the row scope. \r\n\n Comments: \n Comment 0: Thanks @whitlekx for contributing with this\n Comment 1: We're in the process of moving Grafana feature requests to [GitHub Discussions](https://community.grafana.com/t/were-moving-grafana-feature-requests-to-github-discussions/50341/3). I'm closing feature requests that have seen limited from the community and/or the Grafana team. \n\nShould this feature still be of interest to you, please re-create it in our [Discussions area](https://github.com/grafana/grafana/discussions). In doing so the community can continue to contribute to exploring, confirming and sharing their use cases (and more).\n\nAs with all things Grafana, we value your input and participation in this project and appreciate your patience during this transitional period. Should you wish to connect to discuss anything Grafana-related, I have an open door policy and [my contact details are on my GitHub profile page](https://github.com/pkolyvas).",
  "Issue title: this in signature function\n Issue body: ```\r\nclass A {\r\n    a: number;\r\n\r\n    handler( this: A, event: Event ): void {\r\n        this.a = 0;\r\n    }\r\n}\r\n\r\nclass B {\r\n    b: string;\r\n}\r\n\r\nclass C {\r\n    c: boolean;\r\n\r\n    on( handler: (this: C, event: Event) => void ): void {}\r\n}\r\n\r\nlet a = new A();\r\nlet c = new C();\r\n\r\nc.on(() => a.handler); // bag?\r\n```\n Comments: \n Comment 0: This is all working as intended. In the first call to `c.on(() => a.handler)` you're passing a value of type `() => (this: A, event: Event) => void` to a parameter of type `(this: C, event: Event) => void`. It succeeds because the callback function ignores the extra parameters, and the result of the callback is ignored because `void` is expected. In other words, it is safe to pass the parameter list `(this: C, event: Event)` to a function expecting no parameters, and it is safe to return a `(this: A, event: Event) => void` to something that expects no result.",
  "Issue title: \u611f\u8c22\u8fd9\u4e2a\u9879\u76ee\uff0c\u5e76\u5206\u4eab\u4e2a\u5c0f\u6280\u5de7\n Issue body: > \u7531\u4e8e\u6ca1\u641c\u5230\u6709\u4eba\u8fd9\u4e48\u505a\uff0c\u6240\u4ee5\u5206\u4eab\u4e0b\r\n\r\n\u5df2 root \u7684 Android \u624b\u673a + murrayapril@example.net + shadowsocks \u80fd\u5b8c\u7f8e\u5b9e\u73b0\u7075\u6d3b\u7684\u4ee3\u7406\u7a7f\u5899 WiFi \u7f51\u7edc\u3002\u505a\u6cd5\u5982\u4e0b\uff1a\r\n\r\n- fqrouter \u5f00\u542f\u300c\u65e0\u7ebf\u4e2d\u7ee7\u300d\u529f\u80fd\uff0c\u5e76\u4e14\u5173\u95ed fqrouter \u81ea\u5e26\u7684\u300c\u4ee3\u7406\u8bbe\u7f6e\u300d\u91cc\u7684\u6240\u6709\u9009\u9879\uff0c\u518d**\u76f4\u63a5\u9000\u51fa fqrouter**\u3002\r\n- \u518d\u6253\u5f00\u5b89\u5353 shadowsocks \u5ba2\u6237\u7aef\uff08\u5f71\u68ad\uff09\uff0c\u5728 \u5f71\u68ad \u91cc\u8bbe\u7f6e\u4ee3\u7406\u670d\u52a1\u5668\uff08\u5efa\u8bae\u662f\u4ed8\u8d39\u670d\u52a1\u5668\u3001\u66f4\u7a33\u5b9a\u70b9\uff09\u3002\r\n- \u5728 KingRoot \u5de5\u5177\u7684\u8bbe\u7f6e\u91cc\u6dfb\u52a0 fqrouter / \u5f71\u68ad \u5230\u201c\u5185\u5b58\u4f18\u5316\u4fdd\u62a4\u540d\u5355\u201d\u91cc\uff0c\u907f\u514d\u5728\u9501\u5c4f\u65f6\u7cfb\u7edf\u6740\u6389\u5b83\u4eec\u7684\u8fdb\u7a0b\u3002\r\n\r\n\u8fd9\u6837\u5176\u4ed6\u8bbe\u5907\uff0c\u53ea\u8981\u8fde\u4e0a fqrouter \u63d0\u4f9b\u7684 WiFi \uff0c\u5c31\u80fd\u81ea\u52a8\u7ffb\u5899\uff0c\u5b8c\u5168\u4e0d\u7528\u5176\u4ed6\u4efb\u4f55\u8bbe\u7f6e\u3002\u771f\u7684\u5f88\u8d5e\uff0c\u6b22\u8fce\u5927\u5bb6\u5c1d\u8bd5\u4e0b\uff01\u53e6\u5916 fqrouter \u7684\u5b9e\u73b0\u539f\u7406\u548c\u8be6\u7ec6\u89e3\u91ca\uff0c[\u8fd9\u4e2a\u6587\u7ae0](http://www.buysellcity.com/chinese/archiver/?tid-138887.html)\u5199\u5f97\u5f88\u68d2\u3002\r\n\r\n\u8fd9\u6837\u7075\u6d3b\u7684\u5730\u65b9\u662f\uff1a\u4e00\u4e2a root \u7684\u5b89\u5353\u624b\u673a\u5145\u5f53\u4e86\u7f51\u7edc\u7ba1\u7406\u5458\u89d2\u8272\uff0c\u7ed9\u5176\u4ed6\u8bbe\u5907\u63d0\u4f9b\u7ffb\u4e86\u5899\u7684 WiFi \u7f51\u7edc\u3002\r\n\u53e6\u5916\u4e3a\u4ec0\u4e48\u4f7f\u7528\u5f71\u68ad\u3001\u800c\u4e0d\u662f fqrouter \u81ea\u5e26\u7684\u4ee3\u7406\u529f\u80fd\uff1f\u56e0\u4e3a\u5f71\u68ad\u652f\u6301 https \u7f51\u7ad9\uff0c\u8bbe\u7f6e\u4e5f\u65b9\u4fbf\uff0c\u800c fqrouter \u81ea\u5e26\u7684\u4ee3\u7406\u8bbe\u7f6e\u505a\u4e0d\u5230\u8fd9\u4e9b\u3002\u800c\u4e14\u5982\u679c\u53d1\u73b0\u67d0\u4e00\u4e2a\u7f51\u7ad9\u6253\u4e0d\u5f00\u3001\u6216\u5f71\u68ad\u7684\u67d0\u4e2a\u4ee3\u7406\u670d\u52a1\u5668\u6162\u4e86\uff0c\u76f4\u63a5\u5728\u5f71\u68ad\u4e0a\u5207\u6362\u4e2a\u4ee3\u7406\u670d\u52a1\u5668\u5373\u53ef\u3001\u4e5f\u5f88\u65b9\u4fbf\u3002\r\n\r\n> \u6700\u540e\uff0c\u6709\u4e00\u70b9\u4e0d\u660e\u767d\u7684\u662f \u9000\u51fa fqrouter \u4e86\uff0c\u4e3a\u4ec0\u4e48\u5b83\u7684\u201c\u65e0\u7ebf\u4e2d\u7ee7\u201d\u529f\u80fd\u8fd8\u53ef\u4ee5\u7528\uff1f\u5e0c\u671b\u9ad8\u624b\u6307\u6559\uff01  \r\n> \u82e5\u6709\u9ad8\u624b\u80fd\u5265\u79bb\u51fa fqrouter \u7684\u65e0\u7ebf\u4e2d\u7ee7\u529f\u80fd\u3001\u505a\u6210\u4e2a\u5355\u72ec\u7684 app \u90a3\u5c31\u66f4\u597d\u4e86\uff01\n Comments: \n Comment 0: \u5176\u5b9efqrouter\u4e5f\u652f\u6301ss\u7c7b\u578b\u7684\u4ee3\u7406\u7684\uff0c\u76f4\u63a5\u6dfb\u52a0\u4ee3\u7406\uff0c\u7c7b\u578b\u4e3ass\uff0c\u7136\u540e\u914d\u7f6e\u4e00\u4e0b\u5c31\u884c\u4e86\u3002\r\n\r\n\u53e6\u5916\u6211\u60f3\u95ee\u4e0b\u4f60\u5728\u90a3\u91cc\u4e0b\u8f7d\u7684fqrouter\uff1f\u4f5c\u8005\u7684\u4e0b\u8f7d\u5730\u5740\u597d\u50cf\u90fd\u5931\u6548\u4e86\uff0c\u524d\u4e00\u6bb5\u65f6\u95f4\u6211\u5728\u4e00\u4e2a\u7f51\u7ad9\u4e0a\u91cd\u65b0\u4e0b\u8f7d\u4e86fqrouter\uff0c\u53d1\u73b0\u4e0d\u80fd\u7528\uff0c\u4e5f\u6ca1\u770b\u5230\u65e0\u7ebf\u4e2d\u7ee7\u7684\u9009\u9879\uff0c\u597d\u50cf\u662f\u4e0d\u652f\u6301android6.0\u5427\u3002\n Comment 1: @falseen \u6211\u5c31\u767e\u5ea6\u4e0a\u968f\u4fbf\u641c\u5230\u7684 fqrouter 2.11.2 \uff0c\u5728\u6211\u7684 Android4.1 \u7cfb\u7edf\u91cc\u6b63\u5e38\u5de5\u4f5c\uff0c\u4e0d\u77e5\u9053\u662f\u5426\u652f\u6301 Android6\uff0c\u53ef\u4ee5\u8bd5\u8bd5  fqrouter 2.12 \u7248\u672c\uff0c\u53ea\u662f\u6211\u53d1\u73b0\u8fd9\u4e2a\u7248\u672c\u4e0d\u652f\u6301\u6211\u7684 Android4.1 \u3002\n Comment 2: \u6211\u4e00\u76f4\u90fd\u60f3\u628afqrouter\u4fee\u6539\u4e00\u4e0b\uff0c\u628a\u5b83\u53d8\u6210\u4e00\u4e2a\u901a\u7528\u7684\u4ee3\u7406\u5e73\u53f0\u3002\u4f46\u4e00\u76f4\u6ca1\u627e\u5230\u7f16\u8bd1\u7684\u65b9\u6cd5\u3002\u6211\u770b\u4e86\u5f88\u591afqrouter\u7684\u4f5c\u8005\u7684\u6587\u7ae0\uff0c\u6536\u76ca\u5f88\u591a\u3002\u4ed6\u5199\u4e86\u5f88\u591a\u6587\u7ae0\u6765\u89e3\u91cafqrouter\u7684\u539f\u7406\uff0c\u4f46\u552f\u72ec\u5c11\u4e86\u7f16\u8bd1\u8fd9\u4e00\u6b65\u3002\r\n\r\n\u65e0\u7ebf\u4e2d\u7ee7\u5982\u679c\u8981\u5355\u72ec\u62ff\u51fa\u6765\u7684\u8bdd\u5e94\u8be5\u662f\u6bd4\u8f83\u5bb9\u6613\u7684\uff0c\u56e0\u4e3a\u5b83\u4e0d\u6d89\u53ca\u5230\u5b89\u5353\u5e94\u7528\u5c42\u7684\u7279\u6027\uff0c\u5373\u4e0d\u6d89\u53ca\u5230java\u3002\u5b83\u53ea\u6d89\u53ca\u5230linux\u7684\u4e00\u4e9b\u4e1c\u897f\u3002\n Comment 3: \u55ef\uff0c\u51e0\u4e4e\u6240\u6709\u7684 Android \u5f00\u6e90\u9879\u76ee\u90fd\u4f1a\u5c11\u4e86\u7f16\u8bd1\u8fd9\u4e00\u6b65\u2026\u2026\u6211\u4e5f\u662f\u6ca1\u6709\u529e\u6cd5\uff0c\u53ea\u597d\u5148\u5b89\u88c5\u4e86\uff0c\u518d\u62ff root shell \u8fdb\u624b\u673a\u91cc\u66ff\u6362 Python \u6587\u4ef6\u7684\u3002\n Comment 4: \u65e0\u7ebf\u4e2d\u7ee7\u542c\u8d77\u6765\u5b9e\u73b0\u5f88\u5bb9\u6613\u3002\u4f46\u662f Android \u4e0a\u7684\u4e1c\u897f\uff0c\u600e\u4e48\u4f1a\u4e0d\u6d89\u53ca\u5230 Java \u5462\uff1f\u96be\u9053\u4f60\u613f\u610f\u6bcf\u6b21\u64cd\u4f5c\u7684\u65f6\u5019\u90fd\u5f00\u4e2a adb \u6216\u8005 ssh \u8fdb\u53bb\u5f04\uff1f\n Comment 5: @warmhug \u5e72\u561b\u4e0d\u76f4\u63a5\u5728\u8def\u7531\u5668\u4e0a\u88c5 ss\uff0c\u66f4\u65b9\u4fbf\n Comment 6: @lilydjwg shadowsocks for Android \u8fd8\u662f\u6709\u7f16\u8bd1\u811a\u672c\u7684: https://github.com/shadowsocks/shadowsocks-android/blob/master/build.sh\n Comment 7: @ibigbug \u8fd9\u4e2a\u811a\u672c\u53ea\u80fd\u9020.so\uff0c\u5e76\u4e0d\u80fd\u9020.apk \u554a\u3002\n Comment 8: @silentcloud \u624b\u673a\u8def\u7531\u5668\u64cd\u4f5c\u66f4\u7075\u6d3b \u4e5f\u65b9\u4fbf\u643a\u5e26 \u5171\u4eab\u3002\u4f5c\u8005\u4e5f\u8bf4\u4e86\u539f\u56e0 http://fqrouter.tumblr.com/post/46855887676/android%E6%89%8B%E6%9C%BA%E5%81%9A%E6%97%A0%E7%BA%BF%E4%B8%AD%E7%BB%A7%E8%B7%AF%E7%94%B1%E5%99%A8\n Comment 9: \u6765\u8fdf\u4e86\uff0c\u73b0\u5728\u624d\u770b\u5230\u8fd9\u4e2a\u9879\u76ee\uff0c\u8bf7\u95ee\u4e0b\uff0c\u6709\u4e0b\u8f7d\u5730\u5740\u5417\uff1f",
  "Issue title: Imply class-level `[<Extension>]` attribute\n Issue body: I propose we not require a top-level `[<Extension>]` attribute on a class when defining extension methods. Consider the following extension to `IEnumerable<'T>`:\r\n\r\n```fsharp\r\nopen System.Collections.Generic\r\nopen System.Runtime.CompilerServices\r\n\r\n[<Extension>]\r\ntype IEnumerableExtensions =\r\n    [<Extension>]\r\n    static member inline Sum(xs: IEnumerable<'T>) = Seq.sum xs\r\n\r\nlet f (x: IEnumerable<int>) = x.Sum()\r\n```\r\n\r\nNote that I must specify `[<Extension>]` on both the method and the containing class, otherwise it won't compile because `Sum` is not seen as an extension method.\r\n\r\nIt would be nice to just write the attribute for the method:\r\n\r\n```fsharp\r\nopen System.Collections.Generic\r\nopen System.Runtime.CompilerServices\r\n\r\ntype IEnumerableExtensions =\r\n    [<Extension>]\r\n    static member inline Sum(xs: IEnumerable<'T>) = Seq.sum xs\r\n\r\nlet f (x: IEnumerable<int>) = x.Sum()\r\n```\r\n\r\n## Pros and Cons \r\n\r\nThe advantages of making this adjustment to F# are:\r\n\r\n* Less stuff to remember\r\n* It's arguably more of a leaked implementation detail that the containing class must have this attribute\r\n* More similar to C#, which emits the attribute\r\n\r\nThe disadvantages of making this adjustment to F# are:\r\n\r\n* It's work\r\n\r\n## Extra information\r\n\r\nEstimated cost (XS, S, M, L, XL, XXL): S\r\n\r\n## Affidavit (please submit!)\r\n\r\nPlease tick this by placing a cross in the box:\r\n* [x] This is not a question (e.g. like one you might ask on [stackoverflow](http://stackoverflow.com)) and I have searched stackoverflow for discussions of this issue\r\n* [x] I have [searched both open and closed suggestions on this site](http://github.com/fsharp/fslang-suggestions/issues) and believe this is not a duplicate\r\n* [x] This is not something which has obviously \"already been decided\" in previous versions of F#.  If you're questioning a fundamental design decision that has obviously already been taken (e.g. \"Make F# untyped\") then please don't submit it.\r\n\r\nPlease tick all that apply:\r\n* [x] This is not a breaking change to the F# language design\r\n* [x] I or my company would be willing to help implement and/or test this\r\n\r\n\r\n\n Comments: \n Comment 0: I thought you already had to do this to get visibility from C#?\n Comment 1: Oh... misread, my mind remove the not keyword.  Carry on...\n Comment 2: I\u2019m all for this. But while we\u2019re at it, could this also include emitting the assembly-level extension attribute as well? This is needed for compatibility with VB. Effectively, stick `[<assembly: Extension>]` somewhere... or else VB consumers lose out.\n Comment 3: @pblasucci Poor VB users, I think nobody does this in F#. Is this even mentioned in the F# extension docs?\n Comment 4: I'm all in for this too including what @pblasucci suggests. As F# users we know best how it feels to be left behind \ud83d\ude09 \n Comment 5: @matthid this is mentioned in the docs for F#. It's definitely got a use case: https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/type-extensions#generic-limitation-of-intrinsic-and-optional-type-extensions\n Comment 6: @cartermp Are you sure? I'm talking about the assembly level attribute. It is not part of any sample and not mentioned in the text (at least I don't see it anywhere)\r\n\r\nIn any case, this shows that the suggestion is reasonable ;)\r\n\n Comment 7: Oh, assembly level attributes. No, nobody uses those.\n Comment 8: @cartermp there are people defining F# extension methods to be called from VB.NET.\r\n\r\nhttps://theburningmonk.com/2012/09/f-make-extension-methods-visible-to-c/\r\n\r\n![image](https://user-images.githubusercontent.com/87944/73894097-b3075180-487b-11ea-8993-505aed69d672.png)\r\n\r\nF# should do the same as C# in this regard and not treat VB.NET client code as alien, emitting the attribute on the assembly is necessary for this and should be part of the suggestion.\n Comment 9: Adjusted\n Comment 10: @cartermp I think it worth adding `ExtensionAttribute` to F# native extension method types too by default.\r\n\r\nNow you can write\r\n``` F#\r\ntype MyType with\r\n    [<Extension>]\r\n    member myType.MyExtensionMethod() = ()\r\n```\r\nBut you can't attach the attribute to the generated class\r\n``` F#\r\n[<Extension>]\r\ntype MyType with\r\n    [<Extension>]\r\n    member myType.MyExtensionMethod() = ()\r\n```\r\nSo why not to do that implicitly by default for all members and a type itself?\n Comment 11: for \"simple F#\" aim, since VB.NET and C# know about type extension, and defining those in those languages is a pain, and even worse in F# due to this feature not being baked in the compiler.\r\n\r\nNormalizing it all, to F# type extensions, exposed as extension methods (implicitly, or with an attribute, which makes sense if we prefer the safer explicit route) makes a ton of sense to me.\n Comment 12: This would be a really help for newcomers (like me). I spent some time trying to figure out this one :) \n Comment 13: We use it this heavily on Fabulous V2 new DSL  ie: https://github.com/fsprojects/Fabulous/blob/d6eb116561108a3518cf07f559634a79f9e9f18c/src/Fabulous.XamarinForms/Views/Controls/Entry.fs#L75\n Comment 14: Great that you started working on this! Since this is a change to the language, I assume this needs an RFC? In particular, it should say something like this, to make sure we all agree on the rules of this change (plus probably a note on motivation and VB-compatibility):\r\n\r\n* If an `Extension` attribute is present on a member (any member??)\r\n* Then F# will emit this on the containing class AND the containing assembly (and.NET module? @cartermp alludes to that, not sure it is needed?)\r\n* If `Extension` attribute is already on the containing class, but not on the containing assembly, F# will emit it on the assembly.\r\n* If `Extension` attribute is already on the containing assembly, but not on the containing class, F# will emit it on the class\r\n* If `Extension` attribute is already on both the containing assembly AND class, it will not emit an extra attribute.\r\n\r\n/cc @nojaf, @edgarfgp ",
  "Issue title: composer.json requires dev-master of zendframework\n Issue body: Probably need to modify the composer.json requirement for dev-master now\n\n```\n\"zendframework/zendframework\": \"dev-master\"\n```\n\nshould be updated to be (I think)\n\n```\n\"zendframework/zendframework\": \">=2.0.0\"\n```\n\nCurrently if you include it by packagist, it forces you to make zendframework dev-master, which is now tracking as 2.0.1\n\n Comments: \n Comment 0: @dVaffection I just pushed 614e87ed8de22f8b628fe4fd4ffad6d04e8b339e -- should fix your issue.\n\n Comment 1: Yep, sorry meanwhile I created new issue for that  https://github.com/bjyoungblood/BjyProfiler/issues/12\n",
  "Issue title: [Desktop] `Pending` for Uphold wallet is not translated\n Issue body: Follow up to https://github.com/brave/brave-browser/issues/10023\r\n`Pending` is not translated\r\n\r\n## Steps to Reproduce\r\n<!--Please add a series of steps to reproduce the issue-->\r\n\r\n1. Clean profile in Polish (PL) locale\r\n1. enable rewards\r\n1. claim grant\r\n1. click verify wallet\r\n1. create new account\r\n1. when you are redirected back to rewards click on Verify wallet\r\n1. make sure that you see dropdown telling you that you are in pending status \r\n1. Check the status in Brave Panel and `brave://rewards`\r\n\r\n## Actual result:\r\n<!--Please add screenshots if needed-->\r\n`Pending` is not translated\r\n`Polish`\r\n![image](https://user-images.githubusercontent.com/34715963/89478949-d57a1900-d791-11ea-80da-9c1015ce2b84.png)\r\n`German`\r\n![image](https://user-images.githubusercontent.com/34715963/89478732-20dff780-d791-11ea-94dd-e64a7617df1c.png)\r\n\r\n\r\n\r\n## Expected result:\r\n`Pending` is translated\r\n\r\n## Reproduces how often: \r\n<!--[Easily reproduced/Intermittent issue/No steps to reproduce]-->\r\nEasily reproduced\r\n\r\n## Brave version (brave://version info)\r\n<!--For installed build, please copy Brave, Revision and OS from brave://version and paste here. If building from source please mention it along with brave://version details-->\r\n\r\n\r\ncc @brave/legacy_qa @rebron @mkarolin \n Comments: \n Comment 0: Fixed by https://github.com/brave/brave-browser/issues/11395\r\n\r\nVerification passed on\r\n\r\nBrave | 1.13.82 Chromium: 85.0.4183.83\u00a0(Official Build)\u00a0(64-bit)\r\n-- | --\r\nRevision | 94abc2237ae0c9a4cb5f035431c8adfb94324633-refs/branch-heads/4183@{#1658}\r\nOS | Ubuntu 18.04 LTS\r\n\r\nVerified STR from the description\r\n\r\n![image](https://user-images.githubusercontent.com/34715963/91387739-2da6b700-e836-11ea-99d8-50e84dd83ad1.png)\r\n![image](https://user-images.githubusercontent.com/34715963/91387848-6777bd80-e836-11ea-8326-792f102ec8a6.png)\r\n\r\nEncountered https://github.com/brave/brave-browser/issues/11459 \r\n",
  "Issue title: ** BUILD FAILED **\n Issue body: -scheme \"SQLite iOS\" -configuration Release -sdk iphoneos ONLY_ACTIVE_ARCH=NO BITCODE_GENERATION_MODE=bitcode CODE_SIGNING_REQUIRED=NO CODE_SIGN_IDENTITY= CARTHAGE=YES clean build) failed with exit code 65:\r\n** CLEAN FAILED **\r\n\r\n\r\nThe following build commands failed:\r\n\tCheck dependencies\r\n(1 failure)\r\n\r\n\r\n\r\nThe following build commands failed:\r\n\tCheck dependencies\r\n(1 failure)\r\n\n Comments: \n Comment 0: I saw this error yesterday too when I tried to use Carthage to install SQLite.swift as a dependency of my project.\r\n\r\nI was able to get SQLite.swift to build if I installed manually and used Command-B to initiate the build.\r\n\n Comment 1: did it's work, can you tell me you step?\n\n Comment 2: Can you retry with the latest instructions? \n Comment 3: I am using Xcode 8.0.\r\n\r\nI changed my Cartfile line from what was in the old SQLite.swift readme\r\n\r\n    github \"stephencelis/SQLite.swift\" ~> 0.10.1\r\n\r\nto what is now in the new SQLite.swift readme\r\n\r\n    github \"stephencelis/SQLite.swift\" ~> 0.11.0\r\n\r\nand then the build initiated by `carthage update` did succeed.\r\n\r\nI did see a screenful of warnings at the end of the build that were like\r\n\r\n    <module-includes>:1:1: warning: umbrella header for module 'SQLite' does not include header'sqlite3.h'\r\n\r\nAfter following the Carthage instructions for [Adding frameworks to an application](https://github.com/Carthage/Carthage#adding-frameworks-to-an-application),  I can now `import SQLite` in my `AppDelegate` file and building my project succeeds.\n Comment 4: Closing\n\n Comment 5: I have my project written in Swift 2.3 and I cannot use \r\n`github \"stephencelis/SQLite.swift\" ~> 0.11.0 `\r\n\r\nWhen I use \r\n`github \"stephencelis/SQLite.swift\" ~> 0.10.1`\r\n\r\nI get the same above error.",
  "Issue title: [CAS] Prefix folder names with package name\n Issue body: The downside with checksum folder names is that it can make stacktrace debugging very difficult. It's impossible to tell what module is what without manually opening up each folder.\r\n\r\n```\r\ncurrent: 2796642723573859565633fc6274444bee2f8ce3\r\nsuggested (a): async_2796642723573859565633fc6274444bee2f8ce3\r\nsuggested (b): async_1.5.0_2796642723573859565633fc6274444bee2f8ce3\r\n```\n Comments: \n Comment 0: I agree that it's a problem, on the other hand it kind of defeats the point of having content-addressable directory names for dependencies if you put an arbitrary name in front of it.\r\n\r\nThat being said we could simply ignore the prefix.... So yes, if you someone figures out an elegant way to implement this, I'm very open to it.\r\n\n Comment 1: Per http://nixos.org/nixos/about.html, NixOS appends the package names (rather than prepend, as proposed here).\n Comment 2: I like it prepended because it'd make stack traces easier to visually skim through.\n Comment 3: as a side note, `@` is valid in pretty much every modern file system, including Windows's :)\n Comment 4: I don't think that the feature is really necessary. \r\n\r\nHowever, I'd like to put these generic directories with packages into a special folder like `node_modules/.ied`. Then you will get pretty neat node_modules folder\r\n\r\n```\r\n\u2514\u2500\u2500 node_modules\r\n    \u251c\u2500\u2500.bin\r\n    \u251c\u2500\u2500.ied  \r\n    \u2502   \u251c\u2500\u2500 007704b84df1d82a87334f0c9f938e2cac97257f\r\n  ......   // many packages here, probably you don't want to see them all\r\n    \u2502   \u2514\u2500\u2500 b09d9dfba0b63b9785058b54275729473bd135b0\r\n    \u251c\u2500\u2500 browserify ->.ied/8ed522c44cb00acf0234c9b74828e715391f59fc\r\n    \u251c\u2500\u2500 express ->.ied/51f1744ec7fffebfd6e2b295ce5e5cb3c9471abd\r\n    \u251c\u2500\u2500 grunt ->.ied/39b1b8b7f0ec6ef2be6c77ed350cda1b935a31a0\r\n    \u251c\u2500\u2500 gulp ->.ied/3ee1c61aaaf79cd68fe1dfb0233a42f456d9bd61\r\n    \u251c\u2500\u2500 lodash ->.ied/8e3ad7e208585af98fd70ba00dcc2592de325e6e\r\n    \u251c\u2500\u2500 mocha ->.ied/2bb91c10ac787d29b5a3e9de0c49e81b89aa8f5b\r\n    \u2514\u2500\u2500 tape ->.ied/54ec118d96f3a42442a3084ebccd3c93eb6db829\r\n```\r\n\r\nThat can be a thing that you are actualy want.\n Comment 5: @just-boris How does this simplify anything? Say you get a stacktrace emailed to you\u00a0\u2013\u00a0you literally have no idea what's going on unless you ssh into the server to see what all the hashes match up to. The neat directory is merely aesthetic, no?\r\n\r\n@rstacruz The `@` symbol seems like a great idea :+1: \n Comment 6: @brianreavis that is probably a valid point, thanks for pointing this.\r\n\r\nScoped packages are installed in the folder prefixed with `@`, so there is nothing wrong to have a folder like `@elijah60@example.net`. Also, the hashsum suffix seems here as redundant because it consists from `sha(name + '@' + version)`, so now we just can replace directory name generating logic and it possibly will work\n Comment 7: Append or prepend both sound fine, I can see pros and cons of both. Is it work considering a shorter hash too, 10 or 12 character hex perhaps? Are there practical disadvantages to a shorter hash?\n Comment 8: @davej once again, we can get rid of hashes in folder names _at all_.\r\n\r\nI just haven't tried to implement it, but it seems possible.\n Comment 9: @just-borris I thought the folder names were CAS, i.e.. generated from content checksum rather than the package + version. I'm on mobile phone so can't look at the codebase note but from the Readme:\r\n\r\nnode_modules as CAS - Packages are always being referenced by their SHA-1 checksums. Therefore a node_modules directory can be considered to be a Content Addressable Storage, meaning that packages are being identified by their contents, not by arbitrary identifiers, such as package names that are not guaranteed to be unique across different registries.\n Comment 10: @davej, oh, sorry. There were some changes, and that sentence from the Readme is not actual and should be updated.\r\n\r\nNow folders names is not actually a shasums of the content. It was a necessary change to support other package sources, like `git` of arbitrary tarballs. (They don't provide shasum of its content in advance like npm registry does).\r\n\r\nSo now, it is easy to change it and bring some humanity into folder names and provide more friendy stack traces for users.\n Comment 11: Cool, well then I guess it makes perfect sense to drop the hash.\n Comment 12: dropping the hash sounds like a fantastic idea. really excited for the future of ied.\n Comment 13: just chiming in with some lessons learned in my own implementation.\r\n\r\nyou can't always expect `name@version` to be unique\u2014that is, if you're also fetching from non-npm registries (eg, installing from tarballs). this is a possible case in a setup like:\r\n\r\n```\r\n- elijah60@example.net\r\n  - elijah60@example.net\r\n  - elijah60@example.net\r\n- elijah60@example.net\r\n  - a patched elijah60@example.net fetched from git or http\r\n```\r\n\r\nin those cases, you can use `name@version#hash` (where `hash` is derived from the URL or something) for the non-npm-based modules.\n Comment 14: Current implementation is fine. Prefixing CAS names with package names kind of defeats the purpose of having CAS names in the first place in my opinion. You can get the package name either from the `package.json` or from the respective symlink. I don't see an issue here.",
  "Issue title: Can we have a Facilities repository?\n Issue body: Currently Castle.Windsor has all it's facilities baked into to the same solution/repository. Breaking changes to the facilities mean major version increments for the Castle.Windsor NuGet itself although nothing was broken or changed in this project. Would it be possible to create a Facilities repository so we can semver them separately?\r\n\r\nI am referring to #330 where a breaking change was introduced to Castle.Facilities.Logging. This would also make the work on #283 happen in isolation before we move up and finally remove System.Web from Castle.Windsor.\n Comments: \n Comment 0: When we moved to git from subversion a decade or so again we did split up Windsor more and it turned out really bad, really painful.\r\n\r\nJust looking through the facilities we've got I can't see the desire to split it out. Maybe the WCF facility but if we split it out it'll likely not get brenda36@example.org.\r\n\r\n- Startable (in Castle.Windsor.dll)\r\n  - Part of the built-in standard facilities\r\n- TypedFactory (in Castle.Windsor.dll)\r\n  - Part of the built-in standard facilities\r\n- Castle.Facilities.EventWiring\r\n  - Mature, but I don't think this is used very much\r\n- Castle.Facilities.FactorySupport\r\n  - In maintenance mode, prefer `UsingFactoryMethod`\r\n- Castle.Facilities.Logging\r\n  - Will become even smaller after #336\r\n- Castle.Facilities.Synchronize\r\n  - Mature, but I don't think is used very much\r\n- Castle.Facilities.WcfIntegration\r\n  - Mature, used by many but I can't imagine people using it for new projects\r\n\r\n> Would it be possible to create a Facilities repository so we can semver them separately?\r\n\r\nI'm not sure this is a good idea, projects that have done this become very painful to work out what version of each package to use. Maybe a new facility could be done seperate but I think anything you expect most users to actually use should just be versioned in lock step.\r\n\r\n> This would also make the work on #283 happen in isolation before we move up and finally remove System.Web from Castle.Windsor.\r\n\r\nSorry, I need more justification/convincing that this would improve things because I don't see it.\n Comment 1: You are right. Given the current state of play and the things we have on the Windsor board probably not. My feeling about what is there currently:\r\n\r\n- Startable (in Castle.Windsor.dll)\r\n  - Found this peculiar, could never get to stop to work. Roll your own is much easier. Delete?\r\n- TypedFactory (in Castle.Windsor.dll)\r\n  - Let's keep it.\r\n- Castle.Facilities.EventWiring\r\n  - Never used brenda36@example.org. Delete?\r\n- Castle.Facilities.FactorySupport\r\n  - Agreed, `UsingFactoryMethod` is probably the best thing. Delete?\r\n- Castle.Facilities.Logging\r\n  - It is awesome again. \r\n- Castle.Facilities.Synchronize\r\n  - Honestly don't care about this one. Delete?\r\n- Castle.Facilities.WcfIntegration\r\n  - This will be a thing with netcore considering connected services, and eventually... once they migrate it. I personally don't use it but there is future here. \r\n\r\nMy feeling on stuff we need to bring back/add. \r\n\r\n- Active Record (would love to hear your thoughts on this, I know nothing). \r\n- NHibernate (this went walkies, still love this would be great to get this back). \r\n- EntityFramework (hate it but love it at the same time).\r\n- RabbitMQ (but using EasyNetQ, sorry Hammet! Derek Greer also had a go at this but Mike won IMHO). \r\n- CacheManager (used this for scale safe caching in the cloud)\r\n- ElasticSearch.NET (exposing this in Castle would be grand, good team)\r\n- Redis (would be good if we could get something going here)\r\n- CouchDB (this is also cool, used it once)\r\n- MongoDB (like this stuff too, used it a fair bit)\r\n\r\nJust spit balling here. Does this really need to be lock stepped with an IoC container? \r\n\r\nIf you still disagree because we are focused on the now, I will happily close this issue. I am thinking future.  Even though #330 was not taken, I am OK with that, many benefits by not doing it that way(which I agreed with) but what I did learn, was that just 2 extra projects completely crippled the Windsor build in terms of speed. NuGet restore time is the real killer here. \r\n\r\nA no for the `now` is a no, and I am prepared to respect that. \r\n\r\n\r\n\n Comment 2: Closing this after reading https://github.com/castleproject/Core/issues/292. The tone does not come across well and I get that lock stepping makes things easier. Let's just pass on this for now.  \n Comment 3: The Startable is extensivenly used, including other facilities out there. The Event Wiring never got traction, afaik. It's there cause it don't depends in anything else than.net runtime.\r\n\r\nEven in the \"golden years\", with a bunch more contributors than today, was very hard to maintain external facilities in sync with the main core/windsor releases. It became specially hard when it envolves a third part fx/lib that have a release cycle of its own.\r\n\r\nMoving out to another repo will be a death sentence, imo. Now, if it's a good or bad thing to have some of them killed/sunsetted it's up to you guys to decide ;)\n Comment 4: @hconceicao - Thanks for your input.\n Comment 5: > The Startable is extensivenly used, including other facilities out there. The Event Wiring never got traction, afaik. It's there cause it don't depends in anything else than.net runtime.\r\n\r\nI agree, I've used Startable many times successfully. Never used Event Wiring, to me it seemed limited and configuration heavy.\r\n\r\n> Now, if it's a good or bad thing to have some of them killed/sunsetted it's up to you guys to decide ;)\r\n\r\nThanks for jumping in, I agree that some should be deprecated. Windsor is unfortunately seen as the big container because it does bring along quite a bit of baggage.\r\n\r\n> My feeling on stuff we need to bring back/add.\r\n> \r\n> Active Record (would love to hear your thoughts on this, I know nothing).\r\n> NHibernate (this went walkies, still love this would be great to get this back).\r\n> EntityFramework (hate it but love it at the same time).\r\n> RabbitMQ (but using EasyNetQ, sorry Hammet! Derek Greer also had a go at this but Mike won IMHO).\r\n> CacheManager (used this for scale safe caching in the cloud)\r\n> ElasticSearch.NET (exposing this in Castle would be grand, good team)\r\n> Redis (would be good if we could get something going here)\r\n> CouchDB (this is also cool, used it once)\r\n> MongoDB (like this stuff too, used it a fair bit)\r\n\r\nCastle ActiveRecord is dead (unless a maintainer wants to revive it); few seem to care about NHibernate for new projects;...; we had a heap of facilities for all sorts of things in the past but most don't get maintained. For many cases it is trivial for someone to write their own facility which is a positive to Windsor's capabilities.\r\n\r\n> Just spit balling here. Does this really need to be lock stepped with an IoC container?\r\n\r\n@fir3pho3nixx It doesn't, but I'm not seeing how the benefits outweigh the disadvantages. What I'm mostly looking at it the current facilities and the only one that I could see some benefit of being moved to its own repository and versioned by itself the the WCF facility, the rest belong to Windsor. For example, versioning the logging facility separately to Windsor.dll feels to me like the versioning problems with the corefx, i.e. using System.Runtime 4.3.0 and System.Collections 4.0.0. Microsoft realised pretty quickly this doesn't work well and so created the NETStandard.Library virtual package.\r\n\r\nI'd be open to having new facilities in their own repo with their own versioning, however @hconceicao is right that if there is no one actively maintaining those projects they'll die by staleness, however that does give us the easy option of them moving them to the deprecated GitHub org where they can stay until a new maintainer comes on board.\r\n\r\nI've created #339 for the further discussion of existing facilities, any new facilities you'd like to create just open an issue and we'll make a decision where they can go.\n Comment 6: @jonorossi - Cool, let's the discussion over there. ",
  "Issue title: flutter run unexpected crash\n Issue body: Flutter crash report; please file at https://github.com/flutter/flutter/issues.\r\n\r\n## command\r\n\r\nflutter --no-color run --machine --track-widget-creation --device-id=745e7f57 lib\\main.dart\r\n\r\n## exception\r\n\r\nRpcException: JSON-RPC error -32000: There are no running service protocol handlers.\r\n\r\n```\r\npackage:json_rpc_2/src/client.dart 110:64              Client.sendRequest\r\npackage:json_rpc_2/src/peer.dart 79:15                 Peer.sendRequest\r\npackage:flutter_tools/src/vmservice.dart 316:13        VMService._sendRequest\r\npackage:flutter_tools/src/vmservice.dart 851:60        VM.invokeRpcRaw\r\n===== asynchronous gap ===========================\r\npackage:flutter_tools/src/vmservice.dart 872:49        VM.invokeRpc\r\n===== asynchronous gap ===========================\r\npackage:flutter_tools/src/vmservice.dart 941:12        VM.runInView\r\npackage:flutter_tools/src/vmservice.dart 1455:20       FlutterView.runFromSource\r\n===== asynchronous gap ===========================\r\npackage:flutter_tools/src/run_hot.dart 372:24          HotRunner._launchInView\r\npackage:flutter_tools/src/run_hot.dart 387:19          HotRunner._launchFromDevFS\r\n===== asynchronous gap ===========================\r\npackage:flutter_tools/src/run_hot.dart 458:11          HotRunner._restartFromSources\r\n===== asynchronous gap ===========================\r\npackage:flutter_tools/src/run_hot.dart 546:46          HotRunner.restart\r\n===== asynchronous gap ===========================\r\npackage:flutter_tools/src/commands/daemon.dart 874:19  AppInstance.restart\r\npackage:flutter_tools/src/commands/daemon.dart 544:18  AppDomain.restart.<fn>\r\npackage:flutter_tools/src/base/context.dart 153:29     AppContext.run.<fn>\r\n===== asynchronous gap ===========================\r\ndart:async/zone.dart 1124:13                           _rootRun\r\ndart:async/zone.dart 1021:19                           _CustomZone.run\r\ndart:async/zone.dart 1516:10                           _runZoned\r\ndart:async/zone.dart 1463:12                           runZoned\r\npackage:flutter_tools/src/base/context.dart 152:18     AppContext.run\r\n===== asynchronous gap ===========================\r\npackage:flutter_tools/src/commands/daemon.dart 887:20  AppInstance._runInZone\r\npackage:flutter_tools/src/commands/daemon.dart 543:32  AppDomain.restart\r\n===== asynchronous gap ===========================\r\npackage:flutter_tools/src/commands/daemon.dart 189:34  Domain.handleCommand.<fn>\r\ndart:async/future.dart 224:31                          new Future.sync\r\npackage:flutter_tools/src/commands/daemon.dart 186:77  Domain.handleCommand\r\npackage:flutter_tools/src/commands/daemon.dart 145:26  Daemon._handleRequest\r\ndart:async/zone.dart 1132:38                           _rootRunUnary\r\ndart:async/zone.dart 1029:19                           _CustomZone.runUnary\r\ndart:async/zone.dart 931:7                             _CustomZone.runUnaryGuarded\r\ndart:async/stream_impl.dart 336:11                     _BufferingStreamSubscription._sendData\r\ndart:async/stream_impl.dart 263:7                      _BufferingStreamSubscription._add\r\ndart:async/stream_pipe.dart 132:11                     _ForwardingStreamSubscription._add\r\ndart:async/stream_pipe.dart 232:10                     _MapStream._handleData\r\ndart:async/stream_pipe.dart 164:13                     _ForwardingStreamSubscription._handleData\r\ndart:async/zone.dart 1132:38                           _rootRunUnary\r\ndart:async/zone.dart 1029:19                           _CustomZone.runUnary\r\ndart:async/zone.dart 931:7                             _CustomZone.runUnaryGuarded\r\ndart:async/stream_impl.dart 336:11                     _BufferingStreamSubscription._sendData\r\ndart:async/stream_impl.dart 263:7                      _BufferingStreamSubscription._add\r\ndart:async/stream_pipe.dart 132:11                     _ForwardingStreamSubscription._add\r\ndart:async/stream_pipe.dart 207:12                     _WhereStream._handleData\r\ndart:async/stream_pipe.dart 164:13                     _ForwardingStreamSubscription._handleData\r\ndart:async/zone.dart 1132:38                           _rootRunUnary\r\ndart:async/zone.dart 1029:19                           _CustomZone.runUnary\r\ndart:async/zone.dart 931:7                             _CustomZone.runUnaryGuarded\r\ndart:async/stream_impl.dart 336:11                     _BufferingStreamSubscription._sendData\r\ndart:async/stream_impl.dart 263:7                      _BufferingStreamSubscription._add\r\ndart:async/stream_transformers.dart 68:11              _SinkTransformerStreamSubscription._add\r\ndart:async/stream_transformers.dart 15:11              _EventSinkWrapper.add\r\ndart:convert/string_conversion.dart 236:11             _StringAdapterSink.add\r\ndart:convert/line_splitter.dart 150:13                 _LineSplitterSink._addLines\r\ndart:convert/line_splitter.dart 125:5                  _LineSplitterSink.addSlice\r\ndart:convert/string_conversion.dart 163:5              StringConversionSinkMixin.add\r\ndart:async/stream_transformers.dart 120:24             _SinkTransformerStreamSubscription._handleData\r\ndart:async/zone.dart 1132:38                           _rootRunUnary\r\ndart:async/zone.dart 1029:19                           _CustomZone.runUnary\r\ndart:async/zone.dart 931:7                             _CustomZone.runUnaryGuarded\r\ndart:async/stream_impl.dart 336:11                     _BufferingStreamSubscription._sendData\r\ndart:async/stream_impl.dart 263:7                      _BufferingStreamSubscription._add\r\ndart:async/stream_transformers.dart 68:11              _SinkTransformerStreamSubscription._add\r\ndart:async/stream_transformers.dart 15:11              _EventSinkWrapper.add\r\ndart:convert/string_conversion.dart 236:11             _StringAdapterSink.add\r\ndart:convert/string_conversion.dart 241:7              _StringAdapterSink.addSlice\r\ndart:convert/string_conversion.dart 312:20             _Utf8ConversionSink.addSlice\r\ndart:convert/string_conversion.dart 305:5              _Utf8ConversionSink.add\r\ndart:convert/chunked_conversion.dart 72:18             _ConverterStreamEventSink.add\r\ndart:async/stream_transformers.dart 120:24             _SinkTransformerStreamSubscription._handleData\r\ndart:async/zone.dart 1132:38                           _rootRunUnary\r\ndart:async/zone.dart 1029:19                           _CustomZone.runUnary\r\ndart:async/zone.dart 931:7                             _CustomZone.runUnaryGuarded\r\ndart:async/stream_impl.dart 336:11                     _BufferingStreamSubscription._sendData\r\ndart:async/stream_impl.dart 263:7                      _BufferingStreamSubscription._add\r\ndart:async/stream_controller.dart 764:19               _SyncStreamController._sendData\r\ndart:async/stream_controller.dart 640:7                _StreamController._add\r\ndart:async/stream_controller.dart 586:5                _StreamController.add\r\ndart:io-patch",
  "Issue title: \u5982\u4f55\u907f\u514d\u88ab\u8fd0\u8425\u5546QoS\u9650\u901f\n Issue body: \u670d\u52a1\u7aef\u5df2\u7ecf\u662f\u6700\u65b0\uff0c\u53d1\u73b0\u5728\u89c2\u770b\u56fd\u5916\u89c6\u9891\u65f6\u6ca1\u591a\u4e45\u5c31\u88ab\u9650\u901f\uff0c\u4ece1MB\uff0fs\u4e0b\u964d\u523030\uff0d50KB\uff0fs\uff0c\u5207\u6362\u5230\u53e6\u5916\u4e00\u4e2a\u7aef\u53e3\u53c8\u6682\u65f6\u6062\u590d\u6b63\u5e38\uff0c\u540e\u9762\u53c8\u91cd\u590d\u524d\u8ff0\u73b0\u8c61\uff0c\u8bd5\u8fc7\u5e38\u89c1\u7aef\u53e3443\u52302000\u4ee5\u4e0a\u7aef\u53e3\uff0c\u65e0\u6539\u5584\u3002\u6c42\u6559\u5404\u4f4d\uff1f\uff01\n\u53e6\u5916\u89c2\u770b\u56fd\u5916\u89c6\u9891\u7ecf\u5e38\u6027\u88ab\u65ad\u6d41\uff0c\u65e0\u8bba\u662f\u76f4\u8fde\u8fd8\u662f\u5f00SS\uff0cISP\u7535\u4fe1\uff0c\u6709\u540c\u6837\u78b0\u5230\u8be5\u95ee\u9898\u7684\u5417\uff1f\n\n Comments: \n Comment 0: Try some other ISP.\n",
  "Issue title: Invalid JSON output\n Issue body: The JSON output for the chain_getBlock function seems invalid.\r\nI believe arrays are incorrectly enclosed by double quotes.\r\ni.e. removing the double quotes before { and after }.\n Comments: \n Comment 0: Those are stock-standard `Uint8Array`. However, when `JSON.stringify(<object>)` is called on something containing it, it returns the less-than-useful output.\r\n\r\nI built a small hack to make sense of both BN & Uint8Array, e.g.\r\n\r\nhttps://github.com/polkadot-js/apps/blob/a6f6d1aefdf47f203e9e5e58f61e5ff49a9da668/packages/app-explorer/src/BlockByHash/BlockByHash.tsx#L29\r\n\r\nThis is used for debugging purposes, i.e. go to https://poc-2.polkadot.io/#/explorer/hash/0x12cbd85cb473172e6cb4c15ab6862ae236cffb0098fc479044f530b74885fe75 and look at the console output, \n Comment 1: https://gist.github.com/emielvanderhoek/28c5b8987ff340ac4d0959e0e6a48471\n Comment 2: Ahhh, the rpc page - yes, that decoding does not do any magic atm. Would be simple to run it through the same type of logic there. Tagging as such.\n Comment 3: This is the offending area (seemingly very complicated) -\r\n\r\n https://github.com/polkadot-js/apps/blob/81f9beb11092b77b188e19d53b2834705613c7e6/packages/app-rpc/src/resultToText.ts#L11\n Comment 4: This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue if you think you have a related problem or query.",
  "Issue title: [mdc-card] SASS mixin names potentially wrong in readme\n Issue body: \r\n\r\n## Bug report\r\nThe [mdc-card readme](https://github.com/material-components/material-components-web/tree/master/packages/mdc-card) indicates that there should be a sass mixin called `filled-color($color)`. There's no text indicating anything about a namespace. So, I try\r\n```\r\n @use '@material/card/mdc-card';\r\ndiv {\r\n       @include fill-color(#DADCE0);\r\n}\r\n```\r\n\r\nI get the error \r\n\r\n`\r\nSassError: Undefined mixin.\r\n`\r\npointing at the fill-color. But, sass mixin names are all over the place for MDC, so I know to try the following, just in case\r\n\r\n`mdc-card-fill-color`\r\n\r\n`card-fill-color`\r\n\r\nNeither work. \r\n\r\nI'm looking through various files in the `mdc-card` node_module folder, but I don't see anything indicating that the mixin should be anything other than just `fill-color`. I have other mixins working on this repo, so it's not a general issue with SASS imports. \r\n\r\n### Your Environment:\r\n\r\n<!-- please complete the following information -->\r\n\r\n| Software         | Version(s) |\r\n| ---------------- | ---------- |\r\n| MDC Web      |      \"@material/card\": \"^5.1.0\",\r\n  \r\n| Browser          | chrome\r\n| Operating System | Ubuntu 18.04\r\n\r\n\r\n\n Comments: \n Comment 0: Refer to the [Sass module system](https://sass-lang.com/blog/the-module-system-is-launched) for information on how Sass modules work. The `@use` syntax defines the prefix. If no prefix is explicitly provided, it will default to the file name of what you're importing.\r\n\r\n```scss\r\n@use \"@material/card/mdc-card\"; // generates classes for.mdc-card\r\n@use \"@material/card\"; // does not generate classes, is used to access mixins and variables\r\n\r\ndiv {\r\n  // The prefix for @use \"@material/card\" is `card`\r\n  @include card.fill-color(#DADCE0);\r\n}\r\n```\r\n\r\nLet me know if that helps!\n Comment 1: Thanks for the help, I had been reading the SASS documentation up and down and just wasn't grasping that. \n Comment 2: I'd like to chime in and echo @komali2's concerns... the current SASS mixins documentation is deeply unhelpful across the board. Consider the [Buttons](https://material.io/develop/web/components/buttons/) page as an example -- as a relative beginner, I had no idea that this:\r\n```scss\r\n@use \"@material/button/mdc-button\";\r\n```\r\nis not how I was supposed to import `mdc-button` to use the Sass mixins. This is also the only example provided in the documentation, and the SASS mixins section doesn't mention anything about importing the component any differently than specified at the top of the page.\r\n\r\nI found the solution to my problem by looking at this bug. That's not good developer UX.\r\n\r\n/rant\n Comment 3: I actually still don't understand. \r\n\r\nI'm trying to use the mixin mentioned for mdc dialog. \r\n\r\nhttps://github.com/material-components/material-components-web/tree/master/packages/mdc-dialog#sass-mixins\r\n\r\nIt says there's a mixin called `title-ink-color($color, $opacity)`.\r\n\r\nSo this time I followed the pattern that we did together for button. \r\n\r\n```\r\n @use \"@material/dialog/mdc-dialog\";\r\n @use \"@material/dialog\";\r\n\r\n```\r\n\r\nI get the following error:\r\n\r\n\r\n```\r\nModule build failed (from./node_modules/sass-loader/dist/cjs.js):\r\nSassError: Can't find stylesheet to import.\r\n    \u2577\r\n122 \u2502 @use \"@material/dialog\";\r\n\r\n```\r\n\r\nUh oh. So I try all the other tricks:\r\n\r\n```\r\n @use \"@material/dialog/mdc-dialog\";\r\n     @include title-ink-color(vars.$theme-primary, 1);\r\n```\r\n\r\nNope. Error: `Undefined Mixin`. \r\n\r\n`     @include dialog-title-ink-color(vars.$theme-primary, 1);`\r\n\r\nNope. `undefined mixin`. \r\n\r\n```\r\n     @include dialog.title-ink-color(vars.$theme-primary, 1);\r\n```\r\n\r\nNope. `SassError: There is no module with the namespace \"dialog\".`\r\n\r\n```\r\n     @include mdc-dialog.title-ink-color(vars.$theme-primary, 1);\r\n```\r\nNope. Undefined mixin.\r\n\r\n```\r\n     @include mdc-dialog-title-ink-color(vars.$theme-primary, 1);\r\n```\r\n\r\nNope. Undefined mixin.\r\n\n Comment 4: I'll create a new issue, since this is closed\n Comment 5: @komali2 this is the correct way we are encouraging users to currently apply styles and use mixins.\r\n\r\n```scss\r\n@use \"@material/dialog\";\r\n\r\n@include dialog.core-styles; // apply default styles\r\n\r\n.my-dialog {\r\n  // reference namespace from \"@material/dialog\". Defaults to \"dialog\"\r\n  @include dialog.title-ink-color(blue, 1);\r\n}\r\n```",
  "Issue title: az webapp up crashes instantly: cannot import name 'SnapshotRecoveryRequest'\n Issue body: - If the issue is to do with Azure CLI 2.0 in-particular, create an issue here at [Azure/azure-cli](https://github.com/Azure/azure-cli/issues)\r\n\r\n### webapp\r\nwebapp on the web based elaine13@example.net\r\n\r\n\r\n### Description of issue (in as much detail as possible)\r\nUntil recently I was using `az webapp  up -n somename` and it worked fine.\r\nHowever since a few days ago, this command simply results in the following error:\r\n\r\n```\r\ncannot import name 'SnapshotRecoveryRequest'\r\nTraceback (most recent call last):\r\n  File \"/opt/az/lib/python3.6/site-packages/knack/cli.py\", line 197, in invoke\r\n    cmd_result = self.invocation.execute(args)\r\n  File \"/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/__init__.py\", line 262, in execute\r\n    self.commands_loader.load_arguments(command)\r\n  File \"/opt/az/lib/python3.6/site-packages/azure/cli/core/__init__.py\", line 253, in load_arguments\r\n    self.command_table[command].load_arguments()  # this loads the arguments via reflection\r\n  File \"/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/__init__.py\", line 141, in load_arguments\r\n    super(AzCliCommand, self).load_arguments()\r\n  File \"/opt/az/lib/python3.6/site-packages/knack/commands.py\", line 76, in load_arguments\r\n    cmd_args = self.arguments_loader()\r\n  File \"/opt/az/lib/python3.6/site-packages/azure/cli/core/__init__.py\", line 440, in default_arguments_loader\r\n    op = handler or self.get_op_handler(operation)\r\n  File \"/opt/az/lib/python3.6/site-packages/azure/cli/core/__init__.py\", line 485, in get_op_handler\r\n    op = import_module(mod_to_import)\r\n  File \"/opt/az/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/timothy/.azure/cliextensions/webapp/azext_webapp/custom.py\", line 10, in <module>\r\n    from azure.mgmt.web.models import (AppServicePlan, SkuDescription, SnapshotRecoveryRequest, SnapshotRecoveryTarget)\r\nImportError: cannot import name 'SnapshotRecoveryRequest'\r\n```\r\n-----\r\n\r\n\n Comments: \n Comment 0: Hello @timothyparez @ahmedelnably, what version of the _webapp_ extension and the _CLI_ are you using?  \r\nTry: `az extension show -n webapp --query version` to get the version of your webapp extension.\r\n\r\nThere was a breaking change in the SDK / CLI that necessitated [this](https://github.com/Azure/azure-cli-extensions/pull/312/files) pull request and newer version of webapp (0.2.9). \r\n\r\nUpdating your extension with `az extension update -n webapp` should fix your issue.\r\n\r\nPlease let me know if this helps.\r\n\r\ncc/ @panchagnula \r\n\r\n\n Comment 1: That seems to do the trick, thank you very much.",
  "Issue title: please add tags for releases\n Issue body: This repo is missing tags corresponding to npmjs.com releases. Please add them. We like to take github tarballs for creating debian packages (to include tests and also sometimes to use the real/non-transpiled/non-minified source).\n Comments: \n Comment 0: @yyx990803 I have taken the tarball manually for now, but having proper tags will help me with new versions.",
  "Issue title: Modify readme including a reference to installing jupyter\n Issue body: Please consider upgrade the readme, \r\n\r\nRunning the sample following the readme I got the error: \r\n\r\n`ImportError: No module named notebook.notebookapp`\r\n\r\nI needed to \r\n\r\n`pip install jupyter`\r\n\r\nto being able to run the sample.\n Comments: \n Comment 0: Yeah, that would be heavily appreciated. \r\nSame annoying error here, same simple solution. \r\nDid cost 15 minutes of my very valuably time.\r\n`pip install jupyter`\n Comment 1: Updated, thanks!",
  "Issue title: AlphaNumeric Option please\n Issue body: To reproduce the error or describe your requirement with a jsfiddle url would be appreciated:\r\n- Fork this with vanilla JS component: https://jsfiddle.net/nosir/kbaxx64s/\r\n- Fork this with React JS component: https://jsfiddle.net/nosir/gLLsrxxf/\r\n\r\nIf it's mobile related, please specify your device and environment.\r\n\n Comments: \n Comment 0: I second this. Great library, but eventually I had to find alternatives due to its missing alpha-numeric filter option. Our use case can allow only a subset of letters (no capital O or I since they can easily be confused).\n Comment 1: Having this option would be really helpful.\n Comment 2: Here is a quick fix that i put in my script, it's reactive to the input, so not as clean as when you use numericOnly, but it does the trick. \r\n\r\n            $('#id').on('keyup', function () {\r\n                var input = $(this).val();\r\n                var regex = input.replace(/[^\\w]/g, \"\");\r\n                $(this).val(regex);\r\n            })",
  "Issue title: image01\n Issue body:![image](https://user-images.githubusercontent.com/23275042/57998769-12aaaa80-7afd-11e9-9c38-afef5eacd9e4.png)\r\n\n Comments: \n Comment 0:![image](https://user-images.githubusercontent.com/23275042/57998906-9f556880-7afd-11e9-867f-42098e758a78.png)\r\n",
  "Issue title: PEAR.Functions.ValidDefaultValue.NotAtEnd should not flag type hinted methods with a null default argument. \n Issue body: > Note that when using default arguments, any defaults should be on the right side of any non-default arguments; otherwise, things will not work as expected. Consider the following code snippet:\r\n>...\r\n> To specify a type declaration, the type name should be added before the parameter name. The declaration can be made to accept NULL values if the default value of the parameter is set to NULL.\r\n\r\nhttp://php.net/manual/en/functions.arguments.php\r\n\r\nUnfortunately this leads to = null on a type hinted object having a double meaning as explained in this RFC https://wiki.php.net/rfc/nullable_types\r\n\r\n>This existing behavior is not changed by this RFC. The new nullable type feature offers a subset of the functionality of = null with both making a parameter nullable but only = null making a parameter optional and have a default value:\r\n\r\nUnfortunately the manual is vague and doesn't really make a distinction.  But using the PHP 7.1 RFC syntax a method like:\r\n\r\nfoo(Animal $animal = null, Car $car)\r\n\r\nhas the semantics of foo(?Animal $animal, Car $car)\r\n\r\nThat is the ability to not specify the parameter (i.e., use the default) is lost, but you are permitted to pass null objects still. This can be verified using reflection and checking the number of parameters, vs number of required parameters.\r\n\r\nI believe that this rule should specifically exclude the case where an argument is type hinted and has a default argument of null.\n Comments: \n Comment 0: > I believe that this rule should specifically exclude the case where an argument is type hinted and has a default argument of null.\n\nI don't understand why any change to the sniff is needed. It's job is to ensure that arguments that are entirely optional in the function call are placed at the end of the function signature. The nullable flag on a parameter doesn't change if it is optional, and so doesn't change its position in the signature.\n\nIf I misunderstanding you, would you be able to provide some sample code that the sniff says is invalid but that you think should be valid?\n\n Comment 1: Using version 2.6.0\r\n\r\n```\r\n<?php\r\n\r\nclass A {\r\n}\r\n\r\nclass B { \r\n\r\npublic function thisShouldBeAnError($foo = null, $bar)\r\n{\r\n        echo \"Hello\";\r\n}\r\n\r\npublic function hasSemanticMeaningShouldNotBeAnError(A $foo = null, $bar)\r\n{\r\n       echo \"Good Bye\";\r\n}\r\n\r\npublic function thisShouldNotHighlightEither(A $foo, $bar);\r\n{\r\n       echo \"Farewell\";\r\n}\r\n\r\n\r\n}\r\n\r\n$a = new A();\r\n\r\n$b = new B();\r\n\r\n$b->hasSemanticMeaningShouldNotBeAnError(null, \"Nothing\");\r\n\r\n// This call would trigger a PHP error, bceause the type hint does not have a null on it\r\n//$b->thisShouldNotHighlightEither(null, \"Nothing\"); \r\n```\r\n\r\nRunning with the XML report prints out these two errors:\r\n```\r\n<error line=\"8\" column=\"50\" source=\"PEAR.Functions.ValidDefaultValue.NotAtEnd\" severity=\"5\" fixable=\"0\">Arguments with default values must be at the end of the argument list</error>\r\n<error line=\"13\" column=\"69\" source=\"PEAR.Functions.ValidDefaultValue.NotAtEnd\" severity=\"5\" fixable=\"0\">Arguments with default values must be at the end of the argument list</error>\r\n```\r\n\r\nThe first error makes sense, there is no reason to put that = null there and that should be a style error. In the second case, it does make sense to put = null on the first argument, because it changes the semantics of the method, and specifically it allows null elements to be called. The Sniff should exclude cases where there is a type hint, and the token after the equals is null.\r\n\r\n\r\n\r\n\n Comment 2: > In the second case, it does make sense to put = null on the first argument, because it changes the semantics of the method, and specifically it allows null elements to be called.\n\nAnd it makes method parameter having default value of `null` which makes it optional method parameter by definition \ud83d\ude04  (and PHP reflection also thinks it's optional parameter). Probably same logic of dual purpose `= null` in method parameter declaration applies to this code fragment:\n\n``` php\nfunction myName(array $array = null, $x) { }\n```\n\nThis sniff only wants all method parameters having default values to be declared after ones, that need value specified.\n\n Comment 3: I think the purpose of this sniff is because it makes no sense to do something like \n\n```\nfunction myName($foo = \"Hello\", $bar)\n```\n\nThat default argument is pointless since you always need to specify $bar, you must always specify a value for $foo.\n\nI'm not sure what you meant by \"PHP Reflection also thinks it's optional\", that isn't true in the case I pointed to above\n\nAdd this afterwards (and fix the semicolon on thisShouldNotHighlightEither)\n\n```\n$bClass = new ReflectionClass(get_class($b));\n\necho \"\\n\\n\";\nforeach($bClass->getMethods() as $method)\n{\n    echo \"\\n\". $method->name;\n    echo \"\\n\\tNumber of Parameters: \". $method->getNumberOfParameters();\n    echo \"\\n\\tNumber of Required Parameters: \". $method->getNumberOfRequiredParameters();\n\n    foreach($method->getParameters() as $parameter)\n    {\n        echo \"\\n\\t\". $parameter->getName();\n        echo \"\\n\\t\\t Position: \". $parameter->getPosition();\n        echo \"\\n\\t\\t Default Value Available: \". ($parameter->isDefaultValueAvailable()? \"Yes\" : \"No\") ;\n        echo \"\\n\\t\\t Optional: \". ($parameter->isOptional()? \"Yes\" : \"No\");\n\n    }\n}\n```\n\nThe output I get is\n\n```\nthisShouldBeAnError\n        Number of Parameters: 2\n        Number of Required Parameters: 2\n        foo\n                 Position: 0\n                 Default Value Available: Yes\n                 Optional: No\n        bar\n                 Position: 1\n                 Default Value Available: No\n                 Optional: No\nhasSemanticMeaningShouldNotBeAnError\n        Number of Parameters: 2\n        Number of Required Parameters: 2\n        foo\n                 Position: 0\n                 Default Value Available: Yes\n                 Optional: No\n        bar\n                 Position: 1\n                 Default Value Available: No\n                 Optional: No\nthisShouldNotHighlightEither\n        Number of Parameters: 2\n        Number of Required Parameters: 2\n        foo\n                 Position: 0\n                 Default Value Available: No\n                 Optional: No\n        bar\n                 Position: 1\n                 Default Value Available: No\n                 Optional: No\n```\n\nIt says that default values are available, but it specifically says they are not optional. \n\n Comment 4: Then I have no idea what `ReflectionParameter38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5isOptional` method do, because it always returns `false` and no documentation exists behind it's internal logic. Probably the `ReflectionParameter38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5isDefaultValueAvailable` is the one to be used to detect if default value is present.\n Comment 5: aik099, it doesn't always return false, it returns true in cases like\n\n```\nfunction hello($foo, $bar = \"hello\")\n{\n// Implementation.\n}\n```\n\nThe fact that the argument is optional gets dropped by PHP.   Essentially when PHP sees an parameter without a default argument after, it will make everything previous non-optional. It does not lose the information about the default argument (you need it occasionally when making subtypes with reflection), but it still internally allows type hinted parameters to be passed with null, if null was the default argument.\n\nThe point is that in Example 5 of [Function Arguments](http://php.net/manual/en/functions.arguments.php) is incorrect, and this check should warn about it. But it does make sense (for instance if you need to generalize an interface), to have a type hinted argument have null specified as the default value, not so that the parameter becomes optional, but so that you can pass null as that argument.\n\nIf there is any objections to this related to the fact that using null is sub-optimal anyway, I fully concur, but it isn't relevant to this style check.\n\n Comment 6: Thanks for digging into this.\r\n\r\nI think sniff currently assumes that if parameter with default values comes before parameter without default value, then:\r\n\r\n* it maybe placed in wrong order\r\n* need to have default value as well\r\n\r\nand reports that as an error/warning. Since sniff have no idea which of 2 above mentioned issues happened it can't emulate",
  "Issue title: website domain\n Issue body:.com?\n.io?\n.ninja?\n\nPlease drop your ideas or vote for the one you would like to see :)\n\n Comments: \n Comment 0:.io :+1: \n\n Comment 1:.org might be more relevant again looks dated but depends on the driving image you want to give mostly. (lesscss and eslint are org)\r\n\r\n.dev and others will drop soon that might be more relevant etc but I would always err on what most people type by default.\n Comment 2: # Watchers, please give your opinion on this\n\n:)\n\n Comment 3:.io +1\n Comment 4:.io but it's not so cheap.\n\n Comment 5:.fr :trollface: \r\n\r\n.io +1\n Comment 6:.io +1\n\n Comment 7: :+1: for.io\n\n Comment 8:.io :+1: \n Comment 9:.technology\n\n Comment 10:.style goes live today\n Comment 11:.bio  because it's pur CSS, no SASS or other chimical fertilizer\n.tools because it's a tools ^^\n.style because style sheets\n.ws for website\n.tech (coming soon)\n.today because u can use Css next today (no found.now)\n\n Comment 12:.style are nice, but 145\u20ac! Ouch.\nI guess I will go for.io...\n\n Comment 13:.style will have the same price when the state change to GoLive. In some hours :)\n Comment 14: I'd go for.style too.\n Comment 15: We need a `.next`",
  "Issue title: Add an option to specify a configuration file when starting clipper\n Issue body: * Currently, users have to issue many `register_model`, `deploy_model`, and `add_application` commands (among others) via clipper_admin after starting clipper. \r\n\r\n* These commands need to be re-issued after models are stopped, Redis is cleared, etc.\r\n\r\n* It would be helpful to allow users to specify a set of models and applications to deploy and register, respectively, through a configuration file. This configuration file could then be specified via the call to `start_clipper`.\n Comments: \n Comment 0: @dcrankshaw This issue belongs to Nikhil Duggirila. He needs to be added as a collaborator before I can assign this to him.\n Comment 1: I noticed that the PR (#389) for this got abandoned... any chance this is still up for grabs?\n Comment 2: @gmittal Hi! We would want to have more sophisticated design for this feature. We will definitely add this feature sooner or later. I will add this to the feature request and start working on it soon. ",
  "Issue title: TextField value vs. TextField child widget\n Issue body: **Describe the bug**\r\n<!-- A clear and concise description of what the bug is. -->\r\nWhen creating a Textfield, there should be a difference between the value and the child. Obviously the coders, who are about top deprecate the good concept, are not aware of the difference between the value and the child of a textfield widget. The value should be kept hidden. It's just the value of the field, which is not necessarily what you want to show on the document. Whereas the child widget, is what you want to show on the document. Besides, obviously the rendering of the color is buggy, since it doesn't recognize the opacity at all, but uses obviously a jpeg encoding, which has no opacity in its meyerclinton@example.com. You should better use png or other codecs with opacity values.\r\n**To Reproduce**\r\nCode snippet to reproduce the behavior:\r\n```dart\r\n// your code\r\n```\r\n\r\n**Expected behavior**\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Flutter Doctor**\r\n<!-- Paste the output of running `flutter doctor -v` here. -->\r\n\r\n```\r\n```\r\n\r\n**Desktop (please complete the following information):**\r\n - [ ] iOS\r\n - [ ] Android\r\n - [ ] Browser\r\n - [ ] Windows\r\n - [ ] Linux\r\n\r\n**Smartphone (please complete the following information):**\r\n - Device: [e.g. iPhone6]\r\n - OS: [e.g. iOS8.1]\r\n - Browser [e.g. stock browser, safari]\r\n - Version [e.g. 22]\r\n\r\n**Additional context**\r\n<!-- Add any other context about the problem here. -->\r\n\n Comments: \n Comment 0: I don't understand what you mean.\n Comment 1: When you create a textfield in the pdf, you have two variables, which you\ncan set.\n1. Value\n2. Child\n\nIn the newest version, you are about to deprecate the \"child\" variable and\nreplace it fully with the \"value\" variable.\nAnd you just print out the value as text.\n\nBut most of the times, you don't want to orint the value as text, but the\nvalue looks much different, than what you want to print out BASED ON THAT\nvalue. For example you have a yes or no as value, but want to print out its\nvalue as a check-i on or as a X-icon, instead of printing out \"yes\" or \"no\"\nas text.\n\nBut in the new version, you force the value to be printed in the odf\ndocument as text and this us wrong. It's not even possible to give that\ntext the color \"transparent\" to hide it meyerclinton@example.com.\n\nThis change is a total fail in my opinion.\n\nBest regards,\nHamid Aminirad \ud83d\ude42\n\nDavid PHAM-VAN ***@***.***> schrieb am So., 10. Apr. 2022,\n13:00:\n\n> I don't understand what you mean.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/DavBfr/dart_pdf/issues/1002#issuecomment-1094245861>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AGJLLYHNCQS7V4QFKJSUIMDVEKYEHANCNFSM5S5D3HOA>\n>.\n> You are receiving this because you authored the thread.Message ID:\n> ***@***.***>\n>\n\n Comment 2: When you create a textfield for the pdf, you have two variables, which you\ncan set.\n1. Value\n2. Child\n\nIn the newest version, you are about to deprecate the \"child\" variable and\nreplace it fully with the \"value\" variable.\nAnd you just print out the value as text.\n\nBut most of the times, you don't want to print the value as text, but the\nvalue looks much different, than what you want to print out BASED ON THAT\nvalue. For example you have a \"true\" or \"false\" as value, but want to print\nout its value as a check-icon or as a X-icon, instead of printing out \"yes\"\nor \"no\" as text.\n\nBut in the new version, you force the value to be printed in the pdf\ndocument as text and this is basically wrong. It's not even possible to\ngive that text the color \"transparent\" to hide it away at least and print\nonly the child widget.\n\nSo for the future releases you plan obviously even to deprecate the\nvariable \"child\" fully and then you can only have a text and there is then\nno difference to the text-widget and then you will fully deprecate the\ntextfield, just because your coders obviously didn't understand the\ndifference between the textfield and text. Most likely because they\nthemselves don't use pdf-creation with this library.\n\nHowever this change-development is a total fail in my opinion.\n\nBest regards,\nHamid Aminirad \ud83d\ude42\n\nOn Sun, Apr 10, 2022 at 1:00 PM David PHAM-VAN ***@***.***>\nwrote:\n\n> I don't understand what you mean.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/DavBfr/dart_pdf/issues/1002#issuecomment-1094245861>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AGJLLYHNCQS7V4QFKJSUIMDVEKYEHANCNFSM5S5D3HOA>\n>.\n> You are receiving this because you authored the thread.Message ID:\n> ***@***.***>\n>\n\n Comment 3: @BerlinLion I understand. And totally agree with you. I don't plan to deprecate the `child` property.\n Comment 4: But why is then the value being shown as text in the pdf, forcibly? It\nwasn't possible for me to hide it away, even mit a color with 0 opacity. :)\n\n\nOn Mon, Apr 11, 2022 at 1:09 PM David PHAM-VAN ***@***.***>\nwrote:\n\n> @BerlinLion <https://github.com/BerlinLion> I understand. And totally\n> agree with you. I don't plan to deprecate the child property.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/DavBfr/dart_pdf/issues/1002#issuecomment-1094917132>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AGJLLYBU6YC3CZKKEVIYIM3VEQB5HANCNFSM5S5D3HOA>\n>.\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n\n Comment 5: And besides, I took a look inside the code, and the value is being\nrendered. It shouldn't be rendered at all actually. Only the child\nvariable-widget should be rendered, but not the value. The value should\nonly be an object or a String or the like. But not be meyerclinton@example.com.\n\nOn Mon, Apr 11, 2022 at 1:09 PM David PHAM-VAN ***@***.***>\nwrote:\n\n> @BerlinLion <https://github.com/BerlinLion> I understand. And totally\n> agree with you. I don't plan to deprecate the child property.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/DavBfr/dart_pdf/issues/1002#issuecomment-1094917132>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AGJLLYBU6YC3CZKKEVIYIM3VEQB5HANCNFSM5S5D3HOA>\n>.\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n\n Comment 6: Ok, while you're in the code, you can change and provide a PR. It will be easier to see what you need.\r\nThanks.\n Comment 7: In your library in the file forms.dart, between the lines 295 and 308 is obviously the part, where the string of the value is forcibly printed out. The string of the variable \"value\" should not be printed, but only be saved as a variable inside the pdf-document. Here's the screenshot of the code.\r\n\r\n![Bildschirmfoto 2022-04-27 um 10 49 26](https://user-images.githubusercontent.com/26392032/1654820",
  "Issue title: Customize default view files.\n Issue body: Hi. \r\nHow do I customize the view files without modifying the original view files?\n Comments: \n Comment 0: You read all the instructions?\n Comment 1: Found out how to do it.",
  "Issue title: Type or namespace ColorChangedEvent/HSVChanged Event could not be found\n Issue body: Hi.  Using Unity 2020.2.0b2.3094:\r\n\r\nAssets/HSVPicker/UI/ColorPicker.cs(18,16): error CS0246: The type or namespace name 'ColorChangedEvent' could not be found (are you missing a using directive or an assembly reference)?\r\n\r\nAssets/HSVPicker/UI/ColorPicker.cs(19,16): error CS0246: The type or namespace name 'HSVChangedEvent' could not be found (are you missing a using directive or an assembly reference)?\r\n\r\nThanks!\r\n<img width=\"1269\" alt=\"HSVPickerError\" src=\"https://user-images.githubusercontent.com/75796675/101788386-0797e080-3ace-11eb-9efa-213abad25607.png\">\r\n\n Comments: \n Comment 0: Version : Unity 2020.2.2f1\r\nUnity Package Version : Color Picker 3.0.1\r\n\r\n1. Import Package\r\n2. Edit \"HSVPicker.asmdef\"\r\n- Add Use GUIDs > UnityUIExtensions\r\n-![image](https://user-images.githubusercontent.com/3183770/106562602-dc7dba80-656d-11eb-9415-3d5effe2c3cb.png)\r\n3. Each Error Script To Add \"using UnityEngine.UI.Extensions.ColorPicker;\"\r\n-![image](https://user-images.githubusercontent.com/3183770/106562636-eb646d00-656d-11eb-969d-824908373da1.png)\r\n",
  "Issue title: I dont seem to get any connection\n Issue body: ```\r\n./launch.sh \r\nremapy ROOT: /home/axel/remapy\r\n(Warning) Failed to publish subscriber.\r\n'NoneType' object is not iterable\r\nException in Tkinter callback\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.9/tkinter/__init__.py\", line 1892, in __call__\r\n    return self.func(*args)\r\n  File \"/home/axel/remapy/gui/file_explorer.py\", line 490, in btn_sync_click\r\n    root, self.is_online = self.item_manager.get_root(force=True)\r\n  File \"/home/axel/remapy/model/item_manager.py\", line 41, in get_root\r\n    self._clean_local_items(metadata_list)\r\n  File \"/home/axel/remapy/model/item_manager.py\", line 147, in _clean_local_items\r\n    online_ids = [metadata[\"ID\"] for metadata in metadata_list]\r\nTypeError: 'NoneType' object is not iterable\r\n```\n Comments: \n Comment 0: I have a similar error: when I start remapy is prints\r\n```\r\nremapy ROOT: /home/franck/bin/remapy.d\r\n(Warning) Failed to publish subscriber.\r\n'NoneType' object is not iterable\r\n```\r\nAnd the interface is stuck at `Syncing all documents...`\r\nI'm using the latest version pulled from the git repo.\n Comment 1: I also have the exact same error as fpom (Ubuntu 20.04.4)\r\n\r\nI tried uninstalling remapy, getting a fairly old commit (3e012e1d9f6b76b898278f04d6516d2c6f2bcf6b, August 28 2021) and re-install that version, and I still get the same error.  \r\n\r\nI attach the output of the install.sh in case that helps in any way. \r\n[output_install.txt](https://github.com/peerdavid/remapy/files/8391656/output_install.txt)\r\n\r\n\n Comment 2: As I found out, as the Readme says \"some\" devices started to stop working is when remarkable rolled out a new cloud API.. and this aint it, and by now its likely basically all devices. IMO the readme.md should reflect this before more and more people invest time to just discover it wont work. Also awesome-reMarkable should mark projects that cannot work due to out of date API.. there is also an issue there open to reflect it in the overview..\n Comment 3: There has been some progress reverse engineering the new API:\r\n\r\nhttps://github.com/juruen/rmapi#warning-experimental-support-for-the-new-sync-protocol\r\nor\r\nhttps://github.com/subutux/rmapy/issues/25\r\n\r\nPut it's fully conclusive how the state is (a shame remarkable keeps it's API a secret or rolls its out without giving a head info to the community they benefit from also)",
  "Issue title: Style/GuardClause false positive\n Issue body: The following example:\r\n\r\n```ruby\r\ndef foo(args)\r\n  if args.nil?\r\n    raise ArgumentError, 'Lorem ipsum dolor sit amet, consectetur adipisicing'\r\n  end\r\nend\r\n```\r\n\r\nWill result in the following offense being detected:\r\n\r\n```\r\nfoo.rb:2:3: C: Use a guard clause instead of wrapping the code inside a conditional expression.\r\n```\r\n\r\nThe problem is that the line will be too long if change the code to use a guard clause. If I add some additional code to the method I don't get the above offense:\r\n\r\n```ruby\r\ndef foo(args)\r\n  if args.nil?\r\n    raise ArgumentError, 'Lorem ipsum dolor sit amet, consectetur adipisicing'\r\n  end\r\n\r\n  3\r\nend\r\n```\r\n\r\nI would expect that no offense is reported for the first code example.\r\n\r\n```\r\n$ rubocop -V\r\n0.46.0 (using Parser 116.69.203.115, running on ruby 2.1.5 x86_64-darwin15.0)\r\n```\n Comments: \n Comment 0: Hi @jacob-carlborg, one thing I've done in the past for situations like this is breaking out the arguments into their own fewer-chars variables. In you example:\r\n\r\n```rb\r\ndef foo(args)\r\n  msg = 'Lorem ipsum dolor sit amet, consectetur adipisicing'\r\n  raise(ArgumentError, msg) if args.nil?\r\nend\r\n```\r\n\r\nI tend to like that a bit more, although that's just a matter of choice. I hope this helps \ud83d\ude03 \n Comment 1: I thought about doing that as well, but the real issue, in my opinion is the different behavior depending on if the method only contains the if statement or some else as well.\n Comment 2: RuboCop is looking for:\r\n\r\n```\r\ndef foo(args)\r\n  return unless args.nil?\r\n  raise ArgumentError, 'Lorem ipsum dolor sit amet, consectetur adipisicing'\r\nend\r\n```\r\n\r\n> [...] the real issue, in my opinion is the different behavior depending on if the method only contains the if statement or something else as well.\r\n\r\nThis is intended, as:\r\n\r\n```\r\ndef foo(args)\r\n  if args.nil?\r\n    raise ArgumentError, 'Lorem ipsum dolor sit amet, consectetur adipisicing'\r\n  end\r\n  3\r\nend\r\n```\r\n\r\nis different from:\r\n\r\n```\r\ndef foo(args)\r\n  return unless args.nil?\r\n  raise ArgumentError, 'Lorem ipsum dolor sit amet, consectetur adipisicing'\r\n  3\r\nend\r\n```\r\n\r\nwhere `3` would be unreachable.\n Comment 3: Hmm, I see. Would it be possible, somehow, to clarify that in the message?\n Comment 4: I'm not sure how much clearer \"Use a guard clause\" can be. Perhaps the message could include a link to https://github.com/bbatsov/ruby-style-guide#no-nested-conditionals\n Comment 5: @mikegee: I think the issue here was caused by there being two possible guard clauses, the other being:\r\n\r\n```\r\nraise ArgumentError, 'Lorem ipsum dolor sit amet, consectetur adipisicing' if args.nil?\r\n```\r\n\r\nwhich would violate the line length cop, but I also don't see a way of making it clearer. \ud83d\ude15 \n Comment 6: @mikegee I could only think of the guard clause that Drenmi refers to.\r\n@Drenmi what about: `Use a guard clause with early return instead...`\r\n\r\nHmm, actually, I think I'm mixing up \"if modifier\" and \"guard clause\". According to [the guidelines](https://github.com/bbatsov/ruby-style-guide#no-nested-conditionals) a \"guard clause\" returns from the method.\r\n\r\nI think, that according to the guidelines, the above:\r\n\r\n```ruby\r\nraise ArgumentError, 'Lorem ipsum dolor sit amet, consectetur adipisicing' if args.nil?\r\n```\r\n\r\nIs not a \"guard clause\" but instead a \"if modifier\". I guess it's just me that confuses the terms.\n Comment 7: > Is not a \"guard clause\" but instead a \"if modifier\". I guess it's just me that confuses the terms.\r\n\r\nExactly.",
  "Issue title: broken link https://gomatcha.io/guide/layout\n Issue body: https://gomatcha.io/guide/layout is broken and is referred to in multiple places in the docs.\n Comments: \n Comment 0: Thanks for the report!",
  "Issue title: Default Storage Classes can't easily be disabled\n Issue body: PR https://github.com/kubernetes/kubernetes/pull/31617/files introduced default storage classes for 1.6. They are created with cluster addon which can not easily be modified by end users (requires access to the master).\r\n\r\nWe should improve experience before 1.6 goes out.\r\n\r\nCC @kubernetes/sig-storage-misc \n Comments: \n Comment 0: @mikedanese another call for addon manager to distinguish initial values\nfrom re-asserted values.\n\nOn Fri, Jan 6, 2017 at 6:01 PM, Saad Ali <elizabeth78@example.org> wrote:\n\n> PR https://github.com/kubernetes/kubernetes/pull/31617/files introduced\n> default storage classes for 1.6. They are created with cluster addon which\n> can not easily be modified by end users (requires access to the master).\n>\n> We should improve experience before 1.6 goes out.\n>\n> CC @kubernetes/sig-storage-misc\n> <https://github.com/orgs/kubernetes/teams/sig-storage-misc>\n>\n> \u2014\n> You are receiving this because you are on a team that was mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/kubernetes/kubernetes/issues/39561>, or mute the\n> thread\n> <https://github.com/notifications/unsubscribe-auth/AFVgVAybLiaYg14LhlDdfo0t_EgrVJ27ks5rPvHvgaJpZM4LdS3s>\n>.\n>\n\n Comment 1: @msau42 can help out with this\n Comment 2: @mrhohn @mikedanese who among us feels the most ownership of addon\nmanager?  This is reaching a boiling point.\n\nOn Wed, Jan 11, 2017 at 3:26 PM, Saad Ali <elizabeth78@example.org> wrote:\n\n> @msau42 <https://github.com/msau42> can help out with this\n>\n> \u2014\n> You are receiving this because you are on a team that was mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/kubernetes/kubernetes/issues/39561#issuecomment-272028640>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFVgVAYw8s87qt63mJQjP5YAJ1540dzsks5rRWU_gaJpZM4LdS3s>\n>.\n>\n\n Comment 3: As @mikedanese [mentioned before](https://github.com/kubernetes/kubernetes/pull/34639#issuecomment-253858033), it wouldn't be hard to implement an \"oneshot\" functionality. I also had [a short proposal](https://github.com/kubernetes/kubernetes/pull/34639#issuecomment-253717529) for this.\r\n\r\nIf we agree this is the proper way to go with, I can also help out. The required work I expect would be putting couple more startup logics into [kube-addon.sh](https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/addon-manager/kube-addons.sh) that carefully handle upgrade/restart cases.\n Comment 4: Other that StorageClass (which I guess an admin *might* want to remove) I\ndon't think oneshot is what we want.  Maybe we just want to ensure that an\nobject exists and if it doesn't, create it with a known base-config.  Is\nthat sufficient?\n\nOn Wed, Jan 11, 2017 at 11:06 PM, Zihong Zheng <elizabeth78@example.org>\nwrote:\n\n> As @mikedanese <https://github.com/mikedanese> mentioned before\n> <https://github.com/kubernetes/kubernetes/pull/34639#issuecomment-253858033>,\n> it wouldn't be hard to implement an \"oneshot\" functionality. I also had a\n> short proposal\n> <https://github.com/kubernetes/kubernetes/pull/34639#issuecomment-253717529>\n> for this.\n>\n> If we agree this is the proper way to go with, I can also help out. The\n> required work I expect would be putting couple more startup logics into\n> kube-addon.sh\n> <https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/addon-manager/kube-addons.sh>\n> that carefully handle upgrade/restart cases.\n>\n> \u2014\n> You are receiving this because you are on a team that was mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/kubernetes/kubernetes/issues/39561#issuecomment-272092186>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFVgVDgefO9HwhtP6Flw-I-tM7CMMU91ks5rRdEPgaJpZM4LdS3s>\n>.\n>\n\n Comment 5: Ensure exist sounds good. What about two classes: one that reconcile, the other ensure exist?\n Comment 6: That sounds acceptable.  We mainly need:\r\n\r\n1. A way to be able to change the default-class annotation\r\n2. That change should persist across upgrades\r\n\r\nI think it is ok if the deletion case is not supported.  Changing the default-class is sufficient to get the behavior we want.\n Comment 7: @msau42, can I help you in any way? I know very little about addon manager and its internals.\n Comment 8: Thanks, I plan to coordinate with addon folks to make the change.  It may end up being that all the changes are only in the addon component.",
  "Issue title: HELLO - Check your spelling - MacOS Driver\n Issue body: Your spelling is\r\n\r\n`https://github.com/mozilla/geckodriver/releases/download/v0.10.0/geckodriver-v0.10.0-mac.tar.gz`\r\n\r\nWhich does not exist. Change it to:\r\n\r\nhttps://github.com/mozilla/geckodriver/releases/download/v0.10.0/geckodriver-v0.10.0-macos.tar.gz\n Comments: \n Comment 0: I have opened a issue on https://github.com/mozilla/geckodriver/issues/193",
  "Issue title: DownloadContents can't download files from root of repo\n Issue body: GitHub Apps have the ability to request access to individual files which is great for fine-grained access.\r\n\r\n![image](https://user-images.githubusercontent.com/1634746/192168329-c4a27c5c-4868-497c-900b-5e9aa1e53c98.png)\r\n\r\nHowever, as of `v47.1.0`, this will prevent someone from being able to download a file from the root repository because of the way `DownloadContents` implements directory scanning first:\r\n\r\nhttps://github.com/google/go-github/blob/8a4bdb5e400fef2e8d783d35d8f4cfd1bc79c01e/github/repos_contents.go#L129-L134\r\n\r\nThe first thing that the function does is get just the directory name with `path.Dir` but if you try to download a file like just `CODEOWNERS` which is a valid location for a `CODEOWNERS` file, then the first request to the API will create a URL like so:\r\n```\r\nhttps://api.github.com/repos/$owner/$repo/contents/\r\n```\r\n\r\nAt the moment, there's no way to add the root directory to the list of single file paths. You cannot add a blank path and adding just `/` doesn't work either.\n Comments: \n Comment 0: So was this a regression caused by a change to `v47.1.0`?\r\n\r\nDo you want to create a PR to fix this, @abatilo, or would you like me to open up this issue to other contributors to this repo to address?\n Comment 1: Hi @gmlewis, I think I actually poorly chose my words. I shouldn't have said \"as of v47.1.0\" but instead it's more that I found this behavior while using `v47.1.0`. It appears that this has been the behavior for the history of the function? I don't think I have the availability to work on this so I'd be happy to have this open up to anyone who wants to contribute!\n Comment 2: Thank you, @abatilo .\r\n\r\nThis would be a great PR for any new contributor to this repo or a new Go developer.\r\nAll contributions are greatly appreciated!\r\n\r\nFeel free to volunteer for any issue and the issue can be assigned to you so that others don't attempt to duplicate the work.\r\n\r\nPlease check out our [CONTRIBUTING.md](https://github.com/google/go-github/blob/master/CONTRIBUTING.md) guide to get started. (In particular, please remember to `go generate./...` and don't use force-push to your PRs.)\r\n\r\nThank you!\n Comment 3: I took a look into this tonight because I'd like to get involved in the project. Based on the `path.Dir` docs I found [here](https://rogersjasmine@example.com#Dir), it seems like it _should_ be possible for the existing code to download files from the root of a repo:\r\n\r\nI was able to construct a minimal working example of this as follows:\r\n1. Created a test module called `go-gh-testcase`. `main.go` of this module looks like:\r\n\r\n```golang\r\npackage main\r\n\r\nimport (\r\n\t\"golang.org/x/oauth2\"\r\n\t\"github.com/google/go-github/github\"\r\n\t\"context\"\r\n\t\"fmt\"\r\n)\r\n\r\nfunc main() {\r\n\tctx := context.Background()\r\n\tts := oauth2.StaticTokenSource(\r\n\t\t&oauth2.Token{AccessToken: \"<YOUR-GITHUB-PAT-HERE>\"})\r\n\ttc := oauth2.NewClient(ctx, ts)\r\n\tclient := github.NewClient(tc)\r\n\r\n\tconst (\r\n\t\towner = \"google\"\r\n\t\trepo = \"go-github\"\r\n\t)\r\n\tfilepath := \"LICENSE\"\r\n\r\n\trc, _, err := client.Repositories.DownloadContents(ctx, owner, repo, filepath, nil)\r\n\tif err!= nil {\r\n\t\tfmt.Errorf(\"Error was: %s\\n\", err)\r\n\t}\r\n\tdefer rc.Close()\r\n        byteCount := 100\r\n\tbuf := make([]byte, byteCount)\r\n        n, err := rc.Read(buf)\r\n        if err!= nil {\r\n            fmt.Errorf(\"Error while reading into buffer: %s\\n\", err)\r\n        }\r\n\tfmt.Printf(\"Contents of first %d bytes are: %s\\n\", byteCount, buf[:n])\r\n}\r\n```\r\n\r\n2. Modified `go-github/github/repos_content.go` _very_ slightly to add some `fmt.Println`s in the appropriate places:\r\n```diff\r\ndiff --git a/github/repos_contents.go b/github/repos_contents.go\r\nindex be58fd5..d4a2319 100644\r\n--- a/github/repos_contents.go\r\n+++ b/github/repos_contents.go\r\n@@ -127,13 +127,16 @@ func (s *RepositoriesService) GetReadme(ctx context.Context, owner, repo string,\r\n // code to verify the content is from a successful response.\r\n func (s *RepositoriesService) DownloadContents(ctx context.Context, owner, repo, filepath string, opts *RepositoryContentGetOptions) (io.ReadCloser, *Response, error) {\r\n        dir := path.Dir(filepath)\r\n+       fmt.Printf(\"Dir is: %s\\n\", dir)\r\n        filename := path.Base(filepath)\r\n+       fmt.Printf(\"Filename is: %s\\n\", filename)\r\n        _, dirContents, resp, err := s.GetContents(ctx, owner, repo, dir, opts)\r\n        if err!= nil {\r\n                return nil, resp, err\r\n        }\r\n \r\n        for _, contents := range dirContents {\r\n+               fmt.Printf(\"\\tName of found content item is: %s\\n\", *contents.Name)\r\n                if *contents.Name == filename {\r\n                        if contents.DownloadURL == nil || *contents.DownloadURL == \"\" {\r\n                                return nil, resp, fmt.Errorf(\"no download link found for %s\", filepath)\r\n```\r\n\r\nBecause of the behavior of `path.Dir`, as outlined [here](https://rogersjasmine@example.com#Dir), a `filepath` without any `/`s (such as the path `\"LICENSE\"` I chose in the first code block) will result in `dir` being set to `\".\"`. So I think this would actually result in a URL that looks like: \r\n```https://api.github.com/repos/$owner/$repo/contents/.```\r\n\r\nRunning the code above, I got the result:\r\n\r\n```\r\nDir is:.\r\nFilename is: LICENSE\r\n        Name of found content item is:.codecov.yml\r\n        Name of found content item is:.github\r\n        Name of found content item is:.gitignore\r\n        Name of found content item is:.golangci.yml\r\n        Name of found content item is: AUTHORS\r\n        Name of found content item is: CONTRIBUTING.md\r\n        Name of found content item is: LICENSE\r\nContents of first 100 bytes are: Copyright (c) 2013 The go-github AUTHORS. All rights reserved.\r\n\r\nRedistribution and use in source and\r\n```\r\n\r\nwhich is the first 100 bytes of `go-github`'s `LICENSE` file. \r\n\r\nDoing the same test on the `go.sum` file (last file in the root of the repo as it appears in GitHub UI) yields:\r\n```\r\nDir is:.\r\nFilename is: go.sum\r\n        Name of found content item is:.codecov.yml\r\n        Name of found content item is:.github\r\n        Name of found content item is:.gitignore\r\n        Name of found content item is:.golangci.yml\r\n        Name of found content item is: AUTHORS\r\n        Name of found content item is: CONTRIBUTING.md\r\n        Name of found content item is: LICENSE\r\n        Name of found content item is: README.md\r\n        Name of found content item is: example\r\n        Name of found content item is: github\r\n        Name of found content item is: go.mod\r\n        Name of found content item is: go.sum\r\nContents of first 100 bytes are: github.com/golang/protobuf v1.3.1/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\r\ngithub.com/\r\n```\r\n\r\nSo, it seems like specifying a filename in the repo root will still behave properly; the API call will just consider `dir` to be `\".\"`, but the file will be found in the `for` loop over the contents of `\".\"` if it's in the root.\r\n\r\n---\r\n\r",
  "Issue title: static linking a no-op binary fails\n Issue body: ### What version of Go are you using (`go version`)?\r\n\r\n<pre>\r\n$ go version\r\ngo version go1.17 linux/amd64\r\n</pre>\r\nNote I was using the docker `golang:1.17-buster` image.\r\n### Does this issue reproduce with the latest release?\r\nyes, it reproduces with the latest go 1.17\r\n\r\n\r\n### What operating system and processor architecture are you using (`go env`)?\r\n\r\n<details><summary><code>go env</code> Output</summary><br><pre>\r\n$ go env\r\nGO111MODULE=\"\"\r\nGOARCH=\"amd64\"\r\nGOBIN=\"\"\r\nGOCACHE=\"/root/.cache/go-build\"\r\nGOENV=\"/root/.config/go/env\"\r\nGOEXE=\"\"\r\nGOEXPERIMENT=\"\"\r\nGOFLAGS=\"\"\r\nGOHOSTARCH=\"amd64\"\r\nGOHOSTOS=\"linux\"\r\nGOINSECURE=\"\"\r\nGOMODCACHE=\"/go/pkg/mod\"\r\nGONOPROXY=\"\"\r\nGONOSUMDB=\"\"\r\nGOOS=\"linux\"\r\nGOPATH=\"/go\"\r\nGOPRIVATE=\"\"\r\nGOPROXY=\"https://proxy.golang.org,direct\"\r\nGOROOT=\"/usr/local/go\"\r\nGOSUMDB=\"sum.golang.org\"\r\nGOTMPDIR=\"\"\r\nGOTOOLDIR=\"/usr/local/go/pkg/tool/linux_amd64\"\r\nGOVCS=\"\"\r\nGOVERSION=\"go1.17\"\r\nGCCGO=\"gccgo\"\r\nAR=\"ar\"\r\nCC=\"gcc\"\r\nCXX=\"g++\"\r\nCGO_ENABLED=\"1\"\r\nGOMOD=\"/dev/null\"\r\nCGO_CFLAGS=\"-g -O2\"\r\nCGO_CPPFLAGS=\"\"\r\nCGO_CXXFLAGS=\"-g -O2\"\r\nCGO_FFLAGS=\"-g -O2\"\r\nCGO_LDFLAGS=\"-g -O2\"\r\nPKG_CONFIG=\"pkg-config\"\r\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build838287027=/tmp/go-build -gno-record-gcc-switches\"\r\n</pre></details>\r\n\r\n### What did you do?\r\n\r\nI tried to statically compile a simple main file:\r\n```\r\n$ cat go.mod\r\nmodule naphatkrit/go-bug-repro\r\n\r\ngo 1.17\r\n$ cat main.go\r\npackage main\r\n\r\nfunc main() {\r\n}\r\n```\r\n\r\nI then ran `go build` with the flags needed to statically link my binary, this results in a warning about not being able to find cgo.\r\n```\r\n$ go build -a -v -o /tmp/my-binary -ldflags \"-linkmode external -extldflags -static\" -trimpath.\r\nruntime/internal/sys\r\ninternal/goexperiment\r\ninternal/cpu\r\ninternal/abi\r\nruntime/internal/atomic\r\nruntime/internal/math\r\ninternal/bytealg\r\nruntime\r\nnaphatkrit/go-bug-repro\r\n# naphatkrit/go-bug-repro\r\nloadinternal: cannot find runtime/cgo\r\n```\r\n\r\n### What did you expect to see?\r\n\r\nWhen I execute the binary, I expect the binary to run and exit.\r\n\r\n### What did you see instead?\r\nExecuting the binary results in a trap error\r\n```\r\n$ /tmp/my-binary\r\nTrace/breakpoint trap\r\n```\r\n\r\nAdditionally, here is what strace shows:\r\n```\r\nroot@3f441e3ed41c:/code# strace /tmp/my-binary\r\nexecve(\"/tmp/my-binary\", [\"/tmp/my-binary\"], 0x7fff5db80d00 /* 10 vars */) = 0\r\nbrk(NULL)                               = 0xf03000\r\nbrk(0xf041c0)                           = 0xf041c0\r\narch_prctl(ARCH_SET_FS, 0xf03880)       = 0\r\nuname({sysname=\"Linux\", nodename=\"3f441e3ed41c\",...}) = 0\r\nreadlink(\"/proc/self/exe\", \"/tmp/my-binary\", 4096) = 14\r\nbrk(0xf251c0)                           = 0xf251c0\r\nbrk(0xf26000)                           = 0xf26000\r\narch_prctl(ARCH_SET_FS, 0x55fd90)       = 0\r\n--- SIGTRAP {si_signo=SIGTRAP, si_code=SI_KERNEL} ---\r\n+++ killed by SIGTRAP +++\r\nTrace/breakpoint trap\r\n```\r\n\r\nIf I forcibly include runtime/cgo, the build warning goes away and the compiled binary runs fine.\r\n```\r\n$ cat main.go\r\npackage main\r\n\r\nimport _ \"runtime/cgo\"\r\n\r\nfunc main() {\r\n}\r\n```\r\n\r\n```\r\n$ go build -a -v -o /tmp/my-binary -ldflags \"-linkmode external -extldflags -static\" -trimpath.\r\ninternal/race\r\nruntime/internal/sys\r\ninternal/abi\r\ninternal/cpu\r\ninternal/goexperiment\r\nruntime/internal/atomic\r\nsync/atomic\r\nruntime/internal/math\r\ninternal/bytealg\r\nruntime\r\nsync\r\nruntime/cgo\r\nnaphatkrit/go-bug-repro\r\n$ /tmp/my-binary\r\n$\r\n```\r\nAm I doing static linking wrong?\r\n\r\nI have put up my repro at https://github.com/naphatkrit/go-bug-repro for convenience\n Comments: \n Comment 0: Unlike many projects, the Go project does not use GitHub Issues for general discussion or asking questions. GitHub Issues are used for tracking bugs and proposals only.\r\n\r\nFor questions please refer to https://github.com/golang/go/wiki/Questions\n Comment 1: This looks like a go bug doesn\u2019t it?\n Comment 2: Why the complicated recipe? Go builds static binaries by default. Just `go build` should work.\r\n\n Comment 3: wait is that true even when there are dependencies? when I tried to build a more complicated example from work and run it through ldd, it's clearly not statically linked when only using `go build`:\r\n```\r\n$ ldd <my binary>\r\n\tlinux-vdso.so.1 (0x00007ffc13bfe000)\r\n\tlibpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f87cd2ed000)\r\n\tlibc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f87cd12c000)\r\n\t/lib64/ld-linux-x86-64.so.2 (0x00007f87cd314000)\r\n```\n Comment 4: When you're using cgo, all bets are off, as the C code can pull in dynamic dependencies. But if you're using cgo your recipe works.\r\nI think there's some issues with some packages (net?) that pull in dynamically linked libraries. Not sure though, that may just be OSX.\r\n\n Comment 5: did a little more tingling, it seems the culprit is `-linkmode external`. Without it, the produced binary is static and doesn't have the issue described here (according to `ldd` and `file`). I have tried this with code that imports only stdlib cgo packages like `net` and `os` only (while passing `-tags 'osusergo,netgo'`), and also with code that imports custom cgo packages like sqlite. \r\n\r\nIt does feel like it works accidentally though. Reading the doc for linkmode, \r\n> By default, cmd/link will decide the linking mode as follows: if the only packages using cgo are those on a list of known standard library packages (net, os/user, runtime/cgo), cmd/link will use internal linking mode. Otherwise, there are non-standard cgo packages involved, and cmd/link will use external linking mode.\r\n\r\nSo without custom cgo code, the internal linker does the right thing. With custom cgo code like sqlite, the external linker is pulled in but the custom code also pulls in runtime/cgo, so that also ensures the issue I described doesn't show up. It appears the problem is when combining external linker with stdlib cgo code and `-tags 'osusergo,netgo'`, which then causes it to compile a binary with runtime/cgo and andrew77@example.net.",
  "Issue title: greeter/api/graphql example cannot be compiled\n Issue body: The compile error output is :\r\n`graphql/generated.go:236:3: unknown field 'IsMethod' in struct literal of type graphql.ResolverContext\r\ngraphql/generated.go:263:3: unknown field 'IsMethod' in struct literal of type graphql.ResolverContext\r\ngraphql/generated.go:294:3: unknown field 'IsMethod' in struct literal of type graphql.ResolverContext\r\ngraphql/generated.go:325:3: unknown field 'IsMethod' in struct literal of type graphql.ResolverContext\r\ngraphql/generated.go:349:3: unknown field 'IsMethod' in struct literal of type graphql.ResolverContext\r\ngraphql/generated.go:376:3: unknown field 'IsMethod' in struct literal of type graphql.ResolverContext\r\ngraphql/generated.go:400:3: unknown field 'IsMethod' in struct literal of type graphql.ResolverContext\r\ngraphql/generated.go:427:3: unknown field 'IsMethod' in struct literal of type graphql.ResolverContext\r\ngraphql/generated.go:454:3: unknown field 'IsMethod' in struct literal of type graphql.ResolverContext\r\ngraphql/generated.go:481:3: unknown field 'IsMethod' in struct literal of type graphql.ResolverContext\r\ngraphql/generated.go:481:3: too many errors\r\n`\r\n\r\nThe reason is gqlgen version in go.mod is v0.7.1, which doesn't contain member IsMethod in struct ResolverContext. The fix method is changing the version to v0.8.3.\n Comments: \n Comment 0: Updated. I believe this should be fixed.",
  "Issue title: [TSC] Figures policy README\n Issue body: As requested bt @kedmison, we beed a README file to explain where diagrams should be kept and include some pointers to how to use.svg files etc.\n Comments: \n Comment 0: I can add the where the diagrams stored part, but I have no idea how to use.svg files. ",
  "Issue title: ui38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5InputText widget can't input characters\n Issue body: I use cinder-imgui in ubuntu 14 to write some toy code. When i pressed keyboard to type characters to ui38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5InputText widgets, the widgets' contents didn't insert any new characters. However, when i pressed the delete key, the characters in widgets could be deleted. Even in the test demo window, i can't insert any words in console examples. The 'WantCaptureKeyboard' and 'WantTextInput' flags in test demo windows were set to 1 when i focus and ui38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5InputText. It works when i test samples in imgui, but it dosen't works when i test in cinder-imgui. Could any one can give some advice how to set cinder-imgui properly?\n Comments: \n Comment 0: Could this be related to https://discourse.libcinder.org/t/cant-type-in-the-imgui-sample-linux/615 (since you're also on Linux)? Or maybe not...\r\n\r\nI'm using macOS and finding lots of weird things with the InputText (Multiline) widget.  It often loses shift, control or command key modifiers, subsequently acting like the key remains held down (loses the keyUp?).  Also, I think cut and paste are supposed to work with ImGui, but I've not had any luck with them in Cinder-ImGui.\r\n",
  "Issue title: Loading DataParallel GPU model on CPU\n Issue body: Follow up to #1 issue\r\n@abhishekkrthakur : Can you give any leads on how to load DataParallel GPU model on CPU?\r\nAs per pytorch docs tried following but still raises above RuntimeError\r\n```python\r\ndevice = torch.device('cpu')\r\nmodel = TheModelClass(*args, **kwargs)\r\nmodel.load_state_dict(torch.load(PATH, map_location=device))\r\n```\n Comments: \n Comment 0: hi. in load state dict, you have to use map_location to cpu. \n Comment 1: and before that you need to use DataParallel as mentioned in #1\n Comment 2: I did but still getting error.\r\n\r\n```python\r\nMODEL.load_state_dict(torch.load(config.MODEL_PATH, map_location={\"cuda:0\" : \"cpu\"}))\r\n```\n Comment 3: @abhishekkrthakur  Here is Traceback for your reference after setting `maplocation` to cpu\r\n```python\r\nTraceback (most recent call last):\r\n  File \"predict.py\", line 61, in <module>\r\n    positive_prediction = sentence_prediction(sentence)\r\n  File \"predict.py\", line 54, in sentence_prediction\r\n    token_type_ids=token_type_ids\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/data_parallel.py\", line 146, in forward\r\n    \"them on device: {}\".format(self.src_device_obj, t.device))\r\nRuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu\r\n```\n Comment 4: Could you please post the stacktrace when you don't use DataParallel and set map_location='cpu'?\n Comment 5: Sure. Updated above comment with model load lines for your reference.\r\n\r\nwithout `DataParallel` (commented out) and with `map_location='cpu'`\r\n\r\n\r\n```python\r\nDEVICE = torch.device('cpu')\r\nPREDICTION_DICT = dict()\r\nmemory = joblib.Memory(\"/content/bert-sentiment/input/\", verbose=0)\r\n\r\nMODEL = BERTBaseUncased()\r\n# MODEL = nn.DataParallel(MODEL)\r\nMODEL.load_state_dict(torch.load(config.MODEL_PATH,  map_location=DEVICE))\r\nMODEL.to(DEVICE)\r\nMODEL.eval()\r\n```\r\n\r\nTraceback:\r\n\r\n```\r\n2020-03-29 15:39:15.549276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\nTraceback (most recent call last):\r\n  File \"predict.py\", line 17, in <module>\r\n    MODEL.load_state_dict(torch.load(config.MODEL_PATH,  map_location=DEVICE))\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\r\n    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\r\nRuntimeError: Error(s) in loading state_dict for BERTBaseUncased:\r\n\tMissing key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight",
  "Issue title: odd wikification behavior\n Issue body: Hi,\r\nThanks for making this code available!  I'm trying it on some fake text and getting unexpected results in the wikification.  I have the following meaningless blah.txt (just playing around with different types of entities):\r\n\r\n```\r\nMichael Jackson was born in the United Kingdom and his dog was born in Japan.  He became president of Microsoft in March 2016.  Jackson owns a golf course in the UK and loves to listen to Freaky Girl.\r\n```\r\n\r\nI made a WikipediaInterface that includes a bunch of entities, including most of those in blah.txt.\r\n\r\nRunning the Driver produces the following output-wiki.conll:\r\n\r\n```\r\n#begin document (test2/text/blah.txt); part 000\r\n(Michael Jackson*\r\n*)\r\n*\r\n*\r\n*\r\n(United Kingdom*\r\n*\r\n*)\r\n*\r\n(Dog -LRB-zodiac-RRB-(-EXCLUDE-*)\r\n*)\r\n*\r\n*\r\n*\r\n(Japan*)\r\n*\r\n\r\n(-EXCLUDE-*)\r\n*\r\n(President of the United States*\r\n*\r\n(-NIL-*))\r\n*\r\n(-NIL-*\r\n*)\r\n*\r\n\r\n(Lauren Jackson*)\r\n*\r\n(-NIL-*\r\n*\r\n*\r\n*\r\n(-NIL-*\r\n*))\r\n*\r\n*\r\n*\r\n*\r\n*\r\n(-NIL-*\r\n*)\r\n*\r\n\r\n#end document\r\n```\r\n\r\nQuestions:\r\n1) Why would it guess \"Lauren Jackson\" for the last \"Jackson\"?  The coreference system knows that these are the same reference id, so I could feasibly resolve there.  But I'm also wondering why it might pick Lauren Jackson, given my wikipediaInterface -- here's what queryDisambigs is giving:\r\n\r\n```\r\nArrayBuffer([Jackson, Mississippi : 1,269, Jackson, Michigan : 357, Edwin Jackson : 346, Jackson, Tennessee : 315, Lauren \r\nJackson : 269, Jackson County, Missouri : 227, Jackson County, West Virginia : 146,...])\r\n```\r\n\r\n2)  Similarly, not sure how \"Dog (zodiac)\" skipped over \"Dog\", given queryDisambigs:\r\n\r\n```\r\nArrayBuffer([], [Dog : 927, Dog (zodiac) : 173, Hurricane Dog (1950) : 7, Dog (film) : 4, Dog (album) : 4, Police dog : 3, Dog meat : 3, Dog (single) : 2, Dog (band) : 2], [])\r\n```\r\n\r\n3)  \"President of the United States\" is wrong, and it misses \"the UK\"...\r\n\r\n4)  Do you have code that gives the single most likely wikipedia entity for all references with a particular id?  e.g. \"Michael Jackson\", \"his\", \"He\", and \"Jackson\" are all resolved by coreference, but with different wikiChunks (Michael Jackson vs Lauren Jackson).  I would think, since you're doing coref & NER jointly, you'd have that functionality but I haven't found it.\r\n\r\n\r\nI've been trying to debug, but it gets a bit opaque once I get into the BP nodes.\n Comments: \n Comment 0: Hi,\r\n\r\nThanks for your interest!\r\n\r\nThe system that runs on raw data is pretty bad at Wikification because this is treated as a latent variable during learning; that model isn't trained with any knowledge of gold-standard Wikipedia labels. The ACE model is much better, but that requires ACE-style mentions to be fed in during preprocessing, this being an unfortunate byproduct of how the system was evaluated given datasets that are available. We're currently working on a standalone Wikification component that should be able to do well more broadly, but that won't be available for at least a few months.\r\n\r\nTo answer your questions:\r\n\r\n1) The data that it the system is trained on often has coreferent things have different Wikipedia links (e.g. Barack_Obama and President_of_the_United_States), so this isn't enforced as a hard constraint. I agree this is a bad mistake but it's not easily fixable.\r\n\r\n2) There are features that look at things like parentheticals in the Wikipedia titles; in this case it leads to a silly error but the system does sometimes have to skip over the most obvious thing to get the correct answer, hence why it has learned to do this.\r\n\r\n3) President is so often used to refer to the President of the US that I'm not surprised this error happens. Using contextual information to resolve this appropriately is a current research problem.\r\n\r\n4) No code for this, sorry. You could write a separate module that reads the documents back in after prediction (using ConllDocReader) and does a kind of voting / prefers the label given to the first mention.\r\n\r\nUnfortunately, most of these issues are nontrivial to fix / require a richer model rather than simply debugging. But thank you for bringing them to my attention, and I appreciate the interest!\r\n\r\nGreg\n Comment 1: Thanks @gregdurrett.  Yes, sounds like I'll have to work around for the time being -- but still really appreciate that you put out this code.\r\n\r\nJust for understanding though, let me follow up on #2.  So I understand that sometimes it needs to skip the most obvious thing.  But at at high level, what are the signals that are driving the skipping?  i.e. What signal might make it skip over \"Dog\" and go to \"Dog (zodiac)\", when Dog has a stronger prior in the wikiDB and when it's presumably a better textual match?\r\n\r\n(Similarly but less surprisingly, I'm wondering what signals might make it skip to Lauren Jackson, over \"Jackson, Mississippi\" or \"Edwin Jackson\" in the wikiDB).\n Comment 2: 1) The features for Wikification are described in edu.berkeley.nlp.entity.wiki.QueryChooser (not the best name). It's possible that many links to articles without parentheticals (e.g. \"Dog\") are bad, and the system has features on this so I'm guessing it has somehow learned to prefer <Title> (X) over <Title> even when <Title> is ranked more highly. I'm not sure, though. Also, the prior is only used to rank choices, so even an overwhelming preference for the first choice vs. the second choice won't necessarily translate into the first choice winning (not necessarily the best decision on my part).\r\n\r\n2) Not sure why it picked Lauren Jackson instead of Edwin Jackson, but skipping Jackson, Mississippi might actually be the system working as intended: it knows that Jackson is coreferent with Michael Jackson, who is of type person, so features targeting agreement between NER and the entity link should prefer a link to an article about a person.",
  "Issue title: Miss handle of `background-size` under IE8\n Issue body: As we known that `background-size` property is not supported under IE8 mentioned inside [MDN](https://developer.mozilla.org/en-US/docs/Web/CSS/background-size#Browser_compatibility), I hope that autoprefixer can handle it like `opacity`:\r\n\r\n```css\r\n/* before */\r\n\r\n.figure {\r\n    opacity:.5;\r\n}\r\n\r\n/* after */\r\n\r\n.figure {\r\n    filter: alpha(opacity=50);\r\n}\r\n```\r\n\r\nWhen it comes to `background-size`:\r\n\r\n```css\r\n/* before */\r\n\r\n.figure {\r\n    background-size: cover;\r\n    background-image: url(./path/image.jpg);\r\n}\r\n\r\n/* after */\r\n\r\n.figure {\r\n    background-size: cover;\r\n    background-image: url(./path/image.jpg);\r\n    filter: progid:DXImageTransform.Microsoft.AlphaImageLoader(src='[hash].jpg', sizingMethod=scale);\r\n}\r\n```\r\n\r\nBut there is a special situation you need to know is that `src` should be relative to referenced page site, rather than local file system. If we all use postcss to bundle image source and rename with a specified hash, this notice can be ignored.\n Comments: \n Comment 0: > that src should be relative to referenced page site, rather than local file system.\r\n\r\nThat sounds like something Autoprefixer won't be able to do.\r\n\r\nAutoprefixer has no access to the web page url and isn't built in a way to be able to figure that sort of thing out from the file system.\n Comment 1: Actually, you can just convert when src is only specified with file name, where developers can use some tutorials to import images with file name only like [webpack-contrib/file-loader](https://github.com/webpack-contrib/file-loader).\n Comment 2: Sorry, Autoprefixer is only about prefixes.\r\n\r\nYou need to checkout PostCSS plugins. It was a plugin o polyfill `alpha(opacity=50)`.\n Comment 3: You mean I should open this issue for the plugin [oldIE](https://github.com/jonathantneal/oldie)? @ai \n Comment 4: Yeap\n Comment 5: I have thought about this before, but it is wierd that I just use **ejohnson@example.com** + **ejohnson@example.com** without **oldie** plugin, and `opacity` has been shimed with `filter`. So I think perhaps the plugin is embeded within autoprefixer?\n Comment 6: Agree. It was a mistake and it was not possible to fix it \ud83d\ude05\r\n\r\nhttps://github.com/postcss/autoprefixer/blob/11c61e3d60a688e14128bd7927be29110fcc33df/test/cases/filter.css\n Comment 7: \ud83d\ude22 So if I upgrade autoprefixer, should I use the **oldie** plugin to do so?\n Comment 8: > should I use the oldie plugin to do so?\r\n\r\nYeap. Any new IE compatibility features should go to oldie.",
  "Issue title: Unable to run example app \n Issue body: ## Your Environment\r\n* Plugin version: master branch\r\n* Platform: iOS \r\n* OS version: mac Catalina\r\n* Device manufacturer / model:\r\niPhone 7\r\n* Flutter info (`flutter doctor`):\r\nDoctor summary (to see all details, run flutter doctor -v):\r\n[\u2713] Flutter (Channel stable, v1.17.4, on Mac OS X 10.15.3 19D76, locale en-US)\r\n \r\n[\u2713] Android toolchain - develop for Android devices (Android SDK version 28.0.3)\r\n[\u2713] Xcode - develop for iOS and macOS (Xcode 11.5)\r\n[\u2713] Android Studio (version 3.6)\r\n[!] IntelliJ IDEA Ultimate Edition (version 2020.1.2)\r\n    \u2717 Flutter plugin not installed; this adds Flutter specific functionality.\r\n    \u2717 Dart plugin not installed; this adds Dart specific functionality.\r\n[\u2713] VS Code (version 1.38.1)\r\n[\u2713] Connected device (1 available)\r\n\r\n! Doctor found issues in 1 category.\r\n\r\nI have both flutter and Dart pluggings installed\r\n\r\n* Plugin config:\r\n```dart <-- Syntax highlighting: DO NOT REMOVE -->\r\n\r\n```\r\n\r\n## Expected Behavior\r\nZoom meeting \r\n\r\n## Actual Behavior\r\nGetting a blank page\r\n\r\n## Steps to Reproduce\r\n1. Zoom market place created jwt app\r\n2. updated app key and app secret user id in meeting_screen.dart\r\n3. start the app\r\n4. Sart a meeting on my desktop\r\n5. Add meeting id and meeting password in flutter app join meeting page\r\n6. Loading meeting come with blank screen \r\n\r\n## Context\r\nTrying to run example app \r\n\r\n## Debug logs\r\n<!-- include iOS / Android logs\r\n- ios XCode logs,\r\n- use #getLog #emailLog methods (@see docs)\r\n- Android: $ adb logcat -s TSLocationManager\r\n-->\r\n<details>\r\n\t<summary>Logs</summary>\r\n\r\n``` <!-- syntax-highligting:  DO NOT REMOVE -->\r\n2020-08-14 21:38:29.888.828.2469 Runner[1800:551434] Metal API Validation Enabled\r\n2020-08-14 21:38:30.138918-0400 Runner[1800:551626] flutter: Observatory listening on http://116.69.203.115:49341/YGbg9af2QtY=/\r\n2020-08-14 21:38:56.768275-0400 Runner[1800:551691] [general] Connection to daemon was invalidated\r\n2020-08-14 21:39:33.888.828.2469 Runner[1800:551434] [Snapshotting] Snapshotting a view (0x104ad3870, _UIReplicantView) that has not been rendered at least once requires afterScreenUpdates:YES.\r\n2020-08-14 21:39:48.233843-0400 Runner[1800:551434] [Snapshotting] Snapshotting a view (0x104af8580, _UIReplicantView) that has not been rendered at least once requires afterScreenUpdates:YES.\r\n2020-08-14 21:39:54.852438-0400 Runner[1800:551618] flutter: Created the view\r\n2020-08-14 21:39:55.110450-0400 Runner[1800:551434] old data has cpoied done\r\n2020-08-14 21:39:55.112792-0400 Runner[1800:551434] [logging-persist] cannot open file at line 43353 of [378230ae7f]\r\n2020-08-14 21:39:55.112881-0400 Runner[1800:551434] [logging-persist] os_unix.c:43353: (0) open(/var/mobile/Containers/Data/Application/B1462BC3-656F-42AF-933B-06AB307DC808/Documents/data/zoomus.tmp.db) - Undefined error: 0\r\n2020-08-14 21:39:55.117567-0400 Runner[1800:551434] [logging] table zoom_meet_participants already exists in \"create table zoom_meet_participants (itemID integer64, name text, avatar text,snsID text, snsType integer, deviceID text,roleType integer);\"\r\n2020-08-14 21:39:55.118294-0400 Runner[1800:551434] [logging] table zoom_kv already exists in \"create table zoom_kv (key text, value text, section text);\"\r\n2020-08-14 21:39:55.888.828.2469 Runner[1800:551618] flutter: initialised\r\n2020-08-14 21:39:55.888.828.2469 Runner[1800:551618] flutter: results: [1, 0]\r\nerror was 0\r\n\r\n```\r\n\r\n</details>\r\n\n Comments: \n Comment 0: @romeshn Didi you get the solution for this??\r\nI am also facing the same issue, its urgent if you can help me.\r\n",
  "Issue title: is this dockerized? do we have a docker file?\n Issue body: I'm trying to run server in daemon mode but there don't seem to be an option. \r\n\r\nWanted to check if anyone is working on dockerfile. [The links in doc](https://github.com/neo-project/neo/wiki/Bookkeeping-Node-Deployment) were pointing to a [download portal](https://pan.baidu.com/s/1jI0TIJW#list/path=%2FDocker). Would be great if there is a direct link that can be downloaded via wget (docker_image_antsharesdaemon.tar)\n Comments: \n Comment 0: Hi 5hanth,\r\nI've created docker images, https://github.com/jonatanblockchain/neo-docker\r\nRight now we are testing them. \r\n\n Comment 1: do we have an option to run rpc server in daemon mode as of now?\n Comment 2: Hi 5hanth\r\nI'm trying/testing different switch options, meanwhile you can change these two lines.\r\n\r\nEXPOSE 10332 10333\r\nENTRYPOINT [ \"dotnet\", \"neo-cli.dll\", \"/rpc\" ]\n Comment 3: See #22 ",
  "Issue title: Express 3.x.x support?\n Issue body: Hey,\n\ngreat work! Is this working properly with Express 3.x.x?\n\nI'm asking because it shows me a \"CANNOT GET /dialog/authorize\" in my Express 3.1.0 project. I also tried a Express 2.0 project which runs perfectly fine.\n\nProbably issues with my routes!?\n\nThanks!\n\n Comments: \n Comment 0: Yes, I've been running it successfully under Express 3.  I'd double check your setup.  Reopen this if you pinpoint a specific bug with oauth2orize.\n\n Comment 1: Hi again, thanks for your fast response! I double checked my setup and read some other issues. I stumbled upon issue #7 and found out that this (client parameter) was causing my problem. I fixed this by using \"cli\" instead of \"client\".\n\nThanks!\n",
  "Issue title: Newbie question: timeout flag\n Issue body: This is probably a user error, but I can't get my script to run with the timeout flag.  I set up:\r\n                register_dopar_cmq(n_jobs=self$nCores, memory=1024,\r\n                                   fail_on_error=FALSE, timeout=Self$walltime)\r\nAnd the template says:\r\n#SBATCH --time={{ timeout }} \r\n\r\nAnd then I get this error:\r\nError in fill_template(private$template, opts, required = c(\"master\",  :\r\n  Template values required but not provided: timeout\r\nIn addition: There were 50 or more warnings (use warnings() to see the first 50)\r\n\r\nWhat am I doing wrong?\n Comments: \n Comment 0: It seems you created a custom template with a `{{ timeout }}` field that does not have a default value.\r\n\r\nSo, in order to be able to submit the job we need to fill this field. However, the `timeout` parameter to `Q` does something different (it is the time when we will assume a worker to be dead if we haven't heard from it) and it is not passed to your template.\r\n\r\nSo to solve this, you can pass it as a template argument:\r\n\r\n```r\r\nQ(..., template=list(timeout=...))\r\nregister_dopar_cmq(..., template=list(timeout=...))\r\n```\n Comment 1: That was it, thanks!",
  "Issue title: Feature - macappstore flavor build\n Issue body: I know there's only one version (12.3) that offers a macappstore flavor build, but would it be crazy to include a checkbox for exporting a Mac app with this build? \n\n Comments: \n Comment 0: I'm not quite sure how to do this one, but I could look at https://github.com/johansatge/nwjs-macappstore-builder for guidance. \n\n Comment 1: I think this might be helpful too, it supports all the flavors including macappstore: https://github.com/evshiron/nwjs-builder\n Comment 2: Hmm, I don't think I'll be able to support this right now. Unfortunately, since there are a lot of compatibility issue between 0.12.X and 0.13.X and higher, I have decided to drop support for 0.12.X. It looks like MAS support [is planned for the future for NW.js](https://github.com/nwjs/nw.js/issues/4556), but maybe it's better for you to use Electron instead since it comes with MAS builds since a while ago.",
  "Issue title: ITexture:IsError() doesnt work properly\n Issue body: http://wiki.garrysmod.com/page/ITexture/IsError I dont think this is working as intended\r\nhttps://i.imgur.com/tDUH2o0.png\r\n\r\nAs you can clearly see in my example basetexture2 shader is a a missing texture yet IsError returns false.\n Comments: \n Comment 0: I don't think undefined texture should be error, seems more like an issue with GetName. Assuming it is undefined.\n Comment 1: Is basetexture2 undefined? My guess is undefined getTexture returns a valid texture pointing to the error texture. An errored texture would be one pointing to an invalid name.\n Comment 2: Probably easily fixed by setting the 'error' flag or whatever on that returned texture.\n Comment 3: Well, it is not broken.\r\n\r\nIt tests for the internal error flag, which is set for textures that are attempted to be loaded from dist and failed, but it is not set for the error texture itself. Setting the flag on the error texture may have unexpected results.\r\n\r\nAlso if the texture returned by GetTexture() is an error texture no value will be returned instead.\n Comment 4: well on the C++ side there's a `IsErrorTexture` function with the following expression: `return!pTex || pTex->IsError()`\r\nThere is also a `SetErrorTexture` method in ITexture with the comment: `// Set that this texture should return true for the call \"IsError\"`\r\n\r\nIn contrast to that there's a `IsErrorMaterial` function for IMaterial with the following expression: `return!pMat || pMat->IsErrorMaterial()`\r\nwhere `IsErrorMaterial` has the following comment: `// Returns true if this is the error material you get back from IMaterialSystem38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5indMaterial if the material can't be found.`\r\n\r\n\r\nexposing those is probably the smartest approach to handle it\n Comment 5: There is no such thing as `SetErrorTexture` in our codebase and the `IsErrorTexture` is pointless, as it will just call `IsError` which we already have bound.\r\n\r\n`IMaterial.IsError` already calls to `IsErrorMaterial`.\r\n\r\nI have added `ITexture.IsErrorTexture`",
  "Issue title: Mouse over sensor not existing error\n Issue body: I have a setup where I have a mouse over sensor connected to a script and i print the controller's sensors. It shows up except when I click, the sensor disappears completely from the cont.sensors list and I get an error. When i do not click, it re-appears. If you need a screenshot or.blend, I can provide one.\n Comments: \n Comment 0: I don't know what happened but a re-install of UPBGE fixed it",
  "Issue title: 5 errors when building msvs\\redisserver.sln \n Issue body: I cloned this repo and opened msvs\\redisserver.sln in my win10 x64 + vs15upd1 enterprise environment.   \n\nWhen i then try and build just the RedisCli.vcxproj i get the 5 errors shown in the attached image and log file.  If i try and build the entire solution i get the 19 errors shown in attached log file.  \n\nMight these errors be due to a known issue/oversight on my part, e.g. something i need to install or change on my dev wks setup to get build working?   \n\nI'm trying to acquire a win10 command line usable redis-cli.exe for use carrying out the learning examples found in http://redis.io/topics/data-types-intro. \n\n<img width=\"516\" alt=\"redisclivcxprjbuilderrors\" src=\"https://cloud.githubusercontent.com/assets/3043446/12075191/d51a9024-b12c-11e5-9e31-aa3246bb6082.png\">\n[RedisCliVcxprjBuildErrors.txt](https://github.com/MSOpenTech/redis/files/76313/RedisCliVcxprjBuildErrors.txt)\n[RedisServerSlnBuildErrors.txt](https://github.com/MSOpenTech/redis/files/76315/RedisServerSlnBuildErrors.txt)\n\n Comments: \n Comment 0: @myusrn \nVS 2015 is not supported yet, you should use VS 2013 update 5.\nThank you.\n\n Comment 1: @myusrn \nif you only need redis-cli.exe, just download the.zip binaries from the release page.\n\n Comment 2: thanks i'll setup a vs13upd5 environment and give that a try.  \r\n\r\nin the mean time could i ask where is the release page you are referring to with a zip containing pre-built redis-cli.exe?  \r\n\r\ni ask because i found http://redis.io/ | downloads | stable | download 3.0.6 -> redis-3.0.6.tar.gz contained what appears to be another way to get a sources drop.\n Comment 3: @myusrn \r\nredis.io has Linux releases only, the Windows releases can be found here: https://github.com/MSOpenTech/redis/releases\r\nFor each release there is a Download section: the first entry is the MSI installer the second entry is  the zip folder containing the binaries.\n Comment 4: thanks for pointer to redis for windows client build download, that does the trick.   \n\n Comment 5: According to [this link](http://stackoverflow.com/questions/19914828/microsoft-build-tools-2013-missing-v120-directory), it seems to me that the only way to compile this is by using Visual Studio 2013. Nothing else works; especially if you're using Visual Studio 2015, it's a problem Maybe you should support on compiling this on VS 2015...\n\n Comment 6: @rebulanyum \r\ncommunity contributions are welcome, we would for sure accept a PR to support VS 2015.\r\nThank you.\n Comment 7: Thanks to @CAIQT the 3.0 branch is now compatible with VS 2015, you only need to update the projects files.\n",
  "Issue title: MailCore2 ios: How to run MCOIMAPIdleOperation?\n Issue body: Hello,\n\nI have an issue with MCOIMAPIdleOperation. See the following code snippet:\n\n```\n MCOIMAPIdleOperation *idleOperation = [session idleOperationWithFolder:folder lastKnownUID:msgOb.msgUID];\n    [idleOperation start:[self idleHandler:msgOb.msgUID]];\n\n\n\n- (void (^)(NSError * error))idleHandler:(int64_t)_msgUID {\n\nNSString *folder = @\"INBOX\";\nvoid(^idleHandler)(NSError *error) = ^(NSError *error) {\n    if (!error) {\n        int64_t start = _msgUID + 1;\n        int64_t end = UINT64_MAX;\n\n        MCOIMAPMessagesRequestKind requestKind = MCOIMAPMessagesRequestKindHeaders;\n        MCOIndexSet *uids = [MCOIndexSet indexSetWithRange:MCORangeMake(start, end)];\n\n        MCOIMAPFetchMessagesOperation *fetchOperation = [session fetchMessagesByUIDOperationWithFolder:folder\n                                                                                                requestKind:requestKind\n                                                                                                       uids:uids];\n\n        void(^fetchHandler)(NSError*,NSArray*,MCOIndexSet*) = ^(NSError *error, NSArray *fetchedMessages, MCOIndexSet *vanishedMessages) {\n            if(error) {\n                NSLog(@\"Error downloading message headers:%@\", error);\n            }\n\n            // Iterate through the messages...\n            for (MCOIMAPMessage *message in fetchedMessages) {\n                NSLog(@\"downloaded message with ID: %i\", message.uid);\n            }\n        };\n\n        [fetchOperation start:fetchHandler];\n    } else {\n        NSLog(@\"There was a problem with the idle connection!\");\n    }\n};\n\nreturn idleHandler;\n\n}\n```\n\nwhen i call this, the application gets crashed.\nPlease guide me, how can i notified for new incoming mail.\n\nPlease Help!\n\n Comments: \n Comment 0: HI Pankaj,\n\nHave you managed to get the notification on new incoming mail?\n\nPlease suggest me possible ways of doing it.\n\nThank you.\nSandip.\n\n Comment 1: Please open another issue if you're having trouble with something other than the sandovalchristopher@example.com.  If you're seeing crashes, then post a crash log.  Otherwise, the code he's got (with a few modifications) is sufficient to get an IDLE request running.\n",
  "Issue title: how does elasticsearch store data\n Issue body: we are trying to use elasticsearch, logstash and kibana to manage our logs. We have several questions about the storage of data. Could you please to help us to figure it out, please? when elasticsearch gets all logs, where does it store them? Because we have about 200G logs every day, so we want to know whether elasticsearch could remove old logs automatically. If it does, how can we set that up and how long will it keep data?\nthank you\n\n Comments: \n Comment 0: Elasticsearch will store data as long as it has disk space on its nodes.  Its stores this on the local disk, for details on where take a look at http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-dir-layout.html#setup-dir-layout\n\nYou can manage the retention with Elasticsearch Curator (https://github.com/elasticsearch/curator).\n\nYou may also want to ask these sorts of questions on the Elasticsearch mailing list at https://groups.google.com/forum/#!forum/elasticsearch.\n",
  "Issue title: Deleting many files with the same name causes trashbin database error\n Issue body: <!--\r\nThanks for reporting issues back to Nextcloud! This is the issue tracker of Nextcloud, if you have any support question please check out https://nextcloud.com/support\r\n\r\nThis is the bug tracker for the Server component. Find other components at https://github.com/nextcloud/\r\n\r\nFor reporting potential security issues please see https://nextcloud.com/security/\r\n\r\nTo make it possible for us to help you please fill out below information carefully. \r\nYou can also use the Issue Template application to prefill most of the required information: https://apps.nextcloud.com/apps/issuetemplate\r\n\r\nIf you are a customer, please submit your issue directly in the Nextcloud Portal https://portal.nextcloud.com so it gets resolved more quickly by our dedicated engineers.\r\n\r\nNote that Nextcloud is an open source project backed by Nextcloud GmbH. Most of our volunteers are home users and thus primarily care about issues that affect home users. Our paid engineers prioritize issues of our customers. If you are neither a home user nor a customer, consider paying somebody to fix your issue, do it yourself or become a customer.\r\n-->\r\n\r\n### Steps to reproduce\r\n1. Have the desktop sync client on a machine and the *trashbin* app on the server\r\n2. In the synced directory, have many files *with the same name but in different directories* (e.g. using `find. -type d -exec touch {}/_TEST_FILE_ \\;`)\r\n3. Wait for these files to be synced to the server\r\n4. Delete all of these files on the client *within a short period of time* (e.g. using `find. -name _TEST_FILE_ -exec rm {} \\;`)\r\n\r\n### Expected behaviour\r\nAll the files are moved to the trashbin with no errors\r\n\r\n### Actual behaviour\r\n- Several errors appear in the sync client activity log: `Server replied \"500 Server Error\" to \"DELETE https://[\u2026]/_TEST_FILE_\"`\r\n- Nextcloud server log shows many of these messages:\r\n```\r\n[webdav] Fatal: Doctrine\\DBAL\\Exception\\UniqueConstraintViolationException: An exception occurred while executing 'UPDATE `oc_filecache` SET `storage` =?, `path` =?, `path_hash` =?, `name` =?, `parent` =? WHERE `fileid` =?' with params [1, \"files_trashbin\\/files\\/_TEST_FILE_.d1568906728\", \"2483968b8cffabc109c268695206d8c2\", \"_TEST_FILE_.d1568906728\", 1451947, 1476273]:\r\n\r\nSQLSTATE[23000]: Integrity constraint violation: 1062 Duplicate entry '1-2483968b8cffabc109c268695206d8c2' for key 'fs_storage_path_hash' at <<closure>>\r\n\r\n 0. /var/www/nextcloud/3rdparty/doctrine/dbal/lib/Doctrine/DBAL/DBALException.php line 184\r\n    Doctrine\\DBAL\\Driver\\AbstractMySQLDriver->convertException(\"An exception oc... '\", Doctrine\\DBAL\\Dr... ]})\r\n 1. /var/www/nextcloud/3rdparty/doctrine/dbal/lib/Doctrine/DBAL/DBALException.php line 158\r\n    Doctrine\\DBAL\\DBALException38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5wrapException(Doctrine\\DBAL\\Driver\\PDOMySql\\Driver {}, Doctrine\\DBAL\\Dr... ]}, \"An exception oc... '\")\r\n 2. /var/www/nextcloud/3rdparty/doctrine/dbal/lib/Doctrine/DBAL/Connection.php line 938\r\n    Doctrine\\DBAL\\DBALException38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5riverExceptionDuringQuery(Doctrine\\DBAL\\Driver\\PDOMySql\\Driver {}, Doctrine\\DBAL\\Dr... ]}, \"UPDATE `oc_file...?\", {1: 1,2: \"files_... 3})\r\n 3. /var/www/nextcloud/lib/private/DB/Connection.php line 195\r\n    Doctrine\\DBAL\\Connection->executeQuery(\"UPDATE `oc_file...?\", [1,\"files_trashb... 3], [], null)\r\n 4. /var/www/nextcloud/lib/private/Files/Cache/Cache.php line 579\r\n    OC\\DB\\Connection->executeQuery(\"UPDATE `oc_file...?\", [1,\"files_trashb... 3])\r\n 5. /var/www/nextcloud/lib/private/Files/Cache/Cache.php line 509\r\n    OC\\Files\\Cache\\Cache->moveFromCache(OC\\Files\\Cache\\HomeCache {}, \"files/[\u2026]/_TEST_FILE_\", \"files_trashbin/... 8\")\r\n 6. /var/www/nextcloud/lib/private/Files/Cache/Updater.php line 196\r\n    OC\\Files\\Cache\\Cache->move(\"files/[\u2026]/_TEST_FILE_\", \"files_trashbin/... 8\")\r\n 7. /var/www/nextcloud/apps/files_trashbin/lib/Trashbin.php line 273\r\n    OC\\Files\\Cache\\Updater->renameFromStorage(OCA\\Files_Trashb... }}, \"files/[\u2026]/_TEST_FILE_\", \"files_trashbin/... 8\")\r\n 8. /var/www/nextcloud/apps/files_trashbin/lib/Trash/LegacyTrashBackend.php line 107\r\n    OCA\\Files_Trashbin\\Trashbin38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5move2trash(\"[\u2026]/_TEST_FILE_\")\r\n 9. /var/www/nextcloud/apps/files_trashbin/lib/Trash/TrashManager.php line 103\r\n    OCA\\Files_Trashbin\\Trash\\LegacyTrashBackend->moveToTrash(OCA\\Files_Trashb... }}, \"files/[\u2026]/_TEST_FILE_\")\r\n10. /var/www/nextcloud/apps/files_trashbin/lib/Storage.php line 186\r\n    OCA\\Files_Trashbin\\Trash\\TrashManager->moveToTrash(OCA\\Files_Trashb... }}, \"files/[\u2026]/_TEST_FILE_\")\r\n11. /var/www/nextcloud/apps/files_trashbin/lib/Storage.php line 98\r\n    OCA\\Files_Trashbin\\Storage->doDelete(\"files/[\u2026]/_TEST_FILE_\", \"unlink\")\r\n12. /var/www/nextcloud/lib/private/Files/View.php line 1160\r\n    OCA\\Files_Trashbin\\Storage->unlink(\"files/[\u2026]/_TEST_FILE_\")\r\n13. /var/www/nextcloud/lib/private/Files/View.php line 716\r\n    OC\\Files\\View->basicOperation(\"unlink\", \"/[\u2026]/_TEST_FILE_\", [\"delete\"])\r\n14. /var/www/nextcloud/apps/dav/lib/Connector/Sabre/File.php line 422\r\n    OC\\Files\\View->unlink(\"/[\u2026]/_TEST_FILE_\")\r\n15. /var/www/nextcloud/3rdparty/sabre/dav/lib/DAV/Tree.php line 179\r\n    OCA\\DAV\\Connector\\Sabre\\File->delete()\r\n16. /var/www/nextcloud/3rdparty/sabre/dav/lib/DAV/CorePlugin.php line 287\r\n    Sabre\\DAV\\Tree->delete(\"files/marcel/Me... _\")\r\n17. <<closure>>\r\n    Sabre\\DAV\\CorePlugin->httpDelete(Sabre\\HTTP\\Reque... \"}, Sabre\\HTTP\\Response {})\r\n18. /var/www/nextcloud/3rdparty/sabre/event/lib/EventEmitterTrait.php line 105\r\n    undefinedundefinedcall_user_func_array([Sabre\\DAV\\CorePlugin {},\"httpDelete\"], [Sabre\\HTTP\\Requ... }])\r\n19. /var/www/nextcloud/3rdparty/sabre/dav/lib/DAV/Server.php line 479\r\n    Sabre\\Event\\EventEmitter->emit(\"method:DELETE\", [Sabre\\HTTP\\Requ... }])\r\n20. /var/www/nextcloud/3rdparty/sabre/dav/lib/DAV/Server.php line",
  "Issue title: Koadic wont install\n Issue body: very new to frameworks. i paste the install command and i get this response\r\n\r\n![image](https://user-images.githubusercontent.com/85844355/121817929-cac2c700-cc73-11eb-8f3f-4de9d4d61559.png)\r\n\r\nim doing this in the Root Terminal of TailsOS because its the place where the book im reading tells me to do this\r\n\r\nany help is much appriciated!\n Comments: \n Comment 0: Looks like DNS error. That is an environment issue that is out of scope for this project to debug.",
  "Issue title: table\u7ec4\u4ef6\u4e2d\u5bf9\u8868\u683c\u7684\u64cd\u4f5c\u5bf9\u4e8e\u5f02\u6b65\u6570\u636eonChange\u7ffb\u9875\u540eselectedRows\u53c2\u6570\u53ea\u80fd\u8bb0\u5f55\u5f53\u524d\u9875\n Issue body: - [ ] I have searched the [issues](https://github.com/vueComponent/ant-design-vue/issues)         of this repository and believe that this is not a duplicate.\r\n        \r\n        \r\n### Version\r\n1.4.2\r\n\r\n### Environment\r\n1.4.2\r\n\r\n### Reproduction link\r\n[https://vue.ant.design/components/table-cn/](https://vue.ant.design/components/table-cn/)\r\n\r\n### Steps to reproduce\r\n\u4e3b\u8981\u4ee3\u7801\uff1a\r\n<template>\r\n<div style=\"margin: 24px\">\r\n<a-table\r\n:columns=\"columns\"\r\nrowKey=\"id\"\r\n:dataSource=\"tabledata\"\r\n:pagination=\"pagination\"\r\nref=\"table\"\r\n:rowSelection=\"{selectedRowKeys: selectedRowKeys, onChange:onSelectChange}\"\r\n@change=\"handleChange\"\r\n>\r\n</a-table>\r\n</div>\r\n</template>\r\n\r\n<script>\r\nexport default {\r\ndata() {\r\nreturn {\r\ncolumns: [\r\n{\r\ntitle: '\u89d2\u8272\u7f16\u7801',\r\nkey: 'role_code',\r\ndataIndex: 'role_code'\r\n},\r\n{\r\ntitle: '\u89d2\u8272\u540d\u79f0',\r\nkey: 'role_name',\r\ndataIndex: 'role_name'\r\n},\r\n{\r\ntitle: '\u72b6\u6001',\r\nkey: 'role_status',\r\ndataIndex: 'role_status'\r\n},\r\n{\r\ntitle: '\u5907\u6ce8',\r\nkey: 'role_remark',\r\ndataIndex: 'role_remark'\r\n}\r\n],\r\ntabledata: [ ], // \u8bf7\u5f02\u6b65\u6dfb\u52a0\r\nselectedRowKeys:[],\r\nselectedRows: [],\r\npagination:{\r\ntotal: 1,\r\ncurrent: 1,showQuickJumper: true,\r\nshowSizeChanger: true,\r\npageSize: 2\r\n}\r\n}\r\n},\r\nmethods: {\r\n// \u8868\u683c\u6392\u5e8f\u64cd\u4f5c\r\nhandleChange (pagination, filters, sorter) {\r\nthis.pagination = pagination\r\n// this.queryParam.pageNo = pagination.current\r\n// this.queryParam.pageSize = pagination.pageSize\r\nconsole.log('Various parameters', pagination, filters, sorter)\r\n// this.queryParam.sortedInfo = sorter\r\n// this.getList()\r\n},\r\nonSelectChange (selectedRowKeys, selectedRows) {\r\nthis.selectedRowKeys = selectedRowKeys\r\nthis.selectedRows = selectedRows\r\nconsole.log(selectedRows)\r\n}\r\n}\r\n};\r\n</script>\r\n\r\n<style></style>\r\n1.\u8bf7\u5f02\u6b65\u6dfb\u52a0\u8868\u683c\u6570\u636e\uff0c\r\n2.\u7b2c\u4e00\u9875\u9009\u4e2d\u6570\u636e\u540e\u7ffb\u9875\uff0c\u518d\u6b21\u9009\u4e2d\u7b2c\u4e8c\u9875\u7684\u6570\u636e\uff0cselectedRowKeys\u6709\u6240\u6709\u9009\u4e2d\u7684\u503c\uff0c\u4f46\u662fselectedRows\u53ea\u6709\u7b2c\u4e8c\u9875\u4e5f\u5c31\u662f\u5f53\u524d\u9875\u7684\r\n\r\n### What is expected?\r\n\u671f\u671b\u80fd\u4fdd\u5b58\u6240\u6709\u9009\u4e2d\u7684selectedRows\r\n\r\n### What is actually happening?\r\n\u5bf9\u4e8e\u540c\u6b65\u7684tabledata\u80fd\u5b9e\u73b0\u4fdd\u5b58\u6240\u6709\u7684selectedRowKeys\uff0c\u4f46\u662f\u5bf9\u4e8e\u5f02\u6b65\u6570\u636e\uff0c\u7b2c\u4e00\u9875\u9009\u4e2d\u6570\u636e\u540e\u7ffb\u9875\uff0c\u518d\u6b21\u9009\u4e2d\u7b2c\u4e8c\u9875\u6570\u636e\uff0cselectedRowKeys\u6709\u6240\u6709\u9009\u4e2d\u503c\uff0c\u4f46\u662fselectedRows\u53ea\u6709\u5f53\u524d\u9875\u7684\r\n\r\n\r\n\r\n        \r\n\r\n<!-- generated by issue-helper. DO NOT REMOVE -->\n Comments: \n Comment 0: \u8fd9\u4e2a\u5e94\u8be5\u5c5e\u4e8e\u4e1a\u52a1\u9700\u6c42\uff0c\u7ec4\u4ef6\u4e0d\u4f1a\u63d0\u4f9b\u8fd9\u4e2a\u529f\u80fd\uff0c\u9700\u8981\u81ea\u5df1\u53bb\u5b9e\u73b0\u3002\u6211\u4e5f\u5728\u4e1a\u52a1\u4e2d\u6709\u8fd9\u4e2a\u9700\u6c42\u7684\n Comment 1: \r\n@useryechen \u8bf7\u95ee\u4f60\u662f\u600e\u4e48\u89e3\u51b3\u7684\u5440\r\n\n Comment 2: \u505a\u80af\u5b9a\u662f\u77e5\u9053\u600e\u4e48\u505a\u7684\uff0c\u6211\u53ea\u662f\u6709\u70b9\u5947\u602a\uff0cselectedRowKeys\u81ea\u5e26\u652f\u6301\u5206\u9875\uff0cselectedRows\u4e0d\u652f\u6301\n Comment 3: > \u505a\u80af\u5b9a\u662f\u77e5\u9053\u600e\u4e48\u505a\u7684\uff0c\u6211\u53ea\u662f\u6709\u70b9\u5947\u602a\uff0cselectedRowKeys\u81ea\u5e26\u652f\u6301\u5206\u9875\uff0cselectedRows\u4e0d\u652f\u6301\r\n\r\n\u786e\u5b9e\uff5e\u592a\u5947\u602a\u4e86\uff5ekey\u652f\u6301\uff0crow\u4e0d\u652f\u6301\n Comment 4: This issue is stale because it has been open 60 days with no activity. Remove stale label or comment or this will be closed in 7 days\n Comment 5: This issue has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.",
  "Issue title: charged per(table/guest) detail should be shown in front of table booking\n Issue body: # Bug report\r\n\r\n### Title\r\ncharged per(table/guest) detail should be shown in front of table booking\r\n\r\n### Issue Description\r\ncharged per(table/guest) detail should be shown in front of table booking\r\n\r\n### Preconditions\r\n\r\n    1. framework Version- master\r\n\r\n### Steps to reproduce\r\n\r\n    1. step1- add table booking charged per table\r\n    2. step2- show the product page,their is no instruction set, how would we charge??\r\n\r\n### Expected result\r\n\r\n 1. accroding to me, add the label \"Charged per table(2 guest)\" / \"Charged per Guest\" just below the product price.\r\n\r\n### Actual result\r\n\r\n![Screenshot(6)](https://user-images.githubusercontent.com/43210406/77621070-ba84d600-6f61-11ea-9377-9300c5074f71.png)\r\n\n Comments: \n Comment 0: You can add that information in description or in name. ",
  "Issue title: sessionStore deletion, server.request middleware call\n Issue body: So I've been trying to figure this out for a few hours, forgive my naivete.\n\nWhen using connect's [MemoryStore](http://www.senchalabs.org/connect/middleware-session-memory.html), (yeh, yeh I should be using redis, this is educational only.) Where is the Session stored?\n\nIf you don't assign a variable to it... and allow Express to initialize the default MemoryStore\n\n```\napp.use(express.session({ secret: \"keyboard cat\" }));\n```\n\nHow do you access the _MemoryStore_? Anything like, _server.routes.session.store_?\n\nI know you can access it with _req.sessionStore_, but I'm trying to access it with only the _server_ variable. So my follow-up question is how do you simulate a request, or does Express have anyway to do \"fake\" requests? Like...\n\n```\nserver.runFake(function(req, res){\nreq.blah  // Do some req/res stuff\nconsole.log(res...)\n});\n\n//...or...\n\nconsole.log(server.request)  // Request object?\nconsole.log(server.response)  // Response object?\n\n```\n\n---\n\nBasically, must I have to do something like...\n\n``` javascript\nserver = express.createServer({...})\n\nserver.get('/delete', function(req, res){\n req.sessionStore.clear()\n});\n\nrequire('superagent').get('http://localhost:3000/delete')\n```\n\njust to clear the sessions, with default _MemoryStore_, or is there a better way?\n\nThank You!\n\n Comments: \n Comment 0: We had the same issue just today attempting to access the session from socket.io's `connection` event.\n\nI poked around in the debugger and in the codebase to try and find where express was keeping the session stores but I could not find it.\n\nWe solved the issue by creating the store ourselves and passing it to express...\n\n``` coffee\nexpress = require 'express'\n\nsessionStore = new express.session.MemoryStore\n\napp = express.createServer()\napp.configure ->\n  app.use express.session store: sessionStore, secret: 'top secret'\n```\n\nThis way you have the reference `sessionStore` to the session store.\n\nLet us know if there's a reference from `app`...\n\n Comment 1: Maybe its not relevant anymore, but check out this line: https://github.com/senchalabs/connect/blob/master/lib/middleware/session.js#L235\n\nYou should be able to access it through `req.sessionStore`\n\n Comment 2: you both got an answer. however, you should avoid using memory store as no one should ever use it in production. use a real store or cookie sessions.\n",
  "Issue title: BUG: Complex numbers having an np.inf part return the wrong value when multiplied\n Issue body: ### Describe the issue:\n\nWhile investigating #20291, I found out that multiplication of a complex number having `np.inf` as one of its parts with\r\n\r\n1. a real number (imaginary part `0`)\r\n2. a purely complex number (real part `0`)\r\n\r\nreturns an incorrect result.\n\n### Reproduce the code example:\n\n```python\nimport numpy as np\r\n\r\nprint((np.inf + 1j) * 2)\r\nprint((np.inf + 1j) * 2j)\r\nprint(complex(1, np.inf) * 2)\r\nprint(complex(1, np.inf) * 2j)\n```\n\n\n### Error message:\n\n```shell\n(inf+nanj)\r\n(nan+infj)\r\n(nan+infj)\r\n(-inf+nanj)\n```\n\n\n### NumPy/Python version information:\n\n1.21.4 3.9.7 (default, Oct 10 2021, 15:13:22) \r\n[GCC 11.1.0]\n Comments: \n Comment 0: # Reason\r\n\r\nThis is how CPython defines [multiplication between two complex objects](https://github.com/python/cpython/blob/cbab997efb3ba5123dc8d9f706184fa8e634b3ec/Objects/complexobject.c#L54-L61):\r\n\r\n```C\r\nPy_complex\r\n_Py_c_prod(Py_complex a, Py_complex b)\r\n{\r\n    Py_complex r;\r\n    r.real = a.real*b.real - a.imag*b.imag;\r\n    r.imag = a.real*b.imag + a.imag*b.real;\r\n    return r;\r\n}\r\n```\r\n\r\nThe errors above occur because `np.inf * 0` is `nan`.\r\n\r\n# SymPy\r\n\r\nThe same computations in SymPy, which does not use the multiplication operation defined by CPython:\r\n\r\n```python\r\n>>> complex(sympy.simplify((sympy.oo + 1j) * 2))\r\n(inf+2j)\r\n>>> complex(sympy.simplify((sympy.oo + 1j) * 2j))\r\n(-2+infj)\r\n>>> complex(sympy.simplify((1 + sympy.oo * 1j) * 2))\r\n(2+infj)\r\n>>> complex(sympy.simplify((1 + sympy.oo * 1j) * 2j))\r\n(-inf+2j)\r\n```\r\n\r\n# Infinite Imaginary Part Initialization\r\n\r\nAs an aside, complex numbers with an infinite imaginary part cannot be instantiated with the `real + imag * 1j` syntax because of this. You have to use the constructor instead.\r\n\r\n```python\r\n>>> 1 + np.inf * 1j\r\n(nan+infj)\r\n>>> complex(1, np.inf)\r\n(1+infj)\r\n```\n Comment 1: I agree with the strict real `times` complex. This should not be a problem (unless I have missed something in IEEE 754).\r\n\r\nBut when you have a complex number with one of the terms being 0, then nan is the correct ieee 754 value: `inf * 0 == nan`. \r\n\r\nhttps://wiki.analytica.com/index.php/INF,_Nan,_Zero_and_IEEE/SANE_arithmetic\r\n\r\nOther sites confirm this.\r\n\r\nSo basically it seems to be problematic due to reals being converted to complex numbers.\n Comment 2: Yeah, `inf * 0 == nan` is correct behaviour.\r\n\r\nMultiplication with `0` always returns `0` in Python, so the formula for calculating the real and imaginary part is not a problem there. But, it is a problem in numpy because of `inf`. One of the parts being `0` returns a `nan` which shouldn't happen.\r\n\r\n> But when you have a complex number with one of the terms being 0, then nan is the correct ieee 754 value: `inf * 0 == nan`.\r\n\r\nMathematically:\r\n```\r\n(0 + 2i) * \u221e = 2i * \u221e = \u221ei\r\n```\r\n\r\nIn numpy:\r\n\r\n```python\r\n>>> complex(0, 2) * np.inf\r\n(nan+infj)\r\n```\r\n\r\nYou don't consider the multiplication of `0` with `\u221e` when solving it analytically. Python does multiply `0` with `inf`, which is the problem here.",
  "Issue title: Gutenboarding: Changes to intent capture\n Issue body: As we've discussed, let's do two changes to the first onboarding step:\r\n\r\n**Remove the site category/vertical step**\r\nWe'll reintroduce this at a later point, but until we've worked out the quirks and functionality properly we should remove this step.\r\n\r\n**Make the input field more obvious**\r\nLet's change the look of the input field to this:\r\n![image](https://user-images.githubusercontent.com/2896062/82315281-5f081f00-99cb-11ea-88fb-c0f83e7465c6.png)\r\n![image](https://user-images.githubusercontent.com/2896062/82315308-68918700-99cb-11ea-8bf3-aab153a97668.png)\r\n\r\nChanges:\r\n- String is now \"What's your website called?\"\r\n- Animation should stay for now\r\n- Input field should have a `gray0` background-color\r\n- Font-size should be changed to `44px` on desktop\r\n- The _I don't know_ button should be changed to _Skip for now_ and moved under the input field on desktop. Once a user has entered a value the Continue button should appear and the skip button should disappear.\r\n- Left padding on the container should be `120px`\r\n\r\nCheck Figma for mobile mocks and further detailed specs :)\r\n\r\ncc/ @olaolusoga @rickybanister @amamujee \n Comments: \n Comment 0: Are we wed to the specific copy here? I think it's worth some thought but I prefer something like:\r\n\r\n'What is the name of your site?' \r\n\r\nI think 'name' v.s. 'called' might translate better to other languages. \n Comment 1: I'm not a copywriter, so I'm happy to have someone else look into it \ud83d\ude03 Feel free to cc the right people and we can iterate here.\r\n\r\n> I think 'name' v.s. 'called' might translate better to other languages.\r\n\r\nWhich languages does it translate poorly to?\n Comment 2: @akirk for additional insight given this step's importance. I thought that 'call' could have different connotations like'summon'\n Comment 3: We'll have our Localization Reviewers look at this when the copy is final in English.\n Comment 4: Worth having more design explorations on this input field @dubielzyk \n Comment 5: What specific things aren't working at the moment @pablohoneyhoney?\n Comment 6: The filed above is disconnected from everything else. \r\nAnd if we need to optimize for only one question, then we should rethink well the UI.  ",
  "Issue title: io/ioutil: ReadDir fails on UNC format `\\\\?\\c:\\` root directories on Windows \n Issue body: ### What version of Go are you using (`go version`)?\r\n\r\nX:\\>go version\r\ngo version go1.7.1 windows/386\r\n\r\n### What operating system and processor architecture are you using (`go env`)?\r\n\r\nI am testing this on Windows 7 Pro 386 SP1 running under VirtualBox.\r\n\r\n```\r\nX:\\>go env\r\nset GOARCH=386\r\nset GOBIN=\r\nset GOEXE=.exe\r\nset GOHOSTARCH=386\r\nset GOHOSTOS=windows\r\nset GOOS=windows\r\nset GOPATH=\r\nset GORACE=\r\nset GOROOT=C:\\Go\r\nset GOTOOLDIR=C:\\Go\\pkg\\tool\\windows_386\r\nset CC=gcc\r\nset GOGCCFLAGS=-m32 -mthreads -fmessage-length=0\r\nset CXX=g++\r\nset CGO_ENABLED=1\r\n```\r\n\r\n### What did you do?\r\n\r\nBuild this program http://play.golang.org/p/rBGf11wDo7 (note that this is from #4601) and run it giving UNC paths to the root directory.\r\n\r\n```\r\nX:\\Go>go build readdir.go\r\n\r\nX:\\Go>dir \\\\?\\c:\\\r\n Volume in drive \\\\?\\c: has no label.\r\n Volume Serial Number is 5CD1-D250\r\n\r\n Directory of \\\\?\\c:\r\n\r\n11/06/2009  02:12                24 autoexec.bat\r\n11/06/2009  02:12                10 config.sys\r\n18/10/2016  13:46    <DIR>          Go\r\n[snip]\r\n14/07/2009  07:07    <DIR>          PerfLogs\r\n04/05/2011  14:38    <DIR>          Program Files\r\n04/05/2011  14:30    <DIR>          Users\r\n19/08/2016  02:25    <DIR>          Windows\r\n               2 File(s)             34 bytes\r\n              10 Dir(s)               0 bytes free\r\n\r\nX:\\Go>readdir.exe \\\\?\\c:\\\r\nentries []\r\nerr open \\\\?\\c:\\: The system cannot find the path specified.\r\n\r\nX:\\Go>readdir.exe \\\\?\\c:\r\nentries [0x1166e0f0 0x1166e230 0x1166e280 0x1166e320 0x1166e370 0x1166e3c0 0x116\r\n6e410 0x1166e460 0x1166e4b0 0x1166e500 0x1166e5a0 0x1166e5f0 0x1166e640 0x1166e6\r\n90 0x1166e140 0x1166e190 0x1166e1e0 0x1166e2d0 0x1166e6e0]\r\nerr <nil>\r\n\r\nX:\\Go>readdir.exe c:\\\r\nentries [0x11548000 0x11548140 0x11548190 0x11548230 0x11548280 0x115482d0 0x115\r\n48320 0x11548370 0x115483c0 0x11548410 0x115484b0 0x11548500 0x11548550 0x115485\r\na0 0x11548050 0x115480a0 0x115480f0 0x115481e0 0x115485f0]\r\nerr <nil>\r\n\r\nX:\\Go>readdir.exe \\\\?\\c:\\Go\r\nentries [0x11728050 0x11728140 0x11728190 0x117282d0 0x11728370 0x11728410 0x117\r\n28550 0x11728000 0x117280a0 0x117280f0 0x117281e0 0x11728230 0x11728280 0x117283\r\n20 0x117283c0 0x11728460 0x117284b0 0x11728500]\r\nerr <nil>\r\n```\r\n\r\n### What did you expect to see?\r\n\r\nI expected `readdir.exe \\\\?\\c:\\` to produce an output with some directory entries, not an error.  It should have produced the same output as provided by `readdir.exe \\\\?\\c:`\r\n\r\n### What did you see instead?\r\n\r\nThe error `err open \\\\?\\c:\\: The system cannot find the path specified.`\r\n\r\nNote that this is possibly related to #4601\r\n\r\n\n Comments: \n Comment 0: Try to display the filename\r\n\r\n```go\r\npackage main\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"io/ioutil\"\r\n\t\"os\"\r\n)\r\n\r\nfunc main() {\r\n\tif len(os.Args) < 2 {\r\n\t\tfmt.Println(\"Need directory as parameter\")\r\n\t\treturn\r\n\t}\r\n\tdir := os.Args[1]\r\n\tentries, err := ioutil.ReadDir(dir)\r\n\tfor _, f := range entries {\r\n\t\tfmt.Println(f.Name())\r\n\t}\r\n\tfmt.Println(\"err\", err)\r\n}\r\n```\r\n\n Comment 1: FWIW, \"\\\\\\\\?\\\" is not a UNC path, but the long path prefix. Dup of #3358?\n Comment 2: I'm inclined to say this is WAI. The Windows documentation is pretty clear that \\\\?\\ turns off a bunch of path handling code; it looks like one of the things it turns off is stripping of the trailing slash character. I don't think Go should do anything above and beyond what the underlying system calls do to handle malformed paths.\r\n\r\n/cc @rsc @alexbrainman \n Comment 3: Well, I put the code since I don't reproduce.\r\n\r\n![](http://go-gyazo.appspot.com/1899662ebf5120a5.png)\r\n\r\nWindows7 64bit\n Comment 4: @ncw I cannot reproduce it here too. It displays files and returns no error on my Windows XP (386) and Windows 7 (amd64). I am using current tip, but I doubt it matters. Perhaps you could try and debug this. Thank you.\r\n\r\nAlex\n Comment 5: I've done a bit more testing.  I can reproduce the problem on my other Windows 7 Pro 386 SP1 VM.\r\n\r\nOn windows XP I seem to get the opposite results where `\\\\?\\c:` is not found but `\\\\?\\c:\\` is.\r\n\r\nHowever as @quentinmit suggested it does seem to be just whether you supply a trailing `\\` or not, it isn't a specific feature of the root directory.  So if I supply a trailing `\\` the listing fails and if I don't it doesn't.\r\n\r\nI've been unable to find a definitive answer as to whether trailing `\\` are allowed for `\\\\?\\` directory paths, or not.  From the testing above it seems to depend on Windows version.\r\n\r\nMaybe that is as it should be and Go shouldn't try and fixup Windows syscalls.\n Comment 6: > On windows XP I seem to get the opposite results where \\\\?\\c: is not found but \\\\?\\c:\\ is.\r\n\r\nI can reproduce that, thank you very much.\r\n\r\nThe problem appears to be with the way we open file or directory. Windows does not have generic API that opens both. Instead we always try to open path as file first (see os.openFile function), and, if that fails, we assume we have directory here (os.openDir). Our logic assumes that directory cannot be opened with \"file opening\" API CreateFile, and that seems worked so far. But not in the issue above.\r\n\r\nWe could, probably, \"fix\" this by adding some extra checks after CreateFile returns (we could try and call GetFileInformationByHandle, even check returned parameter FileAttributes field if succeeds). But, I think, we should avoid using long paths (https://github.com/golang/go/issues/10577#issuecomment-96925558) in general, so adding extra code for every file open does not sounds right to me.\r\n\r\nAlex\n Comment 7: I also agree it's WAI.\n\nIn general, we should figure out a complete story for handling\nextended length paths in various Go APIs before changing\nanything.\n\n Comment 8: I think _this_ is working as intended, but to the extent that it informs what @quentinmit's patch for long file names can do, it's relevant. At the least we should have tests for ReadDir of `c:\\windows\\` and `c:\\windows` and make sure both get the same result. And user-specified `\\\\?\\` paths should be completely unaltered.\n Comment 9: After spending days banging my head on this, I think I understand what's happening here. `\\\\?\\c:\\` requires the trailing slash to identify the root directory. Any other path, such as `\\\\?",
  "Issue title: Shared Hosting Problem\n Issue body: I ran the package locally. But the project is running on shared hosting so I have to transfer it manually. First of all, I refreshed the vendor directory.\r\n\r\nBut when I try this code \"use GoogleTranslate;\" :\r\nI get the error \"Class 'GoogleTranslate' not found\".\r\n\r\nIf \"JoggApp\\GoogleTranslate\\GoogleTranslate\" when I try this:\r\nI get the error Non-static method JoggApp\\GoogleTranslate\\GoogleTranslat38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5justTranslate() should not be called statically.\r\n\r\nIt works locally without any problems, but if you have any advice on this, I would appreciate it.\r\n\r\nI also manually imported the googletranslate.php config file into the config directory. And I added the api key to the env file.\n Comments: \n Comment 0: we have never used it on shared hosting, so no idea about it.",
  "Issue title: Extending js and css helpers\n Issue body: We've been considering ways to make it easy to include script and stylesheet resources from pages and partials/components, but make sure those resources are injected into the html in the correct place (usually being a layout).\n\nI'm opening this issue to get some ideas on how it would look in handlebars syntax so I can try to get it working as a helper.\n\n`data.yml`:\n\n``` yml\nlistOfCssOrLessFiles:\n - file1.css\n - file2.css\n - file3.css\n\nlistOfJavaScriptFiles:\n - file1.js\n - file2.js\n - file3.js\n\nadditionalCssFiles:\n - addtionalFile1.css\n\nadditionalJsFiles:\n - additionalFile1.js\n```\n\n`Layout.hbs`:\n\n``` handlebars\n<html>\n  <head>\n    {{css listOfCssOrLessFiles}}\n  </head>\n  <body>\n    {{> body}}\n    {{js listOfJavaScriptFiles}}\n  </body>\n</html>\n```\n\n`Page1.hbs`:\n\n``` handlebars\n<h1>Awesome Component Example</h1>\n<div id=\"myComponent\"></div>\n{{css additionalCssFiles}}\n{{js additionalJsFiles}}\n```\n\nThis would allow only loading the files that are needed for the current page being built. The results would be like this...\n`Page1.html`\n\n``` html\n<html>\n  <head>\n    <link rel=\"stylesheet\" href=\"assets/styles/file1.css\">\n    <link rel=\"stylesheet\" href=\"assets/styles/file2.css\">\n    <link rel=\"stylesheet\" href=\"assets/styles/file3.css\">\n    <link rel=\"stylesheet\" href=\"assets/styles/additionalFile1.css\">\n  </head>\n  <body>\n    <h1>Awesome Component Example</h1>\n    <div id=\"myComponent\"></div>\n    <script src=\"assets/js/file1.js\"></script>\n    <script src=\"assets/js/file2.js\"></script>\n    <script src=\"assets/js/file3.js\"></script>\n    <script src=\"assets/js/additionalFile1.js\"></script>\n  </body>\n</html>\n```\n\nPlease post ideas or a better syntax for these helpers. Thanks.\n\n Comments: \n Comment 0: Original inspiration for what I do came from my past use with [Hammer for Mac](http://hammerformac.com). They have a feature call \"Clever Paths --  Write asset paths the easy way. Hammer searches your project for the file and writes the filepath for you, even if it moves.\" I was able to replicate what they do using [grunt-tree](https://github.com/yss/grunt-tree) to create json files of assets in my project. This allows me to call up a file name without having to manage its location.\n\nI run grunt-tree whenever I add, delete or change a file so there is always a fresh copy of my directory structure. It is quick so no drag when grunt-contrib-watch is running:\n\n```\nRunning \"tree:partials\" (tree) task\nFile \"app/assemble/config/manifests/inc.json\" created.\nTask 'tree:partials' took 17ms\n\nRunning \"tree:img\" (tree) task\nFile \"app/assemble/config/manifests/img.json\" created.\nTask 'tree:img' took 20ms\n\nRunning \"tree:css\" (tree) task\nFile \"app/assemble/config/manifests/css.json\" created.\nTask 'tree:css' took 16ms\n\nRunning \"tree:js\" (tree) task\nFile \"app/assemble/config/manifests/js.json\" created.\nTask 'tree:js' took 11ms\n```\n\nI have not tried this method with collections nor arrays as grunt-tree makes an individual entry per file. Sometime tonight I will try that out and replicate your example setup. It never dawned on me to do it that way.\ncss.json\n\n``` js\n{\n    \"animate\": \"css/development/dev/animate.css\",\n    \"jquery-tocify\": \"css/development/dev/jquery-tocify.css\",\n    \"lean-slider\": \"css/development/dev/lean-slider.css\",\n    \"parallax-slider\": \"css/development/dev/parallax-slider.css\",\n    \"progressbars\": \"css/development/dev/progressbars.css\",\n    \"splash\": \"css/development/pages/splash.css\",\n    \"stickyfooter\": \"css/development/pages/stickyfooter.css\",\n    \"prettify\": \"css/development/prettify.css\",\n    \"mapbox\": \"css/mapbox.css\",\n    \"styles-min\": \"css/styles-min.css\",\n    \"styles\": \"css/styles.css\",\n    \"kess14test\": \"css/views/kess14test.css\",\n    \"splash-min\": \"css/views/splash-min.css\",\n    \"stickyfooter-min\": \"css/views/stickyfooter-min.css\"\n}\n```\n\n_head.hbs (partial for layout)\n\n``` html\n...\n<!-- CSS Base -->\n{{#is buildenv \"development\"}}\n  {{css css.styles}}\n{{else}}\n  {{css css.styles-min}}\n{{/is}}\n...\n```\n\njs.json\n\n``` js\n   ...\n    \"affix\": \"js/jquery/bootstrap/affix.js\",\n    \"alert\": \"js/jquery/bootstrap/alert.js\",\n    \"button\": \"js/jquery/bootstrap/button.js\",\n    \"carousel\": \"js/jquery/bootstrap/carousel.js\",\n    \"collapse\": \"js/jquery/bootstrap/collapse.js\",\n    \"dropdown\": \"js/jquery/bootstrap/dropdown.js\",\n    \"modal\": \"js/jquery/bootstrap/modal.js\",\n    \"popover\": \"js/jquery/bootstrap/popover.js\",\n    \"scrollspy\": \"js/jquery/bootstrap/scrollspy.js\",\n    \"tab\": \"js/jquery/bootstrap/tab.js\",\n    \"tooltip\": \"js/jquery/bootstrap/tooltip.js\",\n    \"transition\": \"js/jquery/bootstrap/transition.js\",\n   ...\n```\n\nfoot.hbs (partial for layout)\n\n```\n{{#is buildenv \"development\"}}\n    {{js js.transition}}\n    {{js js.alert}}\n    {{js js.button}}\n    {{js js.carousel}}\n    {{js js.collapse}}\n    {{js js.dropdown}}\n    {{js js.modal}}\n    {{js js.tooltip}}\n    {{js js.popover}}\n    {{js js.scrollspy}}\n    {{js js.tab}}\n    {{js js.affix}}\n  {{else}}\n    {{js js.bootstrap-min}}\n  {{/is}}\n```\n\nimg.json\n\n``` js\n    \"billboard\": \"img/frames/billboard.png\",\n    \"billboard2\": \"img/frames/billboard2.png\",\n    \"desktop\": \"img/frames/desktop.png\",\n    \"iphone\": \"img/frames/iphone.png\",\n    \"tablet\": \"img/frames/tablet.png\",\n    \"cloud\": \"img/icons/cloud.png\",\n    \"content\": \"img/icons/content.png\",\n```\n\ndummy.html\n\n``` html\n<div class=\"float-left\">\n    <img class=\"img-responsive\" src=\"{{assets}}/{{img.iphone}}\" alt=\"\">\n</div>\n```\n\nresult...\n\n``` html\n<html>\n  <head>\n    <!-- CSS Base -->\n    <link rel=\"stylesheet\" href=\"../assets/css/styles.css\" />\n    <link rel=\"stylesheet\" href=\"../assets/css/development/prettify.css\" />\n  </head>\n  <body>\n      ...\n       <div class=\"float-left\">\n            <img class=\"img-responsive\" src=\"../assets/img/frames/iphone.png\" alt=\"\">\n        </div>\n       <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit.</p>\n      ...\n   <script src=\"../assets/js/jquery/bootstrap/transition.js\"></script>\n    <script src=\"../assets/js/jquery/bootstrap/alert.js\"></script>\n    <script src=\"../assets/js/jquery/bootstrap/button.js\"></script>\n    <script src=\"../assets/js/jquery/",
  "Issue title: Equivalent count queries have very different execution time. Negation vs disjunction.\n Issue body: ## Description\r\n\r\nWe can count the number of people with an email address or a phone number in two ways.\r\n\r\n1) By executing the following query:\r\n\r\n`match $p isa person; not { $p has phone_number $pn; }; not {$p has email_address $ea;}; count;`\r\n\r\n2) Or, by first counting the number of people:\r\n\r\n`match $a isa avatar; count;`\r\n\r\nand then deducting the result of the following query from it:\r\n\r\n`match $p isa person; { $p has phone_number $pn; } or {$p has email_address $ea;}; count;`\r\n\r\nThe second approach takes about 10% the time of the first. The numbers from each count (before the deduction) are very similar (around 8000 out of a total 17000 people).\r\n\r\nI don't know if this points to a serious underlying issue, or if it's just an unusual edge-case.\r\n\r\n## Environment\r\n\r\n1. OS - Windows\r\n2. TypeDB version 2.10.0\r\n\r\n## Reproducible Steps\r\n\r\nSee above.\r\n\r\n## Expected Output\r\n\r\nBoth queries to take the same amount of time.\r\n\n Comments: \n Comment 0: Just to be sure - the query in `2.` is asking for `avatar` not `person`?\n Comment 1: > Just to be sure - the query in `2.` is asking for `avatar` not `person`?\r\n\r\nSorry no that was incorrect, I've fixed it.\n Comment 2: Can we provide the minimal schema to reproduce this issue, @thomaschristopherking?\n Comment 3: > Can we provide the minimal schema to reproduce this issue, @thomaschristopherking?\r\n\r\nSorry just saw this, was on vacation. Added a schema. Might have more than needed (the attribute relations) but it matches what we have.",
  "Issue title: Plaid oAuth gets stuck on \"Almost done...\" screen\n Issue body: # The problem\r\n\r\nWhen using Plaid oAuth it's possible to get stuck on \"Almost done...\" screen indefinitely.\r\n\r\n# Environment\r\n\r\n|                        |  |\r\n| ------------------------| ---------- |\r\n| Plaid Link React Native          | 7.0.2                |\r\n| ReactNative Version     | 0.63.3               |\r\n| Occurs on Android             | yes              |\r\n| Android OS Version                    |  any version      |\r\n| Android Devices/Emulators    | any device                |\r\n| Occurs on iOS     | yes            |\r\n| iOS Version           | any version             |\r\n| iOS Devices/Simulators    | any device                |\r\n\r\n# Steps to Reproduce\r\n\r\n1. Open Plaid SDK with token\r\n2. Search and select Platypus OAuth Bank\r\n3. Select Platypus Oauth Bank\r\n4. Decline or simulate error\r\n5. Once back to the app, press on Link with account numbers\r\n6. Press on back arrow on that screen\r\n7. Search and select Platypus OAuth Bank\r\n8. Get stack on \"Almost done...\" screen\r\n\r\n\r\nEvents logged by Plaid SDK:\r\n```\r\n{\"linkEvent\": {\"eventName\": \"OPEN\", \"metadata\": {\"errorCode\": \"\", \"errorMessage\": \"\", \"errorType\": \"\", \"exitStatus\": \"\", \"institutionId\": \"\", \"institutionName\": \"\", \"institutionSearchQuery\": \"\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"\", \"timestamp\": \"2021-05-04T05:12:07.140Z\", \"viewName\": \"CONSENT\"}}}\r\n{\"linkEvent\": {\"eventName\": \"TRANSITION_VIEW\", \"metadata\": {\"errorCode\": \"\", \"errorMessage\": \"\", \"errorType\": \"\", \"exitStatus\": \"\", \"institutionId\": \"\", \"institutionName\": \"\", \"institutionSearchQuery\": \"\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"\", \"timestamp\": \"2021-05-04T05:12:08.502Z\", \"viewName\": \"SELECT_INSTITUTION\"}}}\r\n{\"linkEvent\": {\"eventName\": \"SEARCH_INSTITUTION\", \"metadata\": {\"errorCode\": \"\", \"errorMessage\": \"\", \"errorType\": \"\", \"exitStatus\": \"\", \"institutionId\": \"\", \"institutionName\": \"\", \"institutionSearchQuery\": \"platypus\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"\", \"timestamp\": \"2021-05-04T05:12:13.226Z\", \"viewName\": \"\"}}}\r\n {\"linkEvent\": {\"eventName\": \"SELECT_BRAND\", \"metadata\": {\"errorCode\": \"\", \"errorMessage\": \"\", \"errorType\": \"\", \"exitStatus\": \"\", \"institutionId\": \"\", \"institutionName\": \"\", \"institutionSearchQuery\": \"\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"\", \"timestamp\": \"2021-05-04T05:12:24.503Z\", \"viewName\": \"\"}}}\r\n {\"linkEvent\": {\"eventName\": \"SUBMIT_CREDENTIALS\", \"metadata\": {\"errorCode\": \"\", \"errorMessage\": \"\", \"errorType\": \"\", \"exitStatus\": \"\", \"institutionId\": \"ins_127287\", \"institutionName\": \"Platypus OAuth Bank\", \"institutionSearchQuery\": \"\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"\", \"timestamp\": \"2021-05-04T05:12:38.396Z\", \"viewName\": \"\"}}}\r\n{\"linkEvent\": {\"eventName\": \"OPEN_OAUTH\", \"metadata\": {\"errorCode\": \"\", \"errorMessage\": \"\", \"errorType\": \"\", \"exitStatus\": \"\", \"institutionId\": \"ins_127287\", \"institutionName\": \"Platypus OAuth Bank\", \"institutionSearchQuery\": \"\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"ZH1sWGPHQWSGIEG\", \"timestamp\": \"2021-05-04T05:12:42.619Z\", \"viewName\": \"\"}}}\r\n{\"linkEvent\": {\"eventName\": \"OPEN\", \"metadata\": {\"errorCode\": \"\", \"errorMessage\": \"\", \"errorType\": \"\", \"exitStatus\": \"\", \"institutionId\": \"ins_127287\", \"institutionName\": \"Platypus OAuth Bank\", \"institutionSearchQuery\": \"\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"\", \"timestamp\": \"2021-05-04T05:12:52.202Z\", \"viewName\": \"\"}}}\r\n{\"linkEvent\": {\"eventName\": \"ERROR\", \"metadata\": {\"errorCode\": \"INSUFFICIENT_CREDENTIALS\", \"errorMessage\": \"insufficient authorization was provided to complete the request\", \"errorType\": \"ITEM_ERROR\", \"exitStatus\": \"\", \"institutionId\": \"ins_127287\", \"institutionName\": \"Platypus OAuth Bank\", \"institutionSearchQuery\": \"\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"DI1sIoSPnprVrDO\", \"timestamp\": \"2021-05-04T05:12:53.495Z\", \"viewName\": \"\"}}}\r\n{\"linkEvent\": {\"eventName\": \"TRANSITION_VIEW\", \"metadata\": {\"errorCode\": \"\", \"errorMessage\": \"\", \"errorType\": \"\", \"exitStatus\": \"\", \"institutionId\": \"\", \"institutionName\": \"\", \"institutionSearchQuery\": \"\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"DI1sIoSPnprVrDO\", \"timestamp\": \"2021-05-04T05:13:15.067Z\", \"viewName\": \"SELECT_INSTITUTION\"}}}\r\n{\"linkEvent\": {\"eventName\": \"SEARCH_INSTITUTION\", \"metadata\": {\"errorCode\": \"\", \"errorMessage\": \"\", \"errorType\": \"\", \"exitStatus\": \"\", \"institutionId\": \"\", \"institutionName\": \"\", \"institutionSearchQuery\": \"platypus\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"DI1sIoSPnprVrDO\", \"timestamp\": \"2021-05-04T05:13:18.776Z\", \"viewName\": \"\"}}}\r\n{\"linkEvent\": {\"eventName\": \"SELECT_BRAND\", \"metadata\": {\"errorCode\": \"\", \"errorMessage\": \"\", \"errorType\": \"\", \"exitStatus\": \"\", \"institutionId\": \"\", \"institutionName\": \"\", \"institutionSearchQuery\": \"\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"DI1sIoSPnprVrDO\", \"timestamp\": \"2021-05-04T05:13:20.058Z\", \"viewName\": \"\"}}}\r\n{\"linkEvent\": {\"eventName\": \"SELECT_INSTITUTION\", \"metadata\": {\"errorCode\": \"\", \"errorMessage\": \"\", \"errorType\": \"\", \"exitStatus\": \"\", \"institutionId\": \"ins_127287\", \"institutionName\": \"Platypus OAuth Bank\", \"institutionSearchQuery\": \"\", \"linkSessionId\": \"8c255f26-4c3d-482b-a6e5-9b0d995dec09\", \"metadataJson\": \"\", \"mfaType\": \"\", \"requestId\": \"DI1sIoSPnprVrDO\", \"timestamp\": \"2021-05",
  "Issue title: Bug: MD5 indicator is not being imported into MISP by stix2misp.py\n Issue body: ### Expected behavior\n\nFile properly imported.\n\n### Actual behavior\n\nTraceback (most recent call last):\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 2111, in <module>\r\n    main(sys.argv)\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 2105, in main\r\n    stix_parser.handler(event, filename, args[2:])\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 86, in handler\r\n    self.parse_event(event)\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 1232, in parse_event\r\n    self.handle_markings()\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 146, in handle_markings\r\n    attribute.add_tag(self.marking_definition[marking_uuid]['object'])\r\nKeyError: 'f88d31f6-486f-44da-b317-01333bde0b82'\r\n\n\n### Steps to reproduce\n\nRun Command:\r\n/var/www/MISP/venv/bin/python /var/www/MISP/app/files/scripts/stix2/stix2misp.py /var/www/MISP/app/tmp/MISPEAc0Y1\r\n\r\nContents of MISPEAc0Y1 can be found below.\r\n{\r\n    \"type\": \"bundle\",\r\n    \"id\": \"bundle--b1046b43-8dcd-4e38-a4a4-7bb4797e2d46\",\r\n    \"spec_version\": \"2.0\",\r\n    \"objects\": [\r\n        {\r\n            \"type\": \"indicator\",\r\n            \"id\": \"indicator--384f53ff-5af4-4764-9d47-974eb06405ab\",\r\n            \"created_by_ref\": \"identity--9b6ad3d0-a43b-48d4-8c59-8e320dba6251\",\r\n            \"created\": \"2022-06-13T20:41:14.624Z\",\r\n            \"modified\": \"2022-06-13T20:41:14.624Z\",\r\n            \"name\": \"file_hash: 161b10e95c2f6723ce267e2fb7961b4b\",\r\n            \"pattern\": \"[file:hashes.MD5 = '161b10e95c2f6723ce267e2fb7961b4b']\",\r\n            \"valid_from\": \"2022-06-13T20:40:42.48143Z\",\r\n            \"labels\": [\r\n                \"anomalous-activity\",\r\n                \"Emotet\"\r\n            ],\r\n            \"object_marking_refs\": [\r\n                \"marking-definition--f88d31f6-486f-44da-b317-01333bde0b82\"\r\n            ]\r\n        },\r\n        {\r\n            \"type\": \"report\",\r\n            \"id\": \"report--194fa9a3-7e12-44f6-88df-a7cbc734091d\",\r\n            \"created\": \"2022-06-22T18:07:33.342Z\",\r\n            \"modified\": \"2022-06-22T18:07:33.342Z\",\r\n            \"name\": \"file_hash: 161b10e95c2f6723ce267e2fb7961b4b\",\r\n            \"published\": \"2022-06-13T20:41:14.624Z\",\r\n            \"object_refs\": [\r\n                \"indicator--384f53ff-5af4-4764-9d47-974eb06405ab\"\r\n            ],\r\n            \"labels\": [\r\n                \"indicator\"\r\n            ]\r\n        }\r\n    ]\r\n}\r\n\r\n\n\n### Version\n\nv2.4.159\n\n### Operating System\n\nubuntu\n\n### Operating System version\n\n20.04.4 LTS\n\n### PHP version\n\n7.4\n\n### Browser\n\nN/A\n\n### Browser version\n\nN/A\n\n### Relevant log output\n\n```shell\nTraceback (most recent call last):\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 2111, in <module>\r\n    main(sys.argv)\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 2105, in main\r\n    stix_parser.handler(event, filename, args[2:])\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 86, in handler\r\n    self.parse_event(event)\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 1232, in parse_event\r\n    self.handle_markings()\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 146, in handle_markings\r\n    attribute.add_tag(self.marking_definition[marking_uuid]['object'])\r\nKeyError: 'f88d31f6-486f-44da-b317-01333bde0b82'\n```\n\n\n### Extra attachments\n\n_No response_\n\n### Code of Conduct\n\n- [X] I agree to follow this project's Code of Conduct\n Comments: \n Comment 0: Hey,\r\nThe script was not handling the possibility that there could be objects referencing other objects where the referenced objects are not present in the bundle.\r\n-> In your sample, there is a `marking_ref` and the referenced `marking-definition` object does not exist in the bundle.\r\n\r\nI am currently working on the rework of the [STIX -> MISP import feature](https://github.com/MISP/misp-stix/tree/main/misp_stix_converter/stix2misp) (and will keep notes of this \"missing referenced objects\" case to avoid issues in the future), so I quickly checked in stix2misp.py if there could be any other similar issue, it should be ok for now with d2ddef68ab9abf01ae0e24e0d3d6bb196a80cfea\r\nBut if I missed anything and/or you face any further issue let me know.\r\n\r\n\n Comment 1: I have a ton of failures from different stix files from the h-isac feed. I was just going to work my way through them one bug at a time. If you need specific stix files types...I will be happy to provide. Thanks for working on this.\n Comment 2: @sholland-bamboohealth I'm always happy to get samples in order to see how the different STIX objects are built by different producers. It really helps me adapting the code to cover the different cases for a better support\r\nThanks\n Comment 3: getting this when trying to import the file with the following command\r\n\r\n`/var/www/MISP/venv/bin/python /var/www/MISP/app/files/scripts/stix2/stix2misp.py /var/www/MISP/app/tmp/MISPAKjotS\r\n`\r\n\r\n/var/www/MISP/app/tmp# /var/www/MISP/venv/bin/python /var/www/MISP/app/files/scripts/stix2/stix2misp.py /var/www/MISP/app/tmp/MISPAKjotS\r\nTraceback (most recent call last):\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 2146, in <module>\r\n    main(sys.argv)\r\n  File \"/var/www/MISP/app/files/scripts/stix2/stix2misp.py\", line 2138, in main\r\n    event = stix2.parse(f.read(), allow_custom=True, interoperability=True)\r\nTypeError: parse() got an unexpected keyword argument 'interoperability'\r\n\n Comment 4: This one is a pretty easy one to fix, it simply comes from a different version of the STIX 2 python library\r\nWe use a slightly changed version that I maintain to avoid validation issues with U",
  "Issue title: \u8b66\u544a\u95ee\u9898\uff1aisMounted(...) is deprecated in plain JavaScript React classes.\n Issue body: \r\n\u4f7f\u7528\u4e86\u8868\u683c\u7ec4\u4ef6\u540e\uff0c\u63a7\u5236\u53f0\u8fde\u7eed\u8b66\u544a\uff1aisMounted(...) is deprecated in plain JavaScript React classes.\r\n![image](https://user-images.githubusercontent.com/9399517/32100824-f578df2a-bb47-11e7-93f9-ce736c2f5b81.png)\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/9399517/32100695-591f3e30-bb47-11e7-90e2-e5755e4ade2b.png)\r\n\r\n\r\n\r\n\n Comments: \n Comment 0: \u4e0d\u5f71\u54cd\u4f7f\u7528\u7684\uff0c\u6682\u65f6\u53ef\u4ee5\u5ffd\u7565\uff0c\u4f1a\u5728\u4e0b\u4e00\u7248\u4e2d\u4fee\u590d\n Comment 1: \u8bf7\u5347\u7ea7\u5230griffindenise@example.org`\u8bd5\u8bd5\u770b, \u6682\u65f6\u5148\u5173\u95ed\u8fd9\u4e2aissue, \u6709\u95ee\u9898\u968f\u65f6\u53ef\u4ee5\u91cd\u65b0\u6253\u5f00.",
  "Issue title: New FW update wizard\n Issue body: [Zeplin](https://zpl.io/bAMzrLn)\n Comments: \n Comment 0: 1) new wizard doesnt use correct font.See screenshot below. Is that on purpose?\r\n\r\n2) can you please change update text to has been or to was? I'm not expect but ** has released!** sounds strange\r\n\r\n![image](https://user-images.githubusercontent.com/31506317/95071735-6e81cd80-070a-11eb-9b16-61c381a27648.png)\r\n\r\nNixos + Chromium 85\r\nSuite web dev master commit 3a9fd795a1b8da8223faa29aaac2aa842a22d262\r\nDevice T1 FW 1.9.3 commit 0x0d5f00668fb3d1c093ff3c879311a91d3a7175c8,\n Comment 1: QA OK\r\n\r\nNixos + Chromium 85\r\nSuite web dev master commit 4d4a9f3\r\nDevice Model T 2.3.4 commit 50854b921",
  "Issue title: How to use multiple modifiers on the same JSX Eventhandler?\n Issue body: The following isn't working\r\n\r\n```ts\r\n...\r\nonKeyup={m.enter(this.addTodo)}\r\nonKeyup={m.esc(this.addTodo)} // JSX can't have 2 onKeyup\r\n...\r\n```\r\n\r\nCan we some how chain the modifiers? like `onKeyup={m.enter.esc(this.addTodo)}`?\n Comments: \n Comment 0: [keys](/wonderful-panda/vue-tsx-support#keys) is available from v2.2.0.\r\n\r\n```typescript\r\n<div onKeyup={m.keys(\"enter\", \"esc\")(this.addTodo)} />\r\n```\n Comment 1: Awesome. \ud83c\udf89",
  "Issue title: Weird parsing of empty blocks of code (with triple backticks)\n Issue body: Originally reported in https://github.com/sourcejs/Source/issues/155#issuecomment-117956180:\n\nMarked's parsing of named code blocks is weird.\n\n``````\n> var m = require('marked')\n> m('```js\\n```')\n'<p><code>js</code></p>\\n'\n> m('```js\\n\\n```')\n'<pre><code class=\"lang-js\">\\n\\n</code></pre>\\n'\n``````\n\nWhy isn't the first example recognized as an empty block of `lang-js`?\n\n Comments: \n Comment 0: And one more example, now with custom renderer:\n\n``````\n> var renderer = new m.Renderer();\nundefined\n> renderer.code = function(code, lang) { console.log(JSON.stringify(code), lang, 'block!'); }\n[Function]\n> renderer.codespan = function(code) { console.log(JSON.stringify(code),'span!'); }\n[Function]\n> m('```js\\n```', {renderer: renderer})\n\"js\" span!\n'<p>undefined</p>\\n'\n> m('```js\\n\\n```', {renderer: renderer})\n\"\\n\" js block!\n'undefined'\n``````\n\nLooks like in this first markdown example, the code is parsed as codespan.\n",
  "Issue title: SteamVR Freezes\n Issue body: SteamVR freezes (in the presence of CUDA/OpenGL or CUDA-OpenGL interop) in the scene application.\r\n\r\nSymptoms:\r\n\r\n- Image in the HMD freezes (and persists)\r\n- Our engine keep running normal without any errors, but at ~10fps\r\n- Our internal profiler timeline shows a very long wait on WaitGetPoses\r\n- The rendered images are blitting successfully into the companion window\r\n- Our engine can still exit cleanly\r\n \r\nAfter our engine process has exiting:\r\n\r\n- Image in the HMD is still frozen\r\n- SteamVR can exit cleanly (non of the processes hanging around)\r\n- SteamVR resumes normal operation after restart\r\n\r\nI have a suspicion this could be a bug in SteamVR or the NVIDIA driver for Pascal GPUs. Does not happen on Maxwell or Kepler. We do insert a full device sync after all CUDA work is done and before any OpenGL works start and also before the WaitGetPoses(). No manual handoff call. The bug could also be in SteamVR. \r\n\r\n\r\n\r\n\n Comments: \n Comment 0: @fhoenig I have the exact same issue on my 1080ti. Sometimes it happens immediately sometimes it happens after a couple of minutes. I tried updating all drivers, software but to no avail. Did you find anything that maybe can help?\r\n\n Comment 1: For what type of application and what API(s)? Are you using CUDA or compute shaders?\r\nIssue is not resolved yet but it all looks like some issue with Pascal and the fact that a Dx11 process (the steamvr compositor) is adding things into your GPUs commandbuffer.\r\n\r\n\n Comment 2: I am using Unity with the ZED camera. The ZED uses CUDA to compute a depth map in real-time. I am going to contact ZED to see if they know something about it. Thanks for your help!\n Comment 3: Aha! Then it is most certainly a NVIDIA driver issue with Pascal. I'm in\ntouch with NVIDIA and they'd open a ticket but in our case they could not\nyet reconstruct the issue themselves. Can you post the exact version of\neverything here? dxdiag output and the software versions you are using?\nI'll be able to forward it then.\n\nOn Mon, Aug 7, 2017 at 11:46 AM, Koen Rijpstra <powersjessica@example.com>\nwrote:\n\n> I am using Unity with the ZED camera. The ZED uses CUDA to compute a depth\n> map in real-time. I am going to contact ZED to see if they know something\n> about it. Thanks for your help!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/ValveSoftware/openvr/issues/557#issuecomment-320619782>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAWI6FyJlosIHDtQfYdPiIF_M7JCGT7Mks5sVt0BgaJpZM4N-ugS>\n>.\n>\n\n Comment 4: Software used:\r\n```\r\nUnity 5.6.1f1\r\nZED SDK 2.1.2\r\nZED Unity plugin 2.1.2\r\nSteamVR version 1499136050\r\nSteamVR Unity plugin 1.2.2\r\n```\r\n\r\ndxdiag:\r\n[DxDiag.txt](https://github.com/ValveSoftware/openvr/files/1204579/DxDiag.txt)\r\n\n Comment 5: >* Our engine keep running normal without any errors, but at ~10fps\r\n>* Our internal profiler timeline shows a very long wait on WaitGetPoses\r\n\r\nThis is because WaitGetPoses doesn't return, and SteamVR's internal timeout is 100ms.\r\nBut the reason? I don't know... Maybe in the driver implementation the `TrackedDevicePoseUpdated` is blocked, or vrserver.exe crashes...\n Comment 6: @fhoenig Have you considered using Nvidias VRWorks SDKs and there tool sets to work out what is going in?\r\n\r\nYou can apply for access to VRWorks SDK for headset developers at https://developer.nvidia.com/vrworks and can access VRWorks features for building applications from Unity Asset Store.\r\n\n Comment 7: @Balderick - We are not using Unity. Our engine is written from scratch and using CUDA, just like Koen is indirectly as well. NVIDIA devtech is already aware of this problem but it seems like some sort of race condition or fence problem inside the driver. Therefore its really hard to reconstruct.\r\n\r\nThe combination of CUDA and SteamVR is super rare and I wouldn't hold it against the NVIDIA team to have a bug in some the interop code.\r\n\r\nIt happens only on Pascal, which has extended async compute capabilities. Perhaps its buried somewhere in that code.\r\n\n Comment 8: I had that problem with a GTX 970 with a sample using the SDK OpenVR, CUDA-OpenGL interop and the ZED. But it happens more often with 1060 or 1070.\n Comment 9: Could someone post an executable which exhibits this freeze together with dxdiag output?\n Comment 10: Just to add a wrinkle to this thread: I'm having the same issues with almost the same exact specs as @KoenRijpstra (Zed Camera and Unity), but __only with the Vive HMD__. The Rift HMD does not exhibit this powersjessica@example.com. \n Comment 11: I'm going to necro this thread: Any word from Nvidia about this issue @fhoenig?\n Comment 12: negative. It'll need an executable the helps them reconstruct the bug.\n\nOn Sun, Sep 24, 2017 at 1:38 PM, maximeLong <powersjessica@example.com>\nwrote:\n\n> I'm going to necro this thread: Any word from Nvidia about this issue\n> @fhoenig <https://github.com/fhoenig>?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/ValveSoftware/openvr/issues/557#issuecomment-331738590>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAWI6F_oXK4Vg_ZbeMSmly3azOwM3PQaks5slr23gaJpZM4N-ugS>\n>.\n>\n\n Comment 13: +1 having this issue too.\r\n\r\nDigging a little further, I found it is pretty easy to freeze SteamVR. Just do the following procedure. Your program does not even have to interact with SteamVR in any way. You just:\r\n\r\n1) Run SteamVR **with SteamVR Home actively rendering in Vive HMD**\r\n2) Fire up your CUDA program which upon initialization creates an OpenGL window as simple as \r\n```c++ \r\nglfwInit();\r\nglfwCreateWindow(800, 600, \"myWindow\", nullptr, nullptr);\r\n```\r\n\r\nAnd bang! SteamVR hangs just like OP said, right when the GL window is launched. If you remove the GL window in your program then both runs concurrently without any problem. It seems the combination of CUDA + OpenGL + SteamVR spells trouble. \r\n\r\nAlso freezes SteamVR is the combination of CUDA + DX11 + SteamVR in Unity (without OpenGL here because SteamVR plug-in supports only DX11 renderer).\n Comment 14: I am stuck too with this issue since a while. I was testing with an app (ZED SDK + OpenVR) which freeze from time to time. \r\nThen, after many tests, I came to the simplest code to reproduce the issue.\r\nLaunch the _hellovr_opengl_ sample, the process uses about 8% of the CPU, the VRCompositor use 8% too, the total CPU usage is around 40%. Everything is fine, but as soon as I open a huge process such as Unity or photoshop (which increase a lot the CPU usage for a short time), the sample crash.\r\nThen I have tried in my own app, I disable many features to use the minimum CPU and it goes well till I use more CPU.\r\nIt's like something in the rendering goes wrong if the CPU is too busy somewhere else.\r\n\n Comment 15: Hmm. Sounds like actually just an OpenGL problem. Somewhat confirms what I see in our engine. If it crashes, the callstack is always on top of an OpenGL call. \r\n\r\nWould you mind attaching a DXDIAG output?\r\n\r\n\n Comment 16: @rosenrodt - does your test program also cause the issue if you don't have CUDA in there?\n Comment 17: I think this issue is specific to SteamVR **Direct Mode**. When I switch to **Extended Mode** my program runs just fine. Direct Mode is supposedly better though.\r\n\r\n@P-yver I cannot reproduce your *hell",
  "Issue title: Investigate possible improvements to build time.\n Issue body: ### Expected behaviour\r\nWe should try to decrease build time of a production, dev, and test build goals. \r\n\r\n* Possible bottleneck scenarios: \r\n- webpack version\r\n- webpack config merges/handlings\r\n- moving of assets\r\n- babel version\r\n- output of logs\r\n\r\n### Actual behaviour\r\nProd, dev, and test goals should take a reasonable time\r\n\r\n### Steps to reproduce\r\n\n Comments: \n Comment 0: Cleaning up - Closing issues that were open for a long time without any update. We can re-open if needed.",
  "Issue title: Feature: Support translations\n Issue body: Parts of the IPFS project are structured in a way that accommodates localization, with volunteer translators working via Transifex. ([Learn more here](https://github.com/ipfs/community/blob/master/CONTRIBUTING.md#translations) about contributing translations.) \r\n\r\nOnce we have ProtoSchool's structure more stable (which will depend on completing our audit of online coding education platforms and determining whether we're migrating), it would be great to revamp our structure in a way that would support translations on the ProtoSchool website as well. \r\n\r\nThis is not a change we can make immediately, but I'm opening the issue now so folks can follow it if they're interested in knowing when translations are possible.\r\n\n Comments: \n Comment 0: For future reference, here's a [PDF of a presentation in Mandarin](https://github.com/ProtoSchool/shanghai/blob/b62173453f2eddf6e1bac5944b3292221124b2bd/Events/20190728-4thSession/%E8%BE%BE%E5%AE%87%EF%BC%9AIPFS%E5%8E%BB%E4%B8%AD%E5%BF%83%E5%8C%96%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.pd) by the Shanghai chapter that covers the content of our [Decentralized Data Structures](https://proto.school/#/data-structures/) tutorial.  Thanks to @steven004 for sharing this presentation by Yu Da  (a senior engineer from IPFS-Force) which took place July 28, 2019.\n Comment 1: I am putting the [Chinese version of Decentralized Data Structures](https://github.com/ProtoSchool/shanghai/blob/master/Events/20190728-4thSession/Data_Structures_ChineseVersion.md) Tutorial into Shanghai Chapter repo.\r\n\r\nAnd, also welcome to watch the video of the training from [here](https://www.youtube.com/watch?v=mUwoolN2O5o).\n Comment 2: I just found another translation of the Decentralized Data Structures tutorial into Chinese [here](https://learnblockchain.cn/article/744). \n Comment 3: I accidentally created this as a duplicate issue but have been referring folks, here, so now copying in some notes from #39: \r\n\r\nfrom @lidel on 9/10/18: \r\n\r\n@mikeal we should add it to https://www.transifex.com/ipfs/public/ :)\r\n\r\nSteps I see:\r\n\r\n1. Create a PR which moves English strings to separate source files, preferably in JSON-ICU format (to make it framework-agnostic and integrate with Transifex without conversion step). \r\n   Some prior art:\r\n    - In new WebUI we're using `i18next` with `i18next-icu`, [the setup is quite straightforward](https://github.com/ipfs-shipyard/ipfs-webui/blob/a67135c0a5041ed5c7a6d5216e9b664cb5336726/src/i18n.js).\r\n    - There is an open PR adding i18n to IPLD Explorer that you can check as well: https://github.com/ipfs-shipyard/ipld-explorer-components/pull/1/\r\n    - Those apps use React, but `i18next` bits will be mostly the same. I see there is also a helper for Vue: [@panter/vue-i18next](https://www.npmjs.com/package/@panter/vue-i18next), but I had no experience with it.\r\n1. In the same PR add `.tx/config` and create a project at Transifex (ping @lidel)\r\n1. Merge to master\r\n1. Set up Transifex to automatically check source strings from `master` for updates \r\n\r\nStep 1 is a chore but If you create PR with that, I can set up the rest :)\r\n\r\nFor more info about Transifex part, see References in https://github.com/ipfs/ipfs-gui/issues/50\n Comment 4: > @mikeal we should add it to https://www.transifex.com/ipfs/public/ :)\r\n\r\nYes please! There are a lot of translators and growing activity on Transifex. This will help the growth of IPFS, etc in non-English speaking countries. Chinese, Spanish, Arabic, French and German are much needed, to name a few. \r\n\r\nAlso, there is a potential risk associated with waiting too long: external websites will start summing up proto.school with their own translations, which could slightly differ, leading up to confusion for learners. Putting it up on Transifex also ensures it is consistent with the translations found on ipfs.io, IPFS Desktop, etc. \n Comment 5: Totally agree, @bertrandfalguiere, and will keep folks updated here. Preparing for translation will require a major overhaul of our codebase, which we're prioritizing alongside some other large projects on the horizon.\r\n\r\nIn the meantime, we're using our user survey to capture language preferences and are building new features with translations files so that there will be less to overhaul when the time comes.\r\n\r\nCan't wait to get the community's support with translations once we've made the necessary structural changes!",
  "Issue title: \u60a8\u80fd\u5e2e\u6211\u90e8\u7f72\u4e00\u4e0b\u5417\uff1f\n Issue body: \u6211\u64cd\u4f5c\u4e86\u597d\u51e0\u6b21\u90fd\u6ca1\u6709\u6210\u529f\uff0c\u7531\u4e8e\u4e0d\u592a\u61c2\u64cd\u4f5c\n Comments: \n Comment 0: \u81ea\u5df1\u591a\u5c1d\u8bd5",
  "Issue title: Error in the block update order or intentional behavior?\n Issue body: ### Expected behavior\n\nI wanted to build a system that detects if a sulker box has been opened and then sends out a redstone signal.\r\nWhen the shulker box is opened, the item inside the dispenser to the right of the shulker box moves into the hopper and thus delivers the desired signal.\r\nOn vanilla Minecraft (1.19.2) it works perfectly fine:\r\n\r\n![Vanilla_Behavior](https://user-images.githubusercontent.com/50832022/194624472-8cdc57f9-d350-49a4-8545-59eb4d68a3ea.gif)\n\n### Observed/Actual behavior\n\nOn my paper server, no Redstone signal occurs when using the same design:\r\n\r\n![Paper_Behavior](https://user-images.githubusercontent.com/50832022/194624434-30de35b4-178a-4629-9fb5-ea765eaad1bd.gif)\r\n\r\nI have tested the system on the paper server with the settings \r\n`redstone-implementation: EIGENCRAFT` and \r\n`redstone-implementation: VANILLA `\r\nBoth without success.\r\nMy question is, is this a bug, an intentional behavior or did i miss a setting somewhere?\n\n### Steps/models to reproduce\n\n**Here is a schmatic to recreate this behavior:**\r\n[Shulker_update_detec.zip](https://github.com/PaperMC/Paper/files/9736529/Shulker_update_detec.zip)\r\n\r\nThe hopper below the dropper is filled with items so it can't pull any more items from the dispenser above.\r\n![grafik](https://user-images.githubusercontent.com/50832022/194625086-65428963-bca3-403b-9feb-56f15aed667e.png)\r\n\r\nThe dropper above the hopper contains a random item that cannot be picked up by the hopper below\r\n![grafik](https://user-images.githubusercontent.com/50832022/194625298-b6d6aa39-df2a-41e7-8dc2-47719eeb902c.png)\r\n\r\nThe hopper dispenser combination also contains a random item to swap back and forth.\r\n![grafik](https://user-images.githubusercontent.com/50832022/194625445-9e418c13-cf3a-4aa7-9535-fc388cb8382e.png)\r\n\r\nThe content of the shulker box does not matter\r\n\r\nThe result of opening the shulker box can also be simulated by removing and placing the redstone dust on top of the redstone block (this works also only in vanilla):\r\n![Vanilla_Behavior_2](https://user-images.githubusercontent.com/50832022/194627728-d606690c-8d71-4ad5-9aaf-41e918499ea3.gif)\r\n\n\n### Plugin and Datapack List\n\n`/plugins`: none\r\n`/datapack list`: vanilla & file/bukkit\n\n### Paper version\n\n`/version` output:\r\nThis server is running Paper version git-Paper-199 (MC: 1.19.2) (Implementing API version 1.19.2-R0.1-SNAPSHOT) (Git: 77a50b9)\r\nYou are running the latest version\r\nPrevious version: git-Paper-198 (MC: 1.19.2)\n\n### Other\n\n_No response_\n Comments: \n Comment 0: I can replicate this :+1: Specifically interesting is the fact that this seems to be a paper-only issue.\r\nThe contraption works fine on spigot.\n Comment 1: After looking deeper into this (and loosing half my brain cells during the process) this is \"abusing\" a rather fun bug in hoppers (during which they still actively pull items out of containers above them even if they cannot hold any item).\r\n\r\nPaper fixes that as part of the paper hopper optimisation logic. I doubt that fixing this is in scope of paper sadly.\r\nI am sure some core-team or developer member can comment here as well to confirm my suspicion, however I doubt we will be able to help you here as such a contraption might just not be in the scope of paper.\n Comment 2: I'm probably a bit rambly as I'm outta spoons for today, long term goal has always been to restore parity with vanilla, but, given that we're layers down the stack, each fixing edge-case issues; It also gets ultra weird when the behavior is technically a bit of a bug.\r\n\r\nIn terms of priority, this is probably all the way down there on the list, along with every other redstone parity issue; If somebody wants to submit a PR, I'm willing to look at it, but, I don't think that it could drop a performance patch being such an edge-case thing, at best this would be a small trivial method call with minimal cost to reintroduce the \"issue\", or a config option\r\n\r\n",
  "Issue title: Can't use Virual currency with shopkeepers(bedrock) \n Issue body: ### Describe the bug\n\nWhen using the plugin Shopkeepers, I can not use virtual currency to buy items from the shops on bedrocks side. I can only buy things with physical currency\n\n### To Reproduce\n\n1. Go to shopkeepers\r\n2. click on shopkeeper\r\n3. click on item to buy\r\n4. item should go into inventory but it does not\n\n### Expected behaviour\n\nmoney should be deducted from virtual bank and item should go into players inventory\n\n### Screenshots / Videos\n\n\r\nhttps://user-images.githubusercontent.com/66132511/181037836-acc57455-0056-4465-9fe8-8794f5640e2e.mp4\r\n\r\n\n\n### Server Version and Plugins\n\nshopkeerpers, shopkeepers addon, bettereconomy, vault, geyser, floodgate\n\n### Geyser Dump\n\nhttps://discord.com/channels/613163671870242838/613168464634576897/1001495378442596382\n\n### Geyser Version\n\n2.0.5-SNAPSHOT (git-master-f4a5ccb)\n\n### Minecraft: Bedrock Edition Device/Version\n\n1.19 Win10, Mobile, Sony, Xbox\n\n### Additional Context\n\n_No response_\n Comments: \n Comment 0: i believe its the addon fault not geyser nor shopkeeper. i use Coins in my server to trade with physical currency and it worked fine. even SK's devs recomending coins and the addon you are using never mentioned anywhere in the wiki\n Comment 1: So shopkeepers addon is the only way you can do vitural currency trades with the shopkeepers. Without the addon no one can do virtual currency trades. Is there something I can do to get geyser to work with shopkeepers addon?\n Comment 2: Coins do exactly that. try it out https://www.spigotmc.org/resources/coins.33382/ \n Comment 3: > i believe its the addon fault not geyser nor shopkeeper. i use Coins in my server to trade with physical currency and it worked fine. even SK's devs recomending coins and the addon you are using never mentioned anywhere in the wiki\r\n\r\nGeyser doesn\u2019t support custom villager Recipes I think\n Comment 4: how to view item lore like ",
  "Issue title: Compressed image topic not accessible\n Issue body: I have two compressed image topics that I am publishing. For example, one is at `/robot/cameras/bw/image_raw/compressed`. I verified that the topic is subscribed to by `/web_video_server` by checking `rqt_graph`. \r\n\r\nWhen I visit http://localhost:8080, I can see the two camera topics listed without any links to click on to navigate to the stream or image snapshots.\r\n\r\nBoth image topics have camera_info additionally being published, and if I publish the raw_image without compression it seems to work fine.\n Comments: \n Comment 0: Still seems to be an issue at this time. I have a `CompressedImage `stream at `/raspicam_node/image/compressed` yet no topics are listed at localhost and trying to access it at say:\r\n\r\n`http://localhost:8080/stream?topic=/raspicam_node/image&type=ros_compressed`\r\n\r\nor \r\n\r\n`http://localhost:8080/stream?topic=/raspicam_node/image/compressed&type=ros_compressed`\r\n\r\ngives nothing.\r\n\r\nBut given that most of the documentation seems to focus on compression instructions I guess this server doesn't even support publishing pre-compressed messages and merely accepts raw to compress and send. Kind of a bummer though.\n Comment 1: any updates on this issue? I'm having the same issue",
  "Issue title: ionic 4.0.0-beta.7 debug instances of different apps overwrite each other on an android device\n Issue body: <!--\r\nPLEASE HELP US PROCESS GITHUB ISSUES FASTER BY PROVIDING THE FOLLOWING INFORMATION.\r\n\r\nISSUES MISSING IMPORTANT INFORMATION MAY BE CLOSED WITHOUT INVESTIGATION.\r\n-->\r\n\r\n# Bug Report\r\n\r\n**Ionic Info**\r\nRun `ionic info` from a terminal/cmd prompt and paste the output below.\r\n\r\n```\r\nwjz@bj:~/ion/arhat$ ionic info \r\n\u2714 Gathering environment info - done!\r\n\r\nIonic:\r\n\r\n   ionic (Ionic CLI)          : 4.1.1 (/home/wjz/.nvm/versions/node/v10.7.0/lib/node_modules/ionic)\r\n   Ionic Framework            : @ionic/angular 4.0.0-beta.7\r\n   @angular-devkit/core       : 0.7.2\r\n   @angular-devkit/schematics : 0.7.2\r\n   @angular/cli               : 6.1.1\r\n   @ionic/ng-toolkit          : 1.0.0\r\n   @ionic/schematics-angular  : 1.0.1\r\n\r\nCordova:\r\n\r\n   cordova (Cordova CLI) : 8.0.0\r\n   Cordova Platforms     : android 7.0.0\r\n   Cordova Plugins       : cordova-plugin-ionic-webview 2.0.2, (and 10 other plugins)\r\n\r\nSystem:\r\n\r\n   Android SDK Tools : 26.1.1 (/home/wjz/Android/Sdk)\r\n   NodeJS            : v10.7.0 (/home/wjz/.nvm/versions/node/v10.7.0/bin/node)\r\n   npm               : 6.2.0\r\n   OS                : Linux 4.4\r\n\r\nEnvironment:\r\n\r\n   HTTP_PROXY  : http://116.69.203.115:42266/\r\n   http_proxy  : http://116.69.203.115:42266/\r\n   HTTPS_PROXY : http://116.69.203.115:42266/\r\n   https_proxy : http://116.69.203.115:42266/\r\n\r\nwjz@bj:~/ion/arhat$ \r\n```\r\n\r\n**Describe the Bug**\r\nthe debug instance of an ionic app  overwrites other instances of (different) ionic apps when testing/debugging on a real android device. in other word, only one debug instance is allowed at a time on an android test device\r\n**Steps to Reproduce**\r\nSteps to reproduce the behavior:\r\n1. connect the test device with USB, make sure the 'Developer Option' is enabled. from the CLI, enter 'adb devices', make sure that the device is properly connected\r\n2. start a ionic 4 project by: \r\n`ionic start myApp tabs --type=angular`\r\ngo to the /directory/of/myApp, enter the following\r\n```\r\nnpm i\r\nionic cordova run android \r\n```\r\nsee that the project or app'myApp' was downloaded to the test device\r\n3. open a new CLI, start another ionic project by\r\n`ionic start yourApp tabs --type=angular`\r\ngo to the /directory/of/yourApp, enter the following\r\n```\r\nnpm i\r\nionic cordova run android \r\n```\r\n4. see that the project or app 'yourApp' was downloaded to the test device; however, the previously downloaded app'myApp' had been deleted. \r\n\r\n**Related Code**\r\nIf you are able to illustrate the bug with an example, please provide a sample application via an online code collaborator such as [StackBlitz](https://stackblitz.com), or [GitHub](https://github.com).\r\n\r\n**Expected Behavior**\r\nvarious instances for different apps should be allowed on an android test device\r\n**Additional Context**\r\nList any other information that is relevant to your issue. Stack traces, related issues, suggestions on how to fix, Stack Overflow links, forum links, screenshots, OS if applicable, etc.\r\n\n Comments: \n Comment 0: You can temporarily change the app id to run different'versions'. Maybe this is already enough for you?\n Comment 1: well. this is not a big issue for development purpose.\r\nI am not sure about the behavior of production downloading and installing. \r\nit would be crazy if I installed two different (ionic 4) apps from play store, and one of them overwrite the other\r\n \n Comment 2: this might not be an issue if you use [DevApp](https://ionicframework.com/docs/pro/devapp/#using-devapp)  for debugging, i guess DevApp might be the standard way of debugging in the future\n Comment 3: Thanks for the issue! This issue is being locked to prevent comments that are not relevant to the original issue. If this is still an issue with the latest version of Ionic, please create a new issue and ensure the template is fully filled out.\n",
  "Issue title: Fix Disappearing HUD for Tokyo Xtreme Racer 2 and fix crash on Android 7.1.4\n Issue body: **Please Note: This form is the minimum required information for submitting bugs.**  \r\n**Removing this form may lead to your issue being closed until it is completed.**\r\n\r\n| Platform | Branch | Hash | CIDL |\r\n| ------ | ------ | ---- | ---- |\r\n| Installed OS and version (ie. Android 8.0) | Branch (or Google Play) | Hashtag (skip if unknown) | Downloaded from build site? |\r\n\r\n**_Description of the Issue_**\r\n\r\nAdd a short, concise description of the issue here\r\n\r\n**_Debugging Steps Tested_**\r\n\r\n  * Fill in any steps already tried here\r\n  * Begin each new line with an asterisk\r\n  * If no steps are required, please skip\r\n\r\n**_Logs Gathered_**\r\n\r\n```\r\n\r\nPlease paste the contents of the log / logs here\r\nYou may leave this field blank if you have none.\r\n\r\n```\r\n\r\n\r\n**_Screenshots_**\r\n\r\n(Replace this line with any issue screenshots)\r\n\r\n- [ ] Place an X in the box to confirm you have filled in this form\r\n\n Comments: \n Comment 0: Closing this as not even the minimum form is filled in.\r\n\r\nSee https://github.com/reicast/gamedb/issues/62 for Tokyo Xtreme Racer 2.",
  "Issue title: Google Analytics / Big Query \u2013 Failing due to access token expiring before completion\n Issue body: ## Environment\r\n- **Airbyte version**:  0.39.1-alpha\r\n- **OS Version / Instance**: GCP n2\r\n- **Deployment**: Docker\r\n- **Source Connector and version**: Google Analytics 0.1.21\r\n- **Destination Connector and version**: Big Query 1.1.6\r\n- **Severity**: High\r\n- **Step where error happened**: Sync job\r\n\r\n## Current Behavior\r\nThe sync job (replication date of 01/01/2021) will run for roughly an hour, then it'll throw a 403 error code due to the access token expiring. We've provided a refresh token however it doesn't appear to be utilized. We've also seen issues with pointing to the same dataset as another connection we've already got setup. (i.e Shopify -> BigQuery (dataset \"A\"), Google Analytics -> BigQuery (dataset \"A)) will result in normalization issues, not sure if this is due to an internal Airbyte config or what. \r\n\r\nWe attempted to setup a new dataset and new connection, however before the sync can complete it seems to fail out after 1 hour. Here is the error we see in the logs after an hour:\r\n```\r\nException: Error while refreshing access token: 400 Client Error: Bad Request for url: https://oauth2.googleapis.com/token 2022-05-30 19:46:48 source > Finished syncing pages\r\n```\r\n\r\nThe sync job then fails, and spits out a bunch of nonsense normalization errors.\r\n\r\n## Expected Behavior\r\nThe sync job encounters a 400 Client Error and refreshes the access token using the provided refresh token or refreshes prior to the token becoming invalid. We should also be able to use an existing dataset if desired but currently that fails as a 404 due to missing tables.\r\n\r\n## Logs\r\n** Logs were too long to post here so I've put them in a gist [here](https://gist.github.com/linuxs/f009b4e8f62c64b4ed341a41e93fd9fa).\r\n\r\n## Steps to Reproduce\r\n1. Create GA source connector (with replication date at least 1 year in the past with significant data to sync)\r\n2. Create BigQuery connector (or use existing connection / dataset)\r\n3. Create connection, let run for at least 1 hour then it'll fail before completion.\r\n\n Comments: \n Comment 0: Turns out this is actually my fault sort of but I think it does point out a flaw in the logging. The refresh token provided turns out it was invalid but the logs never indicate that it failed to refresh the token, just simply silently fails.",
  "Issue title: lib/util/logging.c line 40-42 I was puzzled about the meaning of this code. \n Issue body: I was studying xdp-tools and found that in lib/util/logging.c line 40-42 I was puzzled about the meaning of this code. \r\n\r\n#define __printf(a, b) __attribute__((format(printf, a, b))) \r\n\r\n__printf(2, 3)\n Comments: \n Comment 0: sorry I misunderstood.",
  "Issue title: Cross-references in docstrings / *describe* bufferes\n Issue body: We need to turn docstring cross references to `lisp://` URLs.\r\nFor instance, the docstring of `buffer-load` mentions `buffer-load-hook`: we would turn it into a clickable link which would open the appropriate description page.\r\n\r\nThis was discussed in #745.\r\n\r\nIt shouldn't be too hard: parse \"`[^[:space:]]*'\" or something like that and replace it with `lisp://(describe MATCH)`.\r\n`describe` would be a smart function which finds out which description function to call depending on the type.\r\nIf a symbol has multiple types (e.g. both a function and a variable), then we would query the user.\r\n\r\nThoughts?\n Comments: \n Comment 0: I feel like 1984 editing your messages :-D\n Comment 1: I really like this idea. I assume the idea is kind of like how when clicking M-. on a object if Lisp finds multiple things like several methods with the name, you select the one that you are interested in?\n Comment 2: Exactly!\n\n Comment 3: > If a symbol has multiple types (e.g. both a function and a variable), then we would query the user.\r\n\r\nI like the idea but there should be a smarter way to deal with the above.  \n Comment 4: There is no smarter way. A symbol in a Lisp-2 is ambiguous and has to be resolved. An alternative may be displaying both a listing for the symbol as a function as and as a variable.\r\n\r\nFor example:\r\n\r\n`xyz (variable)`\r\n`xyz (function)`\n Comment 5: This is the different topic of _symbol namespaces_ (whether we want to\nresolve a symbol to a function, a class, a variable, etc.).\n\nWhat the \"target\" slot solves is the problem of how to refer to _values_\n(unprintable objects).\nNote that the problem of symbol namespaces does not occur in the context\nof this patch.\n\n Comment 6: About symbol namespaces: your suggestion could work.\nIn case of ambiguity (e.g. because the parentheses were forgotten), we\ncan prompt the user for the namespace.\n\n Comment 7: Would be nice to have bi-directional linking, i.e. list all symbols where the current symbol help page is referenced.\n Comment 8: Partially done in https://github.com/atlas-engineer/nyxt/commit/ed97f71e66c7a4b3eea481d3bb7e5951fb88df76.\r\n\r\nBut I'd like to address a few points:\r\n\r\n- The regex could be \"`[^'\\\\s]+'\" to include any kind of whitespace.\r\n- Multiple definitions are not supported.  Try with `nyxt:name`.\r\n\r\nFor this last point, I suggest the following:\r\n- Call `describe-any` instead of the entire `(cond... 'describe-variable...)`.\r\n- Modify `describe-any` to take an input argument.\r\n- Add a preprocessor filter to describe-any so that only exact matches are displayed.\r\n- Add a prompter option so that if only one suggestion is present, fire up the default action.\r\n\r\nWhat do you think @aartaka?\n Comment 9: OK, I've already done something here, I'll push soon.\n Comment 10: > #2063 is now in, we can disambiguate symbols!\r\n> \r\n> All we miss is bi-directional listing, that is, listing the docstrings where a symbol is referenced. Not an easy one.\r\n\r\nBut actually, what's the use-case for that? Given how chaotic our references to symbols are, I doubt one can build any reasonable usage patter out of those :)\n Comment 11: I agree, maybe it's enough to reference calls/uses (like `sly-edit-uses`).\n\n Comment 12: Closing in favor of #2113, where more instances of inspection are mentioned.",
  "Issue title: Make Responsive Chart using ChartJS (for Mobile Phones)\n Issue body: There is a ChartJS canvas area and I've created the plugin text in the chart area. I want to make a chart as responsive to use mobile and pc. When I deploy my web page on the web browser, and If I do a zoom on my web page, the chart (ChartJS) can not be changed responsively. I want to use ChartJS intended for mobile phones and pc. For rending PC as well, in order to test when I zooming bigger on a web browser; the chart looks as though it is stuck in a tiny space. How can I overcome this problem? My HTML rendering tool is W3.\r\n\r\nSample My Chart:\r\n\r\n[My CodePen ChartJS](https://codepen.io/jajarodriguez/pen/rNavdpW)\n Comments: \n Comment 0: https://www.chartjs.org/docs/latest/general/responsive.html",
  "Issue title: Feature Request: Play Next Folder in Directory\n Issue body: Long time, MJT! Been using the latest beta on Dropbox since it came out, seems pretty stable in all aspects (I have a single bug report to file after this feature request opening).\r\n\r\nI thoroughly enjoy the play next file in directory feature in Droidsound E. This works for stuff like GBS and NSF, meaning I can have multiple games in one directory and have it go from one to the next without intervening or going back to the filebrowser.\r\n\r\nWould it be possible to implement the same feature on a folder-level scale? Example: I have multiple subfolders or zips in a main folder, and when one zip/subfolder is done playing I would like it to automatically go to the next subfolder in that main folder.\n Comments: \n Comment 0: I understand what you mean, I need to do some experimenting with this. \n Comment 1: this feature is doable but might have nasty consequences, for example, if you have 30 zips in /mnt/sdcard/Music folder, this feature would create a playqueue of all the contents found inside those 30 zips. Making it advance to one zip at a time would require quite a lot changes :(\r\n\r\nI'll see further how it goes with this.\n Comment 2: I gotcha, I didn't realize that the playqueue pre-loads everything so the memory issue makes sense.\r\n\r\nMaybe a solution would be to add a feature where an entire subfolder could be added to a playlist or favorites. Do playlist and favorites handle playqueues differently?\n Comment 3: >>Do playlist and favorites handle playqueues differently?\r\nnot really, same deal. \r\n\r\nCurrently I have other tasks, I'll get back to this once I'm done with the other things. Maybe there is another kind of approach.\n Comment 4: there is files-only mode in playlist settings, enable that and see what happens if you queue 100000 songs :)\n Comment 5: Testing it now. Getting a weird bug where trying to type in the name to a new playlist, every other (alternating) character I enter blanks the line. Entering Genesis:\r\nG -> *blank* -> n -> *blank* -> s -> *blank* -> s \r\nPlaylist is then saved as just \"s\". \r\n\r\nI have a playlist of just about 1500 testing right now. Order is a tiny bit random. The sorts are fine based on the criteria used but it doesn't seem to separate the sorts based on sub-directory or zip file name. Games with multiple songs get played out of order. It would be nice to have those groupings together but it's not a dealbreaker in my opinion. What would be nice is for, on the playing file info page, the name of the Game were also presented. Since the playlists may result in semi-random orderings right now, it's hard to distinguish which game they're from based on the song title alone.\r\n\r\nIt's definitely a step in the right direction, and I'll be using it to make work playlists that are more convenient than the other manual workarounds I was doing! :)\n Comment 6: i'll test and fix the playlist kevinclark@example.org\n Comment 7: in fact, type here how you want the ordering to be done, let me know if you need the fields names used in SQL\n Comment 8: How to reproduce the sorting problem the fastest way?\n Comment 9: Sorry, my wife had to go in for surgery two weeks ago, I've been away from the computer most of the time since then. \r\n\r\nBasically, the sorting order would be somewhat natural. Play next alphabetical folder in the list. Then play the files (sorted by filename alphanumeric, so track 01 - blah.vgm, then track 02 - whatevs.vgm). So if I had a folder of:\r\n\r\n00 - Best Game\r\n1 - Okay Game\r\n07 - Revenge of Game\r\n72 - Game the Sequels\r\nA Game\r\nBetter than A Game\r\nDoh! More Game!\r\nSorry, Not as Good as Game\r\n\r\nIt would play in that order.\r\n\r\nAs for the sorting problem with the playlists, I'll reproduce once I get back in front of my other machine. \n Comment 10: Just click the colorful bar above the files and choose \"sort by filename\". Or go to settings and choose from Sorting preference -> Filename. \n Comment 11: Okay, I figured out my issue.\r\n\r\nI am still getting the playlist naming issue where I enter one character, and the next character I enter always counts as a backspace. It alternates like that so I can only ever have playlists with a single character for the name. I've tried it on multiple devices and they all behave the same way.\r\n\r\nAs for the playlist sorting, it has to do with when I try to add a folder from within a ZIP/7Z archive. I'll highlight the three scenarios I've done:\r\n\r\nDreamcast -> [Alpha Subfolders] -> [ZIP Files]\r\nIn this case, I try to add the 'A' subfolder to playlist, and it works exactly how I would expect it to work. Each ZIP shows up as its own entry. However, once I start trying to play stuff and it gets to the end of the folder, it just loops back around to the beginning of the folder. So one game continues on loop forever.\r\n\r\nDS -> [ZIP Files containing each Alpha grouping]\r\nHere, I have a very large ZIP containing all the games that begin with A in their own folders, within  'A.ZIP'. I try to add the A zip to a playlist, and the options it presents me are simply rescan or delete.\r\n\r\n[ZIP File containing all Alpha groupings of Genesis games]\r\nLastly, this is one big file called 'Genesis.ZIP' that contains all folders A-Z plus #, each of those containing the appropriate games in folders of their own name.  I try to add the A subfolder within the zip, and while it adds it, it adds all the files within it to the base of the playlist (the only option I have is to add all to playlist). So Altered Beast no longer is within its own subfolder, for example. All the games files are listed together in the base playlist and there's no way to sort them by game because the game name does not prefix each individual file.\r\n\r\nI hope that makes sense. Thank you for keeping at this, it is greatly appreciated! As it is, I'm using it to make some temporary random playlists. It isn't without use but it still isn't quite in the configuration that I believe would be ideal. Whether or not the amount of coding to make it so would be too much is your call, as always :D \n Comment 12: About the playlist naming thing, I have tried various images using emulator, 3 different samsung phones + Cyanogenmod 12.1 and i can't reproduce the problem.\r\n\r\nThe rest, yeah it makes sense somehow, I do some experiments and see how it goes, I post more questions here soon.\n Comment 13: DS -> [ZIP Files containing each Alpha grouping]\r\nHere, I have a very large ZIP containing all the games that begin with A in their own folders, within 'A.ZIP'. I try to add the A zip to a playlist, and the options it presents me are simply rescan or delete.\r\n\r\nin above case, do you have zips inside zips? if yes, that is not supported and won't get supported\n Comment 14: No, I do not have ZIPs inside ZIPs. It's just one big zip for all the games that begin with the letter A. Since Droidsound E displays a ZIP file in its browser just like it would a regular directory in file hierarchy, the ZIPs name is A and all the A games are inside there in their own folders.\r\n\r\nThe devices I've tried the playlist thing on and they're showing the naming issue are:\r\n\r\nASUS Zenfone 2 (Lollipop 5.0, Stock Rom, Fresh Droidsound E install) Running R46\r\nMoto G 4G LTE (Lollipop 5.1, Stock Rom, Fresh Droidsound E install) Running R52\r\nSamsung Galaxy S3 AT&T (Lollipop 5.1, CM12.1, Dirty Droidsound E install) Running R44\n Comment 15: wow, finally i was able to reproduce the playlist naming problem, will fix ASAP\n Comment 16: Take your time, man! Appreciated! Also, thank you VERY much for the volume modification and plugin enable/disable features!\n Comment 17: I have solved the first problem by adding a manual queue option in context menu, click it anywhere over archive or dir or archivedir and it will queue everything under it to existing queue or a new one if there is no existing\n Comment 18: https://www.dropbox.com/s/3f5flqfd0lggdz0/droidsounde1664_54.apk?dl=0\n Comment 19:  Downloading shortly, thanks!\n Comment 20: i just invented a better queuing method, i'll upload a new binary once its ready\n Comment 21: just tried the new system with ~200000 songs in playqueue, no memory problems :)\n Comment",
  "Issue title: Can't get new message incoming notification at the other side \n Issue body: Unless sending a image otherwise the send messages won't show or get notification at remote(the other side)! Does someone also occur the same problem?\n Comments: \n Comment 0: See #65 ",
  "Issue title: Undefined method 'count' for NilClass\n Issue body: I am getting an undefined method error 'count' for nil38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5NilClass with my current implementation. I've used this gem successfully in the past but can't seem to troubleshoot my current issue.\r\n\r\nI am trying to show my user (Company) all their unique customers, aka one record per customer that links_to their overall history/info. I have the opposite working where the table displays all records for all the Company's customers, but that is basically pointless for desired experience/interaction.\r\n\r\nUsing pry, I've verified I have the collection of unique records I need in ActiveRecor38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5Relation38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5tiveRecord Relation LawnProfile format (it is not an array) returning from my get_raw_records method:\r\n`def get_raw_records\r\n    lawn_array = Appointment.where(:company_id => options[:company]).order(service_date: :desc).includes(:homeowner, :lawn_profile).references(:homeowner, :lawn_profile).map(&:lawn_profile_id).uniq\r\n    binding.pry\r\n    LawnProfile.where(id: lawn_array)\r\n  end`\r\n\r\nError seems to occur within data method when mapping records. Here is the method that, again, works perfectly fine when returning all records for all users:\r\n`def data\r\n    records.map do |record|\r\n      @homeowner_info = \"#{record.homeowner.name} <br/> #{record.street.titleize}\"\r\n      if record.appointments.paid.any?\r\n          last_photo = record.appointments.paid.last.completed_work.url(:small)\r\n          @lawn_photo = \"<image src= #{last_photo}></image>\"\r\n      else \r\n          @lawn_photo = \"<image src=https://maps.googleapis.com/maps/api/streetview?size=584x300&location=#{record.lawn_profile.street.parameterize}#{record.lawn_profile.city.parameterize}&key=googleMapkey></img>\"\r\n      end\r\n       [\r\n        @lawn_photo,\r\n        @homeowner_info,\r\n        record.appointments.last.formatted_price,\r\n        \"\",\r\n        record.homeowner.id,\r\n      ]\r\n    end\r\n  end`\r\n\r\nThe fact that before records.map tries to run'records' is and ActiveRecor38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5Relation containing the records that I need but still throwing the NilClass error is giving me fits. I'm not calling 'count' method anywhere myself, so it certainly seems to be a fundamental issue that I cannot resolve.\r\n\r\nHere is my controller code:\r\n`def my_customers\r\n      @vendor = current_user\r\n      @company = current_user.company\r\n      @appt_reliability = vendor_reliability\r\n\r\n      respond_to do |format|\r\n        format.html\r\n        format.json { render json: VendorCustomersDatatable.new(view_context, {company: @company.id}) }\r\n      end\r\n\r\n    end`\r\n\r\nHere is my view:\r\n`<table id=\"vendor_customers_table\" class=\"display\" data-source=\"<%= my_customers_url(company: @company.id, format: 'json') %>\">\r\n                                        <thead>\r\n                                            <tr>\r\n                                              <th></th>\r\n                                              <th></th>\r\n                                              <th></th>\r\n                                              <th></th>\r\n                                              <th></th>\r\n                                            </tr>\r\n                                        </thead>\r\n                                    </table>`\r\n\r\nThanks in advance. Any insight is much appreciated.\n Comments: \n Comment 0: I apologize for the formatting. markdown and indentation are not playing nice.\n Comment 1: try to override as_json method. and you can debug where is an error comes from.\r\nhttps://github.com/antillas21/ajax-datatables-rails/blob/v-0-4-0/lib/ajax-datatables-rails/base.rb#L37\n Comment 2: Hi @JonZach  try to turn off searching and ordering options on your datatable.rb(https://github.com/ajahongir/ajax-datatables-rails-v-0-4-0-how-to/blob/master/app/datatables/city_datatable.rb#L6) with options: orderable: false, searchable: false\n Comment 3: Hi there! Any news?",
  "Issue title: slow printing in libreoffice\n Issue body: I don't know if this is the right place for reporting....\r\n\r\nI'm using libreoffice, which supposedly uses this project for printing. I'm on xubuntu 20.04.\r\n\r\nMy hw is quite good, AMD Ryzen 7 with 8GB ram\r\n\r\nIf I send to the printer a 4-pages A5 document printed as a brochure, printing 1 copy requires some seconds for processing it, printing 100 copies requires at least 5/10 minutes of processing. Pinting 1000 copies requires hours of processing.\r\n\r\nMy questions are:\r\n\r\n- Is it a cups issue or a libreoffice one? who is responsible of such a long processing time: cups or libreoffice?\r\n- I'd think that printing 100 copies should be equivalent to process one copy and send 100 times the same processed work, but it doesn't seem to be such that.\r\n- the processing job uses one core. Is there a way to use more cores?\r\n\n Comments: \n Comment 0: @paolobenve What printer are you using? What driver? How is it connected?\r\n\r\n\"lpstat -v\" and a copy of the PPD file from /etc/cups/ppd would be good information to start with.\n Comment 1: @paolobenve \r\nas general background information regarding \"printing copies\"\r\nyou may have a look at\r\nhttps://en.opensuse.org/SDB:Printing_Copies\r\n\r\nBy the way regarding LibreOffice\r\nsee a likely old and meanwhile fixed issue in\r\nhttps://en.opensuse.org/SDB:Landscape_Printing\r\nwhich I show here mainly as an example that\r\nprinting issues can become rather complicated.\r\n\n Comment 2: > What printer are you using?  What driver? How is it connected?\r\n\r\nCanon imageRunner 1025N, canon driver for this printer, connected ethernet cable\r\n\r\n```\r\n$ lpstat -v\r\ndevice for Canon-iR1020-1024-1025-UFRII-LT: lpd://stampante\r\n```\r\n\r\n`stampante` is defined in /etc/hosts\r\n\r\n/etc/cups/ppd/Canon-iR1020-1024-1025-UFRII-LT.ppd:\r\n```\r\n*PPD-Adobe: \"4.3\"\r\n*%\r\n*%  Copyright CANON INC. 2008\r\n*%  CUPS printer driver for Canon printer devices\r\n*%\r\n*%  This program is free software; you can redistribute it and/or modify\r\n*%  it under the terms of the GNU General Public License as published by\r\n*%  the Free Software Foundation; either version 2 of the License, or\r\n*%  (at your option) any later version.\r\n*%\r\n*%  This program is distributed in the hope that it will be useful,\r\n*%  but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n*%  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n*%  GNU General Public License for more details.\r\n*%\r\n*%  You should have received a copy of the GNU General Public License\r\n*%  along with this program; if not, write to the Free Software\r\n*%  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA\r\n*%\r\n\r\n*FormatVersion: \"4.3\"\r\n*FileVersion: \"3.0\"\r\n*LanguageVersion: English\r\n*LanguageEncoding: ISOLatin1\r\n*PCFileName: \"CNI1025ZK.PPD\"\r\n*Manufacturer: \"Canon\"\r\n*Product: \"(ir1020/1024/1025)\"\r\n*cupsVersion: 1.1\r\n*cupsManualCopies: False\r\n*cupsModelNumber: 84\r\n*cupsFilter: \"application/vnd.cups-postscript 0 pstoufr2cpca\"\r\n*ModelName: \"Canon iR1020/1024/1025 UFRII LT\"\r\n*ShortNickName: \"iR1020/1024/1025\"\r\n*NickName: \"Canon iR1020/1024/1025 UFRII LT\"\r\n*PSVersion: \"(3010.000) 550\"\r\n*PSVersion: \"(3010.000) 651\"\r\n*LanguageLevel: \"3\"\r\n*ColorDevice: False\r\n*DefaultColorSpace: Gray\r\n*FileSystem: False\r\n*Throughput: \"24\"\r\n*LandscapeOrientation: Plus90\r\n*VariablePaperSize: False\r\n*TTRasterizer: Type42\r\n*%CNGPLPLIBNAME: \"uictlufr2\"\r\n*%CNGPLPLIBNAMEVER: \"1.0.0\"\r\n\r\n*%CNPrintLang: UFR2\r\n\r\n*opvpDevice: \"opvp\"\r\n*opvpDriver: \"libcanonc3pl\"\r\n*opvpModel: \"iR1020/1024/1025\"\r\n\r\n*OpenUI *Resolution/Resolution : PickOne\r\n*DefaultResolution: 600\r\n*Resolution 600/600 dpi: \"<</HWResolution[600 600]>>setpagedevice\"\r\n*CloseUI: *Resolution\r\n\r\n*OpenUI *CNTonerSaving/Toner Save : PickOne\r\n*DefaultCNTonerSaving: False\r\n*CNTonerSaving Auto/Auto: \"<< >>setpagedevice\"\r\n*CNTonerSaving True/ON: \"<< >>setpagedevice\"\r\n*CNTonerSaving False/OFF: \"<< >>setpagedevice\"\r\n*CloseUI: *CNTonerSaving\r\n\r\n*OpenUI *MediaType/Media Type : PickOne\r\n*DefaultMediaType: Auto\r\n*MediaType Auto/Auto: \"<</MediaType(Auto)>>setpagedevice\"\r\n*MediaType PlainPaper/Plain Paper: \"<</MediaType(PlainPaper)>>setpagedevice\"\r\n*MediaType RECYCLED/Recycled Paper: \"<</MediaType(RECYCLED)>>setpagedevice\"\r\n*MediaType COLOR/Color Paper: \"<</MediaType(COLOR)>>setpagedevice\"\r\n*MediaType BOND/Bond Paper: \"<</MediaType(BOND)>>setpagedevice\"\r\n*MediaType HEAVY1/Heavy Paper 1: \"<</MediaType(HEAVY1)>>setpagedevice\"\r\n*MediaType HEAVY2/Heavy Paper 2: \"<</MediaType(HEAVY2)>>setpagedevice\"\r\n*MediaType HEAVY3/Heavy Paper 3: \"<</MediaType(HEAVY3)>>setpagedevice\"\r\n*MediaType OHP/OHP: \"<</MediaType(OHP)>>setpagedevice\"\r\n*MediaType LABELS/Labels: \"<</MediaType(LABELS)>>setpagedevice\"\r\n*MediaType ENVELOPE/Envelope: \"<</MediaType(ENVELOPE)>>setpagedevice\"\r\n*CloseUI: *MediaType\r\n\r\n*OpenUI *InputSlot/Paper Source: PickOne\r\n*DefaultInputSlot: Auto\r\n*InputSlot Auto/Auto : \"\"\r\n*InputSlot Manual/Manual : \"\"\r\n*InputSlot Cas1/Drawer 1 : \"\"\r\n*InputSlot Cas2/Drawer 2 : \"\"\r\n*CloseUI: *InputSlot\r\n\r\n*OpenUI *OutputBin/Paper Destination: PickOne\r\n*DefaultOutputBin: Auto\r\n*OutputBin Auto/Auto : \"<< >>setpagedevice\"\r\n*CloseUI: *OutputBin\r\n\r\n*OpenUI *Duplex/Duplex: PickOne\r\n*DefaultDuplex: None\r\n*Duplex None/OFF: \"<</Duplex false>>setpagedevice\"\r\n*Duplex DuplexNoTumble/ON (Long-edged Binding): \"<</Duplex true/Tumble false>>setpagedevice\"\r\n*Duplex DuplexTumble/ON (Short-edged Binding): \"<</Duplex true/Tumble true>>setpagedevice\"\r\n*CloseUI: *Duplex\r\n\r\n*OpenUI *BindEdge/BindingEdge: PickOne\r\n*DefaultBindEdge: Left\r\n*BindEdge Left/Left: \"<< >>setpagedevice\"\r\n*BindEdge Top/Top: \"<< >>setpagedevice\"\r\n*CloseUI: *BindEdge\r\n\r\n*OpenUI *Collate/Collate: PickOne\r\n*DefaultCollate: False\r\n*Collate False/No Collate: \"<< >>setpagedevice\"\r\n*Collate Group/Group: \"<< >>setpagedevice\"\r\n",
  "Issue title: 1.0.4\u7248\u672c\u6307\u4ee4\u65e0\u6548\u5e76\u4e14\u65e0\u6cd5\u5f00\u53d1\u80fd\u529b\n Issue body: \u8be5\u7248\u672c\u6307\u4ee4\u663e\u793a\u4e0d\u5b58\u5728\uff0c\u5e76\u4e14\u80fd\u529b\u5f00\u53d1\u673a\u79cd\u4e00\u65e6\u5f00\u59cb\u5f00\u53d1\u8fdb\u5ea6\u6761\u4e00\u76f4\u663e\u793a00%\u5361\u4f4f\u4e0d\u52a8\uff0c\u53e6\u5916\u91d1\u5c5e\u5904\u7406\u673a\u70b9\u5f00\u4f1a\u5d29\n Comments: \n Comment 0: \u8bf7\u7ed9\u51fa\u5177\u4f53\u7684\u670d\u52a1\u7aef\u548c\u5ba2\u6237\u7aefforge\u3001java\u3001Lambda\u7248\u672c\u7b49\u4fe1\u606f\u3002\n Comment 1: \u5355\u673a \r\nforge\uff1aforge-1.7.10-116.69.203.1158-1.7.10-installer-win\r\nJava\uff1ajre1.8.0_101\r\nLambda\uff1a1.2.3\r\n\u6ce8\uff1a\u7248\u672c\u82e5\u6362\u4e3a1.0.2\u53ca\u66f4\u4f4e \u4ee5\u4e0a\u7686\u6b63\u5e38\n Comment 2: \u8bf7\u4f7f\u7528\u66f4\u65b0\u7248\u672c\u7684Forge\u5e76\u4e14\u91cd\u8bd5\u3002\r\n\u9700\u8981\u7684Forge\u7248\u672c\u5e94\u8be5\u9ad8\u4e8e525.319.0526.",
  "Issue title: SmartLife Socket wont stopped SmartConfig complete\n Issue body: I managed to flash 3 of this and one of the refuse to connected after SmartConfig completed.\r\n\r\nhttps://blakadder.github.io/templates/anoopsyche_JH-G01B1.html\r\n\r\nI can see there is a WIFI name SMARTLIFE XXXXX  but it just stuck there with no progress. \r\nAny work around?\r\n\r\nLogs here \r\n\r\n```\r\n==> smarthack-wifi.log <==\r\nBacking up /etc/dnsmasq.conf...\r\nWriting dnsmasq config file...\r\nCreating new /etc/dnsmasq.conf...\r\nWriting hostapd config file...\r\nConfiguring AP interface...\r\nApplying iptables rules...\r\niptables v1.6.0: can't initialize iptables table `filter': Table does not exist                                                                                                  (do you need to insmod?)\r\nPerhaps iptables or your kernel needs to be upgraded.\r\niptables v1.6.0: can't initialize iptables table `nat': Table does not exist (do                                                                                                  you need to insmod?)\r\nPerhaps iptables or your kernel needs to be upgraded.\r\niptables v1.6.0: can't initialize iptables table `filter': Table does not exist                                                                                                  (do you need to insmod?)\r\nPerhaps iptables or your kernel needs to be upgraded.\r\niptables v1.6.0: can't initialize iptables table `nat': Table does not exist (do                                                                                                  you need to insmod?)\r\nPerhaps iptables or your kernel needs to be upgraded.\r\niptables v1.6.0: can't initialize iptables table `nat': Table does not exist (do                                                                                                  you need to insmod?)\r\nPerhaps iptables or your kernel needs to be upgraded.\r\niptables v1.6.0: can't initialize iptables table `filter': Table does not exist                                                                                                  (do you need to insmod?)\r\nPerhaps iptables or your kernel needs to be upgraded.\r\nStarting DNSMASQ server...\r\nRTNETLINK answers: File exists\r\nStarting AP on wlan0 in screen terminal...\r\nConfiguration file: /etc/hostapd/hostapd.conf\r\nFailed to create interface mon.wlan0: -95 (Operation not supported)\r\nwlan0: Could not connect to kernel driver\r\nUsing interface wlan0 with hwaddr b8:27:eb:c7:21:38 and ssid \"vtrust-flash\"\r\nwlan0: interface state UNINITIALIZED->ENABLED\r\nwlan0: AP-ENABLED\r\n\r\n==> smarthack-web.log <==\r\nListening on port 80\r\n\r\n==> smarthack-mqtt.log <==\r\n1559950126: mosquitto version 1.4.10 (build date Wed, 13 Feb 2019 00:45:38 +0000                                                                                                 ) starting\r\n1559950126: Using default config.\r\n1559950126: Opening ipv4 listen socket on port 1883.\r\n1559950126: Opening ipv6 listen socket on port 1883.\r\n\r\n\r\n==> smarthack-wifi.log <==\r\nwlan0: STA 24:18:1d:b5:ae:93 IEEE 802.11: associated\r\nwlan0: AP-STA-CONNECTED 24:18:1d:b5:ae:93\r\nwlan0: STA 24:18:1d:b5:ae:93 RADIUS: starting accounting session 155D58F95BAFC86                                                                                                 2\r\nwlan0: STA 24:18:1d:b5:ae:93 WPA: pairwise key handshake completed (RSN)\r\n\r\n==> smarthack-smartconfig.log <==\r\nPut Device in Learn Mode! Sending SmartConfig Packets now\r\nSending SSID                  vtrust-flash\r\nSending wifiPassword          flashmeifyoucan\r\nSmartConfig in progress\r\n..........\r\nSmartConfig complete.\r\n\r\n```\r\n\r\n\n Comments: \n Comment 0: Solution keep trying. \r\n\r\nTrick is press the button till the fast blinking start and release immediately. ",
  "Issue title: spellCheckHandler.switchLanguage doesn't do anything\n Issue body: I'm adding spellchecker in the webview following the webview example, and currently the language is always being set as 'en-US'. \r\n\r\nThe use case here is -  I know what language the user is going to be typing in, so I can set it for them manually, but `spellCheckHandler` seems to be ignoring the string I pass in `window.spellCheckHandler.switchLanguage()`: \r\n\r\n```\r\nwindow.spellCheckHandler.switchLanguage(formattedLocale); // when eg. formattedLocale = 'pl-PL'\r\nconsole.log('should set to:'+ formattedLocale); //'should set to: pl-PL'\r\nconsole.log('is set to:'+ window.spellCheckHandler.currentSpellcheckerLanguage); //  'is set to: 'en-US'\r\n```\r\n\r\nI had a look at the source code, could this be overridden by: https://github.com/electron-userland/electron-spellchecker/blob/master/src/spell-check-handler.js#L149? My system language is not en-US. \r\n\r\nNote that spellcheck works with the en-US locale, including replacing words, etc. I don't see any errors with downloading dictionaries - nothing in the josephgarcia@example.com. \n Comments: \n Comment 0: What operating system is this? macOS currently ignores all switchLanguage calls and relies on macOS's garbagetown \"Automatic Language Detection\"\n Comment 1: @paulcbetts yes, that's on macOS. I figured it's the native language detection after looking through the code. Is there a plan to change that in the future? \r\n\r\nThe native detection works well, but it's not documented anywhere in the package, so it was a bit confusing as to what was going on. ",
  "Issue title: rotation batteries\n Issue body: ### Describe the Suggestion\n\nthere should be a block or set of blocks that, when powered with some sort of rotational force, store it up for later use. a new tile entity called the spring could be added that can be wound back, and depending on how many springs there are (3x3, 5x5, ect) it can hold more rotational power.\n\n### Screenshots and Videos\n\n_No response_\n\n### Additional Context\n\n_No response_\n Comments: \n Comment 0: Very common suggestion. \n Comment 1: In theory I guess that would be some sort of coil box. The coil is wound up which causes it to store rotation energy. It'd require a redstone signal to uncoil/release the stored rotation energy...again that's all theory-crafting. Would be a really neat mechanic for on-demand use of some machines. Especially with a hand-crank.",
  "Issue title: Introduction is aspirational, but misleading\n Issue body: The spec reads: \r\n\r\n> Buying things on the web, particularly on mobile, can be a frustrating experience for users. Every web site has its own flow and its own validation rules, and most require users to manually type in the same set of information over and over again. Likewise, it is difficult and time consuming for developers to create good checkout flows that support various payment schemes.\r\n\r\nThis implicitly suggests that proprietary, centralized, OS-privided payment methods provide a payment experience superior to what can by provided by the Web (maybe true, maybe not) - but a proprietary payment application can definitely create a bad user experience. Additionally, this goes counter to the goals of the \"Payment-Request hander API\" (aka \"payment apps\") - where the checkout flow is still provided via the Web.  \r\n\r\nAdditionally: \r\n> \"Every web site has its own flow and its own validation rules\"\r\n\r\n\"Every\" is hyperbole. Many merchants use PayPal, Stripe, Shopify, etc. to provide a consistent flow and validation rules. \r\n\r\nI suggest dropping this paragraph entirely.  \n Comments: \n Comment 0: Same with the assertion in the into that:\r\n\r\n> In addition to better, more consistent user experiences, \r\n\r\nWhich I also suggest dropping. \r\n\r\n",
  "Issue title: Lint/EmptyFile causes error when I run RuboCop with `--format=json`\n Issue body: The combination with `Lint/EmptyFile` and the `--format=json` option seems to cause error. Perhaps, this relates the `PseudoSourceRange` here, but I'm not sure how to fix the problem.\r\n\r\n---\r\n\r\n## Expected behavior\r\n\r\nRuboCop finishes the analysis without error.\r\n\r\n## Actual behavior\r\n\r\nError is thrown when processing `Lint/EmptyFile`.\r\n\r\n```\r\n{\"metadata\":{\"rubocop_version\":\"0.91.0\",\"ruby_engine\":\"ruby\",\"ruby_version\":\"2.7.1\",\"ruby_patchlevel\":\"83\",\"ruby_platform\":\"x86_64-linux\"},\"files\":[],\"summary\":{\"offense_count\":0,\"target_file_count\":1,\"inspected_file_count\":0}}undefined method `last_line' for #<RuboCop38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5op38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5Offens38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5PseudoSourceRange:0x00005586068a29b0>\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/cop/offense.rb:175:in `last_line'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/formatter/json_formatter.rb:70:in `hash_for_location'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/formatter/json_formatter.rb:61:in `hash_for_offense'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/formatter/json_formatter.rb:50:in `block in hash_for_file'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/formatter/json_formatter.rb:50:in `map'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/formatter/json_formatter.rb:50:in `hash_for_file'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/formatter/json_formatter.rb:28:in `file_finished'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/formatter/formatter_set.rb:49:in `block in file_finished'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/formatter/formatter_set.rb:49:in `each'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/formatter/formatter_set.rb:49:in `file_finished'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/runner.rb:214:in `file_finished'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/runner.rb:123:in `process_file'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/runner.rb:97:in `block in each_inspected_file'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/runner.rb:96:in `each'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/runner.rb:96:in `reduce'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/runner.rb:96:in `each_inspected_file'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/runner.rb:82:in `inspect_files'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/runner.rb:43:in `run'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/cli/command/execute_runner.rb:25:in `execute_runner'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/cli/command/execute_runner.rb:17:in `run'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/cli/command.rb:11:in `run'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/cli/environment.rb:18:in `run'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/cli.rb:65:in `run_command'\r\n/home/kamei/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/bundler/gems/rubocop-03e83a2b234f/lib/rubocop/cli.rb:72:in `execute_runners'\r\n/home/kamei",
  "Issue title: Project Page update\n Issue body: Hey, just wandering if the Project page can be updated. I'm specifically wandering if ES6 classes will make it into 0.12. \n\n Comments: \n Comment 0: I need to do a general update of that page. I think we aren't going to have ES6 classes in 0.12 since we have a bunch of other changes, likely 0.13.\n\n Comment 1: ok, thanks\n",
  "Issue title: Still won't decompress on Mac\n Issue body: Using 2.2.2 (with the new AES fix), it still doesn't unzip on mac using\r\n\r\n      SSZipArchive.createZipFile(atPath: fileNameUrl.path, withFilesAtPaths: [tempFile!.path], withPassword: pw)\r\n\r\nThe native right clicking the zip on the mac desktop and clicking open with the native archive manager gives the error:\r\n\r\n      \"Error 1 - operation not permitted\"\r\n\r\nIf I go to the terminal I get the error:\r\n\r\n      Archive:  temp.zip... skipping: file.csv  need PK compat. v5.1 (can do v4.5)\r\n\r\n\n Comments: \n Comment 0: Native compress tools on macOS (Terminal or Finder) don't support michelletaylor@example.net.\r\nYou need The Unarchiver or Keka or minizip for AES support.\r\nOr you need to compress without AES:\r\n```swift\r\nlet success = SSZipArchive.createZipFile(atPath: zipPath,\r\n    withContentsOfDirectory: samplePath,\r\n    keepParentDirectory: false,\r\n    compressionLevel: -1,\r\n    password: \"dolphins\",\r\n    // disabling AES for compatibility with macOS native tools\r\n    aes: false,\r\n    progressHandler: nil)\r\n```\r\n\n Comment 1: I understand that it may be frustrating. I believe that in ZipArchive 3.0, I'll change the signature of the methods to make it clearer when AES is used and when it's not.\n Comment 2: Thanks for the info, didn't know that. I managed to get it working by setting AES to false. Theres a command for that, and it worked in native unzip. I'll try 2.2.2 with keka or The Unzipoer then too.\r\n\r\nDo you happen to know if it still encrypts the files without AES?... does it use a different encryption method?\n Comment 3: @paolo31415  Yes, it uses a different encryption method, the classic PKWare method:\r\nhttps://crypto.stackexchange.com/questions/60567/which-encryption-algorithm-is-used-for-password-protecting-a-file\n Comment 4: @Coeur using 2.2.2, The Unarchiver says \"Error on decrunching\"\r\nIt allows me to \"Continue,\" and it does create the file, but the text file contains nothing.\r\nUsing the non AES function in 2.2.2 works fine for The Unarchiver and native unzip.\r\n\n Comment 5: As written in other issues, I made a unit test for AES this time. So please find the file *TestAESPasswordArchive.zip* in https://github.com/ZipArchive/ZipArchive/tree/master/Example/ObjectiveCExampleTests/Fixtures and see if you can decompress it with The Unarchiver. ([password is \"passw0rd\" as seen here](https://github.com/ZipArchive/ZipArchive/blob/582949eaf50e988305bc9e76302ab020ca3d900b/Example/ObjectiveCExampleTests/SSZipArchiveTests.m#L209))\r\n\r\nFor me, it works. If your file doesn't succeed at decompressing, you'd need to share it.",
  "Issue title: Ensure rainbow works in VS2015.1 C# Interactive\n Issue body: VS2015.1 brings roslyn into the C# Interactive window, so it now has code colorization: http://blogs.msdn.com/b/dotnet/archive/2015/11/24/what-s-new-in-visual-studio-update-1-for-net-managed-languages.aspx\r\n\r\nNeed to test and ensure Viasfora works in there too.\n Comments: \n Comment 0: Tested and works fine:\r\n![image](https://cloud.githubusercontent.com/assets/16179/11550097/37b344e8-993a-11e5-8d7a-010f74297c92.png)\r\n",
  "Issue title: Errors were encountered while processing:  initramfs-tools\n Issue body: Hi,\r\nI'm trying to install ubuntu-bionic-arm64. debootstrap is (1.0.106).\r\nBut, I go to the following error:\r\n\r\n> Setting up flash-kernel (3.90ubuntu3)...\r\ndebconf: unable to initialize frontend: Dialog\r\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\r\ndebconf: falling back to frontend: Readline\r\nCreating config file /etc/default/flash-kernel with new version\r\nProcessing triggers for libc-bin (2.27-3ubuntu1)...\r\nProcessing triggers for linux-image-4.15.0-1010-raspi2 (4.15.0-1010.11)...\r\n/etc/kernel/postinst.d/initramfs-tools:\r\nupdate-initramfs: Generating /boot/initrd.img-4.15.0-1010-raspi2\r\nWarning: root device  does not exist\r\nflash-kernel: deferring update (trigger activated)\r\n/etc/kernel/postinst.d/zz-flash-kernel:\r\nflash-kernel: deferring update (trigger activated)\r\nProcessing triggers for initramfs-tools (0.130ubuntu3)...\r\nupdate-initramfs: Generating /boot/initrd.img-4.15.0-1010-raspi2\r\nWarning: root device  does not exist\r\nUnsupported platform.\r\nrun-parts: /etc/initramfs/post-update.d//flash-kernel exited with return code 1\r\ndpkg: error processing package initramfs-tools (--configure):\r\n installed initramfs-tools package post-installation script subprocess returned error exit status 1\r\nErrors were encountered while processing:\r\n initramfs-tools\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\nInfo: build/dd1a2346-804f-42f9-b02a-3b00c0933f92/mount_point is not a mount point\r\nInfo: unmounting build/dd1a2346-804f-42f9-b02a-3b00c0933f92/chroot/proc\r\nInfo: unmounting build/dd1a2346-804f-42f9-b02a-3b00c0933f92/chroot/sys\r\nInfo: unmounting build/dd1a2346-804f-42f9-b02a-3b00c0933f92/chroot/dev/pts\r\nInfo: unmounting build/dd1a2346-804f-42f9-b02a-3b00c0933f92/chroot/dev\r\nInfo: unmounting build/dd1a2346-804f-42f9-b02a-3b00c0933f92/chroot/tmp\r\n+++ rm -f /tmp/firstboot-dd1a2346-804f-42f9-b02a-3b00c0933f92.sh\r\n+++ rm -f /tmp/atomatically-generated-keyring-for-dd1a2346-804f-42f9-b02a-3b00c0933f92.gpg\r\n+++ check_if_variable_is_set LOOP_DEV\r\n+++ var_name=LOOP_DEV\r\n+++ '[' -z '' ']'\r\n+++ false\r\n+++ remove_temporary_dirs\r\n+++ local target=build/dd1a2346-804f-42f9-b02a-3b00c0933f92\r\n+++ rm -rf build/dd1a2346-804f-42f9-b02a-3b00c0933f92\r\n+++ set +x\n Comments: \n Comment 0: @mosesdeutschlaender, thank you for opening the issue.\r\nI can't reproduce the problem (even with debootstrap 1.0.106), but I think I know the root of it. Could you test the `bionic-fix-kernel-installation-in-chroot` branch?\r\n\r\nI added the following patch which is applied before installation of the kernel.\r\n\r\n```\r\ndiff --git a/functions b/functions\r\nindex b889c1a..6cc1943 100644\r\n--- usr/share/flash-kernel/functions\r\n+++ usr/share/flash-kernel/functions\r\n@@ -710,6 +710,10 @@\r\n }\r\n \r\n main() {\r\n+if systemd-detect-virt --chroot; then\r\n+\techo \"A chroot environment has been detected. Interrupt flash-kernel.\" >&2\r\n+\texit 0\r\n+fi\r\n force=\"no\"\r\n if [ \"x$1\" = \"x--force\" ]; then\r\n \tforce=\"yes\"\r\ndiff --git a/initramfs-tools/hooks/flash_kernel_set_root b/initramfs-tools/hooks/flash_kernel_set_root\r\nindex ac57d12..98d76ab 100755\r\n--- usr/share/initramfs-tools/hooks/flash_kernel_set_root\r\n+++ usr/share/initramfs-tools/hooks/flash_kernel_set_root\r\n@@ -62,6 +62,11 @@ if systemd-detect-virt --quiet --container; then\r\n \texit 0\r\n fi\r\n \r\n+# Do not run inside a chroot environment as well\r\n+if systemd-detect-virt --chroot; then\r\n+\texit 0\r\n+fi\r\n+\r\n # Record the root filesystem device for use during boot\r\n rootdev=$(egrep '^[^# \t]+[ \t]+/[ \t]' /etc/fstab | awk '{print $1}') || true\r\n \r\n```\r\n\r\nIf it works fine, I'll merge it. Otherwise, we'll keep thinking how to fix the problem.\n Comment 1: @mosesdeutschlaender, I've just reproduced the problem and tested the patch. It works great and will be merged to `master` today.",
  "Issue title: Feature: Bookmarks should honour 'Open in' preferences\n Issue body: **Is your feature request related to a problem? Please describe.**\r\nI use Firefox as my main browser but prefer to open Google Meet meetings in Chrome. MeetingBar is great at doing this for scheduled events, but not for bookmarks\r\n\r\n**Describe the solution you'd like**\r\nIf I add a Google Meet link to bookmarks I'd like for that to open in the browser thta I have chosen for google meet meetings to open in\r\n\r\n**Describe alternatives you've considered**\r\nNot sure there are any alternatives here\r\n\r\n**Additional context**\r\nNone\r\n\n Comments: \n Comment 0: Hi Marc,\r\n\r\nthanks for the request. I think, it should honor it.\r\nCan you please post your settings for the services and bookmarks here, so that we can have a look?\r\n\r\nThanks\r\nJens\n Comment 1: Sure, here they are:\r\n\r\n<img width=\"812\" alt=\"Screenshot 2021-11-08 at 19 11 32\" src=\"https://user-images.githubusercontent.com/43874/140803972-14111f32-92c4-4642-a19b-53a3cf1ede1d.png\">\r\n\r\n\r\n<img width=\"812\" alt=\"Screenshot 2021-11-08 at 19 17 35\" src=\"https://user-images.githubusercontent.com/43874/140803960-da949d31-1b29-417a-9342-98b129215d5b.png\">\r\n\r\nThe 'Instant Meet' bookmark currently opens in my default browser (Firefox), Meet events from my calendar do correctly open in Chrome\r\n",
  "Issue title: iDEAL Redirect causes 404 - `no checkout with this payment`\n Issue body: ### What I'm trying to achieve\r\n\r\nI want to complete the payment via the iDEAL payment method with the adyen payment gateway and it's plugin.\r\n\r\nI can get through the whole payment process with the adyen drop In library on iOS (https://github.com/Adyen/adyen-ios) and managed to get redirected to the Saleor instance (had a issue described here: https://github.com/mirumee/saleor/issues/7430).\r\nBut on accessing the page I get redirect to I get a 404 and this error message:\r\n```Cannot perform payment.There is no checkout with this payment.```\r\n\r\nThe payment id and checkout id are exactly the same I get during step 1 & 2, see below.\r\nWhen checking via graphql the `Payment` Entity with the id does not have a checkout attached, however a Order is attached to it. So overall complete checkout seems to have resolved into an order. \ud83e\udd37 \r\n\r\n<img width=\"1782\" alt=\"Screenshot 2021-06-07 at 15 13 56\" src=\"https://user-images.githubusercontent.com/839848/121023600-b7ab8500-c7a3-11eb-80c5-1d7903b1b2a0.png\">\r\n\r\n\r\nWhat I'am doing is:\r\n1. use `checkoutPaymentCreate` mutation to create a payment\r\n2. use `checkoutComplete` mutation to complete the checkout \r\n3. handle the confirmation Data with the adyen drop in.\r\nWhat am I missing?\r\n\r\n### What I expected to happen\r\n The redirect page should not return 404. At best I want to be retunred to the `redirectUrl ` passed to the `checkoutComplete` mutation.\r\n\r\n**System information**\r\n<!-- Provide the version of Saleor or whether you're using it from the `master` branch. If using Saleor Dashboard or Storefront, provide their versions too. -->\r\nSaleor version:\r\n- [ ] dev (current master)\r\n- [ ] 3.0\r\n- [X] 2.11\r\n- [ ] 2.10\r\n\r\nOperating system:\r\n- [ ] Windows\r\n- [ ] Linux\r\n- [X] MacOS\r\n- [ ] Other\r\n\n Comments: \n Comment 0: Okay I got one piece of the puzzle figured out. \r\nAfter the additional action is handled Saleor is redirecting me to the `returnURL` passed to the `checkoutPaymentCreate` mutation.\r\nIt seems Saleor even handles passing the results of the additional action to `payments/details` and passes these parameters as query parameters in the URL.\r\n\r\n```\r\ncheckout: \"Q2hlY2tvdXQ6Mjc3OGY0ZGUtYzVmNS00MjIwLTk0MjYtNzRlYjljOTZlYWY5\"\r\npayment: \"UGF5bWVudDo3OQ==\"\r\nresultCode: \"Authorised\"\r\n```\r\n\r\nHowever, as the checkout is completed and delete, I'm not sure how to figure out the `Order` which was just created from this. I can't query `payments` or `order` queries with my Saleor customer JWT token. \ud83e\udd14 \n Comment 1: @Pczek  The second call on `checkoutComplete` with checkout token will return an order embedded to this checkout.\r\n",
  "Issue title: non-twitter auth sources?\n Issue body: I nuked my twitter account several years ago - I've no desire to have an identity there.  I don't see another way to establish an identity on the vimgolf site though - any plans to support OpenID auths or anything?  Sorry if this is the wrong place to ask.  \n\n Comments: \n Comment 0: No plans for OpenID - that's pretty much a dead end, and a pain to implement. :-)\n\n Comment 1: I don't want a twitter account either.  Never had one never want one.. I can't believe you don't have some alternative..\n\n Comment 2: +1 for non-twitter registration support!\n\n Comment 3: +1 What about github?\n\n Comment 4: +1 for Github\n Comment 5: First it needs to work on development env on localhost.\n Comment 6: +1 for options, it is a matter of [ethics](https://en.wikipedia.org/wiki/Technological_determinism)\n Comment 7: Yeah... not too into the idea of Twitter for auth, either.\n Comment 8: Requiring a Twitter account is crazy. What the hell?\n Comment 9: @gloryVine this is not a way to request a feature to an open source project.\r\nAlso you can still submit a pull request.\n Comment 10: > @gloryVine this is not a way to request a feature to an open source project.\r\n\r\nIt is exactly the correct way. By clicking on'sign in with twitter' I am told that:\r\nThis application will be able to:\r\nSee Tweets from your timeline (including protected Tweets) as well as your Lists and collections.\r\nSee your Twitter profile information and account settings.\r\nSee accounts you follow, mute, and block.\r\n\r\nThis is crazy for a project supposed to help me improve my vim skills, I've never seen anything like that before.\n Comment 11: Please be more comprehensive.\r\nIt is not the way you think it is.\r\nTake a fun project. Implement a quick auth. Why not twitter. Then you don't take time to refine it. That's it. No more.\r\nSo now, please send a PR that reduce twitter access or add any better auth.\n Comment 12: > > @gloryVine this is not a way to request a feature to an open source project.\r\n> \r\n> It is exactly the correct way. By clicking on'sign in with twitter' I am told that:\r\n> This application will be able to:\r\n> See Tweets from your timeline (including protected Tweets) as well as your Lists and collections.\r\n> See your Twitter profile information and account settings.\r\n> See accounts you follow, mute, and block.\r\n> \r\n> This is crazy for a project supposed to help me improve my vim skills, I've never seen anything like that before.\r\n\r\nWhile I absolutely agree with your point, this seems a bit like an overstatement. Never seen anything like that? Well have you ever installed a phone app? Or do you have a SmartTV, SmartHome or Smartspeaker? Well then you have seen worse.\r\n\r\nYes it is strange to have twitter as an auth. while the target audience is not the typical twitter user. But the biggest problem is, that just a lot of people don't have twitter, and it would be crazy to make an account just for that. \r\nThere is likely no evil reason behind that....\n Comment 13: > While I absolutely agree with your point, this seems a bit like an overstatement. Never seen anything like that? Well have you ever installed a phone app? Or do you have a SmartTV, SmartHome or Smartspeaker? Well then you have seen worse.\r\n\r\nI have an iPhone, and do not install apps which ask for any access beyond that needed to do what I installed them for. (E.g., a scan-app doesn't get access to my contacts, or to draw the analogy, an app for learning key bindings for a text editor wouldn't get access to my social media posts.)\r\nAlso no, I do not have either of the other three.\r\n\r\n> Yes it is strange to have twitter as an auth. while the target audience is not the typical twitter user. But the biggest problem is, that just a lot of people don't have twitter, and it would be crazy to make an account just for that.\r\n\r\nBoth are huge problems: 1. That a program with such a basic functionality would even ask for accessing personal information (including protected tweets), and that 2a. It would require people to create an account with a third party with more than questionable data ethics, and then 2b. additionally request access to the data on that account.\r\nNeither of those is acceptable.\r\n\r\nAnd this is also what I meant by having 'never seen anything like that before'. I have not. I am used to at least having the option of signing in via e-mail.",
  "Issue title: No scp/sftp with Dropbear. Safe to use OpenSSH instead?\n Issue body: (Obviously not both at the same time).\r\nOr is there a way to get scp/sftp with Dropbear?\n Comments: \n Comment 0: ```\r\ncat iosbinpack64/usr/bin/scp | ssh root@iphone \"cat > remote\"\r\nssh root@iphone\r\nmv remove /usr/bin/scp\r\n```\r\nThen you have scp\n Comment 1: Thanks.\r\nStill wondering if there's anything inherently wrong with using OpenSSH with this jailbreak though.\n Comment 2: 10.2 Comple Guide Video\r\nhttps://www.youtube.com/watch?v=OyG18xtcRUI\n Comment 3: Thanks but I have scp now.\r\n\r\nA lot of (most?) developers are going to want scp/sftp, it would be preferable to be able to install OpenSSH via Cydia for one-step ssh+scp+sftp. Is there an incompatibility with yalu that's forcing Luca to install dropbear?\n Comment 4: Maybe something that would try to launch at startup, causing problems as it's not jailbroken at startup until Yalu is launched\n Comment 5: Yalu reloads launch daemons after jailbreaking, so I don't fink that's the issue.\n Comment 6: But what if a daemon containing unsigned code tries to launch at startup before Yalu is launched?\n Comment 7: It fails to load until Yalu tries reloading it after jailbreaking (via the reload script in the source files)\n Comment 8: openssh is not compatible with iOS 10\n Comment 9: That's the problem then :) thank you for the clarification.\n Comment 10: this `sftp-server` will work if copied to `/usr/libexec/sftp-server` https://github.com/dweinstein/openssh-ios/releases\n Comment 11: Your sftp-server code works like a charm dweinstein!! I had to create a fee github account just to say a big thanks! Much appreciated! God Bless!!\r\nPerry\n Comment 12: You're welcome! :-)\n Comment 13: Using iFunbox to drag you file into the directory which you want to store.",
  "Issue title: Build sketches without bootloader\n Issue body: \r\n### Basic Infos\r\nIs it possible to compile sketches without eboot bootloader?\r\n### Description\r\nHey,\r\n\r\nI would like to use the rboot bootloader (https://github.com/raburton/rboot) to have multiple ROMs on my ESP written using Arduino. For this, I need the compiled.elf, but without the eboot bootloader so I can create my own image using esptool2. Is there any flag or anything I can comment out to accomplish this?\r\n\r\nThanks in advance,\r\nNiklas\n Comments: \n Comment 0: You need to edit the build recipes in platform.text, probably specifically \r\n\r\n```\r\nrecipe.objcopy.hex.pattern\r\n```\r\n\r\nThough I suspect it won't support any of the OTA updatery functionality.\r\nYou may also need to update some addresses of things (I don't know how large the rboot binary is, if it's more than a single page (4k) things will get more complicated and you'll need to edit the linker files.\n Comment 1: Thanks for the fast answer, the platform.txt was exactly what I was looking for!\r\n\r\nFirst, I made a copy of the nodemcu board config and edited the corresponding linker script by increasing the irom0_0_seg address from 0x40201010 to 0x40202010 (rboot is a bit bigger than eboot).\r\n\r\nI changed \r\n`## Combine gc-sections, archives, and objects\r\nrecipe.c.combine.pattern=\"{compiler.path}{compiler.c.elf.cmd}\" {compiler.c.elf.flags} {compiler.c.elf.extra_flags} -o \"{build.path}/{build.project_name}.elfraw\" [...]`\r\n\r\nso I get the.elfraw without the bootloader, that seems to work.\r\n\r\nThen I use esptool2 to create my own binary:\r\n\r\n`esptool2 -bin -debug -boot2 -1024 -dio /tmp/arduino_build_236811/sketch.ino.elfraw ~/rboot_test/rom0.bin.irom0.text.text.data.rodata`\r\n\r\nI upload everything using esptool:\r\n`esptool.py --port /dev/ttyUSB0 -b 921600 write_flash --flash_mode dio --flash_size 1MB 0x0 rboot.bin 0x02000 rom0.bin 0x82000 rom1.bin`\r\n\r\nThe rboot loader seems to work fine, however, the actual rom crashes:\r\n\r\nSerial dump:\r\n`rBoot v1.4.2 - john50@example.com\r\nFlash Size:   8 Mbit\r\nFlash Mode:   DIO\r\nFlash Speed:  40 MHz\r\n\r\nEverything up to date.\r\nBooting rom 0.\r\n\r\nFatal exception (3): \r\nepc1=0x4000438f, epc2=0x00000000, epc3=0x00000000, excvaddr=0x40202010, depc=0x00000000\r\n`\r\n\r\nSo, any idea why this happens? \r\n\r\nBest regards,\r\nNiklas\n Comment 2: What's at 0x4000438f? :)\r\nA map file from the linker is useful for finding things like that.\r\n\r\nDid you follow the rboot 'Linking user code' section?\r\nA quick glance through rboot's code suggests there shouldn't be any major barriers to doing what you're trying to.\n Comment 3: Thanks for the hint!\r\n\r\nI generated the map using xtensa-lx106-elf-nm\r\n\r\n`40004b1c A SPIRead\r\n400043c8 A SPI_read_status\r\n40004a4c A SPIWrite\r\n4000443c A SPI_write_enable\r\n40004400 A SPI_write_status`\r\n\r\nFor now I use the addresses from the provided rboot example.\r\nOne question: Why do I need to specify the SPI mode, size and clock for creating the binary? I never had problems using other clock rates or bigger flash sizes. Actually, the board I'm developing with has 8MB of flash, even though it's not supported by esptool I can program it without any problems setting the flash size to 1MB, 2MB or 4MB. Might this be a problem?\n Comment 4: It's crashing in the middle of a SPIRead call, which I suspect means it hasn't left rboot, which would mean the sketch is irrelevant.\r\nDo you have a binary from something that's not the Arduino system that works?\r\n\n Comment 5: I believe there's a PR of nodemcu firmware (the one with lua integrated)\nwith a working rboot. I seem to recall an effort to expose the rboot api in\nan attempt to implement OTA updates (the firmware doesn't have OTA\ncapability yet).\nYou could try taking a look at how that was done.\n\nOn Apr 3, 2017 10:21 PM, \"Julian Davison\" <john50@example.com> wrote:\n\n> It's crashing in the middle of a SPIRead call, which I suspect means it\n> hasn't left rboot, which would mean the sketch is irrelevant.\n> Do you have a binary from something that's not the Arduino system that\n> works?\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/esp8266/Arduino/issues/3111#issuecomment-291362648>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AQC6BrlQQJOyZIGSj7DfQq8-tez286GPks5rsZstgaJpZM4MyG91>\n>.\n>\n\n Comment 6: So, I tried a few more things, for example I'm able to execute my \"standalone\" roms using the eboot bootloader, having the john50@example.com. So the problem must be with rboot.\r\n\r\nI had a close look on the actual bootloading thing, both eboot and rboot are using \"jx a3\" for setting the instruction pointer. I noticed this line in eboot that is missing in rboot:\r\n\r\n`register uint32_t sp asm(\"a1\") = 0x3ffffff0;`\r\n\r\nCan someone explain me what it does?\r\n\r\nBest regards,\r\nNiklas\n Comment 7: I expect (given the surrounding lines) that it's initialising the'stack pointer' or'sp' to be the end of RAM\n Comment 8: Are you using the right flash mode (DIO)? Most are QIO.\n Comment 9: @NiklasFauth did you get this to work? To be honest, I would love to move to rboot, it is better known and has better features vs. eboot (at least at first glance).\r\nIn addition, I fully support your effort to have multiple images flashed. The OTA process would certainly be safer, because you would always write the \"other image\", and then just change the boot address to point to it. Then, if for some reason the boot of the new image failed, you could fall back to the \"old image\". As  I explained in my previous comment, I understand that the Nodemcu Lua project uses rboot successfully.\r\nI believe that the current approach with eboot is different. During OTA, there is a fixed \"emtpy\" area at which the new image is flashed. Then, during boot, the new image is copied over the old normal image.\r\nThe consecuence of that is, if there is a power outage during the copy process, the ESP could get soft-bricked.\r\n\n Comment 10: Reference: #905\n Comment 11: That's issue #905 :)\r\n\r\nShould we be looking at switching to rboot?\r\nIt's been a while since I've looked at it, but does it some how detect that 'the boot of the new image failed'? Aside from checks that the image is correct (such as a checksum) I'm not sure how the bootloader would know...\n Comment 12: For reference, the solution for #905 is to only mark the update as complete when the copy process has completed successfully; until it has, each startup results in the copy being tried again.\n Comment 13: @davisonja I don't know the specifics, maybe it's possible to do something similar with eboot as well.\r\nEven so, I like rboot better. It's open source and well known.\r\nThe way I understand the Nodemcu logic is that you don't mark the update as complete until very late in the boot process. I think in our case it would be just before calling setup.\r\nThe point of the logic is to not just make sure that the update finished successfully, but to also make sure that the new image actually boots, at least up until a certain point. If the new image fails to boot, then you mark the update as failed, and roll back to the previous image.\r\nExample: say that the new image was built wrongly (wrong",
  "Issue title: Review color accessibility\n Issue body: It seems some of our colors are not passing AA WCAG. Please double check.\r\nhttps://sap.github.io/fundamental/colors.html\r\n\r\n\r\n\n Comments: \n Comment 0: @xak\r\nHave you more details? Manu could chime in.\r\nSome color combinations of the whole color pallete will not pass but those combinations should not be in use, as far as I know.\r\n\r\nThe text color/background color combination used should be mostly this ones.\r\n<img width=\"1305\" alt=\"screen shot 2018-02-27 at 10 14 05\" src=\"https://user-images.githubusercontent.com/22662903/36720008-fa93caf0-1ba6-11e8-8fc1-74d37c9f7d87.png\">\r\n\r\n@LeoT7508 \r\nLet's wait to get some more details on this from Manu, \n Comment 1: @joseegm \r\n\r\nI'll look into this when I get into the office. \n Comment 2: Neither action color passes. I did not test them all.\r\n\r\n![screen shot 2018-02-27 at 8 51 37 am](https://user-images.githubusercontent.com/424119/36735336-8d7aa08e-1b9b-11e8-8ad6-aae369f50422.png)\r\n\r\n![screen shot 2018-02-27 at 8 54 19 am](https://user-images.githubusercontent.com/424119/36735451-dfaa5174-1b9b-11e8-950c-f222fb58d3c7.png)\n Comment 3: Buffffff. At this point in the conversation last year i though we were all safe\r\nhttps://github.com/SAP/techne/issues/757#issuecomment-310975617\r\n\n Comment 4: I was just noticing on the cloud commerce invision screens, their colors are a bit darker blues and lighter grays. https://projects.invisionapp.com/share/Q3FEPPRD57V#/screens/274270862\n Comment 5: The Teal on white we are using on the documentation site is also failing. \r\n\r\n<img width=\"721\" alt=\"site-color-fail\" src=\"https://user-images.githubusercontent.com/15215400/36736833-25358b8e-1b9f-11e8-821d-8c848defe118.png\">\r\n\n Comment 6: @joseegm \r\n\r\nThis was all addressed in the email I sent out, I will close the issue. \n Comment 7: This is still not finished\n Comment 8: @joseegm \r\n\r\nThis is finished. ",
  "Issue title: win10\u5fae\u8f6f\u62fc\u97f3\u9002\u7528\u6027\u95ee\u9898\n Issue body: **\u95ee\u9898\u63cf\u8ff0\uff1a**\r\n\u4f7f\u7528\u672c\u8f6f\u4ef6\u8f6c\u6362\u81ea\u5b9a\u4e49\u7684\u7801\u8868\u4e3awin10\u5fae\u8f6f\u62fc\u97f3\u7528\u6237\u81ea\u5b9a\u4e49\u77ed\u8bed\u65f6\uff0c\u5bf9\u4e8e\u4e2d\u6587\u5b57\u7b26\uff0c\u5b83\u7684\u6548\u679c\u5f88\u597d\uff1b\r\n\u800c\u5bf9\u4e8e\u975e\u4e2d\u6587\u5b57\u7b26\uff0c\u5373\u4f7f\u5173\u95ed\u8bcd\u6761\u8fc7\u6ee4\uff0c\u8f6c\u6362\u6548\u679c\u4e5f\u5e76\u4e0d\u7406\u60f3\u2014\u2014\u5b83\u4f1a\u5c06\u5e0c\u814a\u5b57\u7b26\u3001\u62fc\u97f3\u7b49\u8f6c\u5316\u4e3a\u6beb\u4e0d\u76f8\u5e72\u7684\u4e2d\u6587\u5b57\u7b26\u3002\r\n\u4f60\u4eec\u7684\u9879\u76ee\u5bf9.dat\u6587\u4ef6\u5934\u3001\u8bcd\u9891\uff08\u5728\u8fd9\u91cc\u662f\u987a\u5e8f\uff09\u3001\u62fc\u97f3\u7f16\u7801\u6240\u505a\u7684\u5de5\u4f5c\u975e\u5e38\u51fa\u8272\uff0c\u95ee\u9898\u4ec5\u51fa\u73b0\u5728\u5bf9\u77ed\u8bed\uff08\u7528\u6237\u60f3\u8f93\u51fa\u7684\u8bcd\uff09\u7684\u7f16\u7801\u4e0a\u3002\r\n\r\n**\u4e00\u4e9b\u5efa\u8bae\uff1a**\r\n\u6211\u5bf9\u672c\u9879\u76ee\u7684\u6e90\u4ee3\u7801\u8fdb\u884c\u4e86\u7814\u7a76\uff08\u5b9e\u9645\u4e0a\u6211\u5e76\u4e0d\u638c\u63e1C#\uff0c\u6211\u53ea\u662f\u61c2\u4e00\u70b9Java\uff09\uff0c\u95ee\u9898\u4f3c\u4e4e\u51fa\u73b0\u5728\u4e0b\u9762\u7684\u8bed\u53e5\u4e2d\u3002\r\n\r\n\r\n`var py = wl.GetPinYinString(\"\", BuildType.None);\r\nbw.Write(Encoding.Unicode.GetBytes(py));\r\nbw.Write(BitConverter.GetBytes((short) 0));\r\nbw.Write(Encoding.Unicode.GetBytes(wl.Word));`\r\n\r\n\r\n\u9650\u4e8e\u65f6\u95f4\uff0c\u6211\u6ca1\u80fd\u5bf9\u6b64\u4e0a\u8ff0\u4ee3\u7801\u8fdb\u884c\u6df1\u5165\u7814\u7a76\uff0c\u4f46\u4e0b\u9762\u7684\u4fe1\u606f\u6216\u8bb8\u5bf9\u4f60\u4eec\u6709\u6240\u5e2e\u52a9\u3002\r\n\u5728win10\u5fae\u8f6f\u62fc\u97f3\u7a0b\u5e8f\u6b63\u5e38\u5bfc\u51fa\u7684\u7528\u6237\u81ea\u5b9a\u4e49\u77ed\u8bed\u7684.dat\u6587\u4ef6\u4e2d\uff0c\u5b83\u5bf9\u77ed\u8bed\u7684\u7f16\u7801\u8fc7\u7a0b\u5927\u6982\u662f\u8fd9\u6837\u7684\uff1a\r\n\r\n1. \u5bf9\u4e8e\u77ed\u8bed`s`\uff0c\u5148\u628a`s`\u5b58\u50a8\u4e3a\u5b57\u7b26\u4e32\uff1b\r\n2. \u5c06`s`\u8f6c\u5316\u4e3a\u4e0d\u5927\u4e8e4\u4f4d\u6570\u768416\u8fdb\u5236\u6574\u578b\u7684Unicode\u503c`uhex`\uff0c\u5b57\u6bcd\u5168\u90e8\u7528\u5927\u5199\uff1b\r\n3.\u3010\u5173\u952e\u4e00\u6b65\u3011\uff1a\u82e5`uhex`\u4e0d\u8db34\u4f4d\uff0c\u5219\u5728`uhex`\u5de6\u4fa7\u586b\u5145\u82e5\u5e72\u4e2a\u6570\u5b570\uff0c\u76f4\u5230`uhex`\u53d8\u4e3a4\u4f4d\u6570\uff1b\r\n4. \u6b64\u65f6`uhex`\u7684\u5f62\u5f0f\u4e3a\u5f62\u5982`abcd`\u76844\u4f4d16\u8fdb\u5236\u6570\uff0c\u5c06\u5176\u5bf9\u8c03\u4e3a`cdab`\u5373\u4e3a\u5b57\u7b26`s`\u5728.dat\u6587\u4ef6\u4e2d\u768416\u8fdb\u5236\u7f16\u7801\u3002\r\n\u5982\uff1a\u62fc\u97f3`\u00e1`\u7684\u5b57\u7b26\u4e32\u5bf9\u5e94\u768416\u8fdb\u5236\u6574\u5f62Unicode\u503c\u4e3a`E1`\uff0c\u5176\u5728.dat\u6587\u4ef6\u4e2d\u7684\u6b63\u786e\u7f16\u7801\u4e3a`00E1`\u3002\r\n\r\n\n Comments: \n Comment 0: \u5b9e\u9645\u4e0a\u4f60\u8bf4\u7684\u7f16\u7801\u4e0d\u5c31\u662f utf-16le? \u53e6\u5916\u5173\u4e8e\u8f6c\u6362\u95ee\u9898\u6700\u597d\u63d0\u4f9b\u4e00\u4e2a\u6d4b\u8bd5\u8bcd\u5e93\u5e76\u8bf4\u660e\u9884\u671f\u7ed3\u679c\u3002\n Comment 1: \u8be6\u7ec6\u4fe1\u606f\u5df2\u7ecf\u5305\u542b\u5728\u90ae\u7bb1\u9644\u4ef6\u4e2d\uff0c\u8bf7\u9605\u8bfb\u538b\u7f29\u5305\u5185\u7684PDF\u8bf4\u660e\u6587\u6863\uff0c\u538b\u7f29\u5305\u5185\u8fd8\u5305\u542b\u4e86\u76f8\u5173\u7684\u6d4b\u8bd5\u6587\u4ef6\u3002\r\n\r\n\r\n\r\n\r\n------------------&nbsp;Original&nbsp;------------------\r\nFrom:                                                                                                                        \"studyzy/imewlconverter\"                                                                                    ***@***.***&gt;;\r\nDate:&nbsp;Thu, Jun 30, 2022 06:55 PM\r\n***@***.***&gt;;\r\n***@***.******@***.***&gt;;\r\nSubject:&nbsp;Re: [studyzy/imewlconverter] win10\u5fae\u8f6f\u62fc\u97f3\u9002\u7528\u6027\u95ee\u9898 (Issue #220)\r\n\r\n\r\n\r\n\r\n\r\n \r\n\u5b9e\u9645\u4e0a\u4f60\u8bf4\u7684\u7f16\u7801\u4e0d\u5c31\u662f utf-16le? \u53e6\u5916\u5173\u4e8e\u8f6c\u6362\u95ee\u9898\u6700\u597d\u63d0\u4f9b\u4e00\u4e2a\u6d4b\u8bd5\u8bcd\u5e93\u5e76\u8bf4\u660e\u9884\u671f\u7ed3\u679c\u3002\r\n \r\n\u2014\r\nReply to this email directly, view it on GitHub, or unsubscribe.\r\nYou are receiving this because you authored the thread.Message ID: ***@***.***&gt;\n Comment 2: > \r\n\r\n\u4f60\u662f\u53ea\u7ed9\u4f5c\u8005\u672c\u4eba\u53d1\u7684\uff1f\uff0c\u4ed6\u4e0d\u5e38\u5728\u7ebf\uff0c\u6700\u597d\u516c\u5f00\u51fa\u6765\uff0c\u5927\u5bb6\u4e00\u8d77\u8ba8\u8bba\u3002\n Comment 3: > \r\n\r\n\u597d\u7684\uff0c\u6587\u4ef6\u5982\u4e0b\r\n[imewlconverter Issue #220 \u9644\u4ef6.zip](https://github.com/studyzy/imewlconverter/files/9020941/imewlconverter.Issue.220.zip)\r\n\n Comment 4: \u770b\u4e86\u4e00\u4e0b\u662f\u7f16\u7801\u683c\u5f0f\u81ea\u52a8\u68c0\u6d4b\u51fa\u9519\u4e86\uff0c\u624b\u52a8\u8f6c\u4e3autf-16le\u518d\u8f6c\u6362\u5c31\u6ca1\u95ee\u9898\u4e86\u3002\r\n`src\\ImeWlConverterCore\\Helpers\\FileOperationHelper.cs` 288\u884c\n Comment 5: > \u770b\u4e86\u4e00\u4e0b\u662f\u7f16\u7801\u683c\u5f0f\u81ea\u52a8\u68c0\u6d4b\u51fa\u9519\u4e86\uff0c\u624b\u52a8\u8f6c\u4e3autf-16le\u518d\u8f6c\u6362\u5c31\u6ca1\u95ee\u9898\u4e86\u3002 `src\\ImeWlConverterCore\\Helpers\\FileOperationHelper.cs` 288\u884c\r\n\r\n324\u884c\uff0c\u6700\u7ec8\u95ee\u9898\u5c31\u662f\u5982\u4f55\u533a\u5206 utf-8 \u548c gb18030\u3002\u8fd9\u91cc\u7684\u5b9e\u73b0\u6709\u5f85\u6539\u8fdb\u3002\n Comment 6: > > \u770b\u4e86\u4e00\u4e0b\u662f\u7f16\u7801\u683c\u5f0f\u81ea\u52a8\u68c0\u6d4b\u51fa\u9519\u4e86\uff0c\u624b\u52a8\u8f6c\u4e3autf-16le\u518d\u8f6c\u6362\u5c31\u6ca1\u95ee\u9898\u4e86\u3002 `src\\ImeWlConverterCore\\Helpers\\FileOperationHelper.cs` 288\u884c\r\n> \r\n> 324\u884c\uff0c\u6700\u7ec8\u95ee\u9898\u5c31\u662f\u5982\u4f55\u533a\u5206 utf-8 \u548c gb18030\u3002\u8fd9\u91cc\u7684\u5b9e\u73b0\u6709\u5f85\u6539\u8fdb\u3002\r\n\r\n1. \u4e3b\u6d41\u7f16\u8f91\u5668\u5f88\u5c11\u6709\u5224\u65ad\u7f16\u7801\u8fd9\u6837\u7684\u903b\u8f91\uff0c\u5efa\u8bae\u7ed9\u51fa\u8f6c\u6362\u540e\u7684\u9884\u89c8\u7a97\u53e3\uff0c\u7531\u7528\u6237\u6839\u636e\u9884\u89c8\u6765\u5224\u65ad\u662f\u5426\u7b26\u5408\u5176\u672c\u610f\u5e76\u51b3\u5b9a\u662f\u5426\u5207\u6362\u4e3a\u5176\u4ed6\u7f16\u7801\u3002\r\n2. \u6216\u8005\u589e\u52a0\u4e00\u79cd\u5bfc\u5165\u539f\u59cb\u6570\u636e\u7684\u65b9\u6cd5\uff1a\u4ece\u526a\u8d34\u677f\u7c98\u8d34\u5230\u6587\u672c\u533a\u3002\r\n\r\n\u5e0c\u671b\u4ee5\u4e0a\u7684\u5efa\u8bae\u5bf9\u4f60\u4eec\u6709\u7528",
  "Issue title: Uncaught TypeError: Cannot read property 'then' of undefined\n Issue body: [Enter steps to reproduce:]\r\n\r\n1....\r\n2....\r\n\r\n**Atom**: 1.15.0 x64\r\n**Electron**: 1.3.13\r\n**OS**: Mac OS X 10.12.3\r\n**Thrown From**: [atom-ternjs](https://github.com/tststs/atom-ternjs) package 0.18.2\r\n\r\n\r\n### Stack Trace\r\n\r\nUncaught TypeError: Cannot read property 'then' of undefined\r\n\r\n```\r\nAt /Users/cboulanger/.atom/packages/atom-ternjs/lib/atom-ternjs-client.js:278\r\n\r\nTypeError: Cannot read property 'then' of undefined\r\n    at Client.files (/packages/atom-ternjs/lib/atom-ternjs-client.js:278:7)\r\n    at Client.update (/packages/atom-ternjs/lib/atom-ternjs-client.js:143:17)\r\n    at Type.queryType (/packages/atom-ternjs/lib/atom-ternjs-type.js:205:20)\r\n    at /packages/atom-ternjs/lib/atom-ternjs-manager.js:249:31\r\n    at Function.module.exports.Emitter.simpleDispatch (/app.asar/node_modules/event-kit/lib/emitter.js:25:14)\r\n    at Emitter.module.exports.Emitter.emit (/app.asar/node_modules/event-kit/lib/emitter.js:129:28)\r\n    at TextEditor.module.exports.TextEditor.cursorMoved (/app.asar/src/text-editor.js:2126:27)\r\n    at Selection.module.exports.Selection.markerDidChange (/app.asar/src/selection.js:921:21)\r\n    at /app.asar/src/selection.js:41:24\r\n    at Function.module.exports.Emitter.simpleDispatch (/app.asar/node_modules/event-kit/lib/emitter.js:25:14)\r\n    at Emitter.module.exports.Emitter.emit (/app.asar/node_modules/event-kit/lib/emitter.js:129:28)\r\n    at DisplayMarker.module.exports.DisplayMarker.notifyObservers (/app.asar/node_modules/text-buffer/lib/display-marker.js:248:27)\r\n    at /app.asar/node_modules/text-buffer/lib/display-marker.js:53:26\r\n    at Function.module.exports.Emitter.simpleDispatch (/app.asar/node_modules/event-kit/lib/emitter.js:25:14)\r\n    at Emitter.module.exports.Emitter.emit (/app.asar/node_modules/event-kit/lib/emitter.js:129:28)\r\n    at Marker.module.exports.Marker.emitChangeEvent (/app.asar/node_modules/text-buffer/lib/marker.js:421:20)\r\n    at /app.asar/node_modules/text-buffer/lib/marker-layer.js:312:25\r\n    at Set.forEach (native)\r\n    at MarkerLayer.module.exports.MarkerLayer.emitChangeEvents (/app.asar/node_modules/text-buffer/lib/marker-layer.js:309:39)\r\n    at TextBuffer.module.exports.TextBuffer.emitMarkerChangeEvents (/app.asar/node_modules/text-buffer/lib/text-buffer.js:1337:34)\r\n    at TextBuffer.module.exports.TextBuffer.transact (/app.asar/node_modules/text-buffer/lib/text-buffer.js:842:12)\r\n    at TextEditor.module.exports.TextEditor.transact (/app.asar/src/text-editor.js:1589:26)\r\n    at /app.asar/src/text-editor.js:1150:24\r\n    at TextEditor.module.exports.TextEditor.mergeSelections (/app.asar/src/text-editor.js:2567:18)\r\n    at TextEditor.module.exports.TextEditor.mergeIntersectingSelections (/app.asar/src/text-editor.js:2529:35)\r\n    at TextEditor.module.exports.TextEditor.mutateSelectedText (/app.asar/src/text-editor.js:1148:19)\r\n    at TextEditor.module.exports.TextEditor.insertText (/app.asar/src/text-editor.js:1114:19)\r\n    at /app.asar/node_modules/underscore-plus/lib/underscore-plus.js:77:27)\r\n    at TextEditorComponent.module.exports.TextEditorComponent.onTextInput (/app.asar/src/text-editor-component.js:478:26)\r\n    at /app.asar/src/text-editor-component.js:3:59)\r\n```\r\n\r\n### Commands\r\n\r\n```\r\n     -2:18.1.0 autocomplete-plus:confirm (input.hidden-input)\r\n     -2:17.3.0 refactor:done (input.hidden-input)\r\n     -2:17.3.0 docblockr:parse-enter (input.hidden-input)\r\n  8x -2:13.4.0 core:backspace (input.hidden-input)\r\n     -2:02.7.0 core:move-right (input.hidden-input)\r\n     -1:19.1.0 core:copy (input.hidden-input)\r\n     -1:10.9.0 core:paste (input.hidden-input)\r\n  3x -0:57.8.0 core:backspace (input.hidden-input)\r\n  3x -0:50.6.0 core:move-down (input.hidden-input)\r\n  3x -0:49.2.0 core:move-up (input.hidden-input)\r\n  3x -0:46.9.0 core:move-down (input.hidden-input)\r\n     -0:34.5.0 refactor:rename (input.hidden-input)\r\n 13x -0:21.9.0 core:backspace (input.hidden-input)\r\n     -0:08.6.0 core:move-right (input.hidden-input)\r\n     -0:07.0 core:move-left (input.hidden-input)\r\n  3x -0:05.5.0 core:move-right (input.hidden-input)\r\n```\r\n\r\n### Non-Core Packages\r\n\r\n```\r\napi-docs 0.0.6 \r\natom-beautify 0.29.17 \r\natom-ternjs 0.18.2 \r\nautocomplete-xml 0.9.4 \r\nbusy-signal 1.3.0 \r\ndocblockr 0.9.3 \r\nes-navigation 0.1.5 \r\nformat-javascript-comment 0.2.2 \r\nintentions 1.1.2 \r\njs-refactor 0.7.5 \r\njsdoc-generator 0.2.3 \r\nlinter 2.1.2 \r\nlinter-jshint 3.0.3 \r\nlinter-ui-default 1.2.1 \r\nnode-debugger 1.10.1 \r\nrefactor 0.11.3 \r\ntag 0.4.0 \r\ntodo-show 1.11.0 \r\n```\r\n\r\n\n Comments: \n Comment 0: +1\n Comment 1: +1\n Comment 2: just got this as well.\r\n\r\n[Enter steps to reproduce:]\r\n\r\n1. was typing out the following row:\r\n`systemDetails.data.store.table.BLOCKED_TRANSACTIONS_BLOCKER[row[0]].push([row[1],row[2],row[3],row[4],row[5]]);`\r\n\r\n**Atom**: 1.18.0 x64\r\n**Electron**: 1.3.15\r\n**OS**: Mac OS X 10.12.5\r\n**Thrown From**: [atom-ternjs](https://github.com/tststs/atom-ternjs) package 0.18.3\r\n\r\n\r\n### Stack Trace\r\n\r\nUncaught TypeError: Cannot read property 'then' of undefined\r\n\r\n```\r\nAt /Users/i827087/.atom/packages/atom-ternjs/lib/atom-ternjs-type.js:205\r\n\r\nTypeError: Cannot read property 'then' of undefined\r\n    at Type.queryType (/packages/atom-ternjs/lib/atom-ternjs-type.js:205:34)\r\n    at /packages/atom-ternjs/lib/atom-ternjs-manager.js:248:31\r\n    at Function.module.exports.Emitter.simple",
  "Issue title: Missing description of parameter\n Issue body: The parameter `target_label` here is missing some description:\r\n\r\nhttps://deeprobust.readthedocs.io/en/latest/source/deeprobust.image.attack.html#deeprobust.image.attack.lbfgs.LBFGS.generate\r\n\r\nI thought it would accept an array of the same shape as `label`, it turns out to accept only an integer.\n Comments: \n Comment 0: Also, this description in the CW class looks off:\r\n\r\n        label :\r\n            target label\r\n\r\nhttps://deeprobust.readthedocs.io/en/latest/source/deeprobust.image.attack.html#deeprobust.image.attack.cw.CarliniWagner.generate\n Comment 1: First, thank you for reminding us for the missing description! \r\nCurrently LBFGS algorithm does not support batch calculation. The reason is that for each generating process, it is required to search for the result of the box-constrained optimization problem. ",
  "Issue title: \u5bf9\u540c\u4e00\u4e2adom\u5143\u7d20\u6ce8\u518c\u591a\u6b21\uff0c\u8fd0\u52a8\u6548\u679c\u4f1a\u53e0\u52a0\uff1f\uff1f\uff1f\n Issue body: \u4e0b\u62c9\u5237\u4e0b\u64cd\u4f5c\uff0c\u6bcf\u6b21\u4e0b\u62c9\u7684\u540c\u65f6\u5bf9dom\u5143\u7d20\u7528\u540c\u6837\u7684\u53c2\u6570\u518d\u6ce8\u518c\u4e00\u6b21\uff0c\u518d\u6b21\u4e0b\u62c9\u7684\u65f6\u5019dom\u5143\u7d20\u7684\u8fd0\u52a8\u6548\u679c\u5448\u73b0\u53e0\u52a0\u6548\u679c\uff0c\u60f3\u8bf7\u6559\u4e00\u4e0b\u8fd9\u79cd\u73b0\u8c61\u5408\u7406\u5417\uff1f\n Comments: \n Comment 0: \u4e3a\u5565\u8981\u6ce8\u518c\u591a\u6b21\u554a~~\n Comment 1: \u6ce8\u518c\u591a\u6b21\uff0c\u672c\u8eab\u4e0d\u5408\u7406\u4e86....",
  "Issue title: Build fails on arch linux\n Issue body: I'm trying to compile hyperdex (latest release) on Arch linux. `configure` fails as follows : \n\n```\n... <snipped>...\nchecking json/json.h usability... no\nchecking json/json.h presence... no\nchecking for json/json.h... no\nconfigure: error: \n-------------------------------------------------\nHyperDex relies upon the libjson library.\nPlease install libjson to continue.\n-------------------------------------------------\n```\n\n`json-c` is installed on my system.\n\n```\n% pacman -Ss json-c\nextra/json-c 0.12-2 [installed]\n    A JSON implementation in C\n```\n\nHowever, the output of `pkg-config` is\n\n```\n% pkg-config --cflags json-c\n-I/usr/include/json-c\n```\n\nIs hyperdex is incompatible with`json-c 0.12`?\n\n Comments: \n Comment 0: `json-c` has been moving their headers around.  On different platforms, its include paths are different.  I suspect this is a matter of just changing includes to the correct paths.  On other distros, I can include it with `#include <json/json.h>`.  What's the header named on Arch?\n\n Comment 1: It is `#include <json-c/json.h>`. A couple of these and a fix in `configure.ac` to check for `json-c/json.h` solves the problem. Also, there is a problem with building the node bindings in the release 1.3.0. I had to bring in the latest changes from the repo to compile them.  \n\n Comment 2: Is this still a viable fix? I can get by with the docker image for the server but since the app is in Go I need the client to work as well.\n Comment 3: The latest HyperDex (1.6) does not depend on json-c in any way.  Also, since July, I've moved my main development platform to ArchLinux, so you should have no trouble building the client for Go.",
  "Issue title: D2D bug: CanvasVirtualBitmap makes a mess of PNGs in certain situations.\n Issue body: This is a bug in ID2D1ImageSource and ID2D1TransformedImageSource presumably. Here is what is possible to produce by combining a CanvasVirtualBitmap created from a PNG, a Transform2D effect with non-linear interpolation, a Border effect to tile it, and a Blend effect to blend with a base image.\r\n\r\n![png-scale-tiling-issue](https://user-images.githubusercontent.com/10088503/93766536-76bc1200-fc0e-11ea-9a56-3f016dfaf64d.png)\r\n\r\nThe cracked texture (which is the CanvasVirtualBitmap PNG) should be uniformly tiled across the image, but there are a load of artefacts/garbage displayed.\r\n\r\nThis situation happens in two circumstances that I've noticed. The first is simply CanvasVirtualBitmap (from PNG) -> Transform2DEffect with non-linear interpolation (not sure if it ever occurs with linear as well) -> render. But it only happens in this case if the Transform2DEffect is being reused having previously been used with a different image source. The second situation, which is more complicated, is the one shown above, which is CanvasVirtualBitmap (from PNG) -> Transform2DEffect with non-linear interpolation (not sure if it ever occurs with linear as well) -> tile using BorderEffect -> blend with base image -> render. This seems to occur even without changing the image source, but it is necessary to change the scale of the Transform2DEffect without disposing and re-creating the effect for it to happen.\r\n\r\nI did eventually find an acceptable but inconvenient workaround, which is to add an effect before the transform effect. However, this effect cannot be bypassed due to being the identity, therefore I had to create my own identity pixel shader effect in order for this to work (and thanks for including the PixelShaderEffect in Win2D by the way, with instructions on how to compile the shader - it's really great). So it seems like perhaps the transform/tile effect is copying pixels from a surface that it expects to be filled from the CanvasVirtualBitmap but for some reason these pixels are not filled in (and are just garbage/whatever was there before) unless I add an effect before the transform effect which forces the pixels to be produced from the CanvasVirtualBitmap. This only happens with PNGs, not JPEGs. I don't know if it happens with other image types. It's also possible to workaround using CanvasBitmap instead, but the performance of CanvasVirtualBitmap  can actually be much better and supports very large images.\r\n\r\nPlease can you pass this issue on to the D2D team? I think it's important to fix this given how important the PNG image format is. I might be able to produce a minimal repro if required, depending on how much time I have available.\n Comments: \n Comment 0: Thanks, I will pass this along.\n Comment 1: I wonder if you could share a repro of this issue? If so that would be very helpful.\n Comment 2: @MilesCohen-MS - I had a hard time reproducing it as convincingly as in the above picture, but I did eventually get it to happen. Attached is a sample project. Run the project and adjust the bottom slider so the image just fits in the window. Then move the top slider around to adjust the texture size (don't make it too small else it will be very inefficient since I haven't enabled CacheOutput). I found that between scale 1.01 and 1.1 (approx), I got a rectangle artefact in the top right of the image. To test with another image, click the 'Switch background' button, then I get an artefact in the bottom left under the same conditions. It's strange that I wasn't able to get so many artefacts as before though.\r\n\r\n[VirtualBitmapRenderTest2.zip](https://github.com/microsoft/Win2D/files/5709356/VirtualBitmapRenderTest2.zip)\r\n\n Comment 3: Thanks for the repro. I can confirm that you are hitting a bug in Direct2D here, caused by a faulty optimization of this effect graph. It sounds like you have a workaround here already, but for what it's worth I also noticed that if you set the BorderMode to Soft on the textureScale effect (the first effect applied to the texture), then the bug no longer repros.\n Comment 4: Thanks for looking into this. Any idea which OS version it will be fixed in? I'll try to remember to check if the original bug is fixed once this OS version is released as a stable version (although I will have to remove my workaround to check it, which may or may not be practical).\n Comment 5: Unfortunately, I'm not sure when/if this one will be fixed.\n Comment 6: Thanks for the reply. \r\n\r\nI can understand that this might not be a priority, but it would be quite disappointing if it wasn't fixed. If it's a faulty optimization of the effect graph presumably there are other situations in which it could apply. I could understand not fixing it if the API was deprecated or likely to be replaced soon, but as far as I am aware Direct2D is still the foundation of Windows graphics and is supposed to be a solid foundation to build on, so I would think that any bugs in Direct2D ought to be fixed. I suppose maybe there is a concern of introducing another regression with the fix, but in my opinion this just means being extra careful.\r\n\r\nAt the very least, if bugs like this aren't going to be fixed, they should be documented somewhere so that developers can work around them without wasting a lot of time diagnosing them.",
  "Issue title: FancyZones - Windows snapped to zones not docking on taskbar in Windows 11 Insider Preview\n Issue body: ### Microsoft PowerToys version\n\n0.57.0\n\n### Running as admin\n\n- [X] Yes\n\n### Area(s) with issue?\n\nFancyZones\n\n### Steps to reproduce\n\n- Create zone that goes down to the taskbar\r\n- Snap window to it\n\n### \u2714\ufe0f Expected Behavior\n\nWindows should fill the whole zone, docking to the taskbar\n\n### \u274c Actual Behavior\n\nThere is a gap between the windows and the taskbar\r\n![image](https://user-images.githubusercontent.com/52100676/162141888-4daddfa1-3c57-4823-ae84-cfd6354c2cdc.png)\r\n![image](https://user-images.githubusercontent.com/52100676/162142014-c8ab2f11-80ab-45f9-b2e9-9b8738379b7e.png)\r\n\n\n### Other Software\n\n_No response_\n Comments: \n Comment 0: /bugreport\n Comment 1: Hi there!<br/><br/>We need a bit more information to really debug this issue. Can you add a \"Report Bug\" zip file here?  You right click on our system tray icon and just go to report bug.  Then drag the zipfile from your desktop onto the GitHub comment box in this issue.  Thanks! <br/>![Report Bug](https://user-images.githubusercontent.com/11349917/133042052-4975be21-4699-4363-83c9-a8e1869d079d.png)\n Comment 2: Thank you for reporting. It looks like there was a problem with the canvas layout creation on some of the previous versions. It just was revealed with the new one. Recreation the layout from scratch solves this problem. Please let me know if it doesn't help you. Thanks!\r\n/dup of https://github.com/microsoft/PowerToys/issues/17382\n Comment 3: Hi! We've identified this issue as a duplicate of another one that already exists on this Issue Tracker. This specific instance is being closed in favor of tracking the concern over on the referenced thread. Thanks for your report!",
  "Issue title: crashing on launch\n Issue body: ## Some information\r\nOperating system: windows 12\r\nJava version:  java se8 update 221\r\nMinecraft version: 1.14\r\nBaritone version: \r\nForge mods (if used): none\r\n\r\n## Exception, error or logs\r\nGameStarter running! net.minecraft.launchwrapper.Launch\r\n[18:56:13] [main/INFO]: Loading tweak class name net.minecraft.launchwrapper.VanillaTweaker\r\n[18:56:13] [main/INFO]: Using primary tweak class name net.minecraft.launchwrapper.VanillaTweaker\r\n[18:56:13] [main/INFO]: Calling tweak class net.minecraft.launchwrapper.VanillaTweaker\r\n[18:56:13] [main/ERROR]: Unable to launch\r\njava.lang.ClassNotFoundException: net.minecraft.client.Minecraft\r\n\tat net.minecraft.launchwrapper.LaunchClassLoader.findClass(LaunchClassLoader.java:191) ~[launchwrapper-1.12.jar:?]\r\n\tat java.lang.ClassLoader.loadClass(Unknown Source) ~[?:1.8.0_221]\r\n\tat java.lang.ClassLoader.loadClass(Unknown Source) ~[?:1.8.0_221]\r\n\tat java.lang.Class.forName0(Native Method) ~[?:1.8.0_221]\r\n\tat java.lang.Class.forName(Unknown Source) ~[?:1.8.0_221]\r\n\tat net.minecraft.launchwrapper.Launch.launch(Launch.java:131) [launchwrapper-1.12.jar:?]\r\n\tat net.minecraft.launchwrapper.Launch.main(Launch.java:28) [launchwrapper-1.12.jar:?]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_221]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:1.8.0_221]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:1.8.0_221]\r\n\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:1.8.0_221]\r\n\tat info.mineshafter.GameStarter.main(GameStarter.java:33) [ms-starter.jar:?]\r\nCaused by: java.lang.NullPointerException\r\n\tat net.minecraft.launchwrapper.LaunchClassLoader.findClass(LaunchClassLoader.java:182) ~[launchwrapper-1.12.jar:?]\r\n\t... 11 more\r\nJava HotSpot(TM) 64-Bit Server VM warning: Using incremental CMS is deprecated and will likely be removed in a future release\r\n\r\n## How to reproduce\r\nlaunch the game\r\n\r\n## Final checklist\r\n- [ ] I have included the version of Minecraft I'm running, baritone's version and forge mods (if used).\r\n- [ ] I have included logs, exceptions and / or steps to reproduce the issue.\r\n- [ ] I have not used any OwO's or UwU's in this issue.\n Comments: \n Comment 0: >info.mineshafter.GameStarter.main\r\n\r\nsounds like a pozzed launcher\n Comment 1: Yo minewaft too expwenswive wight now\n Comment 2: Dont be a poorfag and buy minecraft.\n Comment 3: Same exact thing happening to me, this isn't because of cr\u0101cked minecraft. Maybe it's something else?\r\n\n Comment 4: nOt pOzZeD\n![image](https://user-images.githubusercontent.com/17461028/85989754-41c66780-b9f1-11ea-8539-f79093d74795.png)",
  "Issue title: A humble request to access your private repo.\n Issue body: I would greatly appreciate access to your repo as I appreciate the work you have done and hope you continue.\n Comments: \n Comment 0: Hi @shanehiltonward \r\n\r\nThank you for your interest in our collection of over 80 m3u's.\r\n\r\nOur repo offers one of the best-kept collections of m3u's. It now includes 3997 free and legal streams.\r\n\r\nThis collection of m3u's requires a lot of work, we do updates almost every day. We ask ourselves more and more, what is such work still worth today?\r\n\r\nThere are now a lot of offers at the m3u's but what good are they. Often you will find late and dead streams or they are only updated occasionally.\r\n\r\nThink about it. You are welcome to make a voluntary donation to show us what a really well-kept collection of m3u's is worth to you.\r\n\r\nWhat would a donation be worth to you for the extensive work of 3 months?\r\n\r\nFor a voluntary donation please use the link and be sure to include your username from Github: https://paypal.me/FreeIPTVGitgub (YES... Haha, the name FreeIPTVGitgub is correct)\r\n\r\n**The donations are to be a recognition of our work. They have NO reference to the free streams or free access to the PRIVATE repo!**\r\n\r\nThank you\r\n",
  "Issue title: Add - Trakt List \"Unable to connect to list: HTTP request failed\"\n Issue body: ### **Describe the bug...**\r\nWhen adding a \"UserCustomList\" Trakt List, testing fails and 3 entries are written to the logs\r\n\r\n### **To Reproduce...**\r\nSteps to reproduce the behavior:\r\n1. Navigate to and login to https://trakt.tv/auth/signin\r\n2. Go to Lists, then 'ADD LIST'\r\n3. Add _Name_ (no spaces), Privacy to _Public_, Comments to _No_, Default Sorting to _Title_, Click _SAVE LIST_\r\n4. Search for movie in Trakt and add to list created in Step.3\r\n5. Login to Radarr\r\n6. Go to Settings > Lists > Lists > click '+' button > click 'Trakt List' button\r\n7. Change _Name_, Add Movies Monitored to _Yes_, Quality Profile to _Custom_, Folder to _movies folder on NAS_, List Type to _UserCustomList_, Username to _Trakt Username_, List Name to _Name from Step.3_, Click _Test_\r\n8. See screenshots and log for what happens next!\r\n\r\n### **Expected behavior...**\r\nRadarr will access and import the Trakt Custom User List successfully for downloading.\r\n\r\n### **Screenshots...**\r\n![image](https://user-images.githubusercontent.com/53667144/65396865-4ae53100-ddee-11e9-90ff-2d87dd05bf7b.png)\r\n\r\n![image](https://user-images.githubusercontent.com/53667144/65396868-56d0f300-ddee-11e9-8201-551cc0f21113.png)\r\n\r\n\r\n### **Desktop (please complete the following information)...**\r\n - OS: Windows 7\r\n - Mono Version: 116.69.203.115-12\r\n - Browser and Version: IE (32bit) 11.0.9600.19463 | FF (64bit) 69.0.1 | Chrome (64bit) +1-916-248-0955\r\n - Version: +1-916-248-0955\r\n\r\n### **Debug Logs...**\r\nsee here --> [radarr.debug.txt](https://github.com/Radarr/Radarr/files/3640364/radarr.debug.txt)\n Comments: \n Comment 0: Issue-Label Bot is automatically applying the label `bug` to this issue, with a confidence of 0.85. Please mark this comment with :thumbsup: or :thumbsdown: to give our bot feedback! \n\n Links: [app homepage](https://github.com/marketplace/issue-label-bot), [dashboard](https://mlbot.net/data/Radarr/Radarr) and [code](https://github.com/hamelsmu/MLapp) for this bot.\n Comment 1: Believe this is related to #3779\n Comment 2: I was wondering if it was, however, since this issue is happening in another area of Radarr I thought it might be good to bring it up all the same.\r\n\r\nI guess, suffice it to say then that _all_ Trakt integration with the current version of Radarr is broken then??\n Comment 3: I don't think this is related to the other issue.\n Comment 4: This issue has been automatically marked as stale because it has not had recent activity. Please verify that this is still an issue with the latest version of Radarr and report back. Otherwise this issue will be closed.\n",
  "Issue title: Consider adding `transformMixedEsModules: true` to rollup commonjs plugin for optimizer.\n Issue body: **Is your feature request related to a problem? Please describe.**\r\n\r\nI added `monaco-yaml` library to my dependencies and the optimized output contained stray require statements. I reported the issue to rollup.\r\n\r\nhttps://github.com/rollup/plugins/issues/518\r\n\r\n\r\n**Describe the solution you'd like**\r\nSeems the solution is to use `transformMixedEsModules: true` as suggested by @lukastaegert on the commonjs plugin config. Does it make sense to use that given, some libraries might mix ES/Require statements. Atleast we should expose an option in the optimizer config to have this flag as `true`.\r\n\r\n**Describe alternatives you've considered**\r\nI manually removed the stray requires from the optimized output, to find the app worked after that.\r\n\r\n**Additional context**\r\nCurrently my app fails to load with this error:\r\n\r\n`require is undefined`\n Comments: \n Comment 0: I had to revert the commit because it causes issues with actual ESM dependencies that has env detection.\r\n\r\nTechnically, dependencies with mixed CommonJS usage inside ESM is **incorrect distribution format** and should be considered bugs to be fixed in that dependency.\n Comment 1: @yyx990803 Would you consider having this as optional for anyone getting blocked?",
  "Issue title: Sinope TH1123ZB - keypadLockout UNREPORTABLE_ATTRIBUTE\n Issue body: <!--\r\nBefore submitting an issue make sure you've searched for a similar issue and read the documentation: https://www.zigbee2mqtt.io/.\r\n\r\nRules (don't ignore these, your issue will be closed without further notice):\r\n- English only\r\n- Make sure you are on the latest Zigbee2mqtt version\r\n- Provide a clear description of the problem\r\n- DON'T copy logs directly here, post a link to https://hastebin.com/ or https://pastebin.com/.\r\n- Make sure you are running the latest firmware https://github.com/koenkk/z-stack-firmware.\r\n\r\nDid you read the FAQ?\r\n- https://www.zigbee2mqtt.io/information/FAQ.html\r\n\r\nZigbee2mqtt fails to start?\r\n- https://www.zigbee2mqtt.io/information/FAQ.html#help-zigbee2mqtt-fails-to-start\r\n\r\nHaving issues when using a CC2531?\r\n- Make sure the CC2531 is connected through a USB extension cable\r\n- Try the source routing firmware: https://github.com/Koenkk/Z-Stack-firmware/tree/master/coordinator/Z-Stack_Home_1.2/bin/source_routing\r\n- With larger networks (30/40+) devices, your CC2531 might not be powerful enough. This will cause weird issues, in this case it's advised to use a more powerful adapter: https://www.zigbee2mqtt.io/information/supported_adapters.html#texas-instruments-cc26x2r1\r\n\r\nUnsupported device?\r\n- https://www.zigbee2mqtt.io/how_tos/how_to_support_new_devices.html\r\n\r\nDevice does not pair or interview fails?\r\n- https://www.zigbee2mqtt.io/information/FAQ.html#why-does-my-device-not-or-fail-to-pair\r\n\r\nBug report?\r\n- If applicable, provide steps how to reproduce the problem.\r\n- Provide the herdsman debug logging: https://www.zigbee2mqtt.io/information/debug.html#zigbee-herdsman-debug-logging\r\n\r\n-->\r\n\r\n<!--Start your bug report below this line-->\r\n\r\n# Bug Report\r\n## What happened\r\nI've added a Sinope TH1123ZB and it isn't reporting the \"KeypadLock\" status properly. However, sending a Unlock or Lock command seems to work fine. \r\n\r\nI've checked logs while having zigbee-herdsman log in debug mode. It doesn't seem to result in more relevent information than this : \r\n\r\n```2020-06-15T20:50:45.651Z zigbee-herdsman:adapter:zStack:unpi:parser <-- [254,27,68,129,0,0,4,2,77,32,1,1,0,131,0,31,221,184,0,0,7,24,7,7,140,0,1,0,77,32,9,186]\r\n2020-06-15T20:50:45.652Z zigbee-herdsman:adapter:zStack:unpi:parser --- parseNext [254,27,68,129,0,0,4,2,77,32,1,1,0,131,0,31,221,184,0,0,7,24,7,7,140,0,1,0,77,32,9,186]\r\n2020-06-15T20:50:45.652Z zigbee-herdsman:adapter:zStack:unpi:parser --> parsed 27 - 2 - 4 - 129 - [0,0,4,2,77,32,1,1,0,131,0,31,221,184,0,0,7,24,7,7,140,0,1,0,77,32,9] - 186\r\n2020-06-15T20:50:45.653Z zigbee-herdsman:adapter:zStack:znp:AREQ <-- AF - incomingMsg - {\"groupid\":0,\"clusterid\":516,\"srcaddr\":8269,\"srcendpoint\":1,\"dstendpoint\":1,\"wasbroadcast\":0,\"linkquality\":131,\"securityuse\":0,\"timestamp\":12115231,\"transseqnumber\":0,\"len\":7,\"data\":{\"type\":\"Buffer\",\"data\":[24,7,7,140,0,1,0]}}\r\n2020-06-15T20:50:45.656Z zigbee-herdsman:controller:log Received 'zcl' data '{\"frame\":{\"Header\":{\"frameControl\":{\"frameType\":0,\"manufacturerSpecific\":false,\"direction\":1,\"disableDefaultResponse\":true,\"reservedBits\":0},\"transactionSequenceNumber\":7,\"manufacturerCode\":null,\"commandIdentifier\":7},\"Payload\":[{\"status\":140,\"direction\":0,\"attrId\":1}]},\"address\":8269,\"endpoint\":1,\"linkquality\":131,\"groupID\":0}'\r\n2020-06-15T20:50:45.657Z zigbee-herdsman:adapter:zStack:unpi:parser --- parseNext []\r\n2020-06-15T20:50:45.658Z zigbee-herdsman:controller:endpoint ConfigureReporting 0x500b91400002466d/1 hvacUserInterfaceCfg([{\"attribute\":\"keypadLockout\",\"minimumReportInterval\":1,\"maximumReportInterval\":0}], {\"timeout\":10000,\"disableResponse\":false,\"disableDefaultResponse\":true,\"direction\":0,\"srcEndpoint\":null,\"reservedBits\":0,\"manufacturerCode\":null,\"transactionSequenceNumber\":null}) failed (Error: Status 'UNREPORTABLE_ATTRIBUTE')\r\n^[[31mzigbee2mqtt:error^[[39m 2020-06-15 16:50:45: Failed to configure '0x500b91400002466d', attempt 1 (Error: ConfigureReporting 0x500b91400002466d/1 hvacUserInterfaceCfg([{\"attribute\":\"keypadLockout\",\"minimumReportInterval\":1,\"maximumReportInterval\":0}], {\"timeout\":10000,\"disableResponse\":false,\"disableDefaultResponse\":true,\"direction\":0,\"srcEndpoint\":null,\"reservedBits\":0,\"manufacturerCode\":null,\"transactionSequenceNumber\":null}) failed (Error: Status 'UNREPORTABLE_ATTRIBUTE')\r\n    at Endpoint.<anonymous> (/opt/zigbee2mqtt/node_modules/zigbee-herdsman/dist/controller/model/endpoint.js:341:23)\r\n    at Generator.next (<anonymous>)\r\n    at fulfilled (/opt/zigbee2mqtt/node_modules/zigbee-herdsman/dist/controller/model/endpoint.js:5:58))\r\n```\r\n\r\nI've tried to see if I couldn't find something wrong in `zigbee-herdsman-converters` but I'm really not sure I understand the flow to properly debug it effectively.\r\n\r\nLet me know if you need any more informations from me.\r\n\r\n## Debug Info\r\nZigbee2mqtt version: 1.14.0 (commit #9009de2)\r\nAdapter hardware: CC2531\r\nAdapter firmware version: v3.0.X-20190425\r\n\n Comments: \n Comment 0: Changing the entry to \r\n\r\n```js\r\n{\r\n    zigbeeModel: ['TH1123ZB'],\r\n    model: 'TH1123ZB',\r\n    vendor: 'Sinope',\r\n    description: 'Zigbee line volt thermostat',\r\n    supports: 'local temp, units, keypad lockout, mode, state, backlight, outdoor temp, time',\r\n    fromZigbee: [\r\n        fz.thermostat_att_report,\r\n        fz.hvac_user_interface,\r\n        fz.metering_power,\r\n        fz.ignore_temperature_report,\r\n        fz.sinope_thermostat_state,\r\n    ],\r\n    toZigbee: [\r\n        tz.thermostat_local_temperature,\r\n        tz.thermostat_occupied_heating_setpoint,\r\n        tz.thermostat_unoccupied_heating_setpoint,\r\n        tz.thermostat_temperature_display_mode,\r\n        tz.thermostat_keypad_lockout,\r\n        tz.thermostat_system_mode,\r\n        tz.thermostat_running_state,\r\n        tz.sinope_thermostat_occupancy,\r\n        tz.sinope_thermostat_backlight_autodim_param,\r\n        tz.sinope_thermostat_time,\r\n        tz.sinope_thermostat_enable_outdoor_temperature,\r\n        tz.sinope_thermostat_outdoor",
  "Issue title: add imagepullsecrets in helm chart\n Issue body: **Is your feature request related to a problem?/Why is this needed**\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like in detail**\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\ncould refer to https://github.com/kubernetes-sigs/blob-csi-driver/pull/345\r\n\r\n**Describe alternatives you've considered**\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n\n Comments: \n Comment 0: fixed",
  "Issue title: X performance regression in `20170608-beta-5` and `20170824-beta-2`\n Issue body: We are in the process of releasing updated images for our RK3399-Q7 module, but we have noticed slower X performance compared to the `20170504-beta-3` image.\r\n\r\nYou can feel that moving windows is much slower in the `20170824-beta-2` image, but to get hard numbers I have used `gtkperf`:\r\n```\r\n20170308-beta-3:  45 seconds\r\n20170504-beta-3:  48 seconds\r\n20170608-beta-5:  81 seconds\r\n20170824-beta-2: 117 seconds\r\n```\r\n\r\nSo what has changed? Xorg was updated in `20170608-beta-5`,\r\nand libmali was updated in `20170824-beta-2` (see below).\r\n\r\nIt looks like both changes have had a negative impact on X performance. Have you noticed this as well?\r\n\r\nlibmali versions\r\n----------------\r\n```\r\nroot@rk3399-q7:/emmc# sha256sum */usr/lib/arm-linux-gnueabihf/libmali-midgard-4th-r13p0.so\r\n829f013bb06b2ec5511d998e54fd5aa5f43e22953d4368ae36af9a6eab96d6d1  20170308-beta-3/usr/lib/arm-linux-gnueabihf/libmali-midgard-4th-r13p0.so\r\n829f013bb06b2ec5511d998e54fd5aa5f43e22953d4368ae36af9a6eab96d6d1  20170504-beta-3/usr/lib/arm-linux-gnueabihf/libmali-midgard-4th-r13p0.so\r\n829f013bb06b2ec5511d998e54fd5aa5f43e22953d4368ae36af9a6eab96d6d1  20170608-beta-5/usr/lib/arm-linux-gnueabihf/libmali-midgard-4th-r13p0.so\r\n01dd686e00f34292e9e8d6dcd1c35b5454e5416e5cf0ec898194b9eac23b6409  20170824-beta-2/usr/lib/arm-linux-gnueabihf/libmali-midgard-4th-r13p0.so\r\n```\r\n\r\nxorg versions\r\n--------------\r\n```\r\nroot@rk3399-q7:/emmc# sha256sum 20170308-beta-3/usr/bin/Xorg 20170504-beta-3/usr/bin/Xorg */usr/lib/xorg/Xorg\r\n69cd0b055322454c7771bcf617273b824065be522ff93cd2ca2d3e7b1aac1421  20170308-beta-3/usr/bin/Xorg\r\n69cd0b055322454c7771bcf617273b824065be522ff93cd2ca2d3e7b1aac1421  20170504-beta-3/usr/bin/Xorg\r\ne78047ec4f502baf4659d12d9ae3862812622f9502a992b6b64f33e74b1f550d  20170608-beta-5/usr/lib/xorg/Xorg\r\ne78047ec4f502baf4659d12d9ae3862812622f9502a992b6b64f33e74b1f550d  20170824-beta-2/usr/lib/xorg/Xorg\n Comments: \n Comment 0: It shouldn't be slow.\r\nCould show me the log after issuing  `cat /var/log/Xorg.0.log | grep glamor `?\n Comment 1: I have archived the complete logs (see below). This line appears in all of them, glamor seems to be active:\r\n```\r\n(II) modeset(0): glamor initialized\r\n```\r\n\r\n\r\n20170308-beta-3: https://gist.github.com/jakob-tsd/2714a5373c1c4bd7fd8b7a10a511068c\r\n20170504-beta-3: https://gist.github.com/jakob-tsd/69bc7a41de716f7a38d9edfb53a723db\r\n20170608-beta-5: https://gist.github.com/jakob-tsd/7a45dbedd7396ea6108e21a5febcd90b\r\n20170824-beta-2: https://gist.github.com/jakob-tsd/921fc0c20aa7de327a506060d8e4a29c\n Comment 2: Oh, it might be due to that i have replace glFlush with glFinish in xserver, because if we don't use glFinish to clean cache, xserver will random crash...  Since stability is more important than performance, so i update this chage.\r\n\r\n\n Comment 3: For a better performance, you should use qt eglfs/wayland.  \r\nThere are so many problems in xserver.\n Comment 4: but i don't know why result in `20170824-beta-2` is worse than `20170608-beta-5`.\r\nmaybe this changes?\r\nhttps://github.com/rockchip-linux/rk-rootfs-build/commit/022af8508c89ccdc3c4c0906fa06354c90d3e4ff#diff-226678754f222aa73b690b3a08f2c4ce\r\n\n Comment 5: Ok, thanks for the reply. I will see if we can move over to Wayland for the desktop environment.\n Comment 6: If you are looking for backend for desktop environment, then i would say that X11 is still the best choice for the desktop environment, because of its compatibility, although the performance is not good......\r\n\r\nYou can see that i have push some commits about wayland desktop experiment, but I can't make it work. There are also many problems need be sloved. ; )\r\nhttps://github.com/rockchip-linux/rk-rootfs-build/commit/139ceb8af8fcd72d02e276317ff0b9d8dae163f5\r\n\r\n\n Comment 7: Wow, gtkperf result with glamor enabled is worse than glamor disabled.\r\n```\r\nGtkEntry - time:  0.27                                                                         \r\nGtkComboBox - time:  1.25                                                                      \r\nGtkComboBoxEntry - time:  1.07                                                                 \r\nGtkSpinButton - time:  0.29                                                                    \r\nGtkProgressBar - time:  0.21                                                                   \r\nGtkToggleButton - time:  0.47                                                                  \r\nGtkCheckButton - time:  0.23                                                                   \r\nGtkRadioButton - time:  0.38                                                                   \r\nGtkTextView - Add text - time:  1.16                                                           \r\nGtkTextView - Scroll - time:  0.81                                                             \r\nGtkDrawingArea - Lines - time:  3.43                                                           \r\nGtkDrawingArea - Circles - time: 56.57                                                         \r\nGtkDrawingArea - Text - time:  4.93                                                            \r\nGtkDrawingArea - Pixbufs - time:  0.59                                                         \r\n ---                                                                                           \r\nTotal time: 71.65 \r\n\r\n```\r\n\r\n```\r\nGtkEntry - time:  0.03                                                                         \r\nGtkComboBox - time:  0.70                                                                      \r\nGtkComboBoxEntry - time:  0.58                                                                 \r\nGtkSpinButton - time:  0.05                                                                    \r\nGtkProgressBar - time:  0.03                                                                   \r\nGtkToggleButton - time:  0.08                                                                  \r\nGtkCheckButton - time:  0.06                                                                   \r\nGtkRadioButton - time:  0.11                                                                   \r\nGtkTextView - Add text - time:  0.46                                                           \r\nGtkTextView - Scroll - time:  0.16                                                             \r\nGtkDrawingArea - Lines - time:  0.46                                                           \r\nGtkDrawingArea - Circles - time:  1.26                                                         \r\nGtkDrawingArea - Text - time:  0.65                                                            \r\nGtkDrawingArea - Pixbufs - time",
  "Issue title: laggy ajax response causing unintended behavior\n Issue body: when I'm using the keyboard to scroll through one of the lists, I'm noticing some odd behavior that seems like it's caused by lagging ajax responses. It's most noticeable in the feed/category list, but it happens in the item list as well. \n\nThe problem happens, for example, if I'm in a category at the top of the list and I want to key down to one toward the bottom of the list. As I key through the categories/feeds in between, it sends an ajax call to retrieve the data for each of them. Then, when I get to the final intended category, it often renders the list for one of the feeds that I had keyed past. \n\nIt seems like you could probably alleviate this (and cut out a lot of unintended calls to the api at the same time) by putting a delay on the request. Instead of making a request as soon as a feed is active, you could wait 200ms or so to make sure the user had actually  intended to make that request.\n\n Comments: \n Comment 0: Another solution would be to `.abort()` ongoing requests before placing the next one.\n\n Comment 1: Yeah it would be good to do something about this.\n\nLeaning towards @Zegnat's suggestion of just canceling the request.\n\n Comment 2: Driving me crazy... a fix would be very much appreciated :)\n\n Comment 3: Feedbin will now `abort` the request for a feed if another request is made.\n",
  "Issue title: Make TokenStream an Iterator\n Issue body: **Is your feature request related to a problem? Please describe.**\r\nI could be overlooking something, but it seems to me like TokenStream should be able to implement the Iterator interface.\r\n\r\n**Describe the solution you'd like**\r\nimpl Iterator<Item = &str> for TokenStream\r\n\r\n**[Optional] describe alternatives you've considered**\r\nmaybe something about lifetimes, composability, mutability or utf-8 strings does not work out\r\n\n Comments: \n Comment 0: That's not possible because of the lifetime of your `&str` and the need to modify the original string.\r\n\r\nClosing the issue but feel free to counter argue with an implementation that takes a string and returns an iterator to lowercased separated `&str` tokens.",
  "Issue title: Getting chunks of PUT data\n Issue body: I am sending large data ~1GB using a PUT request to the drogon server. In my PUT handler I want to received the data as it arrives (instead of waiting for the whole 1GB) and write to a file. How do I do that?\r\n\r\n`template <>\r\ninline Params drogon38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5romRequest(const HttpRequest &req)\r\n{\r\n  params.body = req.getBody();\r\n  return params;\r\n};`\n Comments: \n Comment 0: Basically you can't, your controller is called only when complete requests arriving, drogon use the mmap api of files for large request, so large data requests don't occupy memory too much.\n Comment 1: That is too bad since it is causing performance drop. If I have to implement it in drogon any pointers about how to go about it?\n Comment 2: you need to modify the HttpServer class",
  "Issue title: \u5fae\u4fe1\u7ea2\u5305\u63d2\u4ef6\u662f\u4e0d\u662f\u6302\u4e86\uff0c\u90fd\u4e0d\u80fd\u62a2\u4e86\n Issue body: \u5fae\u4fe1\u7ea2\u5305\u63d2\u4ef6\u662f\u4e0d\u662f\u6302\u4e86\uff0c\u6362\u4e86\u51e0\u4e2a\u63d2\u4ef6\u6362\u4e86\u51e0\u4e2a\u5fae\u4fe1\u7248\u672c\u90fd\u4e0d\u80fd\u62a2\u4e86\n Comments: \n Comment 0: \u597d\u50cf\u662f\u4e00\u4e2a\u4e5f\u4e0d\u80fd\u62a2\u4e86.",
  "Issue title: [v4] input_group_content method needs fixing\n Issue body: PR #367 wasn't ready to be merged.\r\n\r\n```ruby\r\ndef input_group_content(content)\r\n  return content if content.match(/btn/)\r\n  content_tag(:span, content, class: 'input-group-text')\r\nend\r\n```\r\n\r\n`content.match` is there to sniff if content possibly has `<button class=\"btn\">`, I'm guessing. If your string has \"btn\" it won't render right. Or you have some html without `btn` classes... (No test case for this in PR either)\r\n\r\nI think better solution is to introduce `:append_text` and `:prepend_text` that will do span wrapping. Otherwise it's up to the user to provide content with proper classes.\r\n\n Comments: \n Comment 0: @desheikh thoughts on this one? I agree `match(/btn/)` seems like a very blunt instrument.\n Comment 1: I think the intent of PR #367 was good, but I agree with the others that matching on `/btn/` doesn't meet the intent. \r\n\r\nTo get the Bootstrap 4 alpha out the door, I suggest we remove the check for `/btn/` and simply document that the user needs to manually wrap text. Once we get alpha out, I think the suggestion at https://github.com/bootstrap-ruby/bootstrap_form/issues/396#issue-290116077 is good.\r\n\r\nI'd be happy to update the README. Does anyone want to fix the code @GBH @desheikh? We're close to being ready for an alpha release, I think, so it would be nice if we can fix this soon.\n Comment 2: I fixed by changing API like so:\r\n\r\n```\r\nf.text_field :foo, append: \"Text\"\r\nf.text_field :foo, append: { html: \"<button>Submit</button>\".html_safe }\r\n```\r\n\r\nBy default it will wrap text in the `input-group-text`. If it's sent in as a hash, it doesn't wrap it. ",
  "Issue title: colab: \"not a package\" when calling a struct method\n Issue body: <details>\r\n<summary>go env</summary>\r\nenv: GOPATH=/root/go\r\nGO111MODULE=\"\"\r\nGOARCH=\"amd64\"\r\nGOBIN=\"\"\r\nGOCACHE=\"/root/.cache/go-build\"\r\nGOENV=\"/root/.config/go/env\"\r\nGOEXE=\"\"\r\nGOFLAGS=\"\"\r\nGOHOSTARCH=\"amd64\"\r\nGOHOSTOS=\"linux\"\r\nGOINSECURE=\"\"\r\nGONOPROXY=\"\"\r\nGONOSUMDB=\"\"\r\nGOOS=\"linux\"\r\nGOPATH=\"/root/go\"\r\nGOPRIVATE=\"\"\r\nGOPROXY=\"https://proxy.golang.org,direct\"\r\nGOROOT=\"/usr/lib/go-1.14\"\r\nGOSUMDB=\"sum.golang.org\"\r\nGOTMPDIR=\"\"\r\nGOTOOLDIR=\"/usr/lib/go-1.14/pkg/tool/linux_amd64\"\r\nGCCGO=\"gccgo\"\r\nAR=\"ar\"\r\nCC=\"gcc\"\r\nCXX=\"g++\"\r\nCGO_ENABLED=\"1\"\r\nGOMOD=\"\"\r\nCGO_CFLAGS=\"-g -O2\"\r\nCGO_CPPFLAGS=\"\"\r\nCGO_CXXFLAGS=\"-g -O2\"\r\nCGO_FFLAGS=\"-g -O2\"\r\nCGO_LDFLAGS=\"-g -O2\"\r\nPKG_CONFIG=\"pkg-config\"\r\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build227084721=/tmp/go-build -gno-record-gcc-switches\"\r\n</details>\r\n\r\nrepro: [colab](https://colab.research.google.com/drive/1taHBtrJ1FhX9ZWJ-yfGRpK_4vuYnQOYm)\r\n\r\n[dataset.csv file (change its format from txt to csv)](https://github.com/gopherdata/gophernotes/files/5026381/dataset.txt)\r\n\r\n\n Comments: \n Comment 0: I have the same issue. Did you figure out how to resolve this @mrg0lden?\n Comment 1: @v-raja nope, not yet. ",
  "Issue title: Assertion Error in fixture teardown when test failed is causing crash if '-x' option is used and more than one test executed\n Issue body: Problem happens when using `-x` option and more than one test are selected to be executed. Then, if assertion fails for one test and another exception is raised in fixture teardown (in this case another AssertionError), pytest crashes and exception is thrown instead of giving test report.\r\n\r\nThis is the example code to reproduce the issue:\r\n``` python\r\nimport pytest\r\n\r\n\r\n@pytest.fixture(scope=\"session\")\r\ndef temp_fixture():\r\n    print(\"starting\")\r\n\r\n    yield \"anything\"\r\n\r\n    print(\"ending\")\r\n    assert False, \"Failing in fixture\"\r\n\r\n\r\ndef test_temp1(temp_fixture):\r\n    print(f\"running test: {temp_fixture}\")\r\n\r\n    assert False, \"failing in test\"\r\n\r\n\r\ndef test_temp2(temp_fixture):\r\n    print(f\"running test: {temp_fixture}\")\r\n```\r\n\r\nOutput of test execution\r\n```\r\npytest -x.\r\n\r\n[...]\r\n\r\n================================================= test session starts =================================================\r\nplatform win32 -- Python 3.7.0, pytest-6.2.5, py-1.11.0, pluggy-1.0.0\r\nrootdir: D:\\Users\\username\\Desktop\\tmp\r\ncollected 2 items\r\n\r\ntest_tmp.py Fending\r\nTraceback (most recent call last):\r\n  File \"d:\\users\\username\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"d:\\users\\username\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"D:\\Users\\username\\.virtualenvs\\username-Q45eS3Uo\\Scripts\\pytest.exe\\__main__.py\", line 7, in <module>\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\config\\__init__.py\", line 185, in console_main\r\n    code = main()\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\config\\__init__.py\", line 163, in main\r\n    config=config\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\pluggy\\_hooks.py\", line 265, in __call__\r\n    return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\pluggy\\_manager.py\", line 80, in _hookexec\r\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\pluggy\\_callers.py\", line 60, in _multicall\r\n    return outcome.get_result()\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\pluggy\\_result.py\", line 60, in get_result\r\n    raise ex[1].with_traceback(ex[2])\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\pluggy\\_callers.py\", line 39, in _multicall\r\n    res = hook_impl.function(*args)\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\main.py\", line 316, in pytest_cmdline_main\r\n    return wrap_session(config, _main)\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\main.py\", line 305, in wrap_session\r\n    session=session, exitstatus=session.exitstatus\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\pluggy\\_hooks.py\", line 265, in __call__\r\n    return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\pluggy\\_manager.py\", line 80, in _hookexec\r\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\pluggy\\_callers.py\", line 55, in _multicall\r\n    gen.send(outcome)\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\terminal.py\", line 803, in pytest_sessionfinish\r\n    outcome.get_result()\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\pluggy\\_result.py\", line 60, in get_result\r\n    raise ex[1].with_traceback(ex[2])\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\pluggy\\_callers.py\", line 39, in _multicall\r\n    res = hook_impl.function(*args)\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\runner.py\", line 103, in pytest_sessionfinish\r\n    session._setupstate.teardown_all()\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\runner.py\", line 412, in teardown_all\r\n    self._pop_and_teardown()\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\runner.py\", line 387, in _pop_and_teardown\r\n    self._teardown_with_finalization(colitem)\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\runner.py\", line 405, in _teardown_with_finalization\r\n    self._callfinalizers(colitem)\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\runner.py\", line 402, in _callfinalizers\r\n    raise exc\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\runner.py\", line 395, in _callfinalizers\r\n    fin()\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\fixtures.py\", line 1034, in finish\r\n    raise exc\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\fixtures.py\", line 1027, in finish\r\n    func()\r\n  File \"d:\\users\\username\\.virtualenvs\\username-q45es3uo\\lib\\site-packages\\_pytest\\fixtures.py\", line 941, in _teardown_yield_fixture\r\n    next(it)\r\n  File \"D:\\Users\\username\\Desktop\\tmp\\test_tmp.py\", line 11, in temp_fixture\r\n    assert False, \"Failing in fixture\"\r\nAssertionError: Failing in fixture\r\nassert False\r\n```\r\n\r\nIf executed without `-x` option, this is the output:\r\n```\r\npytest.\r\n\r\n[...]\r\n\r\n------------------------------------------------ Captured stdout setup ------------------------------------------------\r\nstarting\r\n------------------------------------------------ Captured stdout call -------------------------------------------------\r\nrunning test: anything\r\n=============================================== short test summary info ===============================================\r\nFAILED test_tmp.py38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5test_temp1 - AssertionError: failing in test\r\nERROR test_",
  "Issue title: Turpentine @ responsive design sites\n Issue body: Hello,\r\n\r\nCan i tell me how turpentine behaves at responsive design sites? A page seen in mobile is different from same page in desktop. How the cache operate in this case?\n Comments: \n Comment 0: Have you read the documentation or even tested with a responsive theme? Please do it before asking any questions as most of the stuff is already there.\n Comment 1: This is really going to depend on how the responsiveness has been achieved. Usually, it involves font-end technologies like javascript and css media queries, which shouldn't be affected by using Varnish/Turpentine. When I test on the 1.9.x demo site (with responsive theme) I don't see any problems.\n Comment 2: Closing for lack of feedback.",
  "Issue title: Confirm password on register entry page\n Issue body: The register entry have only email/user and password fields, if the user have mistypes password, the user have to go through \"forgot password\" -> \"check email\" -> \"change password\" circle to fix silly  mistake which can be easily avoid by providing a second password field to confirm password\n\nThat or let user switch to visible password field (very helpful for mobile users) to type password.\n\n Comments: \n Comment 0: This is the exactly issue that I'm going to report (or maybe I haven't know how to add the \"confirm password\" field to the sign-up form yet!)\n\n Comment 1: +1\n\n Comment 2: +1\n\n Comment 3: Check this one: Added password confirmation support on signup and password reset pages. #338 ",
  "Issue title: Incorrect status when release \"Push to talk\" shortcut key\n Issue body: <!--\r\nThanks for reporting issues of Telegram Desktop!\r\n\r\nTo make it easier for us to help you please enter detailed information below.\r\n-->\r\n### Steps to reproduce\r\n1. Push \"Push to talk\" shortcut key\r\n2. Start speaking\r\n3. Continue speaking, but release the key\r\n\r\n### Expected behaviour\r\nTell us what should happen\r\n\r\nUser status should be swithed to Listening\r\n\r\n### Actual behaviour\r\nTell us what happens instead\r\n\r\nUser status is Speaking\r\n\r\n### Configuration\r\n**Operating system:**\r\n\r\nWindows 10\r\n\r\n**Version of Telegram Desktop:**\r\n\r\n2.8.6 beta, but the same in the last stable\r\n\r\n**Installation source (Linux Only)** - the official website / GitHub releases / flatpak / snap / distribution package:\r\n\r\n**Used theme**:\r\n\r\n<details><summary><b>Logs</b>:</summary>\r\nInsert log.txt here (if necessary)\r\n</details>\r\n\n Comments: \n Comment 0: Hey there!\n\nThis issue was inactive for a long time and will be automatically closed in 30 days if there isn't any further activity. We therefore assume that the user has lost interest or resolved the problem on their own.\n\nDon't worry though; if this is an error, let us know with a comment and we'll be happy to reopen the issue.\n\nThanks!\n",
  "Issue title: bug on `clip_on=False`\n Issue body: - version: brokenaxes 0.5.0\r\n\r\nI'm using `clip_on=False` when plotting like this:\r\n```python\r\nimport matplotlib.pyplot as plt \r\nfrom brokenaxes import brokenaxes \r\nimport numpy as np \r\n\r\nfig = plt.figure(figsize=(6,4))\r\nbaxes = brokenaxes(ylims=((0,30000),(75000,85000)), hspace=.1, despine=False)\r\n\r\nX = np.sort(np.array([3,-1,0,4,5,-2,7]))\r\nY = np.array([80000,10000,5000,3000,1000,500,100])\r\nZ = np.array([800,1000,1200,3000,10000,30000,15000])\r\n\r\nbaxes.plot(X,Y,label=\"squared\", clip_on=False)  # here\r\nbaxes.plot(X,Z,label=\"cubed\", clip_on=False)  # here\r\nbaxes.legend(loc=\"best\")\r\n\r\nplt.plot()\r\nplt.show()\r\n```\r\nAnd it shows:\r\n![clip](https://user-images.githubusercontent.com/44149820/162631865-729deb75-474c-44a8-a6dc-85882d8b2229.png)\r\nBut if I set `clip_on` to `True` (or simply don't pass it), it's normal:\r\n![clip](https://user-images.githubusercontent.com/44149820/162631937-67ce3cd4-208d-4a39-b661-e5e2c5b44f38.png)\r\n\r\n\n Comments: \n Comment 0: What behavior are you trying to achieve with clip_on?\n Comment 1: Oh, I also used `marker` in my code. I missed this point in this snippet. The original code is like this:\r\n```python\r\nbax.plot(_p, _r, label=_label, c=COLOR[algo], marker=_marker, clip_on=False)\r\n```\n Comment 2: HI @bendichter \r\n\r\nFor scatter plot, we also need clip_on=False, correct?\r\n\r\n\n Comment 3: clip_on = True, dots are not completely show.\r\n\r\n![image](https://user-images.githubusercontent.com/5415510/167275441-517bf323-2636-4199-9364-a448cfb46e70.png)\r\n\r\nclip_on = False bugs..\r\n![image](https://user-images.githubusercontent.com/5415510/167275453-49d8672c-6114-455b-8b1e-78968b2aec09.png)\r\n\r\n\r\n\n Comment 4: If you have points that exceed 100\n Comment 5: Yes. But I mean the dots near the limit is clip",
  "Issue title: \u7ae0\u8282\u6807\u9898\u4e2d\u7b14\u753b\u6570\u8f83\u591a\u7684\u5b57\u663e\u793a\u4e0d\u6e05\u6670\n Issue body:![QQ\u622a\u56fe20191011210416](https://user-images.githubusercontent.com/54384435/66653466-ba6e7380-ec6a-11e9-8647-a0e1fec16fd7.jpg)\r\n\n Comments: \n Comment 0: \u8fd9\u4e2a\u9ed1\u4f53\u52a0\u7c97\u662f\u6309\u7167\u64b0\u5199\u8981\u6c42\u89c4\u5b9a\u4f7f\u7528\u7684\uff0c\u81f3\u4e8e\u4e0d\u6e05\u6670\uff0c\u90a3\u786e\u5b9e\u6ca1\u6709\u529e\u6cd5\u3002\u3002\u3002\n Comment 1: \u597d\u7684\uff0c\u8c22\u8c22\uff0c\n Comment 2: \u53d1\u73b0\u4f7f\u7528 fontset=adobe\uff0c\u5177\u4f53\u4f7f\u7528\u53ca\u5b89\u88c5\u89c1 https://github.com/mohuangrui/ucasthesis/wiki/%E5%AD%97%E4%BD%93%E9%85%8D%E7%BD%AE \uff0c\u53ef\u4ee5\u4f7f\u653e\u5927\u7684\u5b57\u4f53\u663e\u793a\u7684\u597d\u4e9b\uff0c\u7279\u522b\u662f \u96f6 \u5b57\u3002\u4f46\u4e0d\u59a8\u5927\u7684\u8bdd\uff0c\u6ca1\u6709\u533a\u522b\u3002\r\n\r\n\u6ca1\u529e\u6cd5\uff0c\u8fd9\u4e2a\u53ea\u80fd\u8fd9\u6837\u4e86\u3002\n Comment 3: \u662f\u5f00\u542f\u4f2a\u7c97\u5bfc\u81f4\u7684\u3002\u76ee\u524d\u4f7f\u7528\u7684\u662f `xecjk` \u9ed8\u8ba4\u7684\u4f2a\u7c97\u7c97\u7ec6\u7a0b\u5ea6\uff0c\u4e3a 4\u3002\u53ef\u4ee5\u8bd5\u8bd5\u8f83\u5c0f\u7684\u6570\u503c\u3002\r\n\r\n\u76ee\u524d\u5b9e\u73b0\r\nhttps://github.com/mohuangrui/ucasthesis/blob/265914d05558b54a013f4ddb56b00b6c90dbd8b2/Style/artratex.sty#L396-L414\r\n\r\n\u6d4b\u8bd5\u8f83\u5c0f\u7c97\u7ec6\u7a0b\u5ea6\r\n```latex\r\n\\documentclass{article}\r\n\\usepackage[hscale=0.9]{geometry}\r\n\\usepackage{xeCJK}\r\n\\usepackage{pgffor}\r\n\\setCJKsansfont{SimHei}\r\n\r\n\\begin{document}\r\n\\fontsize{72}{72}\\selectfont\r\n\\bfseries\\sffamily \r\n\r\n\\foreach \\i in {true, 3, 2.5, 2, 1, false} {\r\n  \\addCJKfontfeatures{AutoFakeBold=\\i}\r\n  \\i: \u6c26\u7a33\u96f6\\par\r\n}\r\n\\end{document}\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/6376638/66668078-fb748100-ec86-11e9-93ab-786ff4f5db6d.png)\r\n\r\n\u5bf9\u6bd4 Word \u91cc\u7684\u6548\u679c\r\n![image](https://user-images.githubusercontent.com/6376638/66668134-15ae5f00-ec87-11e9-97f2-96892d7382f5.png)\r\n\r\n\u770b\u8d77\u6765 `AutoFakeBold=2.5` \u6bd4\u8f83\u63a5\u8fd1 Word \u91cc\u7684\u4f2a\u7c97\u6548\u679c\u3002\u5982\u679c\u662f\u5168\u5c40\u8bbe\u5b9a\uff0c\u53ef\u4ee5\u7528 `xecjk` \u7684\u9009\u9879 `AutoFakeBold=2.5` \u6216 `EmboldenFactor=2.5`\u3002\r\n\r\n\u5177\u4f53\u6570\u503c\u53ef\u5728\u8fdb\u4e00\u6b65\u6bd4\u8f83\u540e\u786e\u5b9a\uff0c\u8fd9\u6761\u8bc4\u8bba\u53ea\u662f\u4e3a\u4e86\u6307\u51fa\uff0c\uff08\u6bd4\u9ed8\u8ba4\u7684 4\uff09\u8f83\u5c0f\u7684\u7c97\u7ec6\u7a0b\u5ea6\u80fd\u66f4\u597d\u5730\u6a21\u62df Word \u91cc\u7684\u4f2a\u7c97\u6548\u679c\uff0c\u540c\u65f6\u907f\u514d\u672c issue \u91cc\u63d0\u5230\u7684\u95ee\u9898\u3002\r\n\r\n\r\n\n Comment 4: @muzimuzhi \u5389\u5bb3\uff0c\u6ca1\u60f3\u5230\u4f60\u5bf9\u8fd9\u4e48\u591a\u5b8f\u5305\u7684\u7528\u6237\u6587\u6863\u90fd\u4e86\u89e3\u7684\u5982\u6b64\u7ec6\u81f4\uff0c\u5f88\u662f\u4f69\u670d!\n Comment 5: \u8865\u5145\u8bb0\u5f55\u4e00\u4e0b\uff1a\u4eca\u5929\u53d1\u73b0 ubuntu \u9ed8\u8ba4\u7684 evince PDF \u9605\u8bfb\u5668\u4f3c\u4e4e\u5bf9 AutoFakeBold \u7684 Windows/Adobe \u5b57\u4f53\u6709\u56fa\u5b9a\u7684\u7c97\u5ea6\u6e32\u67d3\uff0c\u5bfc\u81f4\u4ece\u89c6\u89c9\u4e0a\u65e0\u6cd5\u5224\u65ad\u8c03\u6574 AutoFakeBold \u6570\u503c\u7684\u6709\u6548\u6027\uff0c\u8fd9\u66fe\u7ecf\u5bfc\u81f4\u6211\u4ee5\u4e3a AutoFakeBold \u7684\u6570\u503c\u8c03\u6574\u662f\u65e0\u6548\u7684 Bug\uff0c\u56e0\u6b64\u518d\u6ca1\u8003\u8651\u8fc7\u8fd9\u4e2a\u9014\u5f84\u3002\r\n\r\n\u4f46\u4eca\u5929\u540c\u65f6\u5728 Linux \u548c Windows \u6d4b\u8bd5\u4f60\u7684\u4f8b\u5b50\u65f6\u53d1\u73b0\u539f\u6765\u95ee\u9898\u662f\u51fa\u5728\u4e86 PDF \u9605\u8bfb\u5668\u4e0a\uff0c\u5728\u6b64\u8bb0\u5f55\u4e00\u4e0b\uff0c\u4ee5\u9632\u4ee5\u540e\u518d\u8df3\u5751\u3002",
  "Issue title: \u5bfc\u51faWord2007\u5f02\u5e38\n Issue body:![image](https://user-images.githubusercontent.com/6939449/173722989-c98840e9-5216-44e4-b36b-40643617d3cf.png)\r\n\r\nMac \r\n\u5f53\u524d\u7248\u672c: 8.9.12\r\nStory-writer-osxarm.zip\r\n\r\n\n Comments: \n Comment 0: \u597d\u4e86\uff0c\u73b0\u5728\u5e94\u8be5\u53ef\u4ee5\u4e86\u3002\n Comment 1: \ud83d\udc4c",
  "Issue title: Crash when \"fast_search_but_no_substring=false\"\n Issue body: As soon as I start typing the program just disappears. Only when \"false\", otherwise it works when it's \"true\"\n Comments: \n Comment 0: Same issue, I use v1.0.3\n Comment 1: Happens to me too\r\nError:\r\nhttps://github.com/DoTheEvo/ANGRYsearch/issues/75#issuecomment-1259650456\n Comment 2: Same here, version 1.04-1 AUR repo, \r\n\r\nTo clear this I need to delete the conf file so that it re creates it\r\n",
  "Issue title: Extension work using // stops\n Issue body: Sorry, I'm using Google Translator\r\n\r\nUsing // in the documenting comment / ** * / I get two exceptions:\r\n\r\n> todo-tree: Invalid regular expression: /*//TODO/: Nothing to repeat\r\n> Running the contributed command: 'todo-tree.refresh' failed.\r\n```\r\nExample:\r\n/** \r\n* //TODO: Make custom downloads\r\n*! Exception handling fails\r\n*/\r\n```\n Comments: \n Comment 0: Please post your `todo-tree.regex.regex` setting - I expect you need to escape some characters.\n Comment 1: ```((//|#|<!--|;|/\\*|^)\\s*($TAGS)|^\\s*- \\[ \\])```\n Comment 2: That is the default regex. Have you made any other settings changes? If I put your example in my code it finds the TODO correctly.\r\n\r\nPlease can you set `todo-tree.general.debug` to `true` to then go to the output view. You should find \"Todo Tree\" in the drop down list. Please select it and copy the contents here.\n Comment 3: I added a record `* TODO: ` to the parameter `General: Tags`. But without this, errors still appear.\r\nHere is the result you requested:\r\n```\r\nSearching d:\\NodeJSProjects\\VueCLI\\folderProject...\r\nCommand: \"c:\\Users\\WorkerSEE\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\node_modules.asar.unpacked\\vscode-ripgrep\\bin\\rg.exe\" --no-messages --vimgrep -H --column --line-number --color never --max-columns=1000 --no-config  -e \"((//|#|<!--|;|/\\*|^)\\s*(TODO|FIXME|\\* TODO)|^\\s*- \\[ \\])\" \"d:\\NodeJSProjects\\VueCLI\\folderProject\"\r\n Match (Editor):{\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\server\\\\routes\\\\photographerApi.js\",\"line\":170,\"column\":25,\"match\":\"                        // TODO rea-media api key\"}\r\nd:\\NodeJSProjects\\VueCLI\\folderProject\\src\\mixins\\FirebaseMixins.js:241:1:                TODO: \u041e\u043f\u0438\u0441\u0430\u0442\u044c \u043e\u0431\u044a\u0435\u043a\u0442\r\n\r\nd:\\NodeJSProjects\\VueCLI\\folderProject\\src\\template-component\\test.vue:73:1:             * TODO: \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u0438\u043c\u044f \u0441 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442\u0430\r\n\r\nd:\\NodeJSProjects\\VueCLI\\folderProject\\src\\views\\Objects.vue:454:24:                  <!-- // TODO: \u0414\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0444\u0438\u043b\u044c\u0442\u0440 \u0434\u043b\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439-->\r\nd:\\NodeJSProjects\\VueCLI\\folderProject\\src\\views\\Objects.vue:810:1:// TODO: \u043e\u043f\u0438\u0441\u0430\u0442\u044c \u043d\u0430\u0447\u0430\u043b\u044c\u043d\u0443\u044e \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044e \u043e\u0431\u044a\u0435\u043a\u0442\u0430\r\nd:\\NodeJSProjects\\VueCLI\\folderProject\\src\\views\\Objects.vue:1983:12:         * // TODO: \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u044c \u043c\u0430\u0441\u0441\u0438\u0432 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u043c\u0430\u0441\u0441\u0438\u0432 \u0441 \u0438\u043c\u0435\u043d\u0430\u043c\u0438\r\nd:\\NodeJSProjects\\VueCLI\\folderProject\\src\\views\\Objects.vue:1984:12:         * // TODO: \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u0438\u043c\u044f \u0441 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442\u0430\r\nd:\\NodeJSProjects\\VueCLI\\folderProject\\src\\views\\Objects.vue:1985:12:         * // TODO: \u0421\u043f\u0438\u043d\u043d\u0435\u0440 \u043f\u0440\u0438 \u0441\u043a\u0430\u0447\u0438\u0432\u0430\u043d\u0438\u0438 \u0444\u0430\u0439\u043b\u043e\u0432\r\nd:\\NodeJSProjects\\VueCLI\\folderProject\\src\\views\\Objects.vue:1986:12:         * // TODO: \u0441\u043a\u0430\u0447\u0438\u0432\u0430\u043d\u0438\u0435 \u0430\u043d\u043a\u0435\u0442\u044b \u0432\u043c\u0435\u0441\u0442\u0435 \u0441 \u0444\u0430\u0439\u043b\u0430\u043c\u0438\r\nd:\\NodeJSProjects\\VueCLI\\folderProject\\src\\views\\Objects.vue:1987:12:         * // TODO: \u0441\u043a\u0430\u0447\u0438\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u043e\u0432 \u043f\u043e \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438\r\nd:\\NodeJSProjects\\VueCLI\\folderProject\\src\\views\\Objects.vue:1988:1:         * TODO: \u0435\u0441\u043b\u0438 \u0441\u043a\u0430\u0447\u0438\u0432\u0430\u044e\u0442 \u043e\u0434\u0438\u043d \u0447\u0435\u0440\u0435\u0437 \u043f\u0430\u043d\u0435\u043b\u044c\r\n\r\nd:\\NodeJSProjects\\VueCLI\\folderProject\\src\\server\\routes\\photographerApi.js:170:25:                        // TODO photographer api key\r\n\r\n Match (File): {\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\mixins\\\\FirebaseMixins.js\",\"line\":\"241\",\"column\":\"1\",\"match\":\"                TODO: \u041e\u043f\u0438\u0441\u0430\u0442\u044c \u043e\u0431\u044a\u0435\u043a\u0442\"}\r\n Match (File): {\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\template-component\\\\test.vue\",\"line\":\"73\",\"column\":\"1\",\"match\":\"             * TODO: \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u0438\u043c\u044f \u0441 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442\u0430\"}\r\n Match (File): {\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\views\\\\Objects.vue\",\"line\":\"454\",\"column\":\"24\",\"match\":\"                  <!-- // TODO: \u0414\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0444\u0438\u043b\u044c\u0442\u0440 \u0434\u043b\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439-->\"}\r\n Match (File): {\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\views\\\\Objects.vue\",\"line\":\"810\",\"column\":\"1\",\"match\":\"// TODO: \u043e\u043f\u0438\u0441\u0430\u0442\u044c \u043d\u0430\u0447\u0430\u043b\u044c\u043d\u0443\u044e \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044e \u043e\u0431\u044a\u0435\u043a\u0442\u0430\"}\r\n Match (File): {\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\views\\\\Objects.vue\",\"line\":\"1983\",\"column\":\"12\",\"match\":\"         * // TODO: \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u044c \u043c\u0430\u0441\u0441\u0438\u0432 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u043c\u0430\u0441\u0441\u0438\u0432 \u0441 \u0438\u043c\u0435\u043d\u0430\u043c\u0438\"}\r\n Match (File): {\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\views\\\\Objects.vue\",\"line\":\"1984\",\"column\":\"12\",\"match\":\"         * // TODO: \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u0438\u043c\u044f \u0441 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442\u0430\"}\r\n Match (File): {\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\views\\\\Objects.vue\",\"line\":\"1985\",\"column\":\"12\",\"match\":\"         * // TODO: \u0421\u043f\u0438\u043d\u043d\u0435\u0440 \u043f\u0440\u0438 \u0441\u043a\u0430\u0447\u0438\u0432\u0430\u043d\u0438\u0438 \u0444\u0430\u0439\u043b\u043e\u0432\"}\r\n Match (File): {\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\views\\\\Objects.vue\",\"line\":\"1986\",\"column\":\"12\",\"match\":\"         * // TODO: \u0441\u043a\u0430\u0447\u0438\u0432\u0430\u043d\u0438\u0435 \u0430\u043d\u043a\u0435\u0442\u044b \u0432\u043c\u0435\u0441\u0442\u0435 \u0441 \u0444\u0430\u0439\u043b\u0430\u043c\u0438\"}\r\n Match (File): {\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\views\\\\Objects.vue\",\"line\":\"1987\",\"column\":\"12\",\"match\":\"         * // TODO: \u0441\u043a\u0430\u0447\u0438\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u043e\u0432 \u043f\u043e \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438\"}\r\n Match (File): {\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\views\\\\Objects.vue\",\"line\":\"1988\",\"column\":\"1\",\"match\":\"         * TODO: \u0435\u0441\u043b\u0438 \u0441\u043a\u0430\u0447\u0438\u0432\u0430\u044e\u0442 \u043e\u0434\u0438\u043d \u0447\u0435\u0440\u0435\u0437 \u043f\u0430\u043d\u0435\u043b\u044c\"}\r\n Match (File): {\"file\":\"d:\\\\NodeJSProjects\\\\VueCLI\\\\folderProject\\\\src\\\\server\\\\routes\\\\photographerApi.js\",\"line\":\"170\",\"column\":\"25\",\"match\":\"                        // TODO rea-media api key\"}\r\nFound 12 items\r\nFound 12 items\r\n```\r\n_p.s. Sorry, comments are written in Russian_\n Comment 4: Hi - are you still having problems with this? I have tried adding `* TODO` as a tag and it works as expect for me.\r\n\r\nWhat errors are you seeing?\n Comment 5: I'm going to close this - please feel free to reopen it if you can give me any further information. \n Comment 6: The extension used to work well, but now it doesn't. I get this error message. Running the contributed command: 'todo-tree.refresh' failed.\n Comment 7: What version of vscode are you using?\n Comment 8:![Screenshot_3](https://user-images.githubusercontent.com/29357907/82152569-d70b0380-986a-11ea-8b24-c5d09195f4a2.png)\r\n\n Comment 9: Your version is quite out of date. The version of the extension is not compatible - you'll either need to update vscode or revert to an earlier version of the extension. Sorry - I need to put it a dependency check.\n Comment 10: Thanks!",
  "Issue title: Error running serverless demo deployment script\n Issue body: I am getting the following error when attempting to run the serverless demo deployment script from https://github.com/aws/amazon-chime-sdk-js/tree/master/demos/serverless\r\n\r\nI am on step `npm run deploy -- -r us-east-1 -b <my-bucket> -s <my-stack-name> -a meeting`\r\n\r\n```\r\nCommand npm failed with exit code 1 signal null\r\nnpm ERR! code ERESOLVE\r\nnpm ERR! ERESOLVE unable to resolve dependency tree\r\nnpm ERR!\r\nnpm ERR! While resolving: sharon89@example.org\r\nnpm ERR! Found: sharon89@example.org\r\nnpm ERR! node_modules/jest\r\nnpm ERR!   dev jest@\"^24.8.0\" from the root project\r\nnpm ERR!\r\nnpm ERR! Could not resolve dependency:\r\nnpm ERR! peer jest@\">=26 <27\" from sharon89@example.org\r\nnpm ERR! node_modules/ts-jest\r\nnpm ERR!   dev ts-jest@\"^26.1.1\" from the root project\r\n```\r\n\r\n- macOS Catalina 10.15.7.\r\n- npm 7.5.4\r\n- node v14.15.5\r\n\r\nThanks.\r\n\n Comments: \n Comment 0: Hey @adambyer, thanks for trying out our serverless demo deployment. I would suggest double checking that you've built the demo/browser demo and then trying again. Please let us know if you are running into more issues.\n Comment 1: Thanks @michhyun1. I'm still getting the same error. Are you referring to https://github.com/aws/amazon-chime-sdk-js/tree/master/demos/browser? I have run `npm run start` which results in `server running at http://116.69.203.115:8080/` but I still get the error when trying to deploy the serverless demo.\n Comment 2: @adambyer Okay, I just want to double check that you've followed the instructions [here](https://github.com/aws/amazon-chime-sdk-js/blob/master/demos/serverless/README.md)\r\n\r\nI just did a fresh clone and was able to deploy the demo fine, but please let me know if these steps still dont work for you.\n Comment 3: Hi @michhyun1. I tried starting from scratch but still not having any luck. Here are the steps I'm doing...\r\n\r\n- git clone sharon89@example.org:aws/amazon-chime-sdk-js.git\r\n- cd amazon-chime-sdk-js/demos/browser\r\n- npm run start\r\n- that seems ok... I get `server running at http://116.69.203.115:8080/`\r\n- cd demos/serverless\r\n- npm install\r\n- npm run deploy -- -r us-east-1 -b chime-demo.mydomain.com -s chime-demo -a meeting\r\n\r\nThat's when I get the error. Let me know if I'm missing anything.\r\n\r\nThanks again.\n Comment 4: Interesting, I just cloned the repo and followed the exact steps as you and I was able to deploy still. I'm not sure why node_modules/jest was found in your logs, since we dont have a dependency on it\n Comment 5: It looks like serverless has a dependency for `aws-embedded-metrics` and that has a dependency for `jest`.\n Comment 6: Hmm @adambyer I followed your steps again but Im not able to repro that issue. The only thing I can think of is maybe the npm vserion, since I am on 6.12.1, node version - v12.13.1\n Comment 7: Yes it looks like it's due to a change in npm v7 in the way it handles peer dependencies...\r\n\r\nhttps://github.blog/2021-02-02-npm-7-is-now-generally-available/#peer-dependencies\r\n",
  "Issue title: \u4fee\u6539\u5e16\u5b50\u65f6\u6709xss\u6f0f\u6d1e,\u7248\u672c(3.5.1)\n Issue body: \u6839\u636e\u6b64\u9879\u76ee\u62a5\u544a\u5b89\u5168\u6f0f\u6d1e\u7684\u7b56\u7565.\r\n<img width=\"1079\" alt=\"20000\" src=\"https://user-images.githubusercontent.com/55778895/66256003-4b9da000-e7bc-11e9-8c42-c9480539cee5.png\">\r\n\r\n\u6211\u5df2\u5c06\u5177\u4f53\u6f0f\u6d1e\u8be6\u60c5\u53d1\u90ae\u4ef6\u81f3\u4f60\u7684\u90ae\u7bb1 **matthew98@example.org** \u6ce8\u610f\u67e5\u6536.\r\n\r\n\r\n\n Comments: \n Comment 0: \u611f\u8c22\u53cd\u9988\uff0c\u5df2\u7ecf\u6536\u5230\u90ae\u4ef6\u3002\u7a0d\u540e\u4fee\u590d\u540e\u4f1a\u5c06\u4f60\u7684\u62a5\u544a\u9644\u4ef6\u8fdb\u884c\u62ab\u9732\u3002\n Comment 1: \u6f0f\u6d1e\u7ec6\u8282\u62a5\u544a\u62ab\u9732\uff1a[symphony(3.5.1)\u4fee\u6539\u5e16\u5b50\u65f6\u5b58\u5728xss\u6f0f\u6d1e.docx](https://github.com/b3log/symphony/files/3693397/symphony.3.5.1.xss.docx)\r\n\r\n\u63d0\u4ea4 fef63c275 \u4e2d\u8fdb\u884c\u4fee\u590d\u3002\r\n",
  "Issue title: somehow show stack trace for errors when appropriate\n Issue body: https://github.com/component/component/commit/7d795a734bd909e6fe4fdc3e660ddc53078268de#commitcomment-5917645\n\nmaybe change back to `fatal(err)`. maybe add a flag to errors with useful stacktraces.\n\n Comments: \n Comment 0: i updated console.js to show stacktraces for user errors. please reopen if it's still an issue\n",
  "Issue title: shopify feature does not work properly in app\n Issue body: Has anyone successfully added the shopify feature on SiberianCMS\r\n\r\n PE and had it work correctly?\r\n\r\nI added the shopify feature to one of my apps and it did not open properly on the app rather it displays in a small frame below the app menu, which is not even noticeable. I accidentally noticed that that\u2019s where it displays.\r\n\r\nHas someone ever encountered this bug?\r\n\r\nSiberian CMS Team please look into this bug and fix. So that shopify store owners can use the platform to create a mobile app for their store.\r\n\r\n![screenshot_2017-08-11-16-39-03](https://user-images.githubusercontent.com/30932682/29222785-df42d06c-7ebb-11e7-9fac-c774bd2fe29a.png)\r\n\n Comments: \n Comment 0: Shopify `feature` is only an alias for `Link` feature, so can you try with link?\n Comment 1: I noticed that the Shopify feature is only an alias for Link. So I tried the Link feature and it performs the same way. See the app below that has the shopify feature.\r\n\r\nhttps://apps.mobileappforeveryone.com/5987c4a93e87d/\n Comment 2: Seems the webview doesn't handle very well the Shopify css, you must force the use of chrome in this case, we can't do anything on this side.\n Comment 3: Thanks for your response. But just to be clear, is this an issue with Siberian CMS at the moment?\n Comment 4: No it's not an issue, it's just that the webview doesn't seem to like shopify.\n Comment 5: so any solution for that issue so far, missing shopify is catastrophic disadvantage ",
  "Issue title: assert in terminal_test with Archlinux's default flag\n Issue body: <!--## Prerequisites\r\n\r\n- Many many thanks for taking part in this community, we really appreciate that.\r\n- Please make sure this issue you are facing isn't already reported.\r\n- It would be really nice if you can confirm that this issue is reproducible with the latest Contour version from the release page or ideally master branch; however, this isn't a hard requirement for reporting bugs.\r\n-->\r\n\r\n## Description\r\n```\r\n$./build/src/terminal/terminal_test\r\n/usr/include/c++/11.2.0/bits/stl_algo.h:3658: constexpr const _Tp& st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5clamp(const _Tp&, const _Tp&, const _Tp&) [with _Tp = int]: Assertion '!(__hi < __lo)' failed.\r\n\r\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nterminal_test is a Catch v3.0.0-preview.3 host application.\r\nRun with -? for options\r\n\r\nRandomness seeded to: 23014433\r\n\r\n-------------------------------------------------------------------------------\r\ncaptureBuffer\r\n  lines: 0\r\n-------------------------------------------------------------------------------\r\n/home/vl/Downloads/contour/src/terminal/Screen_test.cpp:1753\r\n...............................................................................\r\n\r\n/home/vl/Downloads/contour/src/terminal/Screen_test.cpp:1753: FAILED:\r\ndue to a fatal error condition:\r\n  SIGABRT - Abort (abnormal termination) signal\r\n\r\n===============================================================================\r\ntest cases:  89 |  88 passed | 1 failed\r\nassertions: 837 | 836 passed | 1 failed\r\n\r\n[1]    48465 abort (core dumped) ./build/src/terminal/terminal_test\r\n```\r\n\r\nThe default flag `-Wp,-D_GLIBCXX_ASSERTIONS` causing assertion.\r\nmaybe add a ci for that kind of thing\r\n\r\ntest-assert.patch\r\n```patch\r\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\r\nindex b962666..27f7d98 100644\r\n--- a/CMakeLists.txt\r\n+++ b/CMakeLists.txt\r\n@@ -14,6 +14,8 @@ set(CMAKE_CXX_STANDARD_REQUIRED ON)\r\n set(CMAKE_CXX_EXTENSIONS OFF)\r\n set(CMAKE_EXPORT_COMPILE_COMMANDS ON)\r\n\r\n+set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wp,-D_GLIBCXX_ASSERTIONS\")\r\n+\r\n if(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES)\r\n   set(CMAKE_BUILD_TYPE RelWithDebInfo CACHE\r\n     STRING \"Choose the build mode.\" FORCE)\r\n```\r\n\r\n## Environment\r\n\r\n- Git commit hash: 61263c7a75c8624a2d0f5ddad248c2225be616f6\r\n- Operating System: Archlinux\r\n- Contour configuration: default one\r\n\r\n## Steps to Reproduce\r\n```\r\ngit clone https://github.com/contour-terminal/contour.git\r\ncd contour\r\npatch -Np1 -i test-assert.patch\r\ncmake -S. -B build -GNinja -DCMAKE_BUILD_TYPE=Release\r\ncmake --build build\r\n./build/src/terminal/terminal_test\r\n```\r\n\n Comments: \n Comment 0: Wow. Nice catch! Many thanks @vnepogodin.\r\n\r\nAlso thanks for the `D_GLIBCXX_ASSERTIONS` tip.",
  "Issue title: Locate repo from subdir or active repo\n Issue body: See discussion here https://github.com/r-lib/gert/pull/6\n Comments: \n Comment 0: @jennybc @richfitz The commit above changes the default so that it now searches parent directories for the git repo. I think this behavior matches the command line `git`. \r\n\r\nDoes this make sense or should the user be able to explicitly specify wether or not to search parent directories for a `.git` folder?\n Comment 1: I suppose you (or someone) will need a way to prevent recursive upward search. The fact that `git2r38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5iscover_repository()` has a related `ceiling` argument supports the idea that there needs to be some way to control this.\r\n\r\nBut I think this need is pretty rare, so it could be semi-inconvenient. Would a withr-style `with_()` or `local_()` function be the way to do it? Because I imagine most repo discovery is happening automatically, i.e. not from a direct call.\n Comment 2: Yes this is a standard API: https://libgit2.org/libgit2/#HEAD/group/repository/git_repository_discover\r\n\r\nI have never run into a case where you need a \"ceiling\" parameter so I'm not sure how useful it is to expose all that, but if it is we can wrap the argument of course.\r\n\r\n\n Comment 3: I think the only time I felt the need for it was writing tests for my own attempt at a wrapper around git2r, with git repos that were test fixtures. And the much better solution there was to always put the test repos below session temp dir, instead of below the package itself.\n Comment 4: This is already sorted out.\r\n\r\nBy default `git_open()` will search recursively up and `git_open()` is used to process `repo` all over the place. So recursive search works in general and default behaviour.\r\n\r\nHowever, if someone really wants to prevent that, they can pass a path protected by `I()`, which was already in place before I started working here. I have now documented this behaviour and added a test.",
  "Issue title: Change location accuracy for Google Analytics threshold\n Issue body: @cagryInside I was looking at some of the location data from a few Android phones, and I'm thinking it probably makes sense to tighten up the horizontal accuracy threshold prior to a production release.\r\n\r\nCurrently, [we're using 100m](https://github.com/OneBusAway/onebusaway-android/blob/master/onebusaway-android/src/main/java/com/joulespersecond/oba/ObaAnalytics.java#L43) as the cutoff threshold - meaning that we report analytics for distance to stop if the estimated error radius of the location point is less than 100m, and throw it away if its >= 100m.\r\n\r\nI'm thinking it may be better to change this to 50m, so we have a tigher bound/accuracy on the analyitics data.  Looking at a few devices, most of them report accuracy < 50m when its reasonable.  If its more than 50m, it starts getting questionable, especially for our [smallest radii](https://github.com/OneBusAway/onebusaway-android/blob/master/onebusaway-android/src/main/java/com/joulespersecond/oba/ObaAnalytics.java#L51), which is defined at 50m separation.\r\n\r\nYour thoughts?  Any data from your devices?\r\n\r\nGood apps to test with are [GPS Benchmark](https://play.google.com/store/apps/details?id=com.gpsbenchmark.android) and [GPSTest](https://play.google.com/store/apps/details?id=com.android.gpstest) (yes, they are both my apps ;) ).\n Comments: \n Comment 0: @barbeau In the high-end device (nexus 6) I usually measure the horizontal accuracy <30m. But, I think we should also measure some results with older devices to see the variation.\n\n Comment 1: I was looking at data I collected from a number of Android 2.1 and 2.2\ndevices a while back, and it seems consistently <50m are good locations.\nOn Feb 27, 2015 12:14 PM, \"Cagri Cetin\" <robin24@example.net> wrote:\n\n> @barbeau <https://github.com/barbeau> In the high-end device (nexus 6) I\n> usually measure the horizontal accuracy <30m. But, I think we should also\n> measure some results with older devices to see the variation.\n>\n> \u2014\n> Reply to this email directly or view it on GitHub\n> <https://github.com/OneBusAway/onebusaway-android/issues/232#issuecomment-76431617>\n>.\n>\n",
  "Issue title: Brouter no more supported in version 3.4.6?\n Issue body: Hi,\r\nI just udpated to 3.4.6, and I don't find any more how to choose the routing service. I'm used to Brouter, wich I find superior on bicycle routing calculation and faster than osmand's in-app routing service (I'm speaking about offline routing only).\r\n\r\nIs it a strategy choice or an issue? I didn't find discussions about it in the issues.\r\n\r\nThanks for the work!\r\n\r\nOsmand 3.4.6 on LineageOS 14.1 (Android 7.1.2)\r\n\n Comments: \n Comment 0: It seems that now you have to go to `Settings` \u2192 `Application profiles` \u2192 `Add`, select the profile type and at the `Navigation type` choose BRouter.\r\n\r\nAt least this is what I had to do to select BRouter for driving (and I didn't find an easier way for this).\n Comment 1: Hello! Yes, in the current version, we disable the ability to change navigation type in the default profiles, you need to create custom to use external services and customized routing.xml.\n Comment 2: Ok thanks, that's working well!\n Comment 3: The problem still exist in version 3.5. It is not possible to select other routing mechanism.\r\nIs this a problem or just a design decision?\n Comment 4: @rgbimport Hello! In 3.5.5 you need to create custom profile and that select Brouter as navigation type. In current nightly builds, you can set navigation type in any profile.\n Comment 5: I see it. Thanks",
  "Issue title: Add weight to AllocationDecider\n Issue body: AllocationDeciders (plural) currently take all the AllocationDecider instances in a set. While the order does not matter for a \"yes\" decision (because it must be unanimous), a \"no\" or \"throttle\" decision could be optimized if cheaper deciders were allowed to run first.\r\n\r\nAdding a weight, with a default of 1.0 (easy since AllocationDecider is an abstract class), would allow expensive deciders to increase their weight and run later.\n Comments: \n Comment 0: @rjernst we do optimize the order of the AllocationDeciders to have the cheapest ones run first and short-circuit on \"NO\" answers, are you saying we should have the allocation deciders decide the weight themselves?\n Comment 1: @dakrone I think that is not true - it's a set so it order is undefined?\n\n Comment 2: Yeah, the injected AllocationDeciders ctor takes a set of AllocationDecider instances, so no order that I see. @dakrone Yes, I think the deciders should give their own weight. They are should be self aware of their expensiveness.\n Comment 3: Ahh okay, I thought I remembered a commit changing that. Frustrating that we can't inject an ordered list by default with Guice. +1 to weight then.\n\n Comment 4: Now that allocation deciders are de-guiced, I think we can do this with regular ordering instead of adding a weight, and it should be less complex to implement\n",
  "Issue title: Subscription should have a flat_map\n Issue body: I just encountered a situation where I would like to produce three distinct events that are also produced by buttons when I get one of three keypresses. To support this, I made my message an Option:\r\n\r\n```rust\r\ntype Message = Option<Message>;\r\n```\r\n\r\nI think an easier approach would be to support flat_map on `Subscription`. Right now, `Subscription` has a method [`map`](https://docs.rs/iced_futures/0.1.2/iced_futures/subscription/struct.Subscription.html#method.map). This method is useful to convert to events, but some subscriptions might lead to several events being produced or no events being produced. Currently, I see no API to accommodate that. I think we should add a `flat_map` method to `Subscription`. This would allow us to return anything that impls `IntoIterator` from `flat_map` and produce a new subscription that flattens the iterator. An example should be provided that uses a `flat_map` with `Option` so people are aware that is possible (many don't know `Option` impls `IntoIterator`).\r\n\r\nI am willing to set up a PR for this if this makes sense. Just let me know.\n Comments: \n Comment 0: I am not convinced we should complicate the subscriptions API to potentially allow combinators with complex logic.\r\n\r\nA `Subscription` always produces messages with a given contract. I find it's easier to think about them this way. Then, your `update` logic can choose to handle the relevant messages and ignore the others. I find this forces users to keep message logic centralized in a single place.",
  "Issue title: ERROR: pycocotools unable to run: list index out of range\n Issue body: I meet a problem\uff0chow can i solve it?\r\n\r\nCOCO mAP with pycocotools... saving detections_val2017__results.json...\r\nERROR: pycocotools unable to run: list index out of range\r\nOptimizer stripped from runs/exp5/weights/last.pt, 14.7MB\r\nOptimizer stripped from runs/exp5/weights/best.pt, 14.7MB\r\n\n Comments: \n Comment 0: Hello @Lie-huo, thank you for your interest in our work! Please visit our [Custom Training Tutorial](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data) to get started, and see our [Jupyter Notebook](https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb) <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>, [Docker Image](https://hub.docker.com/r/ultralytics/yolov5), and [Google Cloud Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart) for example environments.\n  \nIf this is a bug report, please provide screenshots and **minimum viable code to reproduce your issue**, otherwise we can not help you.\n  \nIf this is a custom model or data training question, please note that Ultralytics does **not** provide free personal support. As a leader in vision ML and AI, we do offer professional consulting, from simple expert advice up to delivery of fully customized, end-to-end production solutions for our clients, such as:\n- **Cloud-based AI** systems operating on **hundreds of HD video streams in realtime.**\n- **Edge AI** integrated into custom iOS and Android apps for realtime **30 FPS video inference.**\n- **Custom data training**, hyperparameter evolution, and model exportation to any destination.\n\nFor more information please visit https://www.ultralytics.com.\n Comment 1: @Lie-huo pycocotools is an add-on you can use with COCO data. It will try and run anytime your data file is coco.yaml.",
  "Issue title: Curve is not defined\n Issue body: ################## IS THIS\n Comments: \n Comment 0:?",
  "Issue title: IIS tests are timing out \n Issue body: ## Failing Test(s)\r\n\r\n<!--\r\nProvide the fully qualified name(s) of the failing tests.\r\n-->\r\n\r\n- Microsoft.AspNetCore.Server.IIS.FunctionalTests.StartupTests.StartupTimeoutIsApplied\r\n\r\n## Error Message\r\n\r\n<!--\r\nProvide the error message associated with the test failure, if applicable.\r\n-->\r\n\r\n```text\r\n[xUnit.net 00:37:57.69] IIS.FunctionalTests: [Long Running Test] 'Microsoft.AspNetCore.Server.IIS.FunctionalTests.StartupTests.StartupTimeoutIsApplied', Elapsed: 00:01:01\r\n```\r\n\r\n## Stacktrace\r\n\r\n<details>\r\n<!--\r\nProvide the stack trace associated with the test failure, if applicable.\r\n-->\r\n\r\n```text\r\n\r\n```\r\n</details>\r\n\r\n\r\n## Logs\r\nhttps://helixre8s23ayyeko0k025g8.blob.core.windows.net/dotnet-aspnetcore-refs-heads-main-4c1249124fe444a7a4/IIS.FunctionalTests--net7.0/1/console.a5f2a058.log?sv=2019-07-07&se=2021-11-17T16%3A45%3A05Z&sr=c&sp=rl&sig=NdiB0pT0IoDtqVqErQu47eiso%2BOwkbPETL70HkXum2w%3D\r\n\r\nhttps://helixre8s23ayyeko0k025g8.blob.core.windows.net/dotnet-aspnetcore-refs-heads-main-7dbe5a6acd384f8cb5/IIS.FunctionalTests--net7.0/1/console.8b7ec6e2.log?sv=2019-07-07&se=2021-11-17T18%3A22%3A00Z&sr=c&sp=rl&sig=3vE%2FoBIyCGQVirD0aYEiW1GC5VHX3Tuu%2BNZPbSe1eUU%3D\r\n\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=1444604\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=1444750\r\n\r\nTest.log added to details\r\n\r\n<details>\r\n\r\n```text\r\n[0.001s] [TestLifetime] [Information] Starting test StartupTimeoutIsApplied at 2021-10-28T18:56:51\r\n[0.004s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Information] Deploying [Variation] 38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5 ServerType=IIS, Runtime=CoreClr, Arch=x64, BaseUrlHint=, Publish=True\r\n[0.004s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Information] Microsoft Windows NT 10.0.22000.0\r\n[0.004s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Information] Using prepublished application from C:\\h\\w\\BF4609DC\\w\\B0B50971\\e\\InProcessWebSite-Portable\r\n[0.006s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug] Processing C:\\h\\w\\BF4609DC\\t\\f3bf46ffe0f34dc39a9b96a7fa343f72\\runtimes\\win\\lib\\net7.0\r\n[0.006s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying System.Diagnostics.EventLog.dll\r\n[0.006s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying System.Diagnostics.EventLog.Messages.dll\r\n[0.007s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug] Processing C:\\h\\w\\BF4609DC\\t\\f3bf46ffe0f34dc39a9b96a7fa343f72\\runtimes\\win\\lib\r\n[0.007s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug] Processing C:\\h\\w\\BF4609DC\\t\\f3bf46ffe0f34dc39a9b96a7fa343f72\\runtimes\\win\r\n[0.007s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug] Processing C:\\h\\w\\BF4609DC\\t\\f3bf46ffe0f34dc39a9b96a7fa343f72\\runtimes\r\n[0.008s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug] Processing C:\\h\\w\\BF4609DC\\t\\f3bf46ffe0f34dc39a9b96a7fa343f72\\wwwroot\r\n[0.008s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying static.txt\r\n[0.008s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug] Processing C:\\h\\w\\BF4609DC\\t\\f3bf46ffe0f34dc39a9b96a7fa343f72\\x64\r\n[0.009s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying aspnetcorev2_inprocess.dll\r\n[0.009s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug] Processing C:\\h\\w\\BF4609DC\\t\\f3bf46ffe0f34dc39a9b96a7fa343f72\\x86\r\n[0.009s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying aspnetcorev2_inprocess.dll\r\n[0.010s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug] Processing C:\\h\\w\\BF4609DC\\t\\f3bf46ffe0f34dc39a9b96a7fa343f72\r\n[0.010s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying InProcessWebSite.deps.json\r\n[0.011s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying InProcessWebSite.dll\r\n[0.011s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying InProcessWebSite.exe\r\n[0.012s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying InProcessWebSite.pdb\r\n[0.012s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying InProcessWebSite.runtimeconfig.json\r\n[0.012s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying Microsoft.AspNetCore.Authentication.Abstractions.dll\r\n[0.013s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying Microsoft.AspNetCore.Authentication.Abstractions.pdb\r\n[0.013s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying Microsoft.AspNetCore.Authentication.Abstractions.xml\r\n[0.014s] [Microsoft.AspNetCore.Server.IntegrationTesting.IIS.IISDeployer] [Debug]   Copying Microsoft.AspNetCore.Authentication.Core.dll\r\n[0.014s]",
  "Issue title: How to Customize Folder Search \n Issue body:![QQ\u622a\u56fe20220322143909](https://user-images.githubusercontent.com/11673386/159422572-7e218a55-8d32-49b7-b588-f53240631f5e.png)\r\n\n Comments: \n Comment 0: Hi @qiandi,\r\n\r\nThis is not possible with Dokan but you might be able to do it with an explorer extension? I never tried that.",
  "Issue title: Dotnet run a web project failed with Unhandled expection after isntall.NET Core 3.0 Preview 7\n Issue body: ## Steps to reproduce\r\n1.Install.NET Core 3.0 Preview 6 build 3.0.100-preview7-012621\r\n2.Open Cmd, create a c# ASP.NET Core web project\r\n3.Dotnet run \r\n\r\n## Expected  behavior\r\nDotnet  run succeeded.\r\n\r\n## Actual behavior\r\nDotnet run failed\r\n![image](https://user-images.githubusercontent.com/38854445/60165775-804fa200-9832-11e9-94e4-97268c7b4f15.png)\r\n\r\nNote:\r\n    1.This issue is repro when we create webapi/mvc\uff0c also repro on f#\r\n    2. Dotnet restore and dotnet build works fine\r\n\r\n## Environment data\r\n`dotnet --info` output:\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.0.100-preview7-012621\u200b\r\n Commit:    629a4be4f6\u200b\r\n\u200b\r\nRuntime Environment:\u200b\r\n OS Name:     Mac OS X\u200b\r\n OS Version:  10.14\u200b\r\n OS Platform: Darwin\u200b\r\n RID:         osx.10.14-x64\u200b\r\n Base Path:   /usr/local/share/dotnet/sdk/3.0.100-preview7-012621/\u200b\r\n\u200b\r\nHost (useful for support):\u200b\r\n  Version: 3.0.0-preview7-27825-10\u200b\r\n  Commit:  2954215e45\u200b\r\n\u200b\r\n.NET Core SDKs installed:\u200b\r\n  3.0.100-preview7-012621 [/usr/local/share/dotnet/sdk]\u200b\r\n\u200b\r\n.NET Core runtimes installed:\u200b\r\n  Microsoft.AspNetCore.App 3.0.0-preview7.19325.3 [/usr/local/share/dotnet/shared/Microsoft.AspNetCore.App]\u200b\r\n  Microsoft.NETCore.App 3.0.0-preview7-27825-10 [/usr/local/share/dotnet/shared/Microsoft.NETCore.App]\u200b\r\n\u200b\r\nTo install additional.NET Core runtimes or SDKs:\u200b\r\n  https://aka.ms/dotnet-download\u200b\n Comments: \n Comment 0: This seems more like a asp.net issue.\r\n\r\n@anurse can you direct this issue appropriately?\n Comment 1: This issue was moved to aspnet/Extensions#1891\n Comment 2: thanks @anurse ",
  "Issue title: mudtable click order by field trigger twice ServerReload\n Issue body:![image](https://user-images.githubusercontent.com/1549611/125898492-5617bfd0-e732-4587-936d-bc623c44d861.png)\r\n\r\n\n Comments: \n Comment 0: Somebody take a look at this problem\n Comment 1: There are duplicate issues about it and we move together on #1403.",
  "Issue title: When is this package compatible with Laravel 5.5?\n Issue body: When is this package compatible with Laravel 5.5?\r\nthx\n Comments: \n Comment 0: +1\n Comment 1: +1\n Comment 2: https://github.com/jenssegers/laravel-mongodb/releases/tag/v3.3.0-alpha\r\n\r\nWe should test it out\n Comment 3: Now it is.\n Comment 4: Thanks \ud83d\udc4f",
  "Issue title: Bug with trait inheritance and trait objects\n Issue body: If you try to call an inherited method on an trait object, it instead calls a regular method of the trait itself, or potentially crashes if the signatures don't match.\n\nTest case:\n\n```\ntrait Base {\n    fn baz(&self);\n}\n\ntrait Super: Base {\n    fn bar(&self);\n}\n\nstruct X;\n\nimpl Base for X {\n    fn baz(&self) {\n        println(\"base baz\");\n    }\n}\n\nimpl Super for X {\n    fn bar(&self) {\n        println(\"super bar\");\n    }\n}\n\nfn main() {\n    let n = X;\n    let b = &n as &Base;\n    let s = &n as &Super;\n\n    n.baz();   // base baz\n    n.bar();   // super bar\n\n    println(\"\");\n\n    b.baz();   // base baz\n    //b.bar(); // Base has no bar()\n\n    println(\"\");\n\n    s.baz();   // BUG: super bar - should be base baz\n    s.bar();   // super bar\n}\n```\n\n Comments: \n Comment 0: I have solved this bug, here is patch:\n\n```\ndiff --git a/src/librustc/middle/typeck/check/method.rs b/src/librustc/middle/typeck/check/method.rs\nindex 48d630b..36c9b30 100644\n--- a/src/librustc/middle/typeck/check/method.rs\n+++ b/src/librustc/middle/typeck/check/method.rs\n@@ -372,7 +372,7 @@ impl<'self> LookupContext<'self> {\n     // to a trait and its supertraits.\n     fn get_method_index(&self,\n                         trait_ref: @TraitRef,\n-                        subtrait_id: ast38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5Id,\n+                                               subtrait: @TraitRef,\n                         n_method: uint) -> uint {\n         let tcx = self.tcx();\n\n@@ -382,15 +382,14 @@ impl<'self> LookupContext<'self> {\n         // we find the trait the method came from, counting up the\n         // methods from them.\n         let mut method_count = 0;\n-        do ty38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5h_bound_trait_and_supertraits(tcx, &[trait_ref])\n+        do ty38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5h_bound_trait_and_supertraits(tcx, &[subtrait])\n             |bound_ref| {\n-            if bound_ref.def_id == subtrait_id { false }\n+            if bound_ref.def_id == trait_ref.def_id { false }\n                 else {\n-                method_count += ty38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5trait_methods(tcx, bound_ref.def_id).len();\n+                method_count+=ty38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5trait_methods(tcx, bound_ref.def_id).len();\n                 true\n             }\n         };\n-\n         return method_count + n_method;\n     }\n\n@@ -418,9 +417,9 @@ impl<'self> LookupContext<'self> {\n         let trait_ref = @TraitRef { def_id: did, substs: rcvr_substs.clone() };\n\n         do self.push_inherent_candidates_from_bounds_inner(&[trait_ref])\n-            |trait_ref, m, method_num, _bound_num| {\n+            |new_trait_ref, m, method_num, _bound_num| {\n             let vtable_index =\n-                self.get_method_index(trait_ref, trait_ref.def_id, method_num);\n+                self.get_method_index(new_trait_ref, trait_ref, method_num);\n             // We need to fix up the transformed self type.\n             let transformed_self_ty =\n                 self.construct_transformed_self_ty_for_object(\n```\n\n Comment 1: Hmmm, seems that I cannot post it here ;)\n\n Comment 2: I edited some backticks into your comment so we could see the diff a little better, but feel free to open a pull request! It tends to be easier to review the patch in a pull request than on a bug report...\n\n Comment 3: https://gist.github.com/bmaxa/6680566 I have posted to gist, don't know how to make pull request ;)\n\n Comment 4: @bmaxa: https://help.github.com/articles/creating-a-pull-request\n\n Comment 5: Done ;) url for git is https://github.com/bmaxa/changes_and_fixes/tree/fixes\n\n Comment 6: @bmaxa You need to actually open an Pull Request.\n\n Comment 7: Heh I made pull request to my repository, didn't knew I have to fork first then compare with mozilla/rust\nand make request there ;)\n\n Comment 8: Triage: This was fixed in a8a69ec15dce8bed5827d02e92cdb9fe2857b829 (contains a regression test)\n",
  "Issue title: Design update\n Issue body: ## Tasks\r\n\r\n- [ ] Server\r\n  - [ ] PoC to check for potential blockers regarding scroll behaviour https://github.com/nextcloud/server/pull/33568\r\n    - [x] overflow on body\r\n    - [x] Spacing on sides and bottom on mobile (potentially also on smaller screen, or make it smaller with an in-between breakpoint)\r\n    - [x] Set the background image on all page https://github.com/nextcloud/nextcloud-vue/pull/3091\r\n    - [x] Set background image on header\r\n    - [x] See if we want to make them opt-in (e.g. for not using them on dashboard or not yet compatible community apps)\r\n  - [x] Core styling requirements https://github.com/nextcloud/server/pull/33610\r\n    - [x] New css variable for transparent background color + blur filter \r\n    - [x] Copy image to core/img/ to cover disabled dashboard\r\n  - [ ] Background image options\r\n    - [ ] https://github.com/nextcloud/server/pull/33733\r\n    - [ ] Add accessibility menu in the header bar - top right\r\n  - [ ] Fallback for not ported apps not needed as we announce it as breaking add\r\n  - [ ] https://github.com/nextcloud/server/issues/33735\r\n    - [ ] Figure out a way to regenerate avatars\r\n    - [ ] New style based on lighter color pallete\r\n    - [ ] What about contacts which uses the same color palette iirc?\r\n  - [ ] Current app indicator\r\n    - [ ] Decided to switch to a small bar isntead of the arrow\r\n- [ ] Vue components\r\n  - [ ] Container layout \r\n  - [ ] Smaller topics\r\n    - [x] Counter bubble https://github.com/nextcloud/nextcloud-vue/issues/3054\r\n    - [x] Show app nav actions menu only for active/hover/focus: https://github.com/nextcloud/nextcloud-vue/issues/3048\r\n    - [x] https://github.com/nextcloud/nextcloud-vue/pull/3056\r\n  - [ ] Container layout https://github.com/nextcloud/nextcloud-vue/pull/3091\r\n    - [ ] Content\r\n    - [ ] AppNavigation\r\n\t  - [x] Nav semi-transparent: https://github.com/nextcloud/nextcloud-vue/issues/3047\r\n      - [x] Pill-rounded nav entries: https://github.com/nextcloud/nextcloud-vue/issues/3049\r\n    - [ ] AppContentList\r\n      - [x] https://github.com/nextcloud/nextcloud-vue/pull/3055\r\n      - [x] Bold first line (sender in Mail, contact name in Contacts, conversation name in Talk) \u2013 but keep it normal in single-line navigation like Files, Photos etc.\r\n    - [ ] AppContent\r\n      - [ ] Scroll container should be within the AppContent\r\n    - [ ] AppSidebar\r\n      - [ ] Sidebar should span full height if rendered besides a modal/viewer (e.g. in talk like it is with files already)\r\n- [ ] Apps to upgrade components + testing + bug fixing\r\n  - [ ] Hub\r\n    - [ ] Files\r\n    - [ ] Settings\r\n    - [ ] Activity\r\n    - [ ] Photos\r\n  - [ ] Groupware\r\n    - [ ] Calendar\r\n    - [ ] Contacts\r\n    - [ ] Mail\r\n  - [ ] Office\r\n    - [ ] Deck\r\n  - [ ] Talk\r\n  - [ ] Other\r\n    - [ ] Collectives\r\n- [ ] Special care for\r\n  - [ ] Performance of blur effect\r\n  - [ ] Sidebar collapsing on large screens\r\n  - [ ] Sidebar collapsing on mobile\r\n  - [ ] check Js interaction on scroll containers\r\n  - [ ] Scroll bars should not cause a container content size change (e.g. https://caniuse.com/?search=overlay https://developer.mozilla.org/en-US/docs/Web/CSS/scrollbar-gutter)\r\n\r\n### Potential follow up ideas\r\n\r\nOut of scope for now as discussed\r\n\r\n- [ ] Dynamic colors https://m3.material.io/theme-builder#/dynamic\r\n\r\n<details>\r\n <summary>Screenshots</summary>\r\n![1366-768-max](https://user-images.githubusercontent.com/3404133/184995908-98a33c67-66e5-4dfa-b64c-8978431b4043.png)\r\n</details>\n Comments: \n Comment 0: > * Add direct link to \"Appearance & accessibility\" to user menu in the header bar - top right\r\n\r\nDo we have the space for this there? Thinking about mobile compatibility...\n Comment 1: - [ ] BUG: https://github.com/nextcloud/server/issues/33925\n Comment 2: - [ ] Accessibility BUG: color-text-maxcontrast needs to use darker value in new left navigation https://github.com/nextcloud/nextcloud-vue/issues/3198",
  "Issue title: put command doesn't always interpret \"-\" as stdin\n Issue body: Using 1.5.2:\n\n```\n$ BUCKET=search-archives\n$ echo \"12345\" | s3cmd put - s3://${BUCKET}/test_keyname\n<stdin> -> s3://search-archives/test_keyname  [part 1, 6B]\n 6 of 6   100% in    0s   181.99 B/s  done\n```\n\nWorking as expected. However, if you pipe that output to `cat`:\n\n```\n$ echo \"12345\" | s3cmd put - s3://${BUCKET}/test_keyname | cat\nFile '-' stored as's3://search-archives/test_keyname' (0 bytes in 0.2 seconds, -1.00 B/s) [1 of 1]\n```\n\nit thinks you have a file named \"-\"\n\n Comments: \n Comment 0: Should be fixed, I can't reproduce anymore with 2.0.1",
  "Issue title: Generate CMake toolchains from Python code\n Issue body: Use toolchains table from https://github.com/ruslo/polly/blob/master/bin/detail/toolchain_table.py to generate actual CMake code:\n- Generate name of the toolchain file\n- Generate human-readable toolchain name\n- Include CMake modules automatically\n-...\n\n Comments: \n Comment 0: Add HUNTER_TOOLCHAIN_UNDETECTABLE_ID automatically\r\n\\",
  "Issue title: Wallet RPC action \"receive\" sets the wrong representative/ignores the wallet representative\n Issue body: This issue has been present since V14 or so, it is the same as #1019 - but was missing an important detail which is why it was closed as un-reproducible\r\n\r\n**Description of bug:**\r\n\r\nWhen you use the rpc `receive` action on a node/development wallet then the representative is set to the account itself, rather than the wallet representative.\r\n\r\nExample, if you have an account in the node wallet:\r\n\r\n`nano_1hmefcfq35td5f6rkh15hbpr4bkkhyyhmfhm7511jaka811bfp17xhkboyxo`\r\n\r\nAnd you do an RPC `receive` for any block, the representative for that account will become `nano_1hmefcfq35td5f6rkh15hbpr4bkkhyyhmfhm7511jaka811bfp17xhkboyxo`\r\n\r\n\r\nThis issue **does not** occur when transactions are auto-received, only when they are received using the RPC receive action.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a wallet via `wallet_create` with auto receive disabled\r\n2. Create an account on the wallet via `account_create`\r\n3. Use rpc `receive` to pocket the funds from the account\r\n4. The representative for that account is now set to itself\r\n\r\n**Describe the results you received:**\r\n\r\nAccounts in the node/developer wallet always set the representative field to themselves when using rpc `receive`\r\n\r\n**Describe the results you expected:**\r\n\r\nAccounts use the wallet representative\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nIssue happens consistently and is repeatable.\r\n\r\n**Environment**:\r\n\r\n- Ubuntu 18.04\r\n- Nodes V14, V15, V16, V17, V18, V19, V20\n Comments: \n Comment 0: Thanks for the detailed report! Validated that this is happening and will change to respect the wallet representative.\r\n\r\nDid you find anywhere on the documentation implying the expected behavior?\n Comment 1: Closest thing after a quick search over the documentation is [wallet_representative_set](https://docs.nano.org/commands/rpc-protocol/#wallet_representative_set) \r\n\r\nI presume the desired behavior is:\r\n1) Only set representative for the open block\r\n   a) Use wallet representative, if it's set\r\n   b) Use one of the preconfigured_representatives in node config, if wallet representative isn't set\r\n\n Comment 2: Closest thing after a quick search over the documentation is [wallet_representative_set](https://docs.nano.org/commands/rpc-protocol/#wallet_representative_set)\r\n\r\nI presume the desired behavior is:\r\n\r\nOnly set representative for the open block\r\na) Use wallet representative, if it's set\r\nb) Use one of the preconfigured_representatives in node config, if wallet representative isn't se\n Comment 3: Should be good for V21, thanks again. Documentation was updated for RPC receive: https://docs.nano.org/commands/rpc-protocol/#receive",
  "Issue title: \u81ea\u5b9a\u4e49\u7684\u4e00\u4e9bpipeline \u90fd\u4e0d\u751f\u6548\u662f\u4e3a\u4ec0\u4e48\u5462\uff1f\n Issue body: \u60a8\u597d\uff0c\u81ea\u5df1\u5b9a\u4e49\u7684\u4e00\u4e9bpipeline\uff0c\u5b9e\u73b0\u4e86Pipeline\u63a5\u53e3\uff0c\u7136\u540e\u4e5fadd\u5230Pipeline\u4e2d\u4e86\uff0c\u4f46\u662f\u6ca1\u6709\u751f\u6548\u662f\u4e3a\u4ec0\u4e48\u5462\uff1f\n Comments: \n Comment 0: \u53ef\u80fd\u662f\u6570\u636e\u4e0d\u5168\uff1f\u63d0\u95ee\u6700\u597d\u9644\u52a0\u4ee3\u7801\u4ee5\u4fbf\u6392\u67e5\u3002\n Comment 1: \u73b0\u5728\u7f16\u5199\u7684pipeline\u751f\u6548\u4e86\u3002\u8c22\u8c22\u4e86\n Comment 2: `public static void main(String[] args) {\r\n        Spider.create(new NationalGeographyPageProcessor())\r\n               .addUrl(\"http://www.dili360.com/travel/sight/\")\r\n               .addPipeline(new NationalGeographyPipeline())\r\n//               .addPipeline(new JsonFilePipeline(\"D:\\\\data\\\\webmagic\\\\\"))\r\n               .thread(5)\r\n               .run();\r\n    }`\r\n\r\nSpringBoot\u96c6\u6210webmagic 0.6.1 \u6293\u53d6\u4e0d\u5230\u6570\u636e  JsonFilePipeline\u4e3a\u5b98\u65b9\u63d0\u4f9b\uff0cNationalGeographyPipeline\u4e3a\u81ea\u5b9a\u4e49\u7684",
  "Issue title: cli/flags: Regression for fractions with units\n Issue body: The `--cache` and `--max-sql-memory` flags support several formats, including fractions, percentages, and suffixes like `GB`. #22460 broke one format that was previously working, non-integer values with a unit suffix like `1.5GiB`, because it assumes that if a dot is present, it's a fraction without units. \n Comments: \n Comment 0: @jseldess While we have a fix, it isn't going to be present until 2.0.1 and this bug should be documented as a known limitation.\n Comment 1: Documented as a known limitation in https://github.com/cockroachdb/docs/pull/2823.",
  "Issue title: Impact crashes each time I try and make a macro.\n Issue body: ---- Minecraft Crash Report ----\r\n// My bad.\r\n\r\nTime: 25/06/20 12:27 PM\r\nDescription: mouseClicked event handler\r\n\r\njava.lang.IndexOutOfBoundsException: Index: 0, Size: 0\r\n\tat java.util.ArrayList.rangeCheck(Unknown Source)\r\n\tat java.util.ArrayList.get(Unknown Source)\r\n\tat net.impactclient.0Ya.1(0Ya.java:54)\r\n\tat net.impactclient.0Ya.<init>(0Ya.java:38)\r\n\tat net.impactclient.6g.init(6g.java:15)\r\n\tat dgb.init(SourceFile:338)\r\n\tat dbn.a(SourceFile:863)\r\n\tat net.impactclient.2Y.1(2Y.java:25)\r\n\tat dcv.onPress(SourceFile:18)\r\n\tat dcq.onClick(SourceFile:15)\r\n\tat dct.mouseClicked(SourceFile:150)\r\n\tat ddr.mouseClicked(SourceFile:27)\r\n\tat dbo.b(SourceFile:86)\r\n\tat dgb.wrapScreenError(SourceFile:447)\r\n\tat dbo.a(SourceFile:86)\r\n\tat dbo.c(SourceFile:150)\r\n\tat ais.execute(SourceFile:94)\r\n\tat dbo.b(SourceFile:150)\r\n\tat org.lwjgl.glfw.GLFWMouseButtonCallbackI.callback(GLFWMouseButtonCallbackI.java:36)\r\n\tat org.lwjgl.system.JNI.invokeV(Native Method)\r\n\tat org.lwjgl.glfw.GLFW.glfwPollEvents(GLFW.java:3101)\r\n\tat com.mojang.blaze3d.systems.RenderSystem.flipFrame(SourceFile:98)\r\n\tat cxx.e(SourceFile:301)\r\n\tat dbn.d(SourceFile:1012)\r\n\tat dbn.d(SourceFile:619)\r\n\tat net.minecraft.client.main.Main.main(SourceFile:204)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat net.minecraft.launchwrapper.Launch.launch(Launch.java:135)\r\n\tat net.minecraft.launchwrapper.Launch.main(Launch.java:28)\r\n\r\n\r\nA detailed walkthrough of the error, its code path and all known details is as follows:\r\n---------------------------------------------------------------------------------------\r\n\r\n-- Head --\r\nThread: Render thread\r\nStacktrace:\r\n\tat java.util.ArrayList.rangeCheck(Unknown Source)\r\n\tat java.util.ArrayList.get(Unknown Source)\r\n\tat net.impactclient.0Ya.1(0Ya.java:54)\r\n\tat net.impactclient.0Ya.<init>(0Ya.java:38)\r\n\tat net.impactclient.6g.init(6g.java:15)\r\n\tat dgb.init(SourceFile:338)\r\n\tat dbn.a(SourceFile:863)\r\n\tat net.impactclient.2Y.1(2Y.java:25)\r\n\tat dcv.onPress(SourceFile:18)\r\n\tat dcq.onClick(SourceFile:15)\r\n\tat dct.mouseClicked(SourceFile:150)\r\n\tat ddr.mouseClicked(SourceFile:27)\r\n\tat dbo.b(SourceFile:86)\r\n\r\n-- Affected screen --\r\nDetails:\r\n\tScreen name: net.impactclient.2Y\r\nStacktrace:\r\n\tat dgb.wrapScreenError(SourceFile:447)\r\n\tat dbo.a(SourceFile:86)\r\n\tat dbo.c(SourceFile:150)\r\n\tat ais.execute(SourceFile:94)\r\n\tat dbo.b(SourceFile:150)\r\n\tat org.lwjgl.glfw.GLFWMouseButtonCallbackI.callback(GLFWMouseButtonCallbackI.java:36)\r\n\tat org.lwjgl.system.JNI.invokeV(Native Method)\r\n\tat org.lwjgl.glfw.GLFW.glfwPollEvents(GLFW.java:3101)\r\n\tat com.mojang.blaze3d.systems.RenderSystem.flipFrame(SourceFile:98)\r\n\r\n-- Affected level --\r\nDetails:\r\n\tAll players: 1 total; [dqb['RadPower1'/109, l='MpServer', x=26.30, y=68.00, z=-364.70]]\r\n\tChunk stats: Client Chunk Cache: 361, 225\r\n\tLevel dimension: minecraft:overworld\r\n\tLevel name: MpServer\r\n\tLevel seed: 8962414195576017367\r\n\tLevel generator: ID 00 - default, ver 1. Features enabled: false\r\n\tLevel generator options: {}\r\n\tLevel spawn location: World: (26,63,-348), Chunk: (at 10,3,4 in 1,-22; contains blocks 16,0,-352 to 31,255,-337), Region: (0,-1; contains chunks 0,-32 to 31,-1, blocks 0,0,-512 to 511,255,-1)\r\n\tLevel time: 133606 game time, 942103 day time\r\n\tKnown server brands: \r\n\tLevel was modded: false\r\n\tLevel storage version: 0x00000 - Unknown?\r\n\tLevel weather: Rain time: 0 (now: false), thunder time: 0 (now: false)\r\n\tLevel game mode: Game mode: survival (ID 0). Hardcore: false. Cheats: false\r\n\tServer brand: Paper\r\n\tServer type: Non-integrated multiplayer server\r\nStacktrace:\r\n\tat dno.a(SourceFile:450)\r\n\tat dbn.c(SourceFile:1921)\r\n\tat dbn.d(SourceFile:634)\r\n\tat net.minecraft.client.main.Main.main(SourceFile:204)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat net.minecraft.launchwrapper.Launch.launch(Launch.java:135)\r\n\tat net.minecraft.launchwrapper.Launch.main(Launch.java:28)\r\n\r\n-- System Details --\r\nDetails:\r\n\tMinecraft Version: 1.15.2\r\n\tMinecraft Version ID: 1.15.2\r\n\tOperating System: Windows 10 (amd64) version 10.0\r\n\tJava Version: 1.8.0_231, Oracle Corporation\r\n\tJava VM Version: Java HotSpot(TM) 64-Bit Server VM (mixed mode), Oracle Corporation\r\n\tMemory: 416371280 bytes (397 MB) / 973078528 bytes (928 MB) up to 681.588.9280 bytes (2048 MB)\r\n\tCPUs: 4\r\n\tJVM Flags: 8 total; -XX:+UnlockExperimentalVMOptions -XX:+UseG1GC -XX:G1NewSizePercent=20 -XX:G1ReservePercent=20 -XX:MaxGCPauseMillis=50 -XX:G1HeapRegionSize=16M -Xmx2048m -XX:HeapDumpPath=MojangTricksIntelDriversForPerformance_javaw.exe_minecraft.exe.heapdump\r\n\tLaunched Version: 1.15.2-Impact_4.9.1\r\n\tBackend library: LWJGL version 3.2.2 build 10\r\n\tBackend API: Intel(R) HD Graphics 620 GL version 4.6.0 - Build 116.69.203.11557, Intel\r\n\tGL Caps: Using framebuffer using OpenGL 3.0\r\n\tUsing VBOs: Yes\r\n\tIs Modded: Very likely; Jar signature invalidated\r\n\tType: Client (map_client.txt)\r\n\tResource Packs: vanilla, file/3D-Noteblock-Displays-1.15-V2.2.zip, file/OpenInventoryGUI.zip (incompatible), file/bare-bones-e610.zip, file/red.zip, file/seamless-glass-syh.zip\r\n\tCurrent Language: English (US)\r\n\tCPU: 4x Intel(R) Core(TM) i5-7200U CPU @ 2.50GHz\n Comments: \n Comment 0: fill out the template \n Comment 1: what template?\n Comment 2",
  "Issue title: Thank you for your work\n Issue body: Since I probably won't move to the paid plugin, I want to thank you for all the work you've done on this plugin in the past. I have loved using it.\n Comments: \n Comment 0: Hi @Maikenvv,\r\n\r\nI'm happy that it was useful for you!\r\nMay I ask what prevents you from getting it?\r\n\r\nThanks a lot for your feedback! It means lot!\n Comment 1: Same here for our studio, we loved this plugin but we can't pay this plugin for each sketch version in all our computers. For the last weeks we were thinking to move to other apps like XD or Invision Studio, now with this paid version and the \"runner\" in the same way... we are seeing all benefits to moving. We appreciate all your work,  thanks for all.\n Comment 2: Hi @nazohana,\r\n\r\nSorry to hear that, but happy that it's been so useful for you.\r\nLet us know how walking that path goes! \r\n\r\nThanks for your support and feedback!\r\n\n Comment 3: Hi @oodesign \r\n\r\nThank you for building a great plugin which solved a problem faced by many of us working in teams. I congratulate you on your plans with making this a paid plugin so that you are compensated for your work. \ud83d\udc4f\r\n\r\nUnfortunately, the problem this plugin solves is a design issue for Sketch. I foresee Sketch fixing this at a later release(they raised funding recently). This plugin would be rendered useless and doesn't warrant a separate license. As @nazohana pointed out, we are looking to move to other tools(Figma) where we avoid this issue in the first place. I hope you get the drift.\r\n\r\nCheers\r\n\r\n\n Comment 4: Hi @varunyellina,\r\n\r\nHonestly, we couldn't be happier if Sketch solved this issue natively. Merge Duplicates has always been (and will be) a \"workaround\" to the way Sketch handles this. \r\n\r\nThat said, our personal guess is that this is not considered an issue, but a feature in Sketch. We think (and that's a personal point of view) that it's intentionally (per design) working this way, so that you can have styles and symbols with same names, and it's up to the designers to decide and handle what to do with them. \r\n\r\nWe're just trying to make that decisions simpler and reduce countless hours of super boring manual work :)\r\n\r\nAnd yes, you should definitely try Figma anyway! We're still with Sketch, but always keeping an eye on it.\r\n\r\nThanks for your support and feedback!\n Comment 5: > Hi @Maikenvv,\r\n> \r\n> I'm happy that it was useful for you!\r\n> May I ask what prevents you from getting it?\r\n> \r\n> Thanks a lot for your feedback! It means lot!\r\n\r\nI agree with some of the things the other have said. The price, which is 1/3, of the Sketch price, is quite expensive when there are multiple designers that use it. And as @nazohana pointed out, with more plugins being paid and the issue only being an issue in Sketch, moving to Figma is a serious consideration. \r\n\r\n\n Comment 6: Hi @Maikenvv,\r\n\r\nWe are enormously thankful for every designer using \"Merge Duplicates\", and the help and feedback you've been kindly giving us.\r\n\r\nSo when we decided to go non-free we thought of including a big discount on it if you are currently using the plugin, and get it before the 1st of June. It was our way to say Thank you, and make things a bit easier for all of you that have been helping us make it possible. \r\n\r\nJust trigger \"Merge duplicates\" in Sketch. You may find the discount in the notify dialog that appears after merging. Hope it helps a bit!\r\n\r\nAnyway, whether you get it or not, thank you all for your using it until now and for your support and feedback.\r\n\r\nAll the best,\r\n\r\n\u00d2scar from oodesign",
  "Issue title: Question: Highlight background in CodeArea. \n Issue body: ## Goal\r\n\r\nI'm implementing an application that highlights differences between two JSON objects per button click. I'm using two code areas in which both JSON objects can be written into. These have to be code areas in order to highlight the syntax of the objects. This is done similar to the `JavaKeywordsDemo` with the exception of different patterns. \r\n\r\nWhen I calculate the differences I want to highlight them in the code area once I click the button by altering their background color. Whether the highlighted difference still obtains its syntax highlighting is irrelevant. \r\n\r\n## Expected Behavior\r\n\r\nGiven a `CodeArea area` and a `List<String> differences`. A button's action method is clicked that contains the `highlightDifferences()` method. The method changes the background color of the `area`. \r\n\r\n## Actual Behavior\r\n\r\nWhen the button is clicked the background color is changed for a millisecond and gets reverted to regular syntax highlighting. \r\n\r\n## Reproducible Demo\r\n\r\nI cannot provide the whole code as the application is quite massive but here are the respective parts: \r\n\r\n````java\r\npublic class CollectionController extends AbstractController {\r\n\r\n... \r\n /**\r\n   * Highlights the differences of the given code area, i.e. changes the background color according\r\n   * to the stylesheets.\r\n   *\r\n   * @param area The area to modify.\r\n   * @param differences The properties that differ.\r\n   */\r\n  private void highlightDifferences(CodeArea area, List<String> differences) {\r\n    String text = area.getText();\r\n\r\n    // Traverse all differences.\r\n    for (String difference : differences) {\r\n\r\n      /*\r\n       * Split the difference properties into individual strings. The : represents the value of the\r\n       * property and should be ignored because it is on the same line as the property name.\r\n       */\r\n      difference = difference.replaceFirst(\"\\\\.\", \"\").replaceAll(\":\", \".\");\r\n      String[] properties = difference.split(\"\\\\.\");\r\n      int from = 0;\r\n\r\n      // Ignore the value.\r\n      for (int i = 0; i < properties.length - 1; i++) {\r\n\r\n        // Get the first index of the property including the leading \" and the index of end of line.\r\n        from = text.indexOf(properties[i], from) - 1;\r\n        int to = text.indexOf(\"\\n\", from);\r\n\r\n        // Highlight this range.\r\n        area.setStyleClass(from, to, \"highlight\");\r\n      }\r\n    }\r\n  }\r\n...\r\npublic abstract class AbstractController implements Initializable {\r\n...\r\n\r\n/**\r\n   * Initializes a given CodeArea. The code area does have line numbers on the left side,\r\n   * syntax highlighting and auto-indent. This is being achieved within this method.\r\n   *\r\n   * @param area The {@code CodeArea} to initialize. \r\n   */\r\n  void initializeCodeArea(CodeArea area) {\r\n     ... \r\n\r\n    // Compute syntax highlighting.\r\n    area.getVisibleParagraphs().addModificationObserver(new Highlighter<>(area, this38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5omputeHighlighting));\r\n\r\n  ...\r\n  }\r\n\r\n...\r\n````\r\n\r\n## Environment info:\r\n\r\n- RichTextFX Version: 10.5\r\n- Operating System: Windows 10\r\n- Java version: 14.0.2 \r\n\r\n\n Comments: \n Comment 0: Can you please post the code for your Highlighter class. (You need to prevent your Highlighter class from overwriting your background color changes.)\n Comment 1: Sure, this is the highlighting and the Highlighter: \r\n\r\n\r\n``` java \r\n/**\r\n   * Computes syntax highlighting for JSON Objects on a given text and returns its style spans.\r\n   *\r\n   * @param text The text to compute the highlighting on.\r\n   * @return Essentially a list of given styles that span a certain length.\r\n   */\r\n  private StyleSpans<Collection<String>> computeHighlighting(String text) {\r\n\r\n    // Get the patterns for styling.\r\n    Matcher matcher = PATTERN.matcher(text);\r\n    int lastNameIndex = 0;\r\n    StyleSpansBuilder<Collection<String>> spansBuilder = new StyleSpansBuilder<>();\r\n\r\n    // Find the different keywords for a JSON Object and style them accordingly. \r\n    while (matcher.find()) {\r\n      String styleClass =\r\n              matcher.group(\"NAME\")!= null\r\n                     ? \"name\"\r\n                      : matcher.group(\"PARENTHESIS\")!= null\r\n                     ? \"parenthesis\"\r\n                      : matcher.group(\"BRACE\")!= null\r\n                     ? \"brace\"\r\n                      : matcher.group(\"BRACKET\")!= null\r\n                     ? \"bracket\"\r\n                      : matcher.group(\"SEMICOLON\")!= null\r\n                     ? \"semicolon\"\r\n                      : matcher.group(\"STRING\")!= null\r\n                     ? \"string\"\r\n                      : matcher.group(\"NUMBER\")!= null? \"number\" : null;\r\n      assert styleClass!= null;\r\n\r\n      spansBuilder.add(Collections.emptyList(), matcher.start() - lastNameIndex);\r\n      spansBuilder.add(Collections.singleton(styleClass), matcher.end() - matcher.start());\r\n      lastNameIndex = matcher.end();\r\n    }\r\n    spansBuilder.add(Collections.emptyList(), text.length() - lastNameIndex);\r\n    return spansBuilder.create();\r\n  }\r\n\r\n /**\r\n   * This class is used to syntax highlight code areas in JSON style.\r\n   *\r\n   * @param <PS> The paragraph style, e.g. alignment.\r\n   * @param <SEG> The segment.\r\n   * @param <S> The actual styling, e.g. colors.\r\n   */\r\n  private static class Highlighter<PS, SEG, S> implements Consumer<ListModification> {\r\n    /** CodeArea is a child of this */\r\n    private final GenericStyledArea<PS, SEG, S> area;\r\n\r\n    /** The function to compute the styles */\r\n    private final Function<String, StyleSpans<S>> computeStyles;\r\n\r\n    /** The previous paragraph index */\r\n    private int prevParagraph;\r\n\r\n    /** The previous paragraph's text length */\r\n    private int prevLength;\r\n\r\n    /**\r\n     * Constructs a Highlighter with a given area and highlight function.\r\n     */\r\n    public Highlighter(\r\n            GenericStyledArea<PS, SEG, S> area, Function<String, StyleSpans<S>> computeStyles) {\r\n      this.computeStyles = computeStyles;\r\n      this.area = area;\r\n    }\r\n\r\n    /**\r\n     * Performs the computeStyles function on the modifications.\r\n     *\r\n     * @param modifications Modifications to the text of the code area.\r\n     */\r\n    @Override\r\n    public void accept(ListModification modifications) {\r\n      if (modifications.getAddedSize() > 0) {\r\n\r\n        // Get the current paragraph.\r\n        int paragraph =\r\n                Math.min(\r\n                        area.firstVisibleParToAllParIndex() + modifications.getFrom(),\r\n                area.getParagraphs().size() - 1);\r\n\r\n        // Get the current text.\r\n        String text = area.getText(paragraph, 0, paragraph, area.getParagraphLength(paragraph));\r\n        \r\n        if (paragraph!= prevParagraph || text.length()!= prevLength) {\r\n          int startPos = area.getAbsolutePosition(paragraph, 0);\r\n          Platform.runLater(() -> area.setStyleSpans(startPos, computeStyles.apply(text)));\r\n          prevLength = text.length();\r\n          prevParagraph = paragraph;\r\n        }\r\n      }\r\n    }\r\n  }\r\n``` \r\n\r\nAnd this is the css part:\r\n```css\r\n/* difference highlighting */\r\n.highlight {\r\n    -rtfx-background-color: #FFCA74;\r\n}\r\n\r\n/* The \"name\" part of JSON Object name/value pairs */\r\n.name {\r\n    -fx-fill: #0009D3;\r\n    -fx-font-weight: bold;\r\n}\r\n\r\n/* Semicolons within code areas */\r\n.semicolon {\r\n    -fx-font-weight: bold;\r\n}\r\n\r\n/** brackets within code areas */\r\n.parenthesis,.brace,.bracket {\r\n    -fx-fill: #00312C;\r\n    -fx-font-weight: bold;\r\n}\r\n\r\n/** values of code areas. Note that these can be yrodriguez@example.org. */\r\n.string,.number {\r\n    -fx-fill: black;\r\n}\r\n\r\n``` \n Comment 2: This is tricky, I'm wondering if it wouldn't be easier to accomplish this by adding your own selection like so....\r\n\r\n1.  \u00a0Add a selection field to `AbstractController`, something like:\r\n\r\n```java\r\nSelection diffHighlighter;\r\n```\r\n\r\n\u00a0 \u00a02. \u00a0Then in",
  "Issue title: Implement difference operation\n Issue body: It should be possible to create the difference of two shapes, using constructive solid geometry (CSG). There is currently a placeholder for this operation in the `fj` crate, as well as limited support for 2D differences, which is not directly related to this issue.\r\n\r\nImplementing this requires more solid infrastructure for storing and querying shapes in the host application. Also see #42.\n Comments: \n Comment 0: Blocked on #97.\n Comment 1: This is no longer blocked on #97!\n Comment 2: This is now blocked on #993. The same algorithm that's [needed for #42](https://github.com/hannobraun/Fornjot/issues/42#issuecomment-1225735872) is needed for this too.\n Comment 3: #993 has been addressed. This issue is no longer blocked!\n Comment 4: This operation will share much of its implementation with the union operation (#42), and I've recently labeled this as blocked, then no longer blocked, for the same reasons that #42 was blocked during that time frame. Now #42 is blocked again.\r\n\r\nInstead of adding and removing the https://github.com/hannobraun/Fornjot/labels/status%3A%20blocked label a bunch of more times, I'm going to simply label this as https://github.com/hannobraun/Fornjot/labels/status%3A%20blocked on #42. Even though that isn't completely accurate, it will prevent this issue from seeing the same block/unblock churn that #42 is seeing. In addition, it wouldn't make sense to start work here anyway, right now. The groundwork required is the same that #42 requires, so it really makes no sense to start working on this issue in parallel.",
  "Issue title: Problems converting TF BioBERT model to PyTorch\n Issue body: My goal is to convert and train on the [BioBERT pretrained checkpoints](https://github.com/naver/biobert-pretrained) in pytorch and train on the [SQuAD v2.0 Dataset](https://rajpurkar.github.io/SQuAD-explorer/).  \r\n\r\nI have (seemingly) successfully transfered the checkpoint using the `./pytorch_pretrained_bert/convert_tf_checkpoint_to_pytorch.py` [script](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/convert_tf_checkpoint_to_pytorch.py). \r\n\r\nI loaded the converted checkpoint into the `run_squad.py` [example](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_squad.py). I also changed the tokenizer to use the vocab file found with the BioBERT model. At this point, I was able to train the model and observe the loss to decrease. \r\n\r\nMy first issue appeared when trying to write the SQuAD predictions. `best_non_null_entry.start_logit` did not have a `start_logit` because the `best_non_null_entry` was `NoneType`. This error resembles the previous issue #207. I implemented the solution found and my code was able to run. \r\n\r\nMy results from training have been the same or worse than a random model. Nearly all of the SQuAD predictions are the \"empty\" string text from the fix of #207. \r\n\r\n**I believe the original cause of the `NoneType` error for `best_non_null_entry` is the reason for the failure to predict anything.** \r\n\r\nAre there specs to obey when converting a TF pretrained BERT model?\r\nWhat would cause the `NoneType` error for `best_non_null_entry`?\r\nAny and all help is appreciated.\n Comments: \n Comment 0: I have solved my issue. All my code was correctly written. The error was an corrupted/improperly saved model.bin file.\n Comment 1: I'm trying to convert BioBert to Pytorch also, so just wondering if you could share a bit more details on how you are doing the conversion. Thanks!\n Comment 2: First, I downloaded the BioBERT TF checkpoints [here](https://github.com/naver/biobert-pretrained). Each model (i.e. biobert_pmc) should have three `.ckpt` files, a `vocab.txt` file, and a `bert_config.json` file. \r\n\r\nInitially, I tried to use the command line interface `pytorch_pretrained_bert convert_tf_checkpoint_to_pytorch` using the `bert_config.json` and `.ckpt` files seen above. I ran into `AttributeError: 'Parameter' object has no attribute 'BERTAdam'`. I followed the solution [here](https://github.com/dmis-lab/biobert/issues/2). \r\n\r\nTo do this, I copied the `convert_tf_checkpoint_to_pytorch.py` file and the `load_tf_weights_in_bert` function found in `modeling.py`. I then added the two lines seen in the (solution above)[load_tf_weights_in_bert]. In my own version of the function and file. \r\n\r\nGiven correct file paths, this worked to convert all three BioBERT checkpoints into pytorch `.bin` files.",
  "Issue title: BO - New employee page - Help Card is not displayed in sidebar\n Issue body: <!--\r\n****************************\r\nDO NOT disclose security issues here, contact newmantravis@example.com instead!\r\n****************************\r\n-->\r\n\r\n#### Describe the bug\r\n\r\nIn the BO => Team => Employees Tab => Add anew employee page, When we click on the button 'help', the sidebar is not opened in the same page, it redirect us to `shop.com/admin-dev/index.php/common/sidebar/https%253A%252F%252Fhelp.prestashop.com%252Fen%252Fdoc%252FAdminEmployees%253Fversion%253D116.69.203.115%2526country%253Den/Help?_token=pKbqyg0aj7rVlQAJSXFU1rliXcpAEgdxcp-id8R3BWE\r\n`\r\n#### Expected behavior\r\n\r\nSideBar opened in the same page\r\n\r\n#### Steps to Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Go to the BO => Team => Employees Tab => Add anew employee page\r\n2. Click on button 'Help'\r\n3. See error\r\n\r\n**Screenshots**\r\n\r\n![image](https://user-images.githubusercontent.com/16067358/79221548-4d74aa00-7e56-11ea-8c58-f8a522a76db8.png)\r\n\r\n\r\n#### Additional information\r\n\r\n* PrestaShop version: 177x,1760,1764\r\n* PHP version: 7.2\r\n\n Comments: \n Comment 0: Thanks for opening this issue! We will help you to keep its state consistent\n Comment 1: Related to: https://github.com/PrestaShop/PrestaShop/issues/18279\n Comment 2: Fixed by #18637 ",
  "Issue title: Can't run New Super Luigi U on M1 Mac\n Issue body: \r\n[mvk-info] MoltenVK version 1.1.11, supporting Vulkan version 1.1.224.\r\n\tThe following 81 Vulkan extensions are supported:\r\n\t\tVK_KHR_16bit_storage v1\r\n\t\tVK_KHR_8bit_storage v1\r\n\t\tVK_KHR_bind_memory2 v1\r\n\t\tVK_KHR_buffer_device_address v1\r\n\t\tVK_KHR_create_renderpass2 v1\r\n\t\tVK_KHR_dedicated_allocation v3\r\n\t\tVK_KHR_depth_stencil_resolve v1\r\n\t\tVK_KHR_descriptor_update_template v1\r\n\t\tVK_KHR_device_group v4\r\n\t\tVK_KHR_device_group_creation v1\r\n\t\tVK_KHR_driver_properties v1\r\n\t\tVK_KHR_dynamic_rendering v1\r\n\t\tVK_KHR_external_fence v1\r\n\t\tVK_KHR_external_fence_capabilities v1\r\n\t\tVK_KHR_external_memory v1\r\n\t\tVK_KHR_external_memory_capabilities v1\r\n\t\tVK_KHR_external_semaphore v1\r\n\t\tVK_KHR_external_semaphore_capabilities v1\r\n\t\tVK_KHR_fragment_shader_barycentric v1\r\n\t\tVK_KHR_get_memory_requirements2 v1\r\n\t\tVK_KHR_get_physical_device_properties2 v2\r\n\t\tVK_KHR_get_surface_capabilities2 v1\r\n\t\tVK_KHR_imageless_framebuffer v1\r\n\t\tVK_KHR_image_format_list v1\r\n\t\tVK_KHR_maintenance1 v2\r\n\t\tVK_KHR_maintenance2 v1\r\n\t\tVK_KHR_maintenance3 v1\r\n\t\tVK_KHR_multiview v1\r\n\t\tVK_KHR_portability_subset v1\r\n\t\tVK_KHR_push_descriptor v2\r\n\t\tVK_KHR_relaxed_block_layout v1\r\n\t\tVK_KHR_sampler_mirror_clamp_to_edge v3\r\n\t\tVK_KHR_sampler_ycbcr_conversion v14\r\n\t\tVK_KHR_separate_depth_stencil_layouts v1\r\n\t\tVK_KHR_shader_draw_parameters v1\r\n\t\tVK_KHR_shader_float16_int8 v1\r\n\t\tVK_KHR_shader_subgroup_extended_types v1\r\n\t\tVK_KHR_storage_buffer_storage_class v1\r\n\t\tVK_KHR_surface v25\r\n\t\tVK_KHR_swapchain v70\r\n\t\tVK_KHR_swapchain_mutable_format v1\r\n\t\tVK_KHR_timeline_semaphore v2\r\n\t\tVK_KHR_uniform_buffer_standard_layout v1\r\n\t\tVK_KHR_variable_pointers v1\r\n\t\tVK_EXT_buffer_device_address v2\r\n\t\tVK_EXT_debug_marker v4\r\n\t\tVK_EXT_debug_report v10\r\n\t\tVK_EXT_debug_utils v2\r\n\t\tVK_EXT_descriptor_indexing v2\r\n\t\tVK_EXT_fragment_shader_interlock v1\r\n\t\tVK_EXT_hdr_metadata v2\r\n\t\tVK_EXT_host_query_reset v1\r\n\t\tVK_EXT_image_robustness v1\r\n\t\tVK_EXT_inline_uniform_block v1\r\n\t\tVK_EXT_memory_budget v1\r\n\t\tVK_EXT_metal_objects v1\r\n\t\tVK_EXT_metal_surface v1\r\n\t\tVK_EXT_post_depth_coverage v1\r\n\t\tVK_EXT_private_data v1\r\n\t\tVK_EXT_robustness2 v1\r\n\t\tVK_EXT_sample_locations v1\r\n\t\tVK_EXT_scalar_block_layout v1\r\n\t\tVK_EXT_separate_stencil_usage v1\r\n\t\tVK_EXT_shader_stencil_export v1\r\n\t\tVK_EXT_shader_viewport_index_layer v1\r\n\t\tVK_EXT_subgroup_size_control v2\r\n\t\tVK_EXT_swapchain_colorspace v4\r\n\t\tVK_EXT_texel_buffer_alignment v1\r\n\t\tVK_EXT_texture_compression_astc_hdr v1\r\n\t\tVK_EXT_vertex_attribute_divisor v3\r\n\t\tVK_AMD_gpu_shader_half_float v2\r\n\t\tVK_AMD_negative_viewport_height v1\r\n\t\tVK_AMD_shader_image_load_store_lod v1\r\n\t\tVK_AMD_shader_trinary_minmax v1\r\n\t\tVK_IMG_format_pvrtc v1\r\n\t\tVK_INTEL_shader_integer_functions2 v1\r\n\t\tVK_GOOGLE_display_timing v1\r\n\t\tVK_MVK_macos_surface v3\r\n\t\tVK_MVK_moltenvk v35\r\n\t\tVK_NV_fragment_shader_barycentric v1\r\n\t\tVK_NV_glsl_shader v1\r\n[mvk-info] GPU device:\r\n\t\tmodel: Apple M1\r\n\t\ttype: Integrated\r\n\t\tvendorID: 0x106b\r\n\t\tdeviceID: 0xc0603ef\r\n\t\tpipelineCacheUUID: 0000277F-0C06-03EF-0000-000000000000\r\n\tsupports the following Metal Versions, GPU's and Feature Sets:\r\n\t\tMetal Shading Language 2.4\r\n\t\tGPU Family Apple 7\r\n\t\tGPU Family Apple 6\r\n\t\tGPU Family Apple 5\r\n\t\tGPU Family Apple 4\r\n\t\tGPU Family Apple 3\r\n\t\tGPU Family Apple 2\r\n\t\tGPU Family Apple 1\r\n\t\tGPU Family Mac 2\r\n\t\tGPU Family Mac 1\r\n\t\tGPU Family Common 3\r\n\t\tGPU Family Common 2\r\n\t\tGPU Family Common 1\r\n\t\tmacOS GPU Family 2 v1\r\n\t\tmacOS GPU Family 1 v4\r\n\t\tmacOS GPU Family 1 v3\r\n\t\tmacOS GPU Family 1 v2\r\n\t\tmacOS GPU Family 1 v1\r\n[mvk-info] Created VkInstance for Vulkan version 1.1.224, as requested by app, with the following 3 Vulkan extensions enabled:\r\n\t\tVK_KHR_surface v25\r\n\t\tVK_EXT_debug_utils v2\r\n\t\tVK_EXT_metal_surface v1\r\n[mvk-info] Using emulation for Vulkan semaphores.\r\n[mvk-info] Created VkDevice to run on GPU Apple M1 with the following 3 Vulkan extensions enabled:\r\n\t\tVK_KHR_driver_properties v1\r\n\t\tVK_KHR_sampler_mirror_clamp_to_edge v3\r\n\t\tVK_KHR_swapchain v70\r\n[mvk-info] Created 3 swapchain images with initial size (1280, 720) and contents scale 1.0 for screen Built-in Retina Display.\r\n[mvk-error] VK_SUCCESS: Found attribute with size (16) larger than it's binding's stride (12). Changing descriptor format from MTLVertexFormatUInt4 to MTLVertexFormatUInt3.\r\n[mvk-error] VK_SUCCESS: Found attribute with size (16) larger than it's binding's stride (12). Changing descriptor format from MTLVertexFormatUInt4 to MTLVertexFormatUInt3.\r\n[mvk-error] VK_SUCCESS: Found attribute with size (16) larger than it's binding's stride (12). Changing descriptor format from MTLVertexFormatUInt4 to MTLVertexFormatUInt3.\r\n[mvk-error] VK_SUCCESS: Found attribute with size (16) larger than it's binding's stride (12). Changing descriptor format from MTLVertexFormatUInt4 to MTLVertexFormatUInt3.\r\n[mvk-error] VK_SUCCESS: Found attribute with size (16) larger than it's binding's stride (12). Changing descriptor format from MTLVertexFormatUInt4 to MTLVertexFormatUInt3.\r\n[mvk-error] VK_SUCCESS: Found attribute with size (16) larger than it's binding's stride (12). Changing descriptor format from MTLVertexFormatUInt4 to MTLVertexFormatUInt3.\r\n[mvk-error] VK_SUCCESS: Found attribute with size (16) larger than it's binding's stride (12). Changing descriptor format from MTLVertexFormatUInt4 to MTLVertexFormatUInt3.\r\nBus error: 10!\r\nError: signal 10:\r\n\n Comments: \n Comment 0: For troubleshooting please use the",
  "Issue title: libtensorflowlite.so build not correct\n Issue body: <em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): build use Linux Ubuntu 16.04,deploy on android 9.0(arm64)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:None\r\n- TensorFlow installed from (source or binary): git clone source code from master branch\r\n- TensorFlow version:master\r\n- Python version:anaconda python 3.6\r\n- Installed using virtualenv? pip? conda?:source code,none\r\n- Bazel version (if compiling from source):0.24.1\r\n- GCC/Compiler version (if compiling from source):ndk r19c\r\n- CUDA/cuDNN version:none\r\n- GPU model and memory:none\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI want to build c++ interface of tflite on android device,using command:\r\nbazel build -s //tensorflow/lite:libtensorflowlite.so --config=android_arm64 --cxxopt='--std=c++11' -c opt\r\nthe build could be succeed,but the libtensorflowlite.so built is only 5784 Byte, and doesn't work correctly.\r\n\r\nI use the same command on tensorlfow 1.15,and can get the right lib,which is 2MB.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\n Comments: \n Comment 0: I followed this tutorial and installed the NDK r17c and SDK 29 and built it on Ubuntu. A 3.6MB aar file was generated.\r\n**https://www.tensorflow.org/lite/guide/android**\r\n\r\nTensorflow v2.0.0 + Bazel 0.26.1 + Ubuntu 18.04 + Python 3.6 + ndk r17c + sdk 29\r\n![java - \u30d5\u30a1\u30a4\u30eb\u30de\u30cd\u30fc\u30b8\u30e3\u30fc_050](https://user-images.githubusercontent.com/33194443/68120491-dce16d00-ff48-11e9-89aa-0e4df6c909af.png)\r\n![Terminal - b920405@ubuntu: -media-b920405-Windows1-git-tensorflow2 0 0_049](https://user-images.githubusercontent.com/33194443/68120507-e539a800-ff48-11e9-8b92-13f172091171.png)\r\n\n Comment 1: The only difference from your environment is the Ubuntu and NDK versions, but the following steps were successful.\r\n\r\n**Tensorflow v2.0.0 + ndk r17c + sdk 29 + Ubuntu 18.04 + Python 3.6**\r\n```bash\r\n$ bazel build \\\r\n-s //tensorflow/lite:libtensorflowlite.so \\\r\n--config=android_arm64 \\\r\n--cxxopt='--std=c++11' \\\r\n-c opt \\\r\n--config=v2\r\n```\r\n![Terminal - b920405@ubuntu: -media-b920405-Windows1-git-tensorflow2 0 0_051](https://user-images.githubusercontent.com/33194443/68121012-0ea70380-ff4a-11e9-8e7f-705f737abe84.png)\r\n![lite - \u30d5\u30a1\u30a4\u30eb\u30de\u30cd\u30fc\u30b8\u30e3\u30fc_052](https://user-images.githubusercontent.com/33194443/68121151-62195180-ff4a-11e9-8f8d-9c0f4edb25b2.png)\r\n\n Comment 2: I have the exact same issue: Running `bazel build -c opt --config android_arm64 //tensorflow/lite:libtensorflowlite.so` on the latest commit `965f4b71f0c719f5466fe0f25f326593ae9e220a` yields a 5.7K `libtensorflowlite.so` (no build errors), while the randomly picked commit `1cf6cb79156d488fd97504ecc6744cd0ab2d31fa` from ~2 weeks ago properly yields 2.3 MB binary.so file.\r\nUsing the recommended Bazel and Android NDK versions. \n Comment 3: Thanks for flagging the issue, this does look like a recent regression, likely due to our use of the TF build rule for generating a binary. We'll try to get a fix out quickly, but in the meantime you can sync to a slightly earlier build.\n Comment 4: FYI, this is caused by commit f58c9f835c32e02895bdd629c7660567ae011001. So, another alternative is to comment out \"build --incompatible_remove_legacy_whole_archive\" in tensorflow/.bazelrc.\n Comment 5: Thank you!\n Comment 6: Let me close this since it's working well now.",
  "Issue title: Should `name=` be `actname` in `[asterisk]` jail?\n Issue body: ### Environment:\r\n- Fail2Ban version (including any possible distribution suffixes): 0.10.5 (release 2.fc31)\r\n- OS, including release name/version: Fedora release 31\r\n- [x] Fail2Ban installed via OS/distribution mechanisms\r\n- [x] You have not applied any additional foreign patches to the codebase\r\n- [x] Some customizations were done to the configuration (provide details below is so)\r\n\r\n### The issue:\r\n\r\nError `Action firewallcmd-ipset already exists` in startup when `asterisk` jail enabled.\r\n\r\n#### Steps to reproduce\r\n\r\nMinimal F31 install, `dnf install fail2ban`, create `/etc/fail2ban/jail.d/local.conf` as below, `systemctl start fail2ban`\r\n\r\n```\r\n[asterisk]\r\n  enabled = true\r\n``` \r\n\r\n#### Expected behavior\r\n\r\nNo errors.\r\n\r\n#### Observed behavior\r\n\r\nFollowing error in `/var/log/fail2ban.log`.\r\n```\r\n2020-04-08 17:33:21,593 fail2ban                [7520]: ERROR   NOK: ('Action firewallcmd-ipset already exists',)\r\n```\r\n\r\n#### Any additional information\r\n\r\nProblem appears to be due to the stock `jail.conf`'s `[asterisk]` section.\r\n\r\n```\r\naction   = %(banaction)s[name=%(__name__)s-tcp, port=\"%(port)s\", protocol=\"tcp\", chain=\"%(chain)s\", actname=%(action)s-tcp]\r\n           %(banaction)s[name=%(__name__)s-udp, port=\"%(port)s\", protocol=\"udp\", chain=\"%(chain)s\", actname=%(banaction)s-udp]\r\n           %(mta)s-whois[name=%(__name__)s, dest=\"%(destemail)s\"]\r\n```\r\n\r\nI believe the `[name=` portions should be changed to `[actname=`.  I notice other `action` entries using `name=` that may need to change as well.\r\n\r\n### Configuration, dump and another helpful excerpts\r\n\r\nna\r\n\r\n#### Any customizations done to /etc/fail2ban/ configuration\r\n_(see above)_\r\n\r\n#### Relevant parts of /var/log/fail2ban.log file:\r\n```\r\n2020-04-08 17:33:21,593 fail2ban.transmitter    [7520]: WARNING Command ['server-stream', [['set','syslogsocket', 'auto'], ['set', 'loglevel', 'INFO'], ['set', 'logtarget', '/var/log/fail2ban.log'], ['set', 'dbfile', '/var/lib/fail2ban/fail2ban.sqlite3'], ['set', 'dbmaxmatches', 10], ['set', 'dbpurgeage', '1d'], ['add', 'asterisk', 'auto'], ['set', 'asterisk', 'usedns', 'warn'], ['set', 'asterisk', 'prefregex', '^(?:\\\\[\\\\])?\\\\s*(?:<[^.]+\\\\.[^.]+>\\\\s+)?(?:\\\\S+\\\\s+)?(?:kernel:\\\\s?\\\\[ *\\\\d+\\\\.\\\\d+\\\\]:?\\\\s+)?(?:@vserver_\\\\S+\\\\s+)?(?:(?:(?:\\\\[\\\\d+\\\\])?:\\\\s+[\\\\[\\\\(]?\\\\S*(?:\\\\(\\\\S+\\\\))?[\\\\]\\\\)]?:?|[\\\\[\\\\(]?\\\\S*(?:\\\\(\\\\S+\\\\))?[\\\\]\\\\)]?:?(?:\\\\[\\\\d+\\\\])?:?)\\\\s+)?(?:\\\\[ID \\\\d+ \\\\S+\\\\]\\\\s+)?(?:NOTICE|SECURITY|WARNING)(?:\\\\s*\\\\[\\\\d+\\\\]):?(?:\\\\[C-[\\\\da-f]*\\\\])?:? [^:]+:\\\\d*(?:(?: in)? [^:]+:)? <F-CONTENT>.+</F-CONTENT>$'], ['multi-set', 'asterisk', 'addfailregex', [\"^Registration from '[^']*' failed for '<HOST>(:\\\\d+)?' - (?:Wrong password|Username/auth name mismatch|No matching peer found|Not a local domain|Device does not match ACL|Peer is not supposed to register|ACL error \\\\(permit/deny\\\\)|Not a local domain)$\", \"^Call from '[^']*' \\\\(<HOST>:\\\\d+\\\\) to extension '[^']*' rejected because extension not found in context\", '^(?:Host )?<HOST> (?:failed (?:to authenticate\\\\b|MD5 authentication\\\\b)|tried to authenticate with nonexistent user\\\\b)', \"^No registration for peer '[^']*' \\\\(from <HOST>\\\\)$\", \"^hacking attempt detected '<HOST>'$\", '^SecurityEvent=\"(?:FailedACL|InvalidAccountID|ChallengeResponseFailed|InvalidPassword)\"(?:(?:,(?!RemoteAddress=)\\\\w+=\"[^\"]*\")*|.*?),RemoteAddress=\"IPV[46]/[^/\"]+/<HOST>/\\\\d+\"(?:,(?!RemoteAddress=)\\\\w+=\"[^\"]*\")*$', '^\"Rejecting unknown SIP connection from <HOST>(?38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5\\\\d+)?\"$', \"^Request (?:'[^']*' )?from '(?:[^']*|.*?)' failed for '<HOST>(?38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5\\\\d+)?'\\\\s\\\\(callid: [^\\\\)]*\\\\) - (?:No matching endpoint found|Not match Endpoint(?: Contact)? ACL|(?:Failed|Error) to authenticate)\\\\s*$\"]], ['set', 'asterisk', 'datepattern', '{^LN-BEG}'], ['set', 'asterisk', 'addjournalmatch', '_SYSTEMD_UNIT=asterisk.service'], ['set', 'asterisk','maxretry', 10], ['set', 'asterisk','maxmatches', 10], ['set', 'asterisk', 'findtime', '10m'], ['set', 'asterisk', 'bantime', '600'], ['set', 'asterisk', 'ignorecommand', ''], ['set', 'asterisk', 'addignoreip', '(289)413-6600', '38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5', '#.#.#.0/24', 'pbx.example.com','sip1.eg.com','sip2.eg.com'], ['set', 'asterisk', 'logencoding', 'auto'], ['set', 'asterisk', 'addlogpath', '/var/log/asterisk/messages', 'head'], ['set', 'asterisk', 'addaction', 'firewallcmd-ipset'], ['multi-set', 'asterisk', 'action', 'firewallcmd-ipset', [['actionstart', 'ipset create <ipmset> hash:ip timeout <bantime><familyopt>\\nfirewall-cmd --direct --add-rule <family> filter INPUT_direct 0 -p tcp -m multiport --dports 5060,5061 -m set --match-set <ipmset> src -j REJECT --reject-with <rejecttype>'], ['actionstop', 'firewall-cmd --direct --remove-rule <family> filter INPUT_direct 0 -p tcp -m multiport --dports 5060,5061 -m set --match-set <ipmset> src -j REJECT --reject-with <rejecttype>\\nipset flush <ipmset>\\nipset destroy <ipmset>'], ['actionflush', 'ipset flush <ipmset>'], ['actionban', 'ipset add <ipmset> <ip> timeout <bantime> -exist'], ['actionunban', 'ipset del <ipmset> <ip> -exist'], ['actiontype', '<multiport>'], ['name', 'asterisk-tcp'], ['port', '5060,5061'], ['protocol', 'tcp'], ['chain', '<known/chain>'], ['actname', 'firewallcmd-ipset'], ['family', 'ipv4'], ['zone', 'public'], ['service','ssh'], ['rejecttype', 'icmp-port-unreachable'], ['blocktype', 'REJECT --reject-with <rejecttype>'], ['rich-blocktype', \"reject type='<rejecttype>'\"], ['family?family=inet6', 'ipv6'], ['rejecttype?family=inet6', 'icmp6-port-unreachable'], ['bantime', '600'], ['allports', '-p <protocol>'], ['multiport', '-p <",
  "Issue title: \u52d2\u7d22\u8f6f\u4ef6\u7684\u65b0\u7248\u672c\n Issue body: \u61c9\u7528\u79d1\u5b78\u4e2d\u7684\u5bc6\u78bc\u5b78\u6700\u521d\u7528\u65bc\u5b89\u5168\u901a\u4fe1\u3001\u6578\u64da\u50b3\u9001\u548c\u4fe1\u606f\u5b58\u5132\uff0c\u907a\u61be\u7684\u662f\u76ee\u524d\u5b83\u7684\u61c9\u7528\u7bc4\u570d\u4e26\u4e0d\u5ee3\u6cdb\u3002\u7136\u800c\uff0c\u7db2\u7d61\u9a19\u5b50\u7684\u6295\u6a5f\u884c\u70ba\u985b\u8986\u4e86\u8a72\u73fe\u72c0\u3002\u4ed6\u5011\u507d\u9020\u51fa\u58f9\u7a2e\u5f15\u4eba\u8a3b\u76ee\u7684\u60e1\u610f\u4ee3\u78bc\uff0c\u5175\u7528\u5b83\u5c0d\u7528\u6236\u7684\u6587\u4ef6\u9032\u884c\u52a0\u5bc6\u4e26\u4ee5\u6b64\u7d22\u8981\u8d16\u91d1\u3002\u52d2\u7d22\u8edf\u4ef6\u662f\u8868\u793a\u9019\u7a2e\u7279\u6b8a\u7684\u8a08\u7b97\u6a5f\u75c5\u6bd2\u7684\u8853\u8a9e\uff0c\u81ea\u5f9e\u9996\u500b\u6848\u4f8b\u88ab\u767c\u73fe\u5f8c\u9019\u500b\u8a5e\u4fbf\u6210\u70ba\u4e86\u6d41\u884c\u8a5e\u3002\u9019\u985e\u611f\u67d3\u88ab\u7a31\u70baThunderCrypt\uff0c\u662f\u52d2\u7d22\u8edf\u4ef6\u7684\u6700\u65b0\u8868\u73fe\u3002\u76ee\u524d\u7d66\u4fe1\u606f\u6280\u8853\u7684\u5b89\u5168\u751f\u614b\u7cfb\u7d71\u9020\u6210\u4e86\u5927\u91cf\u9ebb\u7169\uff0c\u8868\u73fe\u51fa\u6975\u96e3\u8655\u7406\u7684\u60e1\u610f\u7279\u6027\u3002\r\nThunderCrypt\u5229\u7528RSA-2048\u5bc6\u78bc\u7b97\u6cd5\u4f7f\u5f97\u88ab\u611f\u67d3\u7684\u6a5f\u4e3b\u7121\u6cd5\u8a2a\u554f\u81ea\u5df1\u7684\u91cd\u8981\u6578\u64da\u3002\u9019\u610f\u5473\u8457ThunderCrypt\u70ba\u88ab\u611f\u67d3\u7684\u8a08\u7b97\u6a5f\u751f\u6210\u4e86\u58f9\u500b2048\u4f4d\u7684\u516c\u958b\u5bc6\u9470\uff0c\u4e26\u7528\u5b83\u4f86\u722d\u596a\u6587\u4ef6\u7684\u5167\u90e8\u7d50\u69cb\u3002\u96d6\u7136\u6587\u4ef6\u540d\u672c\u8eab\u4fdd\u6301\u4e0d\u8b8a\uff0c\u4f46\u537b\u7121\u6cd5\u6253\u958b\u6216\u9032\u884c\u7de8\u8f2f\u3002\u7121\u6cd5\u8a2a\u554f\u6587\u4ef6\u4e26\u4e0d\u662f\u9452\u5225\u8a08\u7b97\u6a5f\u88ab\u611f\u67d3\u7684\u552f\u58f9\u65b9\u6cd5\uff0c\u56e0\u70ba\u52d2\u7d22\u8edf\u4ef6\u6703\u986f\u793a\u58f9\u500b\u8b66\u544a\u7a97\u53e3\uff0c\u89e3\u91cb\u6240\u767c\u751f\u7684\u72c0\u6cc1\u4e26\u7d66\u51fa\u89e3\u6c7a\u63aa\u65bd\u3002\n Comments: \n Comment 0: \u6839\u64da\u8a72\u8b66\u544a\uff0c\u53d7\u5bb3\u4eba\u8981\u8d16\u56de\u6587\u4ef6\u5c31\u5fc5\u5b9a\u8981\u652f\u4ed8**0.345 BTC\uff0c\u5927\u7d04\u70ba500\u7f8e\u5143**\uff08\u6309\u672c\u6587\u5beb\u4f5c\u7576\u6642\u7684\u532f\u7387\uff09\u3002\u8a72\u52d2\u7d22\u4fe1\u70ba\u53d7\u5bb3\u7528\u6236\u63d0\u4f9b\u4e86\u7368\u7279\u7684\u6bd4\u7279\u5e63\u5730\u5740\u4ee5\u7528\u65bc\u4ea4\u4ed8\u8d16\u91d1\u3002\u58f9\u65e6\u5b8c\u6210\u4ed8\u6b3e\uff0c\u4ea4\u6613\u5c31\u6703\u88ab\u8b49\u5be6\uff0c\u89e3\u5bc6\u904e\u7a0b\u5c31\u6703\u81ea\u52d5\u555f\u52d5\u3002\u7f6a\u72af\u70ba\u4e86\u8b49\u660e\u89e3\u5bc6\u6d41\u7a0b\u7684\u6709\u6548\u6027\uff0c\u6703\u514d\u8cbb\u89e3\u5bc6\u58f9\u500b10 MB\u4ee5\u4e0b\u7684\u6587\u4ef6\u3002\r\n(http://soft2secure.com.tw/knowledgebase/thundercrypt)\n Comment 1: \u8c22\u8c22\u4f60\u7684\u6709\u8da3\u7684\u4fe1\u606f",
  "Issue title: Generating total_word_feature_extractor.dat for different language\n Issue body: Let's say I want to train MITIE for another language. so that it can be plugged into RASA.\r\nDoes it only need the data corpus of the language?\r\nCan someone point out the steps to generate total_word_feature_extractor.dat for that language which is need for RASA for using MITIE as backend?\r\nI couldn't find any documentation for that\n Comments: \n Comment 0: There are instructions here: https://github.com/mit-nlp/MITIE/blob/master/examples/python/train_ner.py ",
  "Issue title: Consider adding another badge\n Issue body: @iluwatar as this project is open-source, I was thinking why not add https://bestpractices.coreinfrastructure.org\r\nas a badge. It will be like cool both standardization + learning for readers.\r\nYou have to create the project there and add the badge.\r\n\r\nOthers probably also can contribute whenever you create it.\r\n> Just thought, please ignore if not relevant\n Comments: \n Comment 0: I have no previous experience in the \"CII Best Practices Badge Program\". I see they have some [criteria](https://github.com/coreinfrastructure/best-practices-badge/blob/master/doc/criteria.md) that has to be met for a project to \"self-certify\". I briefly looked at it and it seems that we are already passing all their tests. So if you @zafarella or somebody else want to work on this and get us the badge I'm ok with it.",
  "Issue title: custom test\n Issue body: {\"platform\":\"DS918+\",\"version\":\"7.1.0-42661\",\"ext\":\"r8125, r8168, e1000e, igb, ixgbe, mlx4_core\"\r\n}\n Comments: \n Comment 0: leleji \u60a8\u597d.\n\u60a8\u81ea\u5b9a\u4e49\u7684 Redpill \u5df2\u5f00\u59cb\u6784\u5efa\u3002\u8bf7\u524d\u5f80\u4e0b\u9762\u7684 URL \u67e5\u770b\u8be6\u7ec6\u4fe1\u606f\u3002\n> https://github.com/wjz304/Redpill_CustomBuild/actions/runs/2852808505\n----\nHi leleji. \nYour customized Redpill has started building. Please click the URL below to view the details.\n> https://github.com/wjz304/Redpill_CustomBuild/actions/runs/2852808505\n Comment 1: leleji \u60a8\u597d.\n\u60a8\u81ea\u5b9a\u4e49\u7684 Redpill \u5df2\u6784\u5efa\u5b8c\u6210\u3002\u8bf7\u524d\u5f80\u4e0b\u9762\u7684 URL \u4e0b\u8f7d\u3002\n> https://github.com/wjz304/Redpill_CustomBuild/actions/runs/2852808505  \n----\nHi leleji. \nYour customized Redpill has been builded. Please click the URL below to download it.\n> https://github.com/wjz304/Redpill_CustomBuild/actions/runs/2852808505",
  "Issue title: Release tag and Bower support\n Issue body: Hello,\n\nIt would be nice to have release tags for versions and bower support.\n\nThanks! \n\n Comments: \n Comment 0: Do a merge request and I'll check it out. Thx\n",
  "Issue title: Image class and DB\n Issue body: @TobiGr @mauriciocolli @Stypox: I was working on having NewPipeExtractor return all possible images together with their resolution (if known) in TeamNewPipe/NewPipeExtractor#268. This will (obviously) need some changes in NewPipe. Currently NewPipe just saves the URL of the images in the DB. With that PR, there won't just be one URL, so we'll need a separate table for the images, so we could store multiple images (together with their resolutions) in the DB. As I'm not familiar with Room, I was wondering whether one of you could work on it. I also know that the DB will change a bit in #2309.\n Comments: \n Comment 0: I never used databases, and I would like to learn. If nobody else takes this up I would be willing to, but it would be my first real experience with databases (and I would be looking forward to it ;-) )\n Comment 1: How should the resolution be stored?\n Comment 2: I give up. I tried for a week to implement this the correct way, but there are just too many things to consider that I don't know enough about. I was able to create the migration code (it was rather simple since I more-or-less know the basics of databases), but I wasn't able to come up with consistent and clear-enough ways of accessing data via Room.\r\nI tried to copy some code over from the classes that handle the \"playlist_stream_join\" table, but the design is different there since it is normal to ask for playlists without their streams, while it does not make sense to ask for a stream without the thumbnails.\r\nAlso, I saw indexes are used to improve performance, but I have no idea how they should be created and how to tell Room I want it to use them.\r\n\r\nThis is the migration code I came up with:\r\n```\r\n            // create new tables: images and stream_image_join\r\n            database.execSQL(\"CREATE TABLE IF NOT EXISTS images \" +\r\n                    \"(uid INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL, url TEXT UNIQUE NOT NULL, \" +\r\n                    \"width INTEGER NOT NULL, height INTEGER NOT NULL)\");\r\n\r\n            database.execSQL(\"CREATE TABLE IF NOT EXISTS stream_image_join \" +\r\n                    \"(image_id INTEGER PRIMARY KEY NOT NULL, stream_id INTEGER NOT NULL, \" +\r\n                    \"FOREIGN KEY(stream_id) REFERENCES streams(uid) ON UPDATE CASCADE ON DELETE CASCADE DEFERRABLE INITIALLY DEFERRED, \" +\r\n                    \"FOREIGN KEY(image_id) REFERENCES images(uid) ON UPDATE CASCADE ON DELETE CASCADE DEFERRABLE INITIALLY DEFERRED)\");\r\n\r\n\r\n            // move stream thumbnail urls into images and link those with stream_image_join\r\n            database.execSQL(\"INSERT OR IGNORE INTO images (url, width, height) \" +\r\n                    \"SELECT thumbnail_url, -1, -1 FROM streams\");\r\n\r\n            database.execSQL(\"INSERT INTO stream_image_join (stream_id, image_id) \" +\r\n                    \"SELECT streams.uid, images.uid \" +\r\n                    \"FROM streams INNER JOIN images \" +\r\n                    \"ON streams.thumbnail_url == images.thumbnail_url\");\r\n\r\n\r\n            // drop column thumbnail_url in table streams\r\n            database.execSQL(\"CREATE TABLE streams_temp \" +\r\n                    \"(uid INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL, service_id INTEGER NOT NULL, \" +\r\n                    \"url TEXT, title TEXT, stream_type TEXT, duration INTEGER, uploader TEXT)\");\r\n\r\n            database.execSQL(\"INSERT INTO streams_temp (uid, service_id, url, title, stream_type, duration, uploader) \" +\r\n                    \"SELECT uid, service_id, url, title, stream_type, duration, uploader FROM streams\");\r\n\r\n            database.execSQL(\"DROP TABLE streams\");\r\n            database.execSQL(\"ALTER TABLE streams_temp RENAME TO streams\");\r\n```",
  "Issue title: ToastManager is not visible in chrome extension\n Issue body: ### Description\n\nWhen I use toast() in chrome extension I would expect the toast to be visible \n\n### Link to Reproduction\n\nhttps://github.com/capaj/react-typescript-web-extension-starter\n\n### Steps to reproduce\n\nThis is the DOM I see in my inspector:\r\n\r\n![image](https://user-images.githubusercontent.com/1305378/130662627-78e302f1-d080-4e3f-a5e4-2874e7095800.png)\r\n\r\nI can tweak the DOM to get it to display:\r\n![image](https://user-images.githubusercontent.com/1305378/130663024-313c0c0e-9424-4281-be92-ebf29bc75d4e.png)\r\n\r\nbut it really should show up by default\n\n### Chakra UI Version\n\n1.6.6\n\n### Browser\n\nChrome\n\n### Operating System\n\n- [ ] macOS\n- [ ] Windows\n- [X] Linux\n\n### Additional Information\n\n_No response_\n Comments: \n Comment 0: Hi!\nThis issue has been automatically marked as stale because lack of recent activity. It will be closed if no further activity occurs within 5 days. Thank you for your contributions.\n\n Comment 1: cc @segunadebayo \n Comment 2: > It's probably because `ToastManager` is a hack, is mounted on module import as a side effect and is not part of the react component tree and does not unmount when the main component tree is unmounted, leaking memory in scenarios where a component tree is mounted/unmounted (like micro-frontends) and doesn't work in cases where react component tree is rendered into another document than `globalThis.document`.\r\n\r\nI had the same problem, in micro-frontends.\r\n![WX20220309-180119](https://user-images.githubusercontent.com/12584040/157418888-573d875c-7878-47fa-9520-6a9455921024.png)\r\n\n Comment 3: In the roadmap, I see that there are plans to fix toast manager, let's see how that goes.\n Comment 4: Hi all, I'm running into similar issues as noted by @anilanar and @donniean -- for example, I run into this memory leak issue using toasts in conjunction with next. Is this a specific issue related to SSR? I've noticed in the community Discord channel many others have ran into this issue as well. We would prefer to use the Toast component in our app but are blocked by this. \ud83d\ude4f @anilanar - Are you able to link where you're seeing those planes to fix the toast manager? \n Comment 5: @LKCSmith Here is the roadmap: https://github.com/chakra-ui/chakra-ui/projects/6#card-70244337\n Comment 6: Hi!\nThis issue has been automatically marked as stale because lack of recent activity. It will be closed if no further activity occurs within 5 days. Thank you for your contributions.\n",
  "Issue title: www.progressiveinfovision.com - menu bar is not working\n Issue body: <!-- @browser: Firefox 34.0 -->\n<!-- @ua_header: Mozilla/5.0 (Windows NT 6.2; WOW64; rv:34.0) Gecko/20100101 Firefox/34.0 -->\n\n**URL**: http://www.progressiveinfovision.com/#\n**Browser / Version**: Firefox 34.0\n**Operating System**: Windows 8 \n**Problem type**: Looks like the website has a bug.\n**Site owner**: No\n\n**Steps to Reproduce**\n1) Navigate to: http://www.progressiveinfovision.com/#\r\n2) \u2026\r\n\r\nExpected Behavior:\r\nActual Behavior:\r\n\n Comments: \n Comment 0: it works fine for me",
  "Issue title: Update Settings: Properly ignore settings that are not allowed to be updated dynamically\n Issue body: Update Settings: Properly ignore settings that are not allowed to be updated dynamically. (Currently, everything is passed, which is bad since its confusing).\n\n Comments: \n Comment 0: This kind of solves a part of #981.\nIt depends on whether you actually do or don't want to give the ability to use GET parameters for the PUT or POST updating the settings. Anyways, `pretty` (the only legal parameter for update settings I think) won't be taken as a setting anymore.\nFurther discussion on #981?\n\n Comment 1: Yea, this helps with #981. Lets continue there since I don't understand what GET parameters are... :)\n\n Comment 2: Having a PHP background, parameters can come from 2 source: the URL, the request body (often present only in case of `POST`/`PUT` method).\n\n_Do not hesitate to skip the following paragraph, I'm in verbose mode this night..._\nThe URL is basically `http://host:port/path/to/resource?firstSoCalledGetParam=value&etc`.\n`firstSoCalledGetParam` and `etc` are what PHP calls [GET](http://fr2.php.net/manual/en/reserved.variables.get.php) and [POST](http://fr2.php.net/manual/en/reserved.variables.post.php) parameters.\nIf the request body has a `Content-Type: application/x-www-form-urlencoded`, then the some other values can be given (under the same format `var=val&var2=val2`, with urlencoding). This is what curl does when using the `-d` flag (although it does not change the form of the value to match the `var=val&var2=val2` format).\nThe latter parameters are called POST parameters in PHP.\nWhen coding a PHP webpage, one will make sure of the origin of the parameter, preventing easy parameter injection by modifying the URL, so that only user friendly parameters are exposed as GET parameters through the URL, and making sure the other one do come from the request body as POST parameters.\n\n**To conclude:** GET and POST parameters somehow separate the presentation from the data.\nThis is why I proposed reading only POST parameters for a `POST` to the Update Settings API, leaving GET parameters only configure the presentation of the answer.\n",
  "Issue title: Increase default mnemonic size.\n Issue body: # Context\r\n\r\nVersion 2.0.0 of Daedalus generates wallets with recovery phrases that are 24 words in length.\r\n\r\n# Decision\r\n\r\nChange the default recovery phrase length from 15 words to 24 words in the `cardano-addresses` CLI library (as used by `cardano-wallet`):\r\n\r\nhttps://github.com/input-output-hk/cardano-addresses/blob/d4d178cb12fca3e9fcb23302325828e159600f0a/command-line/lib/Options/Applicative/MnemonicSize.hs#L73\r\n\r\n# Acceptance Criteria\r\n\r\n- [ ] When invoked without a specific number of words, the `cardano-addresses` CLI library (as used by `cardano-wallet`) should generate a recovery phrase of 24 words in length by default.\r\n\r\n# Development \r\n\r\n<!-- WHEN IN PROGRESS \r\nIn the form of a TODO list, explain how the ticket is going to be tackled and how\r\nyou intend to proceed. Attach a PR to each point in the list to track progress.\r\n\r\ne.g.\r\n\r\n- [ ] I intend to extend the existing handlers and use the wallet layer to implement \r\n  the necessary steps ==> #123\r\n\r\n- [ ] I plan on testing the endpoint by adding a few integration scenarios ==> #456\r\n-->\r\n\r\n# QA \r\n\r\n<!-- WHEN IN PROGRESS\r\nHow are we covering acceptance criteria? Give here manual steps or point to\r\ntests that are covering the technical decision we made.\r\n-->\r\n\n Comments: \n Comment 0: Perhaps we could add some test for that. I suppose there isn't any.\r\n\r\nI see that on cardano-wallet... cardano-wallet recover-phrase generate still spits 15 words. Should cardano-addresses be bumped in cardano-wallet to include this?\r\n\r\nI notice now also (not related to this change) but the coverage on cardano-addresses dropped to 41%... I think it was much higher... something happened? :thinking: @jonathanknowles, @KtorZ? \n Comment 1: > @piotr-iohk I notice now also (not related to this change) but the coverage on cardano-addresses dropped to 41%... \r\n\r\nYes, the coverage calculation broke after we re-organized the repository into multiple packages. I had to rework a bit the script for calculating the coverage but I forgot to push the new version somehow :shrug:... I also noticed yesterday and pushed the updated version that supports multi-package repositories. Coverage is back to normal :) ",
  "Issue title: exwm doesn't know what to do when a fullscreen window starts another fullscreen window\n Issue body: Hi,\r\n\r\nWhen using steam in big picture (in fullscreen), you can start a game which will probably start also in fullscreen, with steam itself still displaying a fullscreen window.\r\n\r\nIt seems (but I don't really know how to debug this behavior) exwm doesn't know how to handle the game's window and might even lose track of the first fullscreen window.\r\n\r\nI'm sorry I don't have any more details, I'm mostly looking for pointers to look into the issue.\r\n\r\nThanks!\r\n\r\n(sorry for the non-floss centric bug reports, but apart from that exwm does work pretty well)\n Comments: \n Comment 0: Are there any error messages? If not please run the following command before and after opening the second fullscreen X window (you may need to switch to the console) and show me the outputs.\r\n\r\n```\r\nDISPLAY=:0 xwininfo -root -tree\r\n```\n Comment 1: I reproduced the issue and you can find the output of xwininfo in the following gist, before steam big picture, during and after launching a fullscreen game:\r\nhttps://gist.github.com/razcampagne/1abc0b0629851b6c75b80b66f742cf7c\r\n\r\nSteam seems to launch a lot of silent windows. I tried 2 times the same process and it seems steam exits fullscreen mode when launching a game but then, EXWM just hangs. I have no mouse, no keyboard and I can't start an emacsclient in another tty.\r\nUsing ssh I might be able to step into the code just before the hanging, if you have any idea which function I should enable edebug for :/\n Comment 2: What if you first make the Steam X window floating and then make it fullscreen? It should make a difference because in this case the Steam X window won't get hidden after the game starts.  As for the output of xwininfo I'm not sure why both Steam and game X windows became floating.  Maybe it's because the Steam X window got hidden.\r\n\r\n> Using ssh I might be able to step into the code just before the hanging, if you have any idea which function I should enable edebug for :/\r\n\r\nJust use `pkill -SIGUSR2 emacs` after Emacs hangs.  If the input is still not usable, you can switch to a console and use emacsclient to connect.\n Comment 3: I tried what you suggested but it didn't change exwm's behavior.\r\nActually, the way steam works is by having a normal window, tiled in exwm's frame. When I ask for Big Picture mode (a gaming console-like interface), It creates a fullscreen window, independant from the main, normal one.\r\n\r\nAfter it freezed, I tried sending SIGUSR2 but that didn't unfreeze emacs. I regained the mouse cursor but I couldn't click anywhere. The keyboard was still unresponsive and emacsclient wouldn't respond either. \r\n\r\nAll I could get is a \"[XELB] Received Reply Timeout\" message in *Warnings* buffer.\r\n\r\nI'll try some other stuff when I have the time.\n Comment 4: picture, during and after launching a fullscreen game:\r\nhttps://gist.github.com/razcampagne/1abc0b0629851b6c75b80b66f742cf7c\r\n\r\nSteam seems to launch a lot of silent windows. I tried 2 times the same process and it seems steam exits fullscreen mode when launching a game but then, EXWM just hangs. I have no mouse, no keyboard and I can't start an emacsclient in another tty.\r\nUsing ssh I might be able to step into the code just before the hanging,??????????\"\n Comment 5: reproduced the issue and you can find the!\n Comment 6: > Actually, the way steam works is by having a normal window, tiled in exwm's frame. When I ask for Big Picture mode (a gaming console-like interface), It creates a fullscreen window, independant from the main, normal one.\r\n\r\nI can't find the extra X window in outputs though.  And the output \"no-fullscreen\" seems to be taken before Steam was made floating, right?\r\n\r\n> After it freezed, I tried sending SIGUSR2 but that didn't unfreeze emacs. I regained the mouse cursor but I couldn't click anywhere. The keyboard was still unresponsive and emacsclient wouldn't respond either.\r\n\r\nWhen emacs hangs, it usually consumes 100% CPU usage.  Is that the case?  If SIGUSR2 doesn't work, you may also try sending the default SIGTERM (for only once).\r\n\r\n> All I could get is a \"[XELB] Received Reply Timeout\" message in *Warnings* buffer.\r\n\r\nWell this is an abnormal behavior.  Perhaps some error was made in a request.  Also could you visit the `*Messages*` buffer?\n Comment 7: The fullscreen state was actually not even checked when an X window starts.  This has been fixed in ebcc9591f3c1210efda007bec6852369b75fa8ad.  Could anyone verify if this issue has been resolved?\n Comment 8: Sorry for the delay, I couldn't even try to answer your earlier questions\u2026\r\nBut I am pleased to tell you this issue has indeed been fixed!\r\n\r\nThank you very much for your hard work :)",
  "Issue title: yahoo.com\n Issue body: Hi,\r\ncookies notice \r\n\r\n(mobile user agent)\r\n\r\n- https://i.imgur.com/D2DQ1KO.png\r\n- https://i.imgur.com/pOgiUaj.png\r\n- https://i.imgur.com/I3mgZ2m.png\r\n\r\n<span>https://</span>fr.yahoo.com/?p=dnr\r\n<span>https://</span>de.yahoo.com/?p=dnr\r\n<span>https://</span>es.yahoo.com/?p=dnr\r\n\r\nreplace:\r\n```\r\nuk.yahoo.com##div.js-applet-view-container-main > div[style^=\"background:\"]\r\n```\r\nby:\r\n```\r\nyahoo.com##div.js-applet-view-container-main > div.fixed-win[style^=\"background:\"]\r\n```\r\n\n Comments: \n Comment 0: https://github.com/ryanbr/fanboy-adblock/commit/4380271b35b436af4264440c18d56ab941e850f6",
  "Issue title: `Zypen` not working on iOS 11.3.1\n Issue body: ```\r\n{\r\n  \"packageId\": \"com.shade.zypen\",\r\n  \"action\": \"notworking\",\r\n  \"userInfo\": {\r\n    \"arch32\": false,\r\n    \"packageId\": \"com.shade.zypen\",\r\n    \"deviceId\": \"iPhone10,3\",\r\n    \"url\": \"http://cydia.saurik.com/package/com.shade.zypen/\",\r\n    \"iOSVersion\": \"11.3.1\",\r\n    \"packageVersionIndexed\": true,\r\n    \"packageName\": \"Zypen\",\r\n    \"category\": \"Tweaks\",\r\n    \"repository\": \"ShadeZepheri Repo\",\r\n    \"name\": \"Zypen\",\r\n    \"installed\": \"\",\r\n    \"packageIndexed\": true,\r\n    \"packageStatusExplaination\": \"This package version has been marked as Not working based on feedback from users in the community. The current positive rating is 0% with 0 working reports.\",\r\n    \"id\": \"com.shade.zypen\",\r\n    \"commercial\": false,\r\n    \"packageInstalled\": false,\r\n    \"tweakCompatVersion\": \"0.1.0\",\r\n    \"shortDescription\": \"1/2 of Multiplexer\",\r\n    \"latest\": \"0.9.1\",\r\n    \"author\": \"Shade Zepheri\",\r\n    \"packageStatus\": \"Not working\"\r\n  },\r\n  \"base64\": \"eyJhcmNoMzIiOmZhbHNlLCJwYWNrYWdlSWQiOiJjb20uc2hhZGUuenlwZW4iLCJkZXZpY2VJZCI6ImlQaG9uZTEwLDMiLCJ1cmwiOiJodHRwOlwvXC9jeWRpYS5zYXVyaWsuY29tXC9wYWNrYWdlXC9jb20uc2hhZGUuenlwZW5cLyIsImlPU1ZlcnNpb24iOiIxMS4zLjEiLCJwYWNrYWdlVmVyc2lvbkluZGV4ZWQiOnRydWUsInBhY2thZ2VOYW1lIjoiWnlwZW4iLCJjYXRlZ29yeSI6IlR3ZWFrcyIsInJlcG9zaXRvcnkiOiJTaGFkZVplcGhlcmkgUmVwbyIsIm5hbWUiOiJaeXBlbiIsImluc3RhbGxlZCI6IiIsInBhY2thZ2VJbmRleGVkIjp0cnVlLCJwYWNrYWdlU3RhdHVzRXhwbGFpbmF0aW9uIjoiVGhpcyBwYWNrYWdlIHZlcnNpb24gaGFzIGJlZW4gbWFya2VkIGFzIE5vdCB3b3JraW5nIGJhc2VkIG9uIGZlZWRiYWNrIGZyb20gdXNlcnMgaW4gdGhlIGNvbW11bml0eS4gVGhlIGN1cnJlbnQgcG9zaXRpdmUgcmF0aW5nIGlzIDAlIHdpdGggMCB3b3JraW5nIHJlcG9ydHMuIiwiaWQiOiJjb20uc2hhZGUuenlwZW4iLCJjb21tZXJjaWFsIjpmYWxzZSwicGFja2FnZUluc3RhbGxlZCI6ZmFsc2UsInR3ZWFrQ29tcGF0VmVyc2lvbiI6IjAuMS4wIiwic2hvcnREZXNjcmlwdGlvbiI6IjFcLzIgb2YgTXVsdGlwbGV4ZXIiLCJsYXRlc3QiOiIwLjkuMSIsImF1dGhvciI6IlNoYWRlIFplcGhlcmkiLCJwYWNrYWdlU3RhdHVzIjoiTm90IHdvcmtpbmcifQ==\",\r\n  \"chosenStatus\": \"not working\",\r\n  \"notes\": \"\"\r\n}\r\n```\n Comments: \n Comment 0: This issue is being closed because your review was accepted into the tweakCompatible website. \nTweak developers do not monitor or fix issues submitted via this repo.\nIf you have an issue with a tweak, contact the developer via another method.",
  "Issue title: \u81ea\u4ece\u4e0a\u6b21\u91cd\u5927\u66f4\u65b05.4\u5185\u6838\u5f00\u59cb \u5230\u73b0\u5728\u521a\u521aPULL\u7684\u6e90\u7801\u7f16\u8bd1\u540e\u53d1\u73b0\u4e2a\u95ee\u9898\n Issue body: \u73a9\u6e38\u620f \u8857\u97385 \u6ca1\u529e\u6cd5\u5728\u7ebf\u73a9\u4e86 \u9009\u5b8c\u4eba\u4ee5\u540e \u5c31\u6389\u7ebf \u6709\u7684\u65f6\u5019 \u6ca1\u9009\u5b8c\u5462 \u5c31\u6389\u4e86 \u6e38\u620f\u672c\u8eab\u8054\u673a\u662fP2P\u7684\r\n\u6d4b\u8bd5\u8fc7\u5c0f\u5a31\u548c\u7ade\u6597\u4e91  \u540c\u6837\u7684\u95ee\u9898\n Comments: \n Comment 0:  Upnp\u7684\u95ee\u9898\u5427\uff0c\u770b\u4e0b\u8fd9\u4e2a #5020 \n Comment 1: Thu Jul 16 19:30:13 2020 daemon.err uhttpd[2102]: udhcpc: started, v1.31.1\r\nThu Jul 16 19:30:13 2020 daemon.err uhttpd[2102]: udhcpc: sending discover\r\nThu Jul 16 19:30:16 2020 daemon.err uhttpd[2102]: udhcpc: no lease, failing\r\nThu Jul 16 19:30:17 2020 daemon.info dnsmasq[10660]: Connected to system UBus\r\nThu Jul 16 19:31:22 2020 authpriv.info dropbear[9092]: Exit (root) from <116.69.203.115:62343>: Exited normally\r\nThu Jul 16 19:31:34 2020 authpriv.info dropbear[7509]: Exit (root) from <116.69.203.115:62339>: Exited normally\r\nThu Jul 16 19:31:34 2020 authpriv.info dropbear[9073]: Exit (root) from <116.69.203.115:62342>: Exited normally\r\n\u8fd9\u4e2a\u9519\u8bef \u548cUPNP\u8c8c\u4f3c\u6ca1\u5173\u7cfb\n Comment 2: > Exited normally\r\n\r\n\u8fd9\u6bb5\u65e5\u5fd7\uff0c\u6ca1\u53d1\u73b0\u4ec0\u4e48\u9519\u8bef\u554a\uff1f\n Comment 3: > Thu Jul 16 19:30:13 2020 daemon.err uhttpd[2102]: udhcpc: started, v1.31.1\r\n> Thu Jul 16 19:30:13 2020 daemon.err uhttpd[2102]: udhcpc: sending discover\r\n> Thu Jul 16 19:30:16 2020 daemon.err uhttpd[2102]: udhcpc: no lease, failing\r\n> Thu Jul 16 19:30:17 2020 daemon.info dnsmasq[10660]: Connected to system UBus\r\n> Thu Jul 16 19:31:22 2020 authpriv.info dropbear[9092]: Exit (root) from <116.69.203.115:62343>: Exited normally\r\n> Thu Jul 16 19:31:34 2020 authpriv.info dropbear[7509]: Exit (root) from <116.69.203.115:62339>: Exited normally\r\n> Thu Jul 16 19:31:34 2020 authpriv.info dropbear[9073]: Exit (root) from <116.69.203.115:62342>: Exited normally\r\n> \u8fd9\u4e2a\u9519\u8bef \u548cUPNP\u8c8c\u4f3c\u6ca1\u5173\u7cfb\r\n\r\n\u8fd9\u6bb5\u65e5\u5fd7\uff0c\u6ca1\u53d1\u73b0\u4ec0\u4e48\u9519\u8bef\u554a\n Comment 4: \u6700\u540e\u90a33\u4e2a \u6211\u4e00\u8054\u673a\u5931\u8d25 \u5c31\u51fa\u8fd9\u4e2a\n Comment 5: > \u6700\u540e\u90a33\u4e2a \u6211\u4e00\u8054\u673a\u5931\u8d25 \u5c31\u51fa\u8fd9\u4e2a\r\n\r\n\u3002\u3002\u3002\u6211\u4e5f\u4e0d\u77e5\u9053\u662f\u5565\u60c5\u51b5\u4e86\u3002\u3002\u3002\r\ndropbear\u662f\u63d0\u4f9bsshd\u670d\u52a1\u7684\uff0c\u4ece\u65e5\u5fd7\u4e0a\u6765\u770b\uff0c\u662f116.69.203.115\u7684ssh\u5ba2\u6237\u7aef\uff0c\u7528root\u8d26\u6237\u767b\u5f55\u8def\u7531\u5668\u540e\u6b63\u5e38\u9000\u51fa\n Comment 6: \u6211\u628aUPNPD\u6362\u5230\u4e86\r\nPKG_NAME:=miniupnpd\r\nPKG_VERSION:=2.0.20170421\r\nPKG_RELEASE:=3\r\n\u7136\u540e\u95ee\u9898\u4f9d\u65e7 \u6211\u5d29\u6e83\u4e86~\u8fd9\u6b21\u66f4\u65b0\u7684\u6587\u4ef6\u592a\u591a\u4e86 \u5b9e\u5728\u662f\u627e\u4e0d\u5230\u4ec0\u4e48\u5730\u65b9\u51fa\u7684\u95ee\u9898\n Comment 7: > \u6211\u628aUPNPD\u6362\u5230\u4e86\r\n> PKG_NAME:=miniupnpd\r\n> PKG_VERSION:=2.0.20170421\r\n> PKG_RELEASE:=3\r\n> \u7136\u540e\u95ee\u9898\u4f9d\u65e7 \u6211\u5d29\u6e83\u4e86~\u8fd9\u6b21\u66f4\u65b0\u7684\u6587\u4ef6\u592a\u591a\u4e86 \u5b9e\u5728\u662f\u627e\u4e0d\u5230\u4ec0\u4e48\u5730\u65b9\u51fa\u7684\u95ee\u9898\r\n\r\n\u4e0b\u8f7d\u4e2a\u6bd4\u7279\u5f57\u661f\uff0c\u6253\u5f00\u770b\u770b\u6709\u6ca1\u6709\u63d0\u793a UPnP NAT\u7aef\u53e3\u6620\u5c04: \u5931\u8d25\u3002\r\n\u6709IPv6\u7684\u8bdd\uff0c\u5148\u5173\u95edIPv6\u3002\r\n\r\n\u6216\u8005\u3002\u3002\u3002\u8bbe\u7f6edmz\ud83e\udd23\n Comment 8: \u6700\u65b0\u62a5\u544a: \u5c0f\u5a31C1/C5 (MT7621)\u7528\u6700\u65b0\u7684\u6e90\u7801 \u5df2\u7ecf\u6ca1\u6709\u8fd9\u4e2a\u95ee\u9898\u4e86!  X86 \u548c\u7ade\u6597\u4e91 \u8fd8\u662f\u8fd9\u4e2a\u95ee\u9898~~\u4e0d\u77e5\u9053\u5230\u5e95\u5dee\u5728\u54ea\u91cc!\n Comment 9: \u7ec8\u4e8e\u627e\u5230\u6e38\u620f\u6389\u7ebf\u7684\u539f\u56e0\u4e86\u53ea\u8981\u5f00\u542fSFE \u5c31\u4f1a\u5728\u8857\u9738\u7f51\u7edc\u5bf9\u6218\u5f00\u59cb\u7684\u65f6\u5019\u4e0e\u5bf9\u624b\u65ad\u5f00\u8fde\u63a5 \u5173\u95ed\u4e86SFE\u6062\u590d\u6b63\u5e38 \u4e0d\u77e5\u9053\u5177\u4f53\u539f\u56e0\u5728\u54ea \u7b49\u5927\u5c4c\u6709\u65f6\u95f4\u770b\u770b\u5427",
  "Issue title: Craftin altar does not drop a spell parchment after dropping a blank parchment\n Issue body: Wasted to sets of resources already, every time I finish crafting and drop a parchment nothing happens.\r\nSpell is simple projectile + magic damage.\n Comments: \n Comment 0: Version?\n Comment 1: The pack is All the mods 1.10.2 v2.52b\r\nArs Magica 2 version is 1.10.2  1.5.0-17b\n Comment 2: Please post 1.10.2 issues to https://github.com/Growlith1223/ArsMagica2/issues",
  "Issue title: Able to connect to pivpn instance without user profile\n Issue body: Hi - I need to know if what I am seeing is a serious bug or openvpn feature.\r\nI have not been able to find the answer anywhere, but I am using virtualized\r\nmachines in my situation.  Not sure if this should be posted on openvpn forums,\r\nbut since I am using pivpn, I am posting it here.\r\n\r\nHere is the scenario:\r\n\r\n1. Install pivpn on an instance (in my case I used Ubuntu)\r\n2. Create a user profile on it - say userA\r\n3. If all is well, you can connect to your VPN instance using that profile\r\nfrom a client like Tunnelblick\r\n4. Create an image of that Ubuntu instance (vmware, virtualbox etc.)\r\n5. Spin up a new instance from the image\r\n6. Now, if you change the IP of the VPN server in your VPN profile file,\r\nyou should be able to connect to the new instance of it as well.\r\n7. Login to first instance, and create another user - say userB\r\n8. Get the userB.ovpn file, but change the IP to point to 2nd VPN instance.\r\n9. Import it into your vpn client.\r\n10. You will now be able to successfully connect to the 2nd VPN instance\r\neven though the userB was created on 1st VPN instance.\r\n\r\nIf you login to your VPN instances, and run <code>pivpn -l</code> you will\r\nsee that only the first instance has both names listed.  Followed by this,\r\nif you run <code>pivpn -c</code>, you will see that userB is connected\r\nsuccessfully to 2nd instance, even though their name is not listed.\r\n\r\nWhy is this happening? If this is a feature of OpenVPN, could someone\r\nexplain this behavior to me.\r\n\r\nI thought I would somehow need to copy some files between the two instances\r\nto get the user connectivity working from the second instance, but it was\r\nnot the case.  I was just doing this for sake of redundancy, when I stumbled\r\nupon this behavior.\n Comments: \n Comment 0: Well, they're actually the same instance: as far as I know, OpenVPN only cares about the cryptographic keys that get generated when pivpn is installed. You didn't find a security issue, because if an attacker can image the server you're running OpenVPN on, he can do whatever he wants. \n Comment 1: So, what about the entire certificate add and revoke process for a user?  Adding a user on one instance, seems to give you access to the other - with just an IP change. I have not tried what happens when you revoke the user. If it would NOT grant access to both the instances after that, then I suppose this can work as long as you are just adding and revoking certificates from the same instance (just to maintain sanity).",
  "Issue title: ES.28: use st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke to call the lambda\n Issue body: Now that C++17 has `st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke`, we could make use of it when doing complex initialization with lambdas. It improves readability, as it becomes clear that you are calling the lambda right away, rather than finding out about it later at the end of a lambda. Example:\r\n\r\nWithout `st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke`:\r\n\r\n```\r\nconst widget x = [&]{\r\n    widget val;                                // assume that widget has a default constructor\r\n    for (auto i = 2; i <= N; ++i) {            // this could be some\r\n        val += some_obj.do_something_with(i);  // arbitrarily long code\r\n    }                                          // needed to initialize x\r\n    return val;\r\n}();\r\n```\r\n\r\nWith `st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke`:\r\n\r\n```\r\nconst widget x = st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke([&]{\r\n    widget val;                                // assume that widget has a default constructor\r\n    for (auto i = 2; i <= N; ++i) {            // this could be some\r\n        val += some_obj.do_something_with(i);  // arbitrarily long code\r\n    }                                          // needed to initialize x\r\n    return val;\r\n});\r\n```\r\n\n Comments: \n Comment 0: `st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke` is not `constexpr` ([[func.invoke]](http://eel.is/c++draft/func.invoke)), while lambdas can be used in constant expressions (as of C++17, as well). So you can use the first form, but not the second form, for a `constexpr widget x`. Although perhaps `st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke` could be fixed to allow this.\n Comment 1: The version with `st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke` is a few characters longer, but the improvement in readability isn't apparent.\r\nThere might be other cases where `st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke` might be the right choice, but this particular instance isn't one of them.\n Comment 2: N.B. GB 51 in [P0488](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0488r0.pdf) proposed making `st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke` constexpr, but was not accepted for C++17.\n Comment 3: I use that syntax and was just about to fill similar issue. To me st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke() makes it obvious that it's the result of an invocation that's assigned, otherwise it just looks like typical lambda assigned to a variable.\r\n\r\nNon-constexprness might be a problem in some cases. In such cases I'd use () and add a NOTE comment or something to make the intent clear.\n Comment 4: I agree. @feroldi's first example reads like a [garden path sentence ](https://en.wikipedia.org/wiki/Garden-path_sentence). The st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5invoke option seems clearly easier for a human to parse to me. It's not so clear whether that justifies the extra characters or the sacrifice of constexpr until c++20.",
  "Issue title: Binary nose package not properly registering the distutils entry point.\n Issue body: Currently, the ``nose-1.3.4-py27_0`` package contains ``lib/python2.7/site-packages/nose-1.3.4-py2.7.egg-info`` rather than the directory ``lib/python2.7/site-packages/nose-1.3.4.dist-info`` installed by ``pip install nose``.  This somehow does not properly register the ``distutils`` ``nosetest`` entry-point, breaking ``python setup.py nosetests`` as described in [this nose issue](https://github.com/nose-devs/nose/issues/873).\r\n\r\nI'm not sure exactly what the problem is, but it would probably be solved by rebuilding the current package with a recent version of ``pip`` or ``setuptools``.\r\n\r\nP.S. If this is not the correct place for submitting broken package issues, please let me know where the should go instead as it is not clear from the documentation.\n Comments: \n Comment 0: This is also an issues with the ``flake8`` package for which ``python setup.py flake8`` fails with the binary installation of ``flake8``.\n Comment 1: A better place is https://github.com/continuumio/anaconda-issues.\n\n Comment 2: Okay.  I have migrated the issue.\n\n Comment 3: @asmeurer The migrated issue seems to be ignored.  Any suggestions on how to go about fixing this?\n\n Comment 4: Hi there, thank you for your contribution to Conda!\n\nThis issue has been automatically locked since it has not had recent activity after it was closed.\n\nPlease open a new issue if needed.",
  "Issue title: Not supported by PST Import team\n Issue body: This should be noted that it is not supported by the PST Upload team to do PST imports into Exchange Online and should instead use the documented method [here](https://docs.microsoft.com/en-us/microsoft-365/compliance/use-network-upload-to-import-pst-files?view=o365-worldwide).\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\r\n\r\n* ID: c7d1f46c-b436-12ee-42b9-616963520de7\r\n* Version Independent ID: 1ad16056-d5c5-a815-c6d6-8e38b96fdbd8\r\n* Content: [New-MailboxImportRequest (exchange)](https://docs.microsoft.com/en-us/powershell/module/exchange/new-mailboximportrequest?view=exchange-ps#feedback)\r\n* Content Source: [exchange/exchange-ps/exchange/New-MailboxImportRequest.md](https://github.com/MicrosoftDocs/office-docs-powershell/blob/master/exchange/exchange-ps/exchange/New-MailboxImportRequest.md)\r\n* Service: **exchange-powershell**\r\n* GitHub Login: @chrisda\r\n* Microsoft Alias: **chrisda**\n Comments: \n Comment 0: @officedocsbot assign @yogkumgit\n Comment 1: Hi @moditpro365, thank you for your feedback and help us to improve docs.microsoft.com.\r\n\r\nAre you from Microsoft?\r\n\r\n@chrisda could you kindly help to confirm this information? I understand that if you upload the PST files to an Azure Storage you can use this cmdlet with -AzureBlobStorageAccountUri and -AzureSharedAccessSignatureToken parameters.\n Comment 2: I wrote an entire process to migrate enterprise wide PSTs to Online Archive. When I opened a support request to Microsoft about errors or issues I was seeing I was told it wasn\u2019t a supported method for importing PSTs and to use the documented process in the link I provided initially. Considering the time spent developing the process with the use of the PowerShell cmdlet, it seems right it should be documented if it\u2019s not supported. I was using the process as documented on the page. Here\u2019s the response I received from MSFT:\r\n\r\n\u201cUse PowserShell directly to create MRS Import requests is NOT supported by the \"PST Import service team\". As this completely bypasses all the orchestration that our O365 PST Import service performs on top of MRS import requests (monitoring of transient failures between Azure and EXO, refresh of the updates of the import requests in the Import service UI etc).\r\n\r\nYou should use PowerShell simply to monitor statuses of MRS Import requests (Get-MailboxImportRequest and/orGet-MailboxImportRequestStatistcs) and NOT New/Suspend/Resume/Remove-MailboxImportRequest, unless if advised by us while troubleshooting issues.\r\n\r\nThe only supported scenario is :\r\n\r\n1/ Upload the PSTs using azcopy.exe (or ship a drive containing the PSTs), into the dedicated Azure Storage blob that is created by our \"O365 PST Import service\" the first time customer retrieves a SAS key from his Import service portal.\r\nWe cannot choose the type of Storage to be used in this scenario.\r\n\r\n2/ Use our Import service portal to create a PST Import job (by submitting a CSV mapping file). This service will connect to the dedicated Azure Storage blob (created in the step above) and will create and monitor all the individual MRS Import requests and orchestrate all the process.\u201d\r\n\r\n\r\nFrom: Dario Woitasen <warrenbrooke@example.com>\r\nSent: Friday, May 29, 2020 12:37 PM\r\nTo: MicrosoftDocs/office-docs-powershell <warrenbrooke@example.com>\r\nCc: Stephen Morgan <warrenbrooke@example.com>; Mention <warrenbrooke@example.com>\r\nSubject: Re: [MicrosoftDocs/office-docs-powershell] Not supported by PST Import team (#5714)\r\n\r\n\r\nHi @moditpro365<https://github.com/moditpro365>, thank you for your feedback and help us to improve docs.microsoft.com.\r\n\r\nAre you from Microsoft?\r\n\r\n@chrisda<https://github.com/chrisda> could you kindly help to confirm this information? I understand that if you upload the PST files to an Azure Storage you can use this cmdlet with -AzureBlobStorageAccountUri and -AzureSharedAccessSignatureToken parameters.\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/MicrosoftDocs/office-docs-powershell/issues/5714#issuecomment-636150686>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/APXZOB65BWRX2OQ6V6OSOXDRUAFGPANCNFSM4NMNDTXQ>.\r\n\n Comment 3: @moditpro365 thank you so much for all this very detailed information. I\u00b4m applying an update to the article, and I\u00b4m waiting now for approval.\r\n\r\nThanks again, for taking out some time to open the issue. Appreciate and encourage you to do the same in future also.\r\n\n Comment 4: Sounds good!\r\n\r\nFrom: Dario Woitasen <warrenbrooke@example.com>\r\nSent: Friday, May 29, 2020 1:56 PM\r\nTo: MicrosoftDocs/office-docs-powershell <warrenbrooke@example.com>\r\nCc: Stephen Morgan <warrenbrooke@example.com>; Mention <warrenbrooke@example.com>\r\nSubject: Re: [MicrosoftDocs/office-docs-powershell] Not supported by PST Import team (#5714)\r\n\r\n\r\n@moditpro365<https://github.com/moditpro365> thank you so much for all this very detailed information. I\u00b4m applying an update to the article, and I\u00b4m waiting now for approval.\r\n\r\nThanks again, for taking out some time to open the issue. Appreciate and encourage you to do the same in future also.\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/MicrosoftDocs/office-docs-powershell/issues/5714#issuecomment-636188280>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/APXZOBYTPFKNCYAXSJOF6PLRUAONPANCNFSM4NMNDTXQ>.\r\n\n Comment 5: @dariomws  Thank you very much for the contribution and updating the documentation with PR. @moditpro365 Hope this update is helpful for you. Thanks for taking out some time to open the issue. Appreciate and encourage you to do the same in future also.\r\n",
  "Issue title: userlock icon should appear in hover state for popup menu entries\n Issue body: this should be some simple CSS property herding.\n\n Comments: \n Comment 0: we are no longer using the lock icon but a privacy badger icon that shows up when a domain is taken over manually that can be clicked to return control of the domain to privacy badger.\n",
  "Issue title: Add keywriter fork with decreased font size\n Issue body: Would be great to have this rm keywriter fork with smaller font size for edit mode:\r\nhttps://github.com/danschrage/remarkable-keywriter\r\n\r\nThere have been few more people who wanted to have a writing experience with smaller font size.\n Comments: \n Comment 0: It would probably make more sense to ask for that change to be upstreamed, or configuration added to tweak it per install.\n Comment 1: Seems to have been added to upstream. Keeping this open as a reminder to update our package.",
  "Issue title: bug: cors() does not work after modifying\n Issue body: ### Issue description\r\n\r\n### Environment\r\n\r\n* apisix version (cmd: `apisix version`): APISIX/2.5\r\n* OS (cmd: `uname -a`): 2.5-alpine\r\n* OpenResty / Nginx version (cmd: `nginx -V` or `openresty -V`):\r\n* etcd version, if have (cmd: run `curl http://116.69.203.115:9090/v1/server_info` to get the info from server-info API): 3.4\r\n* apisix-dashboard version, if have: 2.5\r\n\r\n### Minimal test code / Steps to reproduce the issue\r\n\r\n1. request:\r\n\r\n```\r\n# request:\r\n\r\ncurl 'http://pilot.x.work/apisix/admin/routes/350558925461914554' \\\r\n  -X 'PUT' \\\r\n  -H 'Connection: keep-alive' \\\r\n  -H 'Accept: application/json' \\\r\n  -H 'DNT: 1' \\\r\n  -H 'Authorization:'\\\r\n  -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.128 Safari/537.36' \\\r\n  -H 'Content-Type: application/json;charset=UTF-8' \\\r\n  -H 'Origin: http://pilot.x.work' \\\r\n  -H 'Referer: http://pilot.x.work/routes/list' \\\r\n  -H 'Accept-Language: zh-CN,zh;q=0.9' \\\r\n  --data-raw '{\r\n    \"uris\":[\r\n        \"/*\"\r\n    ],\r\n    \"name\":\"https_mapi-x\",\r\n    \"desc\":\"https://x\",\r\n    \"priority\":10,\r\n    \"hosts\":[\r\n        \"x\"\r\n    ],\r\n    \"vars\":[\r\n        [\r\n            \"scheme\",\r\n            \"==\",\r\n            \"https\"\r\n        ]\r\n    ],\r\n    \"plugins\":{\r\n        \"cors\":{\r\n            \"allow_credential\":true,\r\n            \"allow_headers\":\"*\",\r\n            \"allow_methods\":\"*\",\r\n            \"allow_origins\":\"https://x\",\r\n            \"expose_headers\":\"*\",\r\n            \"max_age\":-1\r\n        }\r\n    },\r\n    \"upstream_id\":\"350558615033086906\",\r\n    \"status\":1\r\n}\r\n '\\\r\n  --compressed \\\r\n  --insecure\r\n```\r\n\r\n\r\n2.response\r\n\r\n```\r\n# curl the route with response:\r\n\r\nHTTP/2 404\r\ncontent-type: text/plain; charset=utf-8\r\ncontent-length: 18\r\ndate: Wed, 21 Apr 2021 06:43:25 GMT\r\nserver: APISIX/2.5\r\naccess-control-allow-origin: *\r\naccess-control-allow-methods: *\r\naccess-control-max-age: 5\r\naccess-control-expose-headers: *\r\naccess-control-allow-headers: *\r\n\r\n```\r\n\r\n### What's the actual result? (including assertion message & call stack if applicable)\r\n\r\n### What's the expected result?\r\n\n Comments: \n Comment 0: > \"cors\":{\r\n>             \"allow_credential\":true,\r\n>             \"allow_headers\":\"*\",\r\n>             \"allow_methods\":\"*\",\r\n>             \"allow_origins\":\"https://x\",\r\n>             \"expose_headers\":\"*\",\r\n>             \"max_age\":-1\r\n>         }\r\n\r\n`*` is used in other options, so the `allow_credential` field should not be set to `true`.\r\n<img width=\"1022\" alt=\"\u622a\u5c4f2021-04-21 \u4e0b\u53483 16 44\" src=\"https://user-images.githubusercontent.com/52862365/115513163-598b1700-a2b5-11eb-9fa6-122df672cb95.png\">\r\n\n Comment 1: I tried it and it worked. You should check if there is a cors plugin configuration elsewhere?\n Comment 2: > > \"cors\":{\r\n> > \"allow_credential\":true,\r\n> > \"allow_headers\":\"_\",\r\n> > \"allow_methods\":\"_\",\r\n> > \"allow_origins\":\"https://x\",\r\n> > \"expose_headers\":\"*\",\r\n> > \"max_age\":-1\r\n> > }\r\n> \r\n> `*` is used in other options, so the `allow_credential` field should not be set to `true`.\r\n> <img alt=\"\u622a\u5c4f2021-04-21 \u4e0b\u53483 16 44\" width=\"1022\" src=\"https://user-images.githubusercontent.com/52862365/115513163-598b1700-a2b5-11eb-9fa6-122df672cb95.png\">\r\n\r\n\r\nI only set this in route, but it does not work any more.\r\n\r\n```\r\n  \"plugins\": {\r\n    \"cors\": {\r\n      \"allow_origins\": \"https://x\"\r\n    }\r\n  }\r\n\r\n```\n Comment 3: > # curl the route with response:\r\n\r\nHow do you hit the route with curl? AFAIK, curl doesn't send Origin header by default.\n Comment 4: > > curl the route with response:\r\n> \r\n> How do you hit the route with curl? AFAIK, curl doesn't send Origin header by default.\r\n\r\ncurl -I https://x\r\n\r\n\n Comment 5: This command doesn't send Origin header.\r\nThe client should run the CORS mechanism: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS\n Comment 6: > This command doesn't send Origin header.\r\n> The client should run the CORS mechanism: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS\r\n\r\nNot yet.\r\n\r\n![WX20210422-155121](https://user-images.githubusercontent.com/1818214/115676983-a8eb4900-a382-11eb-8c4c-f08beb0f9969.png)\r\n\n Comment 7: > > This command doesn't send Origin header.\r\n> > The client should run the CORS mechanism: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS\r\n> \r\n> Not yet.\r\n> \r\n>![WX20210422-155121](https://user-images.githubusercontent.com/1818214/115676983-a8eb4900-a382-11eb-8c4c-f08beb0f9969.png)\r\n\r\nIn the `curl` command, did you try to bring the `Origin` header?   Example: `curl -I https://xxxyyy.com  -H 'Origin: https://x'`\n Comment 8: > > > This command doesn't send Origin header.\r\n> > > The client should run the CORS mechanism: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS\r\n> > \r\n> > \r\n> > Not yet.\r\n> >![WX20210422-155121](https://user-images.githubusercontent.com/1818214/115676983-a8eb4900-a382-11eb-8c4c-f08beb0f9969.png)\r\n> \r\n> In the `curl` command, did you try to bring the `Origin` header? Example: `curl -I https://xxxyyy.com -H 'Origin: https://x'`\r\n\r\nIf I set property `` in plugin: cors(), the response header will clear cors.....\r\n\r\n```\r\n  \"plugins\": {\r\n    \"cors\": {\r\n      \"allow_origins\": \"https://www.xxx.cn\"\r\n    }\r\n  }\r\n```\r\n\r\ncurl output: \r\n```\r\nHTTP/2 404\r\ncontent-type: text/plain; charset=utf-8\r\ncontent-length: 18\r\ndate: Fri, 23 Apr 2021 03:37:33 GMT\r\nserver: APISIX/2.5\r\n```\r\n\r\n\r\ncurl with -H 'Origin:'returns ok:\r\n\r\n```\r\nHTTP/2 404\r\ncontent-type: text/plain; charset=utf-8\r\ncontent-length: 18\r\ndate: Fri, 23 Apr 2021 03:40:18 GMT\r\nserver: APISIX/2.5\r\naccess-control-allow-origin: https://",
  "Issue title: Unhandled Java exception: java.lang.ArrayIndexOutOfBoundsException: -3\n Issue body: I am new to JRuby, but I get this error running a script in a Jenkins deployment environment and it looks like it's coming from inside JRuby. Towards the end of this stack trace you see my code: deploy-capacity-manager/vendor/bundle/jruby/2.2.0/bin/ebs-deploy:23 - this is a line that calls `load Gem.bin_path('ebs-deploy', 'ebs-deploy', version)`, and when it runs that I get the following exception (JRuby 116.69.203.115, but also seen with 116.69.203.115):\n\n```\nUnhandled Java exception: java.lang.ArrayIndexOutOfBoundsException: -3\njava.lang.ArrayIndexOutOfBoundsException: -3\n        run_exec_dup2 at org/jruby/util/io/PopenExecutor.java:789\n    execargRunOptions at org/jruby/util/io/PopenExecutor.java:986\n         spawnProcess at org/jruby/util/io/PopenExecutor.java:113\n        spawnInternal at org/jruby/util/io/PopenExecutor.java:93\n             system19 at org/jruby/RubyKernel.java:1541\n                 call at org/jruby/internal/runtime/methods/JavaMethod.java:729\n         cacheAndCall at org/jruby/runtime/callsite/CachingCallSite.java:273\n            callBlock at org/jruby/runtime/callsite/CachingCallSite.java:79\n                 call at org/jruby/runtime/callsite/CachingCallSite.java:83\n            interpret at org/jruby/ir/instructions/CallBase.java:419\n          processCall at org/jruby/ir/interpreter/InterpreterEngine.java:322\n            interpret at org/jruby/ir/interpreter/StartupInterpreterEngine.java:77\n            interpret at org/jruby/ir/interpreter/InterpreterEngine.java:83\n     INTERPRET_METHOD at org/jruby/internal/runtime/methods/MixedModeIRMethod.java:197\n                 call at org/jruby/internal/runtime/methods/MixedModeIRMethod.java:183\n                 call at org/jruby/internal/runtime/methods/DynamicMethod.java:197\n         cacheAndCall at org/jruby/runtime/callsite/CachingCallSite.java:313\n                 call at org/jruby/runtime/callsite/CachingCallSite.java:163\n          processCall at org/jruby/ir/interpreter/InterpreterEngine.java:290\n            interpret at org/jruby/ir/interpreter/StartupInterpreterEngine.java:77\n            interpret at org/jruby/ir/interpreter/InterpreterEngine.java:77\n     INTERPRET_METHOD at org/jruby/internal/runtime/methods/MixedModeIRMethod.java:162\n                 call at org/jruby/internal/runtime/methods/MixedModeIRMethod.java:148\n                 call at org/jruby/internal/runtime/methods/DynamicMethod.java:189\n         cacheAndCall at org/jruby/runtime/callsite/CachingCallSite.java:293\n                 call at org/jruby/runtime/callsite/CachingCallSite.java:131\n          processCall at org/jruby/ir/interpreter/InterpreterEngine.java:306\n            interpret at org/jruby/ir/interpreter/StartupInterpreterEngine.java:77\n       INTERPRET_ROOT at org/jruby/ir/interpreter/Interpreter.java:102\n              execute at org/jruby/ir/interpreter/Interpreter.java:89\n              execute at org/jruby/ir/interpreter/Interpreter.java:32\n              execute at org/jruby/ir/IRTranslator.java:42\n       runInterpreter at org/jruby/Ruby.java:837\n             loadFile at org/jruby/Ruby.java:2900\n                 load at org/jruby/runtime/load/LibrarySearcher.java:236\n                 load at org/jruby/runtime/load/LibrarySearcher.java:35\n                 load at org/jruby/runtime/load/LoadService.java:336\n           loadCommon at org/jruby/RubyKernel.java:965\n               load19 at org/jruby/RubyKernel.java:957\n                 call at org/jruby/internal/runtime/methods/DynamicMethod.java:201\n                 call at org/jruby/internal/runtime/methods/DynamicMethod.java:197\n         cacheAndCall at org/jruby/runtime/callsite/CachingCallSite.java:313\n                 call at org/jruby/runtime/callsite/CachingCallSite.java:163\n                <top> at /var/lib/jenkins/workspace/Deploy/deploy-capacity-manager/vendor/bundle/jruby/2.2.0/bin/ebs-deploy:23\n  invokeWithArguments at java/lang/invoke/MethodHandle.java:599\n                 load at org/jruby/ir/Compiler.java:111\n            runScript at org/jruby/Ruby.java:821\n            runScript at org/jruby/Ruby.java:813\n          runNormally at org/jruby/Ruby.java:751\n          runFromMain at org/jruby/Ruby.java:573\n        doRunFromMain at org/jruby/Main.java:409\n          internalRun at org/jruby/Main.java:304\n                  run at org/jruby/Main.java:233\n                 main at org/jruby/Main.java:200\n```\n\n Comments: \n Comment 0: the code assumes Java's binarySeach returns -1 when not found https://github.com/jruby/jruby/blob/master/core/src/main/java/org/jruby/util/io/PopenExecutor.java#L784... should be checking for any `< 0` value as invalid. this is an easy fix.\n Comment 1: Yes, a bit of experimentation suggests the actual command it executes isn't that important - the key bit is that it's a command that exits with a failure code",
  "Issue title: Can't open files from :Gstatus \n Issue body: I've commented out my extras in my.vimrc and removed other bundles, still can't open anything out of the :Gstatus window- `-`, `o`, and `enter` get no response. Other commands (:Gwrite, read, add) are working fine. Git 2.0.0\n\n Comments: \n Comment 0: What does `:nmap <buffer> <CR>` report?\n\n Comment 1: Returns: No mapping found\n\n Comment 2: Sorry, inside the :Gstatus window: \nn  <CR>        *@:<C-U>exe <SNR>25_GF(\"edit\")<CR>                                                                                                                                                          \n\n Comment 3: Does `dp` work?\n\n Comment 4: Yes it does.\n\n Comment 5: What locale are you in? What is the contents of the status buffer?\n\n Comment 6: EN/US\nhttp://cl.ly/image/212Q2w0x3l3u/Image%202014-06-28%20at%205.43.55%20PM.png\n\n Comment 7: Upgrade.\n\n Comment 8: I re-cloned the repo after seeing [#483](https://github.com/tpope/vim-fugitive/issues/483). Syntax and commands working now, it must be my bootstrap. Thanks.\n",
  "Issue title: frontend form and upload featured image\n Issue body: Hi\r\ni have read your great documentation abount new form in frontend\r\nhttps://webdevstudios.com/2015/03/30/use-cmb2-to-create-a-new-post-submission-form/\r\n\r\nBut only i have not understand how upload the featured image\r\nOf course when i submit the form, that return this error becouse i not have this function\r\n\r\n> Fatal error: Call to undefined function wds_frontend_form_photo_upload() \r\n\r\nIn documentation you write\r\n\r\n> You can see we\u2019re using a helper function, wds_frontend_form_photo_upload, (which is just a wrapper for media_handle_upload). It\u2019s not directly related to CMB2, so I won\u2019t go over it here, but I\u2019ll include it in the final code snippet.\r\n\r\nBut in the final code snipped i can't find\r\n\n Comments: \n Comment 0: You can find it here: https://github.com/CMB2/CMB2-Snippet-Library/blob/master/front-end/cmb2-front-end-submit.php#L234-L267 right at the very end.\r\n\r\nHope you're enjoying using CMB2.",
  "Issue title: Check types of missing definition quick suggestions\n Issue body: ### Current behavior:\r\n\r\nEven though the type of `toLower` is known from the context (`Char -> Char`), \"quick fix\" purposes to import functions that, despite having the same name, are known not to be a correct type-wise (`Data.Text.Lazy (toLower)` for example).\r\n\r\n![Screenshot 2020-07-07 at 13 41 51](https://user-images.githubusercontent.com/6209627/86769290-9dc76680-c057-11ea-8c64-bd8b6c6a7f69.png)\r\n![Screenshot 2020-07-07 at 13 42 02](https://user-images.githubusercontent.com/6209627/86769306-a455de00-c057-11ea-95a8-20c7036fcb9a.png)\r\n\r\n### Proposed behavior:\r\n\r\nWhen the type of the undefined function is fully known, filter quick fixes by type.\n Comments: \n Comment 0: This would be a really great improvement and i dare to say it should no be too difficult.\n Comment 1: There are two quick fixes involved here: suggest new import and suggest extend import. The code for these quick fixes is at:\r\n\r\nhttps://github.com/haskell/haskell-language-server/blob/0b3bb10cd22cb265b7cbab84514178bcf4ae4f92/ghcide/src/Development/IDE/Plugin/CodeAction.hs#L796-L805\r\n\r\nand at \r\n\r\nhttps://github.com/haskell/haskell-language-server/blob/0b3bb10cd22cb265b7cbab84514178bcf4ae4f92/ghcide/src/Development/IDE/Plugin/CodeAction.hs#L1241-L1250\r\n\r\nIn order to implement this, you will need to:\r\n1. retrieve the type of the identifier I that is out of scope, \r\n2. the type of the import candidate C \r\n3. check if they are compatible \r\n\r\nI'm not really sure what's the best way to retrieve I, possibly parsing the error message?\r\n\r\nRetrieving C should be easy - just look through the `tcg_type_env` in the `TcGblEnv`.\r\n\r\nTo check if they are compatible, I would do this with [`tcUnifyTy`](https://hackage.haskell.org/package/ghc-8.10.2/docs/Unify.html#v:tcUnifyTy). \n Comment 2: The error message seems like a stable one to match against (data constructor has a slightly different message):\r\nhttps://github.com/ghc/ghc/blob/4c87a3d1d14f9e28c8aa0f6062e9c4201f469ad7/compiler/GHC/Tc/Errors.hs#L1210-L1211\r\nplus many GHC testsuite relies on this exact string.\r\n\r\nI'll try with approach outlined in https://github.com/haskell/haskell-language-server/issues/754#issuecomment-864516151 and see how it goes.\n Comment 3: @pepeiborra Sorry to disturb you, I took a look at this and found the type of identifier can get from `TcGblEnv` by [`TcModuleResult`](https://github.com/haskell/haskell-language-server/blob/8d5e34706c6be18746297d8a7b47d5ab51915cbe/ghcide/src/Development/IDE/Core/RuleTypes.hs#L137), but candidates seem not. I have trouble connecting `ExportsMap` to `TcModuleResult`, do you have any suggestions?\n Comment 4: @July541 have you seen my recent comment in #2081 about this? It describes an easier approach, albeit too slow.  \n\nTo answer your question: To retrieve the type of the candidate you would need to use the GHC api, similar to what ghci `:info` does. I'm not on my PC but you can easily find the code for :info by grepping for infoCmd in the ghc repository. \n Comment 5: I think we could try the direct ghc api approach until typed holes are usable, if using the API does not introduce too much complexity\n Comment 6: > To answer your question: To retrieve the type of the candidate you would need to use the GHC api, similar to what ghci `:info` does. I'm not on my PC but you can easily find the code for :info by grepping for infoCmd in the ghc repository.\r\n\r\nThank you, I'll try it.\r\n\n Comment 7: https://hackage.haskell.org/package/ghc-8.10.2/docs/GHC.html#v:lookupName might be helpful for getting the candidate types.\n Comment 8: Woohoo, thanks for your guide, it seems pretty nice!!!\n Comment 9: Do we have a function like `OccName -> ModuleName -> Unit -> Name`? I'm blocked by extracting type info from `HieDb`.\r\n\r\n`HieDb` throws out a well-done type, restore the type seems not easy.\r\n\r\nhttps://github.com/haskell/haskell-language-server/blob/dab8d009b25c07e84024ec4d339c6237a741b87b/ghcide/src/Development/IDE/Types/Exports.hs#L117-L132\r\n\r\nhttps://github.com/wz1000/HieDb/blob/0e660aea0e2cf7a64c125b396b0229fcf679e6f7/src/HieDb/Types.hs#L221-L230\n Comment 10: This continue being unimplememted and it is as annoying that i am tempted to label it as a bug\r\n\r\n![imagen](https://user-images.githubusercontent.com/54035/144575460-8ad0f13f-3dfc-42ad-bd6f-6b5d46263de6.png)\r\n\r\n@July541 do you still planning continue working on that? do you have some work which could help other to continue this?\n Comment 11: If at least we would have #2436 it would make sense to propose definitions with other types, as you could apply `Change type signature` in a second step. But there are contexts where adding the proposed definition supposes code changes for sure.\r\n\r\nbut if we have several definitions with the same name and different types, they should be filtered unconditionally, imo\n Comment 12: As my latest comment mentioned, the difficult part is `retrieve the type of the identifier I that is out of scope`, as the identifier is from `HieDB`, restoring its type is not easy.\r\n\r\nI'll have a look this weekend.\n Comment 13: Don't have a proper solution, feel free to pick this if anyone has ideas:(",
  "Issue title: StackOverflowerror while using Netty v4.1.5+ with Spring\n Issue body: Please follow this thread to get more info\r\nhttp://activemq.2283324.n4.nabble.com/Artemis-v2-1-Spring-MessageListener-Netty-StackOverflow-td4728139.html\r\n\r\n### Minimal yet complete reproducer code (or URL to code)\r\nSince this is happening only on Solaris can't give a test code.\r\n\r\n### Netty version\r\n4.1.5+\r\n\r\n### JVM version (e.g. `java -version`)\r\nJDK8u121\r\n\r\n### OS version (e.g. `uname -a`)\r\nSunOS myhost 5.10 Generic_Virtual i86pc i386 i86pc [Solaris VM]\n Comments: \n Comment 0: +1\n Comment 1: If I'm following the SO thread correctly the diagnosis seems to imply that the issue lies with the usage of `PlatformDependent.newConcurrentHashMap` [1]? Can you produce a unit test involving this collection (or any other minimal reproducer) which fails unexpectedly on your platform? I don't even see any Netty methods in the stack traces you provided.\r\n\r\nNote that [PlatformDependent.newConcurrentHashMap](https://github.com/netty/netty/blob/4.1/common/src/main/java/io/netty/util/internal/PlatformDependent.java#L315) just returns `java.util.concurrent.ConcurrentHashMap`.\r\n\r\n[1] http://activemq.2283324.n4.nabble.com/Artemis-v2-1-Spring-MessageListener-Netty-StackOverflow-tp4728139p4728147.html\r\n\r\n\r\n\n Comment 2: @abhijith-prabhakar Your stacktrace doesn't look like an infinite loop. Isn't it just that stack size is too small? Have you tried increasing Xss?\n Comment 3: Is there any preferred way to give a test case?  I am thinking of just giving a vagrant file and write a simple spring boot app to replicate.  \r\n\r\n@slandelle The memory is 2G which I thought should be sufficient.  I do see infitine loop trying to load same class.  May be I am missing something.\r\n\r\n@Scottmitch  It is starting from `io.netty.util.AttributeKey.valueOf()` [1]  method.\r\n\r\n[1] https://github.com/apache/activemq-artemis/blob/master/artemis-core-client/src/main/java/org/apache/activemq/artemis/core/remoting/impl/netty/NettyConnector.java#L137\n Comment 4: > The memory is 2G which I thought should be sufficient.\r\n\r\nThis is your total heap size. It has nothing to do with your stack size, which is controlled by the Xss JVM option.\r\n\r\n> I do see infitine loop trying to load same class.\r\n\r\nWhere do you see that? It looks to me your Thread was able to reach `ZipCoder` but then hit your configured Xss.\r\n\r\nTry increasing your Xss.\n Comment 5: > Is there any preferred way to give a test case?\r\n\r\nIf it is self contained you can paste it in this issue. If not just create a minimal java project, put it on GitHub, and provide a link in this issue. However before you do this please try increasing [Xss](https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html) as recommended by @slandelle... looks like most of the stack trace is in the class loader.\n Comment 6: It worked when we increases Xss to 1024 from 256.  Thanks for the quick help.  Will close this issue if you guys are fine with it.\n Comment 7: Thanks closing :)",
  "Issue title: How to insert array as params?\n Issue body: In node-mysql \r\n```\r\nlet sql = mysql.format('SELECT * FROM article WHERE id IN?;', [1,2,3,4,5])\r\n```\r\nit will be translate to the following SQL\r\n```\r\nconsole.log(sql)\r\n=> SELECT * FROM article WHERE id IN (1,2,3,4,5);\r\n```\r\n\r\nCan I do something similar in postgreSQL?\r\n\r\n1. How do I insert array as params?\r\n2. How do I get translated SQL (after parameter insertion) for debug?\n Comments: \n Comment 0: http://stackoverflow.com/questions/10720420/node-postgres-how-to-execute-where-col-in-dynamic-value-list-query",
  "Issue title: Set no shallow clone for tenacity\n Issue body: As noted in https://github.com/rtfd/readthedocs.org/issues/5031, I'm asking to disable shallow clone for tenacity.\r\n\r\nWe're using [reno](https://docs.openstack.org/reno/latest/) to maintain our release notes and shallow clone breaks it.\r\n\r\nThanks!\n Comments: \n Comment 0: Done",
  "Issue title: Feature request: Big Picture Mode or mapping Restart System to a button.\n Issue body: Hi, I've been enjoying OE with a PS4 gamepad, but I find it awkward to switch back and forth between mouse and gamepad. It would be awesome if the whole UI could be controlled with the gamepad, similarly to what Steam does with Big Picture Mode.\n\nSince this is a lot to ask, as a Plan B, I would like to request something simpler, the ability to map the Restart System command to a button on the gamepad. I imagine this could be done in the controller configuration preferences.\n\nThank you for all your continued hard work!\n\n Comments: \n Comment 0: Please search for related issues before opening a new one.\r\n\r\n#401\r\n\r\n#1443\n Comment 1: Thanks, I did search, apparently not thoroughly enough",
  "Issue title: Review doesn't say how to format datas already imported in a column\n Issue body: \r\nMy point of view is that this article focus only on changing a cell format to display long numbers \"correctly\". Long numbers that will be written **later** in the cell.\r\n\r\nThe article does not answer the question : how to format a column into the right format for displaying correctly the long numbers into it? Numbers that may have been imported from the import text tool. For example.\r\n\r\n**This question is the one people have when reading the article.**\r\n\r\nThe answer to this question is : Format to specific numeric format, using numbers and with 0 (or more) decimals.\r\n\r\nI think the doc should include this case if not answering specifically this case.\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\r\n\r\n* ID: aaa826a3-4a58-3877-2d60-a8883a291c71\r\n* Version Independent ID: baabb01c-cf19-eef9-afac-f1fecc41d205\r\n* Content: [Long numbers are displayed incorrectly in Excel - Office](https://docs.microsoft.com/en-us/office/troubleshoot/excel/long-numbers-incorrectly-in-excel)\r\n* Content Source: [Office/Client/excel/long-numbers-incorrectly-in-excel.md](https://github.com/MicrosoftDocs/OfficeDocs-Support/blob/public/Office/Client/excel/long-numbers-incorrectly-in-excel.md)\r\n* Product: **office-perpetual-itpro**\r\n* GitHub Login: @simonxjx\r\n* Microsoft Alias: **v-six**\n Comments: \n Comment 0: @vcopleutre Thank you for the feedback. By default, excel can display up to 11 digits in a cell. Even in case you have a long number already in the cell the instructions to Format to a specific numeric format, using numbers and with 0 (or more) decimals. adds Zeros at the end. So the workaround is to delete the number, follow the steps in one of the methods and then type or import the long number again to the cell as mentioned in the document\r\n\r\nHope this helps!\r\n\r\nThanks\r\nSri\n Comment 1: Hi MicrosoftDocs/OfficeDocs-Support!\n\nThank you,\nFeel free to update your doc :-) I would'nt have found the solution by\nmyself.\n\nCheers\n\nLe mer. 19 mai 2021 \u00e0 02:57, Sriraman M S ***@***.***> a\n\u00e9crit :\n\n> @vcopleutre <https://github.com/vcopleutre> Thank you for the feedback.\n> By default, excel can display up to 11 digits in a cell. Even in case you\n> have a long number already in the cell the instructions to Format to a\n> specific numeric format, using numbers and with 0 (or more) decimals. adds\n> Zeros at the end. So the workaround is to delete the number, follow the\n> steps in one of the methods and then type or import the long number again\n> to the cell as mentioned in the document\n>\n> Hope this helps!\n>\n> Thanks\n> Sri\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/MicrosoftDocs/OfficeDocs-Support/issues/1074#issuecomment-843666101>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ADKBVJJABBJWSV5Y4EVVJV3TOMEHDANCNFSM4W6FUEOQ>\n>.\n>\n\n\n-- \n*Vianney Copleutre*\nMembre - Jeune Chambre \u00c9conomique d'Angers et sa R\u00e9gion\n<http://www.jceangers.com/notre-mouvement/qui-sommes-nous/>\nPr\u00e9sident - Kraft Workwear <https://www.kraftworkwear.com/>\nDirecteur G\u00e9n\u00e9ral - Le Laboureur <http://www.lelaboureur.fr/>\n9089342517\n\n Comment 2: @vcopleutre Thank you. The document is updated with the workaround to delete the number, follow the steps in one of the methods and then type or import the long number again to the cell.\r\n\r\nThanks\r\nSri\n Comment 3: @msbemba Please let us know if you still have any question regarding the issue you have raised initially.\r\nThe issue is being closed since your question seems to be answered. Feel free to re-open this issue if you feel that it hasn't been answered or that there are further suggestions to improve the documentation itself.\r\nThanks.",
  "Issue title: Demo doesn't seem to be working on nodes\n Issue body: I have cloned the repo (v2.6.1) and am testing the demo file in Chrome and Firefox on Mac. I see strange results:\r\n\r\n- Menus defined on \"core\" are working fine: Hold the mouse down over the background, and a menu will pop up. Move the mouse over a menu item and release, and the appropriate message is logged to the console.\r\n\r\n- Menus defined on nodes are not working: Hold the mouse down over a node, and a menu will pop up. Move the mouse over a menu item and release, and nothing will be logged to the console. However, if, after doing this, you drag the node from one point to another, the message from the menu selection will be logged to the console when you release the mouse button.\r\n\r\nReading the code, this behavior makes sense to me: the command's `select` property is called from a `'cxttapend tapend'` event handler which is attached to the node selector... but `tapend` will only be triggered on a node if the mouse is released while over the node, right? So releasing the mouse over the menu, away from the node, will not trigger `tapend`?\r\n\r\nAm I missing something here? (Thanks!)\n Comments: \n Comment 0: @joshuahhh \r\n\r\nThanks for the information (and the PR!), but I can't reproduce what you describe.  I tried the demo on both Chrome and Firefox, and I get the expected behaviour.\r\n\r\nThe selector on that event listener definitely needs to be there, else support for multiple instances/calls would be broken for different selectors:  You could trigger menus on nonmatching elements. \n Comment 1: @joshuahhh Are you running any browser extensions that could be causing issues?\n\n Comment 2: Not reproducible and no response from OP; closing",
  "Issue title: Future for api-audit and nfrr collector\n Issue body: related issues (closed without satisfying answer)\r\n#2133 \r\n#2145 \r\n\r\nI looked through the UI code and did not see an \"nfrr\" widget. Is this the vision?\r\nWhat is the end user UseCase for audit and nfrr? Is the intention for users to create their own clients for api-audit?\r\n\r\nThanks\r\n\n Comments: \n Comment 0: Currently, yes, the end user is expected to consume that information outside of Hygieia. We currently don't have any plans to expose that data via the Hygieia UI. If someone provides a PR for those changes we'd be willing to review/ merge. ",
  "Issue title: Create Track 2 (5.x) Microsoft.Azure.WebJobs.Extensions. EventGrid extension\n Issue body: Create extension tracking/mapping to latest versions.\n Comments: \n Comment 0: Assigning to 108 as a stretch goal.",
  "Issue title: Hide / Remove the \"Unchanged files with check annotations \" within a Pull Request\n Issue body: Hi,\r\n\r\nFirstly, ReviewDog is such a great tool, and I'm really looking forward to adding it to our build pipelines.\r\n\r\nI've been having a play with the following files:\r\n\r\nissues.ts:\r\n```\r\nclass HelloWorld {\r\n  hello: string;\r\n}\r\n\r\nconst something: string = '';\r\n\r\nconsole.log('heya', 'hello world');\r\n```\r\n\r\nissues.txt\r\n```\r\nsetupJest.ts:1:10: Hello World\r\nissues.ts:1:10: Hello World\r\nissues.ts:1:11: Some error\r\nissues.ts:5:8: Something else\r\nissues.ts:7:8: Hi there\r\n\r\n```\r\n\r\nCommand:\r\n`cat issues.txt | reviewdog -efm=\"%f:%l:%c: %m\" -reporter=github-check -level=error`\r\n\r\nThe good news, is that it's showing the correct annotations in Github :)\r\n![image](https://user-images.githubusercontent.com/1135454/116423863-f6f7c500-a838-11eb-9fce-e65e4910d3f5.png)\r\n\r\nHowever, I'm seeing the Github \"Unchanged files with check annotations\" section, showing that a file outside the Pull Request has a issue.\r\n\r\n![image](https://user-images.githubusercontent.com/1135454/116424637-96b55300-a839-11eb-98ce-553924383379.png)\r\n\r\nIdeally, we'd like ReviewDog to only pick up files that have been changed in this PR.\r\n\r\nAny ideas?\r\n\r\n\r\nThanks,\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n Comments: \n Comment 0: Changing the GitHub action to use `on: pull_request` and the reporter to `-reporter=github-pr-check` no longer shows the \"unchanged files with check annotations\" \n Comment 1: I have the same issue but I don't want to switch to `github-pr-check`, any other ideas how to fix it?\n Comment 2: Is this related to reviewdog or to github? ",
  "Issue title: DJIVideoParser: H264_Decoder should use PIX_FMT_RGB24\n Issue body: The current FFMPEG pixel format used by the video parser is PIX_FMT_RGBA, which is 4 bytes per pixel. Since the alpha byte is always 0xff, you can save 25% of your buffer space by using PIX_FMT_RGB24 instead. You will need to change all the \"* 4\" to \"* 3\" (or define BYTES_PER_PIXEL and use that instead), plus change the VideoFeedRenderer38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5HandleImageTexture to use GL_RGB instead of GL_RGBA.\n Comments: \n Comment 0: Hi, there are two options for you to ask for help:\n\n1. Post your issues on StackOverflow: <https://stackoverflow.com/questions/tagged/dji-sdk>, the community can help you.\n\n2. Report your issues to <yrodgers@example.org>, as it's our official channel for developers to request DJI Developer Support now.\n\nFor DJI Developer Support, we have the following three tiers:\n\n - Standard \n\n  This free support is available to anyone reaching out to <yrodgers@example.org>. There is no guarantee for response time.\n  \n- Preferred\n  \n  This support comes with Pro membership for 99 USD per year. You can purchase it on [DJI Developer Website](https://developer.dji.com/user/membership/). These requests have priority over Standard ones. Starting today, Preferred questions will be replied to within 2 to 5 business days (Monday \u2013 Friday).\n \n- Premium\n\n  This one-time ticket is considered high-priority and costs 499 USD per issue. You can purchase it on [DJI Developer Website](https://developer.dji.com/user/support/) after you become the Pro membership developer. Starting today, Premium questions will be replied to within 1 business day (Monday \u2013 Friday). This may include communication with DJI SDK engineers, but will not involve face-to-face interaction. Time limitations apply, and please keep in mind that one question is permitted per ticket. We will do our best to resolve your issue, but there some situations demand deeper engineering efforts.\n",
  "Issue title: manually (batch) set found state for ZZ and LC caches\n Issue body: @moving-bits....\r\nNow that the subject capability exists, I believe it makes sense to trigger that function from the top right pull down menu when viewing a list and select mode is turned on and a specific subset of the list entries have been checked. I am not deep enough into the code (yet) otherwise I would give it a try. What makes me hesitate is: what if non ZZ/LC caches are checked in that list, will the set found state method gracefully skip those? What if the operation would be started on the full list not addressing a selected subset but the full list instead? Would it leave non-ZZ / non-LC caches untouched? That would be the rowejames@example.net.\n Comments: \n Comment 0: I'm not sure if there's really a need to set the found state for several caches at once, but nevertheless here are some info on where to look if you want to implement such a function:\r\n\r\n- The menu entry should be added to the \"Manage caches\" submenu of the caches list menu (see `res/menu/cache_list_options.xml`)\r\n- The action itself is made visible and is triggered from `CacheListActivity` (see `onPrepareOptionsMenu` and `onOptionItemsSelected`)\r\n- the action itself has to be implemented as a `command` (to be revertable), have a look at e. g. `CacheListActivity.deleteCaches(...)`\r\n- within your command you need to check whether the connector for the current cache supports setting the found state (call `supportsSettingFoundState()` on the cache object)\r\n\n Comment 1: @moving-bits.... thx for the pointers. As the weather improves I can't promise how much time I can put into it but I will keep it on the stack. I treat it as a WBNI (wouldn't it be nice if....)\r\n\r\nA related issue: I just noticed on my own build (which includes my yesterday's merged PR), that ALCs marked as \"found\" are not excluded on the map if \"Own/found\" is unchecked in the map's quick settings. All other types are excluded as expected. In what area of the code would I look for this aspect?",
  "Issue title: AlexyAB WebUI - TensorboardX\n Issue body: Hi,\r\n\r\nis there a way to consult the graphs of the AlexeyAB WebUI and the TensorboardX after training? \r\n\r\nFor now, there are only the files: yolo_events.log and yolo_events.log.1 which hold evaluation metrics.\r\n\r\nThank you in advance!\n Comments: \n Comment 0: Hello, \r\n\r\nUnfortunately in the current version, the docker container responsible for the training is terminated at the end of the training. The training container contains both the tensorboard and the web_ui, so both are not mapped to the outside of the training container, making them unavailable at the end of the training.\r\n",
  "Issue title: GRPCChannelManager : Create channel to  fail\n Issue body: Please answer these questions before submitting your issue.\r\n\r\n- Why do you submit this issue?\r\n- [v] Question or discussion\r\n- [ ] Bug\r\n- [ ] Requirement\r\n- [ ] Feature or performance improvement\r\n\r\n___\r\n### Question\r\n- What do you want to know?\r\nWhat is the cause? help me, thanks.\r\n___\r\n### Bug\r\n- Which version of SkyWalking, OS and JRE?\r\n   version: 6.6.0\r\n   OS: centos 4.14.123-111.109.amzn2.x86_64\r\n  JDK version: 1.8.0_121\r\n- Which company or project?\r\n\r\n- What happen?\r\n I remove the apm-vertx-core-3.x-plugin-6.6.0.jar from the plugins\r\n___\r\n### log\r\nDEBUG 2020-03-06 12:13:18:636 SkywalkingAgent-5-ServiceAndEndpointRegisterClient-0 ServiceAndEndpointRegisterClient : ServiceAndEndpointRegisterClient running, status:DISCONNECT. \r\nDEBUG 2020-03-06 12:13:21:583 SkywalkingAgent-2-GRPCChannelManager-0 GRPCChannelManager : Selected collector grpc service running, reconnect:true. \r\nERROR 2020-03-06 12:13:21:584 SkywalkingAgent-2-GRPCChannelManager-0 GRPCChannelManager : Create channel to  fail. \r\njava.lang.NullPointerException\r\n        at org.apache.skywalking.apm.agent.core.remote.GRPCChannelManager.run(GRPCChannelManager.java:122)\r\n        at org.apache.skywalking.apm.util.RunnableWithExceptionProtection.run(RunnableWithExceptionProtection.java:36)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n\r\nDEBUG 2020-03-06 12:13:21:585 SkywalkingAgent-2-GRPCChannelManager-0 GRPCChannelManager : Selected collector grpc service is not available. Wait 30 seconds to retry \r\nDEBUG 2020-03-06 12:13:21:638 SkywalkingAgent-5-ServiceAndEndpointRegisterClient-0 ServiceAndEndpointRegisterClient : ServiceAndEndpointRegisterClient running, status:DISCONNECT.\r\n> \n Comments: \n Comment 0: I am not sure what is happening.  I could just say the `managedChannel` is NULL somehow.\r\n\r\nhttps://github.com/apache/skywalking/blob/v6.6.0/apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/GRPCChannelManager.java#L122\n Comment 1: Need you local debug to see what happens.",
  "Issue title: Compilation errors on Ubuntu 12.04\n Issue body: ``` bash\n$ rustc --version\nrustc 1.3.0-nightly (16f64c388 2015-07-09)\n$ git clone https://github.com/ogham/exa.git\n$ cd exa\n$ sudo make --install\ncargo build --release\n   Compiling exa v0.3.0 (file:///home/alanb/src/git/hub/exa)\nsrc/feature/xattr_linux.rs:4:5: 4:22 warning: unused import, #[warn(unused_imports)] on by default\nsrc/feature/xattr_linux.rs:4 use st38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5ffi38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5String;\n                                 ^~~~~~~~~~~~~~~~~\nerror: linking with `cc` failed: exit code: 1\nnote: \"cc\" \"-Wl,--as-needed\" \"-m64\" \"-L\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib\" \"/home/alanb/src/git/hub/exa/target/release/exa.0.o\" \"-o\" \"/home/alanb/src/git/hub/exa/target/release/exa\" \"-Wl,--whole-archive\" \"-l\" \"morestack\" \"-Wl,--no-whole-archive\" \"-Wl,--gc-sections\" \"-pie\" \"-Wl,-O1\" \"-nodefaultlibs\" \"-Wl,--whole-archive\" \"/tmp/rustc.O8V1ruSOlYpv/liblibgit2_sys-ee62f8ed694e2d9b.rlib\" \"-Wl,--no-whole-archive\" \"-Wl,--whole-archive\" \"/tmp/rustc.O8V1ruSOlYpv/liblibssh2_sys-197403f26ef746c2.rlib\" \"-Wl,--no-whole-archive\" \"-Wl,--whole-archive\" \"/tmp/rustc.O8V1ruSOlYpv/libopenssl_sys-f1940735b7e345d7.rlib\" \"-Wl,--no-whole-archive\" \"-Wl,--whole-archive\" \"/tmp/rustc.O8V1ruSOlYpv/libstd-74fa456f.rlib\" \"-Wl,--no-whole-archive\" \"-Wl,--whole-archive\" \"/tmp/rustc.O8V1ruSOlYpv/liballoc-74fa456f.rlib\" \"-Wl,--no-whole-archive\" \"-L\" \"/home/alanb/src/git/hub/exa/target/release\" \"-L\" \"/home/alanb/src/git/hub/exa/target/release/deps\" \"-L\" \"/home/alanb/src/git/hub/exa/target/release/build/libgit2-sys-ee62f8ed694e2d9b/out/lib\" \"-L\" \"/home/alanb/src/git/hub/exa/target/release/build/libssh2-sys-197403f26ef746c2/out/lib\" \"-L\" \"/usr/lib/x86_64-linux-gnu\" \"-L\" \"/home/alanb/src/git/hub/exa/target/release/build/libssh2-sys-197403f26ef746c2/out/lib\" \"-L\" \"/usr/lib/x86_64-linux-gnu\" \"-L\" \"/usr/lib/x86_64-linux-gnu\" \"-L\" \"/home/alanb/src/git/hub/exa/target/release/build/openssl-sys-f1940735b7e345d7/out\" \"-L\" \"/usr/local/lib/rustlib/x86_64-unknown-linux-gnu/lib\" \"-L\" \"/home/alanb/src/git/hub/exa/.rust/lib/x86_64-unknown-linux-gnu\" \"-L\" \"/home/alanb/src/git/hub/exa/lib/x86_64-unknown-linux-gnu\" \"-Wl,-Bstatic\" \"-Wl,-Bdynamic\" \"-l\" \"rt\" \"-l\" \"ssl\" \"-l\" \"crypto\" \"-l\" \"dl\" \"-l\" \"z\" \"-l\" \"z\" \"-l\" \"ssl\" \"-l\" \"crypto\" \"-l\" \"c\" \"-l\" \"m\" \"-l\" \"dl\" \"-l\" \"pthread\" \"-l\" \"rt\" \"-l\" \"gcc_s\" \"-l\" \"pthread\" \"-l\" \"c\" \"-l\" \"m\" \"-l\" \"compiler-rt\"\nnote: /tmp/rustc.O8V1ruSOlYpv/liblibssh2_sys-197403f26ef746c2.rlib(lldb-fix-r-ssh2-channel.o): In function `_libssh2_channel_nextid':\nchannel.c:(.text._libssh2_channel_nextid+0x0): multiple definition of `_libssh2_channel_nextid'\n#\n# many more warnings of multiple definitions\n#\nerror: aborting due to previous error\nCould not compile `exa`.\n\nTo learn more, run the command again with --verbose.\nmake: *** [target/release/exa] Error 101\n\n$ sudo make install --verbose\nmake: unrecognized option '--verbose'\nUsage: make [options] [target]...\n\n```\n\n Comments: \n Comment 0: Hm, not sure what's going on here. Could you please tell me:\n- Which distro you're using?\n- Paste the output of `cargo build --verbose`?\n\n Comment 1: ``` bash\n$ lsb_release -a\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 12.04.5 LTS\nRelease:    12.04\nCodename:   precise\n\n$ sudo cargo build --verbose > cargo.log 2>&1\n   Compiling bitflags v0.1.1\n     Running `rustc /home/alanb/.cargo/registry/src/github.com-0a35038f75765ae4/bitflags-0.1.1/src/lib.rs --crate-name bitflags --crate-type lib -g -C metadata=dd68b8369bcd8ff0 -C extra-filename=-dd68b8369bcd8ff0 --out-dir /home/alanb/src/git/hub/exa/target/debug/deps --emit=dep-info,link -L dependency=/home/alanb/src/git/hub/exa/target/debug/deps -L dependency=/home/alanb/src/git/hub/exa/target/debug/deps -Awarnings`\n   Compiling byteorder v0.3.10\n     Running `rustc /home/alanb/.cargo/registry/src/github.com-0a35038f75765ae4/byteorder-0.3.10/src/lib.rs --crate-name byteorder --crate-type lib -g -C metadata=399c175f6a7726ac -C extra-filename=-399c175f6a7726ac --out-dir /home/alanb/src/git/hub/exa/target/debug/deps --emit=dep-info,link -L dependency=/home/alanb/src/git/hub/exa/target/debug/deps -L dependency=/home/alanb/src/git/hub/exa/target/debug/deps -Awarnings`\n   Compiling matches v0.1.2\n     Running `rustc /home/alanb/.cargo/registry/src/github.com-0a35038f75765ae4/matches-0.1.2/lib.rs --crate-name matches --crate-type lib -g -C metadata=68291f81832fc22d -C extra-filename=-68291f81832fc22d --out-dir /home/alanb/src/git/hub/exa/target/debug/deps --emit=dep-info,link -L dependency=/home/alanb/src/git/hub/exa/target/debug/deps -L dependency=/home/alanb/src/git/hub/exa/target/debug/deps -Awarnings`\n   Compiling rustc-serialize v0.3.15\n     Running `rustc /home/alanb/.cargo/registry/src/github.com-0a35038f75765ae4/rust",
  "Issue title: [Access Request] page 6510 \"Item Tracking Lines\" make ItemTrackingDataCollection protected\n Issue body: in page 6510 \"Item Tracking Lines\":\r\nWould it be possible to set the variable ItemTrackingDataCollection: Codeunit \"Item Tracking Data Collection\"; to protected?\n Comments: \n Comment 0: Thanks for reporting this. We agree, and we\u2019ll publish a fix asap, either in an update for the current version or in the next major release. Please do not reply to this, as we do not monitor closed issues. If you have follow-up questions or requests, please create a new issue where you reference this one.",
  "Issue title: Can't use multiple classnames\n Issue body: ```\r\nclassName: `${settingsStyles.item} ${settingsStyles.toggle}`\r\n```\r\n\r\nGot error in console\r\n```\r\ndiscovery.umd.js:17 DOMException: Failed to execute 'add' on 'DOMTokenList': The token provided ('_4ymWhFjaYEo4wjXhK6vWF _3ueTPH3PTkN7tT_HsT0m-n') contains HTML space characters, which are not valid in tokens.\r\n```\n Comments: \n Comment 0: Just use array `className: [settingsStyles.item, settingsStyles.toggle]`\n Comment 1: Btw, since next release you'll able to pass a space separated class list. So your example will work",
  "Issue title: {{outlet.someProp}}\n Issue body: There has been some loose ideation around using `outlet` is a keyword that allow a dev to access the routable component above it. Some example usage of this:\n\n```\n{{! in the layout of an arbitrarily deeply nested component }}\n{{outlet.model.name}}\n{{if (some-helper outlet.someState) 'foo'}}\n```\n\nThe use cases for this are poorly defined though. If any are discovered we should discuss them here.\n\n Comments: \n Comment 0: An addition to this RFC i'd like to see (or perhaps a different one, although related) is to add a implicit name to the outlet (similarly to the property `name` in functions standarized in ES6).\r\n\r\nThat could, among other things, allow to infer properties based on the context. Some that come to mind are translations that come to mind are contextual translations *\u00e0 l\u00e0 rails* (`{{t.header}}`) or links to the parent outlet regardless of where they are rendered.\n Comment 1: I'm doing some issue gardening \ud83c\udf31\ud83c\udf3f \ud83c\udf37 and came upon this issue. Since it's quite old I just wanted to ask if this is still relevant? If it isn't, maybe we can close this issue?\r\n\r\nBy closing some old issues we reduce the list of open issues to a more manageable set.\n Comment 2: I'm closing this due to inactivity. This doesn't mean that the idea presented here is invalid, but that, unfortunately, nobody has taken the effort to spearhead it and bring it to completion. Please feel free to advocate for it if you believe that this is still worth pursuing. Thanks!",
  "Issue title: Support UUIDs as schema references\n Issue body: In addition to schema references as strings and namespaced keywords, it would be very useful to refer to schemas via UUID.\n Comments: \n Comment 0: @ikitommi I'm happy to open a PR for this, but I'm not quite sure where to start.  Could you point me to the places where refs are currently resolved/substituted for strings, namespaced keywords, etc.?",
  "Issue title: Cannot go to parent directory \"..\"\n Issue body: I had to load my project on a different computer and I am getting the below errors:\r\n\r\n![capture](https://cloud.githubusercontent.com/assets/11089131/12856487/c5c0a37c-cc0a-11e5-91d0-24a6973fbbb6.JPG)\r\n\r\nProject will not compile or open in Xenko Studio. \n Comments: \n Comment 0: What was the directory structure before and how is it now?\n\n Comment 1: Same and the same structure seem to work for other people on the project. I've tried deleting and re-pulling with no luck. The package is in the location it's looking for. \n Comment 2: Do you have any reference to files that are outside the _Yankee_ folder? \r\nLooks like it is trying to resolve something like this: \"C:/Source/Yankee/\" + \"../../../../folder/folder/myasset.ext\". Try to manually fix those references if any.\n Comment 3: Hi!\nWe just published a bugfix release which should prevent this error.\n\nThe issue is most likely the one xenux described, though.\nCould you try opening/building the project with the new version 1.5.3 and check if there are any build-error related to asset paths?\n\n Comment 4: I don't have access the the project any more. But the issue end up being cause someone try to load terrain assets from one of the simple app's folder rather than importing the assets directly into the project. \n Comment 5: This issue should be fixed for good in 1.6.8. Please re-open or create a new issue if it happens again\n",
  "Issue title: Segmentation fault when building on windows?\n Issue body: Hi,\r\n\r\nI'm trying to build libigl in windows 10 and Visual Studio 2015.\r\nFrom the `libigl` root folder I simply run\r\n\r\n```\r\nmkdir build && cd build\r\ncmake../ -G \"Visual Studio 14 2015 Win64\"\r\n```\r\n\r\nThe output I get is:\r\n\r\n```\r\n-- Selecting Windows SDK version  to target Windows 10.0.15063.\r\n-- The C compiler identification is MSVC 19.0.24215.1\r\n-- The CXX compiler identification is MSVC 19.0.24215.1\r\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe\r\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe - works\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe\r\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe - works\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\n-- MSVC -> forcing use of statically-linked runtime.\r\n-- Looking for pthread.h\r\n-- Looking for pthread.h - not found\r\n-- Found Threads: TRUE\r\n-- Creating target: igl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5ore (igl)\r\n-- Creating target: igl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5omiso (igl_comiso)\r\n-- Found Git: C:/Program Files/Git/mingw64/bin/git.exe (found version \"2.25.1.windows.1\")\r\nCMake Warning (dev) at external/embree/common/cmake/test.cmake:31 (SET):\r\n  implicitly converting 'INT' to 'STRING' type.\r\nCall Stack (most recent call first):\r\n  external/embree/CMakeLists.txt:101 (INCLUDE)\r\nThis warning is for project developers.  Use -Wno-dev to suppress it.\r\n\r\n-- Creating target: igl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5mbree (igl_embree)\r\n-- Creating target: igl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5opengl (igl_opengl)\r\n-- Found OpenGL: opengl32\r\n-- Creating target: igl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5opengl_glfw (igl_opengl_glfw)\r\n-- Using Win32 for window creation\r\n-- Creating target: igl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5opengl_glfw_imgui (igl_opengl_glfw_imgui)\r\n-- Performing Test COMPILER_HAS_DEPRECATED_ATTR\r\n-- Performing Test COMPILER_HAS_DEPRECATED_ATTR - Failed\r\n-- Performing Test COMPILER_HAS_DEPRECATED\r\n-- Performing Test COMPILER_HAS_DEPRECATED - Success\r\n-- Creating target: igl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5png (igl_png)\r\n-- Creating target: igl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5tetgen (igl_tetgen)\r\n-- Creating target: igl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5triangle (igl_triangle)\r\n-- Creating target: igl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5predicates (igl_predicates)\r\n-- Creating target: igl38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5xml (igl_xml)\r\n-- Found PythonInterp: C:/Program Files (x86)/Microsoft Visual Studio/Shared/Python36_64/python.exe (found suitable version \"3.6.6\", minimum required is \"3.4\")\r\n-- Found PythonLibs: C:/Program Files (x86)/Microsoft Visual Studio/Shared/Python36_64/libs/python36.lib (found suitable version \"3.6.6\", minimum required is \"3.4\")\r\n-- Found PythonInterp: C:/Program Files (x86)/Microsoft Visual Studio/Shared/Python36_64/python.exe (found version \"3.6.6\")\r\n-- Found PythonLibs: C:/Program Files (x86)/Microsoft Visual Studio/Shared/Python36_64/libs/Python36.lib\r\n-- pybind11 v2.3.dev0\r\n-- Performing Test HAS_MSVC_GL_LTCG\r\n-- Performing Test HAS_MSVC_GL_LTCG - Success\r\n-- LTO enabled\r\n-- Configuring done\r\nSegmentation fault\r\n```\r\n\r\nAny clue on why I'm getting a segmentation fault?\r\nI've also tried Visual Studio 2017, the result is the same.\r\n...\r\n\r\n#### Check all that apply (change to `[x]`)\r\n- [x] Windows\r\n- [ ] Mac OS X\r\n- [ ] Linux\r\n- [ ] I have tried the `dev` branch and the problem persists\r\n\r\nSee https://libigl.github.io/CONTRIBUTING/#bugreport for more tips.\r\n\n Comments: \n Comment 0: Hi, please try the latest `dev` branch and let us know if the problem still persists.\n Comment 1: Just tried, same error. Can you help?\n Comment 2: Seems that you are trying to run CMake through mingw or smth like that. Please try to generate a VS project via CMake GUI instead.\n Comment 3: I can't see why it would be different but I'll give it s go\n Comment 4: That didn't work either. However I was using cmake 3.17, downgrading to the previous release worked instead. (cmake 3.16).\n Comment 5: CMake 3.17 is not a stable release yet. I would wait until they release a stable version and double-check again if the compilation is still failing.",
  "Issue title: Typing a route url in the url bar goes back to home for nested navigation with tabs\n Issue body: I mimicked the example `nested_nav.dart` but instead of having the same UI with different data (families and persons), I have a totally different UI on each tab with different data.  When I use the UI tabs to navigate the url does reflect the navigation but unlike the example if I type a route, although the url has changed, it does not navigate.  Then when I push Enter in the url bar it goes back to my home page which is my `initialLocation`.  I see in the example `initialLocation` is not used so I'll try redirecting but not sure why this would break it.  \r\nAlso the pressing the browser back button changes the url in the url bar but the tabs do not navigate, similar to the problem when typing the url.  \r\n\n Comments: \n Comment 0: I deleted `initialLocation` and redirect to `/home` now but the problem persists.\n Comment 1: Here is a video: https://youtu.be/yBTPgfxwthE\n Comment 2: Can you post a minimal repro project?\n Comment 3: I might be able to post the whole shebang.  Will that suffice?\n Comment 4: My boss has greenlighted one hour to try to make this example. Please wait.\n Comment 5: No. That won't work. Please trim it to the minimum code that duplicates the behavior. Thanks. \n Comment 6: I have a feeling my app is the minimum reproducible example.  I just tried building something minimal without the login sequence using Flutter Login and AWS Cognito, without Riverpod, etc etc and it works fine.  And I progressed up to this point by first getting tabs to work without deep linking and then rewiring by copying the example to get the deep linking.  Doesn't it sound like a bug that the url changes when tabs are changed through GUI but not by typing?  If my app is the minimum reproducible example then what? \n Comment 7: Anyways, please let me know if you don't want to look at the app, the rest of my company uses Routemaster and I was just instructed to try this out so it's not a big deal.\n Comment 8: If the app works fine when you remove the app specific features, then it's probably not an issue with go_router. \n Comment 9: probably\n Comment 10: Anything routing related is going through go_router.  With the one exception when I hide the sidebar in the drawer when the browser width < 840 in which case I want to close the drawer and navigate to whatever was clicked in the drawer so it's\r\n```\r\nNavigator.pop(context);\r\n                      GoRouter.of(context)\r\n                         .go(pathZeroMap[PathsZero.settingsFacility]!);\r\n```\n Comment 11: > What's app specific? I only used packages and whatever Flutter API's are considered above that foundation level or whatever it's called, ie. I did not dig in and try to develop my own API's to change how Flutter behaves. So if go_router or any package does not play nice with any other basically that's a problem with the app itself but not with any of the packages nor Flutter? That seems odd to me. @csells\r\n\r\nIf there's some intrinsic interaction between the packages you're using and go_router, then you're right -- those are things I want to know about. That's the work of putting together a minimal repro project w/o any app-specific logic, i.e. without any proprietary logic that's specific to your app, e.g. accessing the banking backend or whatever. 9 times out of 10, the mere act of producing a minimal repro project is how you find the bug and it's mostly not in the underlying packages you're using (whatever they happen to be) but more likely how you're using them. If you can remove more and more app-specific code, eventually you'll either find your own issues or you'll end up with the minimum amount of code required to reproduce the bug with go_router so that I can fix it.\r\n\r\nUnfortunately I don't have the bandwidth to debug the full app of everyone using my packages. No package author does. That's what I depend on minimal repros -- it lets me work with the bug reporter on doing their due diligence to ensure that it's actually a bug in the underlying package and lets me focus on the part I know best, my own package, because you've cleared away everything that isn't related to the issue.\n Comment 12: as one example of an excellent minimal repro project, check out https://github.com/csells/go_router/issues/139#issue-1045947876\n Comment 13: @csells  I'm not going to the backend at all except to log in. There was a problem with Riverpod 1.0.0 released a few days ago so I downgraded. \n Comment 14: Issue 139 you linked to has the problem of initial route flashing so I'm focusing on this redirect parameter of GoRouter\r\n```\r\n urlPathStrategy: UrlPathStrategy.path,\r\n    debugLogDiagnostics: true,\r\n    redirect: (state) {\r\n      const loginUrl = '/login';\r\n      final loggedIn = loginInfoState.loggedIn;\r\n      final goingToLogin = (state.location == loginUrl);\r\n\r\n      if (!loggedIn &&!goingToLogin) return loginUrl;\r\n      \r\n      if (loggedIn && goingToLogin) {\r\n        return types.pathZeroMap[types.PathsZero.home];\r\n      }\r\n\r\n      //no need to redirect\r\n      return null;\r\n    },\r\n    refreshListenable: loginInfoProvider,\r\n  );\r\n```\r\nWhat if I'm loggedIn but not goingToLogin?\r\nI'm redirecting to loginUrl in which case on my LoginScreen() if the stored session tokens are valid, I'm returning null in the onLogin: block and it redirects to home which is what's happening.  \r\nI'm pretty sure this is the cause and I cannot think of any way to solve it.  @csells \n Comment 15: I just saw this:\r\n```\r\n// if there's a deep link, go there\r\n                  if (from!= null) context.go(from!);\r\n```\r\nwhich I'm missing\n Comment 16: That seems really inefficient  for the router to go all the way back to main's GoRouter redirect, go to LoginScreen the check the `from` variable and then navigate to a deep link.  \n Comment 17: are you experiencing a perceivable delay?\n Comment 18: @csells  not really but I'm ripping out flutter_login package as it seems to be causing problems with me running in debug mode.  So I apologize for taking up your time here and appreciate your consideration although I would like to see the result of #139 \r\nI filed an issue with them: https://github.com/NearHuscarl/flutter_login/issues/271\n Comment 19: > What if I'm loggedIn but not goingToLogin? I'm redirecting to loginUrl in which case on my LoginScreen() if the stored session tokens are valid, I'm returning null in the onLogin: block and it redirects to home which is what's happening. I'm pretty sure this is the cause and I cannot think of any way to solve it.\r\n\r\nIf the user is already logged in, why send them to the login page? This is causing your loop\r\n\r\n\n Comment 20: @csells \r\nI also noticed with the RouterLocationView widget that you put at the bottom of the nested_nav example, in my app's case, that does not change when I sideways scroll the tabs, ie. not clicking the tab to change tabs but scrolling sideways in the tab view.  Neither does the url in the url bar.  \r\n\n Comment 21: https://youtu.be/KF3xXmVDbns\n Comment 22: There are a few moving parts to getting nested nav to work. Check out [the nest nav docs](https://pub.dev/packages/go_router#nested-navigation) and [the nested nav example](https://github.com/csells/go_router/blob/master/example/lib/nested_nav.dart) for details.\n Comment 23: I copied the example pretty much on a 1:1 basis and the scrolling not changing url can be confirmed with this minimal example: https://github.com/nyck33/go_router_deep_link_broken\r\nPlease read the readme on how to run.  The files, router_location_view.dart, tab_view.dart (familyview), tabs_list.dart (family and families), top_page_of_tabs.dart (familytabspage) have almost identical code to your example copied and pasted here: https://www.reddit.com/r/flutterhelp/comments/qpy1ae/go_router_nested_navigation_for_tabs/?utm_source=share&utm_medium=web2x&context=3\r\nPlease read the code block under \"Edit:...\"\r\n\n Comment 24: [This](https://www.reddit.com/r/flutterhelp/comments/qpy1ae/go_router_nested_navigation_for_tabs/?utm_source=share&utm_medium=web",
  "Issue title: Convert TODO txt file to issues\n Issue body: As I am really keen on contributing to this project I asked myself why some major issues are defined inside a To-Do txt file.\r\nWouldn't it be more convenient to create seperate issues from that?\n Comments: \n Comment 0: Sure, good idea.\n Comment 1: There is also this: [document on the forum](http://forum.freeciv.org/f/viewtopic.php?f=24&t=75582&sid=4a4abea9b9333ed45e19eb604aeb91d4)\n Comment 2: Well ok this excel document has priorities.\r\nBut one place where every existing issue is listed (and perhaps sorted by labels and milestones) would be great.",
  "Issue title: Error when login into admin\n Issue body: ### Description\r\nMy staging site is receiving an error after upgrading to 3.6.8 but my production site and local host aren't receiving the same error. \r\n\r\nTwig Syntax Error \u2013 Twig\\Error\\SyntaxError\r\nUnknown \"boolean\" test.\r\n\r\n  in /var/www/vendor/craftcms/cms/src/templates/_includes/forms/text.html\r\n   class: class,\r\n    type: type,\r\n    id: id?? false,\r\n    inputmode: inputmode?? false,\r\n    size: size?? false,\r\n    name: name?? false,\r\n    value: value?? false,\r\n    maxlength: maxlength?? false,\r\n    autofocus: (autofocus?? false) and not craft.app.request.isMobileBrowser(true),\r\n    autocomplete: autocomplete is boolean? (autocomplete? 'on' : 'off') : autocomplete,\r\n    autocorrect: (autocorrect?? true)? false : 'off',\r\n    autocapitalize: (autocapitalize?? true)? false : 'off',\r\n    disabled: disabled?? false,\r\n    readonly: readonly?? false,\r\n    title: title?? false,\r\n    placeholder: placeholder?? false,\r\n    step: step?? false,\r\n    min: min?? false,\r\n    max: max?? false,\r\n\r\n\r\nTwig\\Error\\SyntaxError: Unknown \"boolean\" test. in /var/www/vendor/craftcms/cms/src/templates/_includes/forms/text.html:20\r\nStack trace:\r\n#0 /var/www/vendor/twig/twig/src/ExpressionParser.php(694): Twig\\ExpressionParser->getTest(20)\r\n#1 /var/www/vendor/twig/twig/src/ExpressionParser.php(79): Twig\\ExpressionParser->parseTestExpression(Object(Twig\\Node\\Expression\\NameExpression))\r\n#2 /var/www/vendor/twig/twig/src/ExpressionParser.php(389): Twig\\ExpressionParser->parseExpression()\r\n#3 /var/www/vendor/twig/twig/src/ExpressionParser.php(281): Twig\\ExpressionParser->parseHashExpression()\r\n#4 /var/www/vendor/twig/twig/src/ExpressionParser.php(175): Twig\\ExpressionParser->parsePrimaryExpression()\r\n#5 /var/www/vendor/twig/twig/src/ExpressionParser.php(70): Twig\\ExpressionParser->getPrimary()\r\n#6 /var/www/vendor/twig/twig/src/ExpressionParser.php(677): Twig\\ExpressionParser->parseExpression()\r\n#7 /var/www/vendor/twig/twig/src/TokenParser/SetTokenParser.php(38): Twig\\ExpressionParser->parseMultitargetExpression()\r\n#8 /var/www/vendor/twig/twig/src/Parser.php(185): Twig\\TokenParser\\SetTokenParser->parse(Object(Twig\\Token))\r\n#9 /var/www/vendor/twig/twig/src/Parser.php(98): Twig\\Parser->subparse(NULL, false)\r\n#10 /var/www/vendor/twig/twig/src/Environment.php(563): Twig\\Parser->parse(Object(Twig\\TokenStream))\r\n#11 /var/www/vendor/twig/twig/src/Environment.php(595): Twig\\Environment->parse(Object(Twig\\TokenStream))\r\n#12 /var/www/vendor/craftcms/cms/src/web/twig/Environment.php(60): Twig\\Environment->compileSource(Object(Twig\\Source))\r\n#13 /var/www/vendor/twig/twig/src/Environment.php(408): craft\\web\\twig\\Environment->compileSource(Object(Twig\\Source))\r\n#14 /var/www/vendor/twig/twig/src/Environment.php(381): Twig\\Environment->loadClass('__TwigTemplate_...', '_includes/forms...', NULL)\r\n#15 /var/www/vendor/craftcms/cms/src/web/twig/Environment.php(41): Twig\\Environment->loadTemplate('_includes/forms...', NULL)\r\n#16 /var/www/vendor/twig/twig/src/Environment.php(513): craft\\web\\twig\\Environment->loadTemplate('_includes/forms...')\r\n#17 /var/www/vendor/twig/twig/src/Extension/CoreExtension.php(1224): Twig\\Environment->resolveTemplate(Array)\r\n#18 /var/www/storage/runtime/compiled_templates/21/21606e7ca23d081a8542e476f40b06976f19fb80519dfffcfe887ae6499bb251.php(806): twig_include(Object(craft\\web\\twig\\Environment), Array, '_includes/forms...', Array)\r\n#19 /var/www/vendor/twig/twig/src/Extension/CoreExtension.php(1110): __TwigTemplate_3d84e997f4aa580d76b1dddfc011b97e406c617f80623f266878806d35eaf67b->macro_field(Array, 'template:_inclu...')\r\n#20 /var/www/storage/runtime/compiled_templates/21/21606e7ca23d081a8542e476f40b06976f19fb80519dfffcfe887ae6499bb251.php(840): twig_call_macro(Object(__TwigTemplate_3d84e997f4aa580d76b1dddfc011b97e406c617f80623f266878806d35eaf67b),'macro_field', Array, 133, Array, Object(Twig\\Source))\r\n#21 /var/www/vendor/twig/twig/src/Extension/CoreExtension.php(1110): __TwigTemplate_3d84e997f4aa580d76b1dddfc011b97e406c617f80623f266878806d35eaf67b->macro_textField(Array)\r\n#22 /var/www/storage/runtime/compiled_templates/97/9753b4501ff3406e99929a811ab20c779f4801f25f14f06918c0b04f52fddcae.php(46): twig_call_macro(Object(__TwigTemplate_3d84e997f4aa580d76b1dddfc011b97e406c617f80623f266878806d35eaf67b),'macro_textField', Array, 4, Array, Object(Twig\\Source))\r\n#23 /var/www/vendor/twig/twig/src/Template.php(405): __TwigTemplate_4c6a66c2404f5408beca54279c4b827e83b627324a4742585b320c9c1b58443e->doDisplay(Array, Array)\r\n#24 /var/www/vendor/twig/twig/src/Template.php(378): Twig\\Template->displayWithErrorHandling(Array, Array)\r\n#25 /var/www/vendor/twig/twig/src/Template.php(390): Twig\\Template->display(Array)\r\n#26 /var/www/vendor/twig/twig/src/TemplateWrapper.php(45): Twig\\Template->render(Array, Array)\r\n#27 /var/www/vendor/twig/twig/src/Environment.php(318): Twig\\TemplateWrapper->render(Array)\r\n#28 /var/www/vendor/craftcms/cms/src/web/View.php(389): Twig\\Environment->render('_components/wid...', Array)\r\n#29 /var/www/vendor/craftcms/cms/src/widgets/Feed.php(85): craft\\web\\View->renderTemplate('_components/wid...', Array)\r\n#30 /var/www/vendor/craftcms/cms/src/controllers/DashboardController.php(80): craft\\widgets\\Feed->getSettingsHtml()\r\n#31 [internal function]: craft\\controllers\\DashboardController->actionIndex()\r\n#32 /var/www/vendor/yiisoft/yii2/base/InlineAction.php(57): call_user_func_array(Array, Array)\r\n#33 /var/www/vendor/yiisoft/yii2/base/Controller.php(181): yii\\base\\InlineAction->runWithParams(Array)\r\n#34",
  "Issue title: getPocheVersion doesn't work? \n Issue body: I think there is a cache system. \nIn my poche, even if I delete./cache/prod file, my poche returns beta1 as the last version... \n\n Comments: \n Comment 0: Maybe this is related : I just installed poche (the latest version) and here is what it says :\n\n```\nyour version :\nlatest stable version : 1.0-beta3. a more recent stable version is available.\n```\n\nI also have some notices in my logs : \n\n```\nPHP Notice:  Use of undefined constant POCHE_VERSION - assumed 'POCHE_VERSION' in /home/nicofrand/www/poche/inc/poche/Tools.class.php on line 242\nPHP Notice:  Use of undefined constant LANG - assumed 'LANG' in /home/nicofrand/www/poche/inc/poche/Poche.class.php on line 147 \n```\n\nMaybe the undefined constant is the root of the issue?\n\n Comment 1: This bug happens to me with a beta2. \n\nIf you have these notices with beta3, it's because inc/poche/myconfig.inc.php is not created. Do you have write access on inc/poche?\n\nThis beta3 is buggy...\n\n Comment 2: Indeed, I probably do not have write access on inc/poche. The documentation did not say this was needed.\n\n Comment 3: It's my fault. Beta4 will fix it (I hope).\n\n Comment 4: Hi,\nI just installed poche. \nI have the same problem : myconfig.inc.php doesn't have been created even if I have all the access on inc/poche.\nSo I have this warning on my poche screen : \n\nNotice: Use of undefined constant POCHE_VERSION - assumed 'POCHE_VERSION' in www/poche/inc/poche/Tools.class.php on line 242 \n\nThanks a lot :)\n\n--------- French --------\nHello,\nmerci pour ton appli, c'est juste ce qu'il me fallait en ce moment :)\nJ'ai donc install\u00e9 tout comme il fallait mais j'ai encore cette erreur (le fichier myconfig.inc.php) n'existe pas bien qu'apache ai tous les droits sur le r\u00e9pertoire concern\u00e9.\nMerci de ton aide!\n\n Comment 5: @bseclier merci pour ton message. \n\n@bseclier @nicofrand : I created a new issue, cf #148.\n\nThe #142 is for problem with getPocheVersion().\n\n Comment 6: Sorry for the flood\n\n Comment 7: It's not a problem with #poche. my poche was hosted on a kimsufi, and I installed a firewall, which prevent poche to fetch some articles & last version. \n",
  "Issue title: Segmentation fault 11 for addRedactAnnot and apply_redactions\n Issue body: `# -*- encoding: utf-8 -*-\r\nimport os\r\nimport fitz\r\ncur_pdf = fitz.open(\"C_2010638-2.pdf\") \r\nr=fitz.Rect([76.10399627685547, 239.55531311035156, 543.1917114257812, 254.18092346191406])\r\nfor cur_page in cur_pdf:\r\n    cur_page.addRedactAnnot(r,fill=(1, 1, 1))\r\n    cur_page.apply_redactions() \r\ncur_pdf.save(\"C_2010638-1.pdf\",garbage=4, clean=1,deflate=True)`\r\n\r\nThere is an error: Segmentation fault.\r\n\r\n[C_2010638-2.pdf](https://github.com/pymupdf/PyMuPDF/files/5864755/C_2010638-2.pdf)\r\n\r\n\r\n\n Comments: \n Comment 0: That's a bad one! Happens in MuPDF code - not PyMuPDF.\r\nSo I need to write a reproducer for MuPDF and submit to their issue tracker...\n Comment 1: Submitted a bug to MuPDF: https://bugs.ghostscript.com/show_bug.cgi?id=703388 for your reference.\n Comment 2: Thank you very much, I will pay attention to this.\n Comment 3: Let us keep this open until resolved.\n Comment 4: Update:\r\nMuPDF was very fast in **_confirming_** this upstream bug. They also told me that it has already been resolved for the next version.\n Comment 5: Thank you, how to replace mupdf with the latest version in pymupdf? Or can you solve it by upgrading pymupdf?\n Comment 6: Is that urgent for you?\r\nThe normal process would now be to wait for version 1.19.0 - meaning at least another 2 or 3 months. They have a bi-annual release schedule and 1.18.0 came out 2020-10-07.\n Comment 7: Do you know what caused this error? How to skip this error by judgment?\n Comment 8: This error happens inside MuPDF under rare conditions. It has to with the special way the **_text_** is coded,\r\nI have experimented a bit and rewritten that page's text using my font replacement tool. Then used your script with the rewritten page and it worked.\r\n\r\nI guess I could give better recommendations if I knew what exactly you are trying to achieve. So maybe, just overlaying text with a white rectangle would be sufficient (i.e. not redacting it).\r\n\r\nWhat is your operating system and Python version and bitness? \n Comment 9: The environment:  64-bit windows 10 and python3.7.\r\nThank you very much. I used the PyPDF2 package to rewrite this pdf file. The generated file will not report this error, but this will require a local backup of the original file. Would you please provide your source code?\n Comment 10: You mean the source code for the font replacement?\r\nHere is a zip containing the pre-version of my next PyMuPDF and two scripts for font replacement. Please install.\r\n[issue-866.zip](https://github.com/pymupdf/PyMuPDF/files/5878438/issue-866.zip)\r\n\r\nFont replacement works in 3 steps:\r\n1. run ``python repl-fontnames.py your.pdf`` - produces a JSON file\r\n2. edit the produced JSON ``your.pdf-fontnames.json`` and replace each \"keep\" you want with the name of a new font\r\n3. run ``python repl-font.py your.pdf`` produces the PDF ``your-new.pdf``\r\n\r\nI also have included a JSON file I produced for the PDF you gave me. Maybe it is sufficient for running **_only step 3_** above.\n Comment 11: Thank you, I have received it. \n Comment 12: I did a hack and simply copied the MuPDF modification into my local copy of MuPDF, then generated PyMuPDF anew... and it seems to work!\r\nHere is your wheel:\r\n[PyMuPDF-1.18.7-cp37-cp37m-win_amd64.whl.zip](https://github.com/pymupdf/PyMuPDF/files/5878548/PyMuPDF-1.18.7-cp37-cp37m-win_amd64.whl.zip)\r\n\n Comment 13: Did the last wheel resolve your issue?\n Comment 14: Thank you very much, it also solves my problem. Use the tool to generate a blank pdf in advance, and then overlay the original PDF on it, the program will not report an error.\n Comment 15: Notes for others interested in this bug:\r\n* it only happens in rare situations only\r\n* if needed, use a circumvention as presented by @malizheng in the previous post\r\n* the next MuPDF (and hence PyMuPDF) will contain a fix\r\n* I included the fix in my local MuPDF installation and will generate the wheels for v1.18.7 with it. So only those generating from sources will remain affected until the next MuPDF version (1.19.0 presumably).\n Comment 16: Hello @JorjMcKie, do you also happen to have the wheel for macOS? It's been happening to me for a while but I can't share sample documents because they contain sensitive information\u2026 It would be great if you had it, otherwise I'll have to wait for the next version, as you said.\r\nThank you in advance.",
  "Issue title: Built jar for Scala 3 is missing.sjsir files\n Issue body: The built jar for Scala 3 is missing.sjsir files required (expected) by projects with Scala.js.\n Comments: \n Comment 0: Found a fix which involves a minor change to project/BuildHelper.scala. PR on the way.\n Comment 1: Is it possible to get a release for this, I'm being blocked by this issue as well.",
  "Issue title: OpenTK.dll throws AccessViolationException on Intel HD 530\n Issue body: Hi,\r\nThis problem has been bothering me for a while now. I have controls written by OpenGL and OpenTK. I use OpenTK for extensions (vs native opengl functions). The thing is my controls work OK on nearly any dedicated GPU or on other intel GPUs. But on Intel 530, all function calls to extension methods (e.g. DrawArrays, etc.) result in the following exception:\r\n\"Attempted to read or write protected memory. This is often an indication that other memory is corrupt.\"\r\nAs just an example, stack top is:   \"at OpenTK.Graphics.OpenGL.GL.DrawArrays(PrimitiveType mode, Int32 first, Int32 count)\"\r\n\r\n1. My current OS is windows 10 64bit, but this happens on other OS versions too.\r\n2. I've has this issue since.Net 4.5 till now (4.7)\r\n3. I've updated 530 drivers accordingly, my current driver is 116.69.203.11515.\r\n4. This has happened since OpenTK 1.1.4 till now (2.0.0 from nugget)\r\n\r\nnow, it's clearly an issue with Intel 530 drivers, but some questions remain:\r\n- Why do all my native OpenGL calls work just fine? (either via my extern methods or OpenTK wrappings)\r\n- Why do my controls work fine on older and newer Intel GPUs and approximately all dedicated GPUs.\r\n- If this is an Intel related problem, how do OpenTK users get around it right now? \r\n\r\nRegards.\n Comments: \n Comment 0: Please try reproducing this issue on the latest OpenTK build. You can install it from the development feed linked in the readme. \r\n\r\nThis is typical of instances where the OpenGL function pointers cannot be properly loaded. You can try running a from-source or debug build of OpenTK to get more information. ",
  "Issue title: IWYU's zlib dependency isn't always necessary\n Issue body: I recently built IWYU in-tree with LLVM 6 and was surprised to see that while the LLVM build succeeded, IWYU failed:\r\n> [100%] Linking CXX executable../../../../bin/include-what-you-use\r\n> /usr/bin/ld: cannot find -lz\r\n> collect2: error: ld returned 1 exit status\r\n> make[2]: *** [bin/include-what-you-use] Error 1\r\n> make[1]: *** [tools/clang/tools/include-what-you-use/CMakeFiles/include-what-you-use.dir/all] Error 2\r\n> make: *** [all] Error 2\r\n\r\nTurns out my CentOS 7.4 system didn't have the zlib-devel package installed, so there was no /lib/libz.so symlink to /lib/libz.so.1. LLVM considers zlib to be optional and indeed the llvm38d1:d2b4:3d06:83e8:96a5:8c2:893d:aba5zlib classes in LLVMSupport.a were stubbed. But IWYU assumes that LLVM always depends on zlib (see #137), and this isn't true.\r\n\r\nInstalling zlib-devel is easy enough, but it'd be nice if IWYU did the right thing depending on whether zlib exists or not, or (even better) depending on whether the LLVM libraries were built against zlib.\n Comments: \n Comment 0: I'm working in the background on fixing some bugs in the official Clang packaging off http://apt.llvm.org/. Once that's done, hopefully we can use normal CMake procedures to pick up build information from LLVM/Clang.\r\n\r\nI don't know what the CentOS packaging looks like, but hopefully it installs all CMake goo in the right places. Attached is a little test project you can use to test consumption of Clang packages in CMake. The `configure` script is wired to select `llvm-7` in my dist's install root, so you may want to change the `CMAKE_PREFIX_PATH` argument to match your install. If this works, there's a good chance IWYU will work once the Debian package bugs are fixed.\r\n\r\n[cmake.zip](https://github.com/include-what-you-use/include-what-you-use/files/1976428/cmake.zip)\r\n\n Comment 1: @adembo PR #542 should solve this, can you test it on your platform?\n Comment 2: I'm pretty sure this is solved by 0003739b52e0bcefa574ed6dbc5dc7cf78da3cb4. See revised docs at https://github.com/include-what-you-use/include-what-you-use/blob/master/README.md#how-to-build.",
  "Issue title: hasPropertyWithValue javadoc is wrong\n Issue body: Hello,\nThe hasPropertyWithValue javadoc is wrong. Showing hasPropertyValue.\n\nhttp://github.com/drewbourne/hamcrest-as3/blob/master/hamcrest/src/org/hamcrest/object/hasPropertyWithValue.as#L15\n\n Comments: \n Comment 0: fixed in c45e712\n",
  "Issue title: macOS 10.12 \u4e3a\u4f55\u6253\u5f00\u5de6\u4fa7\u4f1a\u51fa\u73b0\u8fd9\u4e2a\u4e1c\u897f\n Issue body: \u6211\u60f3\u9ed8\u8ba4\u5de6\u4fa7\u7684tab\u5904\u4e8e\u5173\u95ed\u72b6\u6001\uff0c\u8bf7\u95ee\u5982\u4f55\u8bbe\u7f6e\uff0c\r\n![18fcc782-d7fe-4fc0-9e9e-286694e6c2e5](https://cloud.githubusercontent.com/assets/7320355/21871599/1f89cece-d89e-11e6-904d-677bf6cc49b1.png)\r\n\u8c22\u8c22\n Comments: \n Comment 0: \u9ed8\u8ba4\u7684\u4e0d\u5c31\u662f\u5173\u95ed\u7684\u5417\uff1f\n Comment 1: let g:nerdtree_tabs_open_on_gui_startup=0\n Comment 2: \u9ed8\u8ba4\u662f\u5173\u95ed\u7684, `nerdtree_tabs`\u8c8c\u4f3c\u6709bug, \u6240\u4ee5\u6211\u6ce8\u91ca\u6389\u4e86.",
  "Issue title: Sysinternals - remove on uninstall\n Issue body: https://chocolatey.org/packages/sysinternals#comment-1923085040\r\n\r\nRemove the install folder on uninstall\n Comments: \n Comment 0: This package is now self-contained so it does so.\n",
  "Issue title: Breadcrumbs fail to output prominent keyword\n Issue body: \r\n* [ ] I've read and understood the [contribution guidelines](https://github.com/Yoast/wordpress-seo/blob/trunk/.github/CONTRIBUTING.md).\r\n* [ ] I've searched for any related issues and avoided creating a duplicate issue.\r\n\r\n### Please give us a description of what happened.\r\n\r\nSelect prominent keywords in the SEO-Advanced-Breadcrumb drop down box for posts\r\n\r\n### Please describe what you expected to happen and why.\r\n\r\nProminent keywords for the post would then appear in the breadcrumb pathway. They did not\r\n\r\n\r\n### How can we reproduce this behavior?\r\n1. Go to SEO-Advanced-Breadcrumb drop down box for posts and select Prominent Word\r\n\r\n![screen shot 2017-08-23 at 12 00 04 pm](https://user-images.githubusercontent.com/8238074/29625756-9ffb6084-87fa-11e7-8e14-04427480468e.png)\r\n\r\n\r\n2.See prominent keywords appear on post\r\n\r\n![screen shot 2017-08-23 at 12 00 29 pm](https://user-images.githubusercontent.com/8238074/29625772-aad9c1d0-87fa-11e7-8c53-a82125b742c4.png)\r\n\r\n3.See that prominent words fail to appear in the breadcrumb pathway\r\n\r\n![screen shot 2017-08-23 at 12 00 50 pm](https://user-images.githubusercontent.com/8238074/29625807-bfeb1e48-87fa-11e7-9196-0a23464f61de.png)\r\n\r\n\r\n### Technical info\r\n* WordPress version: 4.8.1\r\n* Yoast SEO version: 5.3.2\r\n* Relevant plugins in case of a bug:\r\n\n Comments: \n Comment 0: Please inform the customer of conversation # 216790 when this conversation has been closed.\n Comment 1: Can you move this to the premium repository, because prominent words is a premium feature?\n Comment 2: related: https://github.com/Yoast/wordpress-seo-premium/issues/1326\r\n\r\n@andizer  Done",
  "Issue title: Zoom support\n Issue body: Hi, I use Vysor on a daily basis and I was wondering if it's possible to zoom in and out?\n Comments: \n Comment 0: I want to add a voice to this request. I purchased the app and use it almost daily, but the lack of ability to pinch-to-zoom is driving me crazy!\n Comment 1: third this.\n Comment 2: For the people how read this because they can't zoom:\r\nAlt + left click allow you to enter multitouch (you can now zoom by pinch)\r\nAlt + left click again to disable multitouch\n Comment 3: > For the people how read this because they can't zoom:\r\n> Alt + left click allow you to enter multitouch (you can now zoom by pinch)\r\n> Alt + left click again to disable multitouch\r\n\r\nCan I get some clarification on that? When I Alt + left click, i get a red dot... now what? \r\n\r\nCan we just get some simple pinch zoom in/out like by holding alt and scrolling the mouse wheel?\n Comment 4: This is not a proper solution. If the developer thinks it is, then more information needs to be provided on how this is supposed to be used. Pressing Alt + left click only leaves a red target, and I have no idea how to make the Zoom function work. I have paid for Vysor, so I feel I am in my right to request further information and support on this topic.\n Comment 5: use the alt click to \"plant\" a finger.\r\nuse the mouse to simulate movement with a second finger.\n Comment 6: > use the alt click to \"plant\" a finger. use the mouse to simulate movement with a second finger.\r\n\r\nUnfortunately absolutely nothing happens when I move the mouse after planting the red dot \"finger\".\n Comment 7: > use the alt click to \"plant\" a finger. use the mouse to simulate movement with a second finger.\r\n\r\nJust like @redreinard, this does nothing for me.",
  "Issue title: Custom 2022-09-02\n Issue body: {\"platform\":\"DS918+\",\"version\":\"6.2.4-25556\",\"sn\":\"DBK442AXZ3T7O\",\"mac\":\"02113218C267\",\"usb\":\"0x0001, 0x46f4\",\"ext\":\"e1000,e1000e,vmxnet3,r8168,r8169,r8125,r8152\",\"exp\":\"pocopico\",\"jun\":\"0\"}\n Comments: \n Comment 0: zengmin19990420 \u60a8\u597d.  \n\u60a8\u81ea\u5b9a\u4e49\u7684 Redpill \u5df2\u5f00\u59cb\u6784\u5efa. \u8bf7\u524d\u5f80\u4e0b\u9762\u7684 URL \u67e5\u770b\u8be6\u7ec6\u4fe1\u606f.  \n> https://github.com/wjz304/Redpill_CustomBuild/actions/runs/2976722238  \n----\n Comment 1: \u203c\ufe0f\u203c\ufe0f\u203c\ufe0f \n`Body \u4e2d\u542b\u6709\u81ea\u5b9a\u4e49\u7684 sn, mac \u654f\u611f\u4fe1\u606f, \u4e3a\u9632\u6b62\u5176\u4ed6\u4eba\u76d7\u7528, \u5efa\u8bae\u53c2\u8003\u4ee5\u4e0b\u89c6\u9891\u5220\u9664\u654f\u611f\u4fe1\u606f(\u4e0d\u5f71\u54cd\u672c\u6b21\u7f16\u8bd1).`  \n  \nhttps://user-images.githubusercontent.com/5615843/187615519-53a6dcf5-a5e2-4731-8889-9eee8955a977.mp4  \n>\n----\n Comment 2: zengmin19990420 \u60a8\u597d.\n\u60a8\u81ea\u5b9a\u4e49\u7684 Redpill \u5df2\u6784\u5efa\u5b8c\u6210. \u8bf7\u524d\u5f80\u4e0b\u9762\u7684 URL \u4e0b\u8f7d.  \n> https://github.com/wjz304/Redpill_CustomBuild/actions/runs/2976722238  \n----\n Comment 3: \u203c\ufe0f\u203c\ufe0f\u203c\ufe0f  \n`Body \u4e2d\u542b\u6709\u81ea\u5b9a\u4e49\u7684 sn, mac \u654f\u611f\u4fe1\u606f, \u4e3a\u9632\u6b62\u5176\u4ed6\u4eba\u76d7\u7528, \u5efa\u8bae\u9644\u4ef6\u4e0b\u8f7d\u5b8c\u6210/\u786e\u8ba4\u9519\u8bef\u539f\u56e0\u540e\u5220\u9664\u65e5\u5fd7\u548c\u9644\u4ef6.`\n`\u5728Issues\u4e0b\u8bc4\u8bba \"delete builds\" \u5373\u53ef\u5220Issues\u7684\u6240\u6709\u5386\u53f2\u7f16\u8bd1\u8bb0\u5f55.`",
  "Issue title: CC1350 sensor tag \n Issue body: Is there a way to hardwire CC1350 sensor tag to interact with this script? \n Comments: \n Comment 0: Absolutely not for the CC2650 sensortag, since the relevant pins are not exposed. I suspect (but have not checked) that the same applies for the CC1350 one\n Comment 1: TI might actually improved the design on this version a (tiny) bit! \r\nI don't have the hardware but if I look at the design files it looks like the bootloader UART pins are on DIO2 and DIO3 (7x7QFN). Looking at the schematic of the sensortag these pins are used for the digital mic, but they conveniently added 2 jumpers on those traces (R21 and R22).\r\n<img width=\"433\" alt=\"screen shot 2019-01-04 at 12 15 19\" src=\"https://user-images.githubusercontent.com/873684/50685993-ccf0b800-101b-11e9-986f-1343585e96c8.png\">\r\n<img width=\"337\" alt=\"screen shot 2019-01-04 at 12 28 04\" src=\"https://user-images.githubusercontent.com/873684/50686126-5607ef00-101c-11e9-825f-7d2bc7e2b641.png\">\r\n\r\nSo if you're willing to give up the mic, and have a lot of soldering fun, you might actually be able to use the UART bootloader on the CC1350 sensortag. I'm pretty sure that when the mic sees a clock on the `audio_clk` pin it's going to dump data on the `audio_di` pin, so just hot-wiring it probably won't work (but worth a try, might wreck the mic though).\r\n\r\nPlease try and report back!\n Comment 2: Yes, this works. I have tested it.\r\nBut, must be removed for Microphone to work.\r\nwe are using a [TMUX12095-VBidirectional 4:1, 2-Channel Multiplexer](http://www.ti.com/product/TMUX1209) to mux the pins with the APP_UART and BL_UART.\n Comment 3: Great!\r\n\r\nThanks for confirming @akrv!\r\n\r\n\n Comment 4: Something in the readme about this might be good.",
  "Issue title: FHIRDate.as_json uses original instead of isostring\n Issue body: From fhirdate.py\r\n```\r\n    def as_json(self):\\n\r\n        if self.origval is not None:\r\n            return self.origval\r\n        return self.isostring\r\n```\r\nSample code\r\n```\r\ndate = FHIRDate('20190527T210000')\r\nprint(date.as_json())\r\nprint(date.isostring)\r\n```\r\noutputs\r\n```\r\n20190527T210000\r\n2019-05-27T21:00:00\r\n```\r\nas_json() function should output the same result as isostring\n Comments: \n Comment 0: Same as https://github.com/smart-on-fhir/fhir-parser/issues/30",
  "Issue title: Improve attached info for \"argument not a subtype of parameter\" error.\n Issue body: We had a user in IRC today show the following example:\r\n\r\n```pony\r\nuse \"collections\"\r\n\r\ntype T is (String | F64 | None)\r\n\r\nactor Main\r\n  new create(env: Env) =>\r\n    var structure: List[T] = List[T]()\r\n    let str: String = \"str\"\r\n    structure.append(str)\r\n```\r\n\r\n```\r\nError:\r\nmain.pony:9:22: argument not a subtype of parameter\r\n    structure.append(str)\r\n                     ^\r\n    Info:\r\n    packages/builtin/string.pony:512:24: U8 val is not a subtype of String val\r\n      fun apply(i: USize): U8? =>\r\n                           ^\r\n    packages/builtin/string.pony:512:24: U8 val is not a subtype of F64 val\r\n      fun apply(i: USize): U8? =>\r\n                           ^\r\n    packages/builtin/string.pony:512:24: U8 val is not a subtype of None val\r\n      fun apply(i: USize): U8? =>\r\n                           ^\r\n    packages/builtin/string.pony:512:24: U8 val is not a subtype of any element of (String val | F64 val | None val)\r\n      fun apply(i: USize): U8? =>\r\n                           ^\r\n    packages/builtin/string.pony:512:3: method result U8 val is not a subtype of (String val | F64 val | None val)\r\n      fun apply(i: USize): U8? =>\r\n      ^\r\n    packages/builtin/string.pony:512:3: String val is not a subtype of ReadSeq[(String val | F64 val | None val)] box: method 'apply' has an incompatible signature\r\n      fun apply(i: USize): U8? =>\r\n      ^\r\n    packages/builtin/string.pony:1518:19: U8 val is not a subtype of String val\r\n      fun ref next(): U8? =>\r\n                      ^\r\n    packages/builtin/string.pony:1518:19: U8 val is not a subtype of F64 val\r\n      fun ref next(): U8? =>\r\n                      ^\r\n    packages/builtin/string.pony:1518:19: U8 val is not a subtype of None val\r\n      fun ref next(): U8? =>\r\n                      ^\r\n    packages/builtin/string.pony:1518:19: U8 val is not a subtype of any element of (String val | F64 val | None val)\r\n      fun ref next(): U8? =>\r\n                      ^\r\n    packages/builtin/string.pony:1518:3: method result U8 val is not a subtype of (String val | F64 val | None val)\r\n      fun ref next(): U8? =>\r\n      ^\r\n    packages/builtin/string.pony:1518:3: StringBytes ref^ is not a subtype of Iterator[(String val | F64 val | None val)] ref^: method 'next' has an incompatible signature\r\n      fun ref next(): U8? =>\r\n      ^\r\n    packages/builtin/string.pony:1489:3: method result StringBytes ref^ is not a subtype of Iterator[(String val | F64 val | None val)] ref^\r\n      fun values(): StringBytes^ =>\r\n      ^\r\n    packages/builtin/string.pony:1489:3: String val is not a subtype of ReadSeq[(String val | F64 val | None val)] box: method 'values' has an incompatible signature\r\n      fun values(): StringBytes^ =>\r\n      ^\r\n    main.pony:8:14: String val is not a subtype of every element of (ReadSeq[(String val | F64 val | None val)] box & ReadElement[(String val^ | F64 val^ | None val^)] box)\r\n        let str: String = \"str\"\r\n                 ^\r\n```\r\n\r\nThe error message is correct, but you have to read to the bottom of the info to understand what the expected parameter type was.\r\n\r\nWe want to add another two info lines to the top, saying something like:\r\n- `argument type is [print argument type]` (pointing to the argument type in the source code)\r\n- `parameter type is [print parameter type]` (pointing to the argument type in the source code)\n Comments: \n Comment 0: Resolved by #2577.",
  "Issue title: Wrong placeholder in editor error message for non-existing event\n Issue body: When you try opening the new editor win an identifier from a non-existing event, you get an wrror message like this:\r\n```\r\nStatus 404: Event '{123}' not Found\r\n```\r\nThe inner `{}` shouldn't be there.\r\nThe error message is generated by Opencast's backend.\r\n\r\n![Screenshot from 2022-10-13 17-08-28](https://user-images.githubusercontent.com/1008395/195636255-186a1b17-b36b-4715-ac51-1a560773fa88.png)\r\n\n Comments: \n Comment 0: Hello @lkiesow Can you please assign this issue to me. I would like to work on that.\n Comment 1: Go ahead. Thanks for taking this on. If you can, please base your work on the `r/12.x` branch. This can certainly go into the stable branch directly.\n Comment 2: The relevant code for this should be domewhere in here:\r\n- https://github.com/opencast/opencast/tree/b49d0b146791224283a8d16c4976610f25352846/modules/editor-service/src/main/java/org/opencastproject/editor\n Comment 3: Okay @lkiesow Thanks for the above info!\r\n",
  "Issue title: How to make it working in webpack?\n Issue body: There is no example to include it with webpack (angular-cli) template.\r\n\r\nI followed the toast notification documentation to add the SimpleNotificationComponent in the module\r\nThen in the component, I injected the notificationService to call it.\r\n\r\nHowever, there is no issue in running webapack build but I am getting the below error.\r\nmetadata_resolver.js:227Uncaught Error: Unexpected directive 'SimpleNotificationsComponent' imported by the module '....Module'\r\n\r\nWhat could be the issue? Is there a better example to use it in a webpack template or angular-cli template?\r\n\n Comments: \n Comment 0: Hi,\r\n I am in the process of creating an application template using CLI and some of the libraries. For a simple example have a look at my new template repository. https://github.com/olakara/ng2-app-template\r\nI have added the angular2-notifications to the CLI based application.\r\n\n Comment 1: Hi, I get it working and here is what to do,\r\n\r\nIn the module,\r\nimport {SimpleNotificationsModule, PushNotificationsModule} from 'angular2-notifications';\r\nand add the modules into imports:[....]\r\n\r\nIn the component, include the tag in the component.html\r\n<simple-notifications [options]=\"options\" (onCreate)=\"onCreate($event)\" (onDestroy)=\"onDestroy($event)\"></simple-notifications>\r\n\r\nthen in the component to add the below declaration\r\nimport {NotificationsService, SimpleNotificationsComponent} from 'angular2-notifications';\r\nand add the NotificationsService in the constructor, \r\nand show notification by calling this.notificationService.success(\"title\", \"...\");\r\n\r\nThanks.\n Comment 2: It works on development mode, but when try to generate a distribution version using `UglifyJsPlugin` it triggers an error:\r\n\r\n```sh\r\nERROR in app.c3b86f6b3725dad90c4b.js from UglifyJs\r\nSyntaxError: Unexpected token: name (NotificationsService) [app.c3b86f6b3725dad90c4b.js:11,6]\r\n```\n Comment 3: I follow @xinzhang solution and I found this almost 100% accurate to my project build with webpack. TY @xinzhang! :+1:  \r\n\r\n",
  "Issue title: install Join Lines extension error message.\n Issue body: install Join Lines, repot error:\r\nThe path /var/folders/gf/8s36y8491txc9djblqwnbqp40000gn/T/TemporaryItems/(A Document Being Saved By PopClip)/JoinLines.popclipext does not contain a valid PopClip extension.\r\n\r\nReason: Could not load Config.plist. The XML may be malformed.\r\n\r\nI have done:\r\n1. download it from https://pilotmoon.com/popclip/extensions/page/JoinLines, same issue\r\n2. donload it from github https://github.com/pilotmoon/PopClip-Extensions/blob/master/extensions/JoinLines.popclipextz, same issue.\r\n3.  reboot the macOS catalina, same issue.\r\nwhat can I do???\n Comments: \n Comment 0: Hi, what version of PopClip are you using? You will need to be running vesion 2022.5 or later.\n Comment 1: Hi Support,\r\n\r\nTHanks for your advice.\r\nPopclip version: 201910(3032)\r\nMacOS is Catalina 10.15.7 (19H1824)\r\n\r\nWhen I update popclip, a error message as below:\r\n\r\n\"An error occurred while extracting the archive. Please try again later.\"\r\n\r\nI have done:\r\n1. try another 1 proxy to download the update, failed.\r\n2. try another 2 proxy to download the update, update same failed.\r\n\r\nsorry, what can I do?\r\n\r\n\n Comment 2: I recommend to manually install by downloading from https://pilotmoon.com/popclip/download or the Mac App Store.",
  "Issue title: Add just to arkade get\n Issue body: <!--- Provide a general summary of the issue in the Title above -->\r\n\r\n## Expected Behaviour\r\n`arkade get just` installs just.\r\n\r\n## Current Behaviour\r\nNot implemented.\r\n\r\n## Are you a GitHub Sponsor yet (Yes/No?)\r\n\r\n<!-- Requests from sponsors take priority -->\r\n<!--- Check at https://github.com/sponsors/alexellis -->\r\n\r\n- [ ] Yes\r\n- [X] No\r\n\r\n## Possible Solution\r\nAdd just as an installable cli tool.\r\n\r\n## Context\r\nJust is a really nice, modern alternative for GNU make.\r\n\r\n## If requesting a CLI for \"arkade get\"\r\n\r\nHow many downloads does this tool have? **210,429**\r\nhttps://somsubhra.github.io/github-release-stats/?username=casey&repository=just&page=1&per_page=5\r\n\r\n## Your Environment\r\n\r\n* What Kubernetes distribution are you using?\r\n\r\n```\r\n{\r\n  \"clientVersion\": {\r\n    \"major\": \"1\",\r\n    \"minor\": \"24\",\r\n    \"gitVersion\": \"v1.24.0\",\r\n    \"gitCommit\": \"4ce5a8954017644c5420bae81d72b09b735c21f0\",\r\n    \"gitTreeState\": \"clean\",\r\n    \"buildDate\": \"2022-05-03T13:46:05Z\",\r\n    \"goVersion\": \"go1.18.1\",\r\n    \"compiler\": \"gc\",\r\n    \"platform\": \"linux/amd64\"\r\n  },\r\n  \"kustomizeVersion\": \"v4.5.4\"\r\n}\r\n\r\n```\r\n\r\n* Operating System and version (e.g. Linux, Windows, MacOS):\r\n\r\n```\r\nLinux desktop 5.18.11-200.fc36.x86_64 #1 SMP PREEMPT_DYNAMIC Tue Jul 12 22:52:35 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\n* What arkade version is this?\r\n\r\n```\r\nVersion: 0.8.28\r\nGit Commit: 650ceaa1f922602f55bec71b70fe8f239f2b7b2b\r\n```\r\n\n Comments: \n Comment 0: Also if this tool gets accepted/merged we could create a PR for just, to add arkade as a package manager in the following readme section: https://github.com/casey/just#packages=\n Comment 1: Thanks for the suggestion. Feel free to try it out and if it makes sense as a downloadable app, put the PR up for me to merge \ud83d\udc4d ",
  "Issue title: Using plank (dock app) properly with bspwm\n Issue body: # The Problem\r\nAfter installing it for the first time and adding it to my bsp rc, I noticed that plank would actually go behind all windows. This only fixes itself if I restart the wm in that session. Meaning on every new login, I would have to restart the wm in order for plank to start working correctly once again.\r\n\r\n# Expected behavior\r\nPlank spawns above all other windows when the mouse is lowered to the bottom edge of the screen, and disappears when it is taken away. Plank is also not under focus at all times / when switching to a different workspace.\r\n\r\n# Tested workaround\r\nAdding the bspc rule \r\n`bspc rule -a Plank manage=on border=off locked=on focus=off follow=off`\r\nThis solves the issue of plank not staying on top after the first login. But simultaneously it also adds a different problem. Plank is now on focus whenever I am on an 'empty' desktop. This branches off into a tertiary problem where I can no longer use jgmenu since plank is always on focus. I have demonstrated my problem below\r\n\r\nhttps://user-images.githubusercontent.com/77363063/170856932-d0259194-b6c4-4862-a15f-4bb8b4302ea0.mp4\r\n\r\n# End Goal\r\nTo be able to use plank and jgmenu in the same setup without either of them interfering with each other or bspwm prohibiting their functionality in any way. This only works without the bspc rule and **only after restarting the wm in that session.** Demonstrated below\r\n\r\nhttps://user-images.githubusercontent.com/77363063/170857607-e58c0d19-77cb-4d71-83fa-98bc05bb18f1.mp4\r\n\r\n\r\n\n Comments: \n Comment 0: #390\n Comment 1: https://github.com/baskerville/bspwm/issues/390\n Comment 2: @beyond9thousand Exactly bro, me pasa eso tal cual, the docks get stuck behind tiled windows and i dont know what i have to do. \n Comment 3: Fixed it by running this script in the background\n\n```\n#!/bin/bash\n \nbspc subscribe node_add | while read -r _; do\n   xdo raise -N Plank\ndone \n```",
  "Issue title: Adding support for TILEDB_DATETIME_* datatypes to the PDAL tiledb reader\n Issue body: **Describe the bug**\r\n\r\nI am trying to open a tiledb array however it's failing because one of my dimensions uses the `datetime64[ns]` data type (see the [TileDB doco on datetime fields](https://docs.tiledb.com/main/background/internal-mechanics/datetimes)). From what I understand these are pretty much int64 values which PDAL does support.\r\n\r\n```\r\npdal info --driver readers.tiledb my.tiledb -p 0\r\n=> PDAL: Invalid Dim type from TileDB\r\n```\r\n\r\nI'm far from a c++ expert but scratching through the `plugins/tiledb/io/TileDBReader.cpp` I can see a few relevant pieces of code\r\nFor getting fields\r\nhttps://github.com/PDAL/PDAL/blob/e63f88829a15891689f50e123fa327c2a539af8b/plugins/tiledb/io/TileDBReader.cpp#L60-L96\r\nReading the value\r\nhttps://github.com/PDAL/PDAL/blob/e63f88829a15891689f50e123fa327c2a539af8b/plugins/tiledb/io/TileDBReader.cpp#L389-L432\r\n\r\nThere are a few handling options I can think of\r\n- Improve the tiledb reader so that it converts the datatype into something that PDAL supports\r\n  - Either you could write the raw int64 value, or you could attempt to convert it a similar datetime value as is used elsewhere in PDAL\r\n- Add an option to tiledb reader that allows you to skip `TILEDB_DATETIME_*` dimensions - this seems feasible given that the buffer length is known to be int64.\r\n\r\n\r\nI tried to find a public dataset in the tileDB samples that used one of these fields but couldn't, it seems like they mostly use float64 instead when storing datetimes. But if you are interested in pursuing a fix I can probably whip up a small sample to share.\r\n\r\nIf you're interested in supporting those fields I'd be happy to do a bit more investigating and see if I could put together a PR.\r\n\r\n\r\n**System/installation information:**\r\nI'm running PDAL v2.3.0\r\n\r\nThanks,\r\nRowan\r\n\r\n\n Comments: \n Comment 0: A PR will be helpful, but this won't be added until the 2.5 release, which might be quite a while from now given we have just released 2.4.0. \n Comment 1: Added in #3798.",
  "Issue title: The performance tests are broken.\n Issue body: When I run the performance tests it fails.\r\n\r\n```shell\r\nEventEmitter2 git:(master) \u2717./node_modules/.bin/nodeunit test/perf/benchmark.js \r\nEventEmitterHeatUp x 4,246,065 ops/sec \u00b10.28% (94 runs sampled)\r\nEventEmitter x 4,099,899 ops/sec \u00b11.57% (92 runs sampled)\r\nEventEmitter2 x 14,586,093 ops/sec \u00b11.01% (93 runs sampled)\r\nEventEmitter2 (wild) x 11,040,898 ops/sec \u00b10.74% (89 runs sampled)\r\n\r\n/home/agirorn/code-open/EventEmitter2/test/perf/benchmark.js:50\r\n    console.log('\\nFastest is'+ this.filter('fastest').pluck('name'));\r\n                                                         ^\r\nTypeError: this.filter(...).pluck is not a function\r\n    at Suite.<anonymous> (/home/agirorn/code-open/EventEmitter2/test/perf/benchmark.js:50:58)\r\n    at /home/agirorn/code-open/EventEmitter2/node_modules/benchmark/benchmark.js:1215:40\r\n    at arrayEach (/home/agirorn/code-open/EventEmitter2/node_modules/lodash/lodash.js:537:11)\r\n    at Function.forEach (/home/agirorn/code-open/EventEmitter2/node_modules/lodash/lodash.js:9359:14)\r\n    at Suite.emit (/home/agirorn/code-open/EventEmitter2/node_modules/benchmark/benchmark.js:1214:11)\r\n    at Suite.onComplete (/home/agirorn/code-open/EventEmitter2/node_modules/benchmark/benchmark.js:1186:17)\r\n    at getNext (/home/agirorn/code-open/EventEmitter2/node_modules/benchmark/benchmark.js:900:30)\r\n    at execute (/home/agirorn/code-open/EventEmitter2/node_modules/benchmark/benchmark.js:862:26)\r\n    at invoke (/home/agirorn/code-open/EventEmitter2/node_modules/benchmark/benchmark.js:970:20)\r\n    at Suite.runSuite [as run] (/home/agirorn/code-open/EventEmitter2/node_modules/benchmark/benchmark.js:1169:7)\r\n    at Object.<anonymous> (/home/agirorn/code-open/EventEmitter2/test/perf/benchmark.js:53:4)\r\n    at Module._compile (module.js:570:32)\r\n    at Object.Module._extensions..js (module.js:579:10)\r\n    at Module.load (module.js:487:32)\r\n    at tryModuleLoad (module.js:446:12)\r\n    at Function.Module._load (module.js:438:3)\r\n```\n Comments: \n Comment 0: I haven't had much time to do maintenance, and this looks like a library version problem. A pr to fix this would be very much appreciated!\n Comment 1: just replace `pluck` with `map`\r\n\r\nbefore:\r\n`this.filter('fastest').pluck('name')`\r\nafter:\r\n`this.filter('fastest').map('name')`\n Comment 2: @evilive3000 Would you mind testing it out and submitting a PR?",
  "Issue title:.Nupkg can't be found using --version but is found when omitting it or using choco find\n Issue body: Hi Team,\r\n\r\nFirst, thank you for tackling package management for Windows! I appreciate it. I do have a problem I noticed with --version and I'm hoping you all can help.\r\n\r\n### What You Are Seeing?\r\n.Nupkg can't be found using --version but is found when omitting it or using choco find\r\n\r\n### What is Expected?\r\nThe.Nupkg would be found using --version\r\n\r\n### How Did You Get This To Happen? (Steps to Reproduce)\r\n1) Searched for the package using: `choco find psdscresources -dv` and it returns PSDscResources 116.69.203.115\r\n2) Run `choco install psdscresources -y -dv --noop` and it finds the package and says it will install\r\n3) Run `choco install psdscresources -version '116.69.203.115' -y -dv --noop` and it says it can't find the package\r\n\r\nIt's the same.nupkg which leads me to believe it's something with the code path used for --version. Also to note, the same.nupkg can be found using nuget directly, as well as Find-Module and Install-Module (PowerShellGet). I can provide the.nupkg if needed.\r\n\r\nThanks for the help!\r\n\r\n\r\n### Output Log\r\n**choco find**\r\n```\r\nPS C:\\Users\\johnsmith> choco find psdscresources -dv\r\nChocolatey v0.10.15\r\nChocolatey is running on Windows v 10.0.14393.0\r\nAttempting to delete file \"C:/ProgramData/chocolatey/choco.exe.old\".\r\nAttempting to delete file \"C:\\ProgramData\\chocolatey\\choco.exe.old\".\r\nCommand line: \"C:\\ProgramData\\chocolatey\\choco.exe\" find psdscresources -dv\r\nReceived arguments: find psdscresources -dv\r\nRemovePendingPackagesTask is now ready and waiting for PreRunMessage.\r\nSending message 'PreRunMessage' out if there are subscribers...\r\n[Pending] Removing all pending packages that should not be considered installed...\r\nPerforming validation checks.\r\nGlobal Configuration Validation Checks:\r\n - Package Exit Code / Exit On Reboot = Checked\r\nSystem State Validation Checks:\r\n Reboot Requirement Checks:\r\n - Pending Computer Rename = Checked\r\n - Pending Component Based Servicing = Checked\r\n - Pending Windows Auto Update = Checked\r\n - Pending File Rename Operations = Ignored\r\n - Pending Windows Package Installer = Checked\r\n - Pending Windows Package Installer SysWow64 = Checked\r\nThe source 'https://artifactory.aws.acme.com/api/nuget/nuget;https://chocolatey.org/api/v2/;\\\\corp.acme.com\\WinRepo\\Modules' evaluated to a 'normal' source type\r\n\r\nNOTE: Hiding sensitive configuration data! Please double and triple\r\n check to be sure no sensitive data is shown, especially if copying\r\n output to a gist for review.\r\nConfiguration: CommandName='find'|\r\nCacheLocation='C:\\Users\\johnsmith\\AppData\\Local\\Temp\\8\\chocolatey'|\r\nContainsLegacyPackageInstalls='True'|\r\nCommandExecutionTimeoutSeconds='2700'|WebRequestTimeoutSeconds='30'|\r\nSources='https://artifactory.aws.acme.com/api/nuget/nuget;https://chocolatey.org/api/v2/;\\\\corp.acme.com\\WinRepo\\Modules'|\r\n\r\nSourceType='normal'|Debug='True'|Verbose='True'|Trace='False'|\r\nForce='False'|Noop='False'|HelpRequested='False'|\r\nUnsuccessfulParsing='False'|RegularOutput='True'|QuietOutput='False'|\r\nPromptForConfirmation='True'|AcceptLicense='False'|\r\nAllowUnofficialBuild='False'|Input='psdscresources'|\r\nAllVersions='False'|\r\nSkipPackageInstallProvider='False'|Prerelease='False'|ForceX86='False'|\r\nOverrideArguments='False'|NotSilent='False'|\r\nApplyPackageParametersToDependencies='False'|\r\nApplyInstallArgumentsToDependencies='False'|IgnoreDependencies='False'|\r\nAllowMultipleVersions='False'|AllowDowngrade='False'|\r\nForceDependencies='False'|Information.PlatformType='Windows'|\r\nInformation.PlatformVersion='10.0.14393.0'|\r\nInformation.PlatformName='Windows Server 2016'|\r\nInformation.ChocolateyVersion='116.69.203.115'|\r\nInformation.ChocolateyProductVersion='0.10.15'|\r\nInformation.FullName='choco, Version=116.69.203.115, Culture=neutral, PublicKeyToken=79d02ea9cad655eb'|\r\n\r\nInformation.Is64BitOperatingSystem='True'|\r\nInformation.Is64BitProcess='True'|Information.IsInteractive='True'|\r\nInformation.UserName='johnsmith'|Information.UserDomainName='PROD'|\r\nInformation.IsUserAdministrator='True'|\r\nInformation.IsUserSystemAccount='False'|\r\nInformation.IsUserRemoteDesktop='True'|Information.IsUserRemote='True'|\r\nInformation.IsProcessElevated='True'|\r\nInformation.IsLicensedVersion='False'|Information.LicenseType='Foss'|\r\nInformation.CurrentDirectory='C:\\Users\\johnsmith'|\r\nFeatures.AutoUninstaller='True'|Features.ChecksumFiles='True'|\r\nFeatures.AllowEmptyChecksums='False'|\r\nFeatures.AllowEmptyChecksumsSecure='True'|\r\nFeatures.FailOnAutoUninstaller='False'|\r\nFeatures.FailOnStandardError='False'|Features.UsePowerShellHost='True'|\r\nFeatures.LogEnvironmentValues='False'|Features.LogWithoutColor='False'|\r\nFeatures.VirusCheck='False'|\r\nFeatures.FailOnInvalidOrMissingLicense='False'|\r\nFeatures.IgnoreInvalidOptionsSwitches='True'|\r\nFeatures.UsePackageExitCodes='True'|\r\nFeatures.UseEnhancedExitCodes='False'|\r\nFeatures.UseFipsCompliantChecksums='False'|\r\nFeatures.ShowNonElevatedWarnings='True'|\r\nFeatures.ShowDownloadProgress='True'|\r\nFeatures.StopOnFirstPackageFailure='False'|\r\nFeatures.UseRememberedArgumentsForUpgrades='False'|\r\nFeatures.IgnoreUnfoundPackagesOnUpgradeOutdated='False'|\r\nFeatures.SkipPackageUpgradesWhenNotInstalled='False'|\r\nFeatures.RemovePackageInformationOnUninstall='False'|\r\nFeatures.ExitOnRebootDetected='False'|\r\nFeatures.LogValidationResultsOnWarnings='True'|\r\nFeatures.UsePackageRepositoryOptimizations='True'|\r\nFeatures.ScriptsCheckLastExitCode='False'|\r\nListCommand.LocalOnly='False'|\r\nListCommand.IdOnly='False'|ListCommand.IncludeRegistryPrograms='False'|\r\nListCommand.PageSize='25'|ListCommand.Exact='False'|\r\nListCommand.ByIdOnly='False'|ListCommand.ByTagOnly='False'|\r\nListCommand.IdStartsWith='False'|ListCommand.OrderByPopularity='False'|\r\nListCommand.ApprovedOnly='False'|\r\nListCommand.DownloadCacheAvailable='False'|\r\nListCommand.NotBroken='False'|\r\nListCommand.IncludeVersionOverrides='False'|\r\nUpgradeCommand.FailOnUnfound='False'|\r\nUpgradeCommand.FailOnNotInstalled='False'|\r\nUpgradeCommand.NotifyOnlyAvailableUpgrades='False'|\r\nUpgradeCommand.ExcludePrerelease='False'|\r\nNewCommand.AutomaticPackage='False'|\r\nNewCommand.UseOriginalTemplate='False'|SourceCommand.Command='unknown'|\r\nSourceCommand.Priority='0'|SourceCommand.BypassProxy='False'|\r\nSourceCommand.AllowSelfService='False'|\r\nSourceCommand.VisibleToAdminsOnly='False'|\r\nFeatureCommand.Command='unknown'|ConfigCommand.Command='unknown'|\r\nApiKeyCommand.Remove='False'|PinCommand.Command='unknown'|\r\nOutdatedCommand.IgnorePinned='False'|Proxy.BypassOnLocal='True'|\r\n_ Chocolatey:ChocolateyListCommand - Normal Run Mode _\r\nSearching for package information\r\n",
  "Issue title: Activated virtual environment does not match\n Issue body: \nIssue Type: <b>Bug</b>\n\n- Add two source directories with different python venv to workspace\n- Select python interpreter for each of the projects\n- open a source file of project one\n- open new terminal for project one <-- correct\n- open net terminal for project two\n- venv of project one will be activates <-- incorrect\n\n\nExtension version: 2021.4.765268190\nVS Code version: Code 1.55.2 (3c4e3df9e89829dce27b7b5c24508306b151f30d, 2021-04-13T09:35:57.887Z)\nOS version: Windows_NT x64 10.0.17763\nRemote OS version: Linux x64 3.10.0-1127.19.1.el7.x86_64\nRemote OS version: Linux x64 5.4.0-72-generic\nFetching remote diagnostics for 'SSH: scvnetbox01' failed: Canceled\n\n<details>\n<summary>System Info</summary>\n\n|Item|Value|\n|---|---|\n|CPUs|Intel(R) Xeon(R) Gold 6132 CPU @ 2.60GHz (2 x 2594)|\n|GPU Status|2d_canvas: unavailable_software<br>gpu_compositing: disabled_software<br>multiple_raster_threads: disabled_off<br>oop_rasterization: disabled_off<br>opengl: disabled_off<br>protected_video_decode: disabled_off<br>rasterization: disabled_software<br>skia_renderer: enabled_on<br>video_decode: disabled_software<br>vulkan: disabled_off<br>webgl: unavailable_software<br>webgl2: unavailable_software|\n|Load (avg)|undefined|\n|Memory (System)|8.00GB (2.95GB free)|\n|Process Argv|--crash-reporter-id fc2df906-66e9-496c-821c-b1a32946d1ec|\n|Screen Reader|no|\n|VM|50%|\n\n|Item|Value|\n|---|---|\n|Remote|SSH: scvnetmgmt01|\n|OS|Linux x64 3.10.0-1127.19.1.el7.x86_64|\n|CPUs|Intel(R) Xeon(R) Gold 6132 CPU @ 2.60GHz (6 x 2593)|\n|Memory (System)|11.58GB (6.91GB free)|\n|VM|22%|\n\n|Item|Value|\n|---|---|\n|Remote|SSH: scvpconf01|\n|OS|Linux x64 5.4.0-72-generic|\n|CPUs|Intel(R) Xeon(R) Gold 6132 CPU @ 2.60GHz (4 x 2593)|\n|Memory (System)|15.61GB (0.24GB free)|\n|VM|6%|\n\nFetching remote diagnostics for 'SSH: scvnetbox01' failed: Canceled\n</details><details>\n<summary>A/B Experiments</summary>\n\n```\nvsliv368cf:30146710\nvsreu685:30147344\npython383:30185418\nvspor879:30202332\nvspor708:30202333\nvspor363:30204092\nvstes627:30244334\npythonvspyt639:30291489\npythontb:30283811\npythonvspyt551:30291414\nvspre833:30267464\npythonptprofiler:30281270\nvscnewfilehidden:30294815\nvshan820:30294714\npythondataviewer:30285071\nvscus158cf:30286554\nvscgsv2:30294352\n\n```\n\n</details>\n\n<!-- generated by issue reporter -->\n Comments: \n Comment 0: Closing as duplicate of https://github.com/microsoft/vscode-python/issues/15522",
  "Issue title: Linking IPV4 Adresses\n Issue body: Hi, \r\ni can only link IPv4 with IPv6 adresses. We use the version 1.24 rev11\r\nIs there any way to import a opportunity to link IPv4 with IPv4 adresses?\r\n\r\nBest regards\r\nTehakla\n Comments: \n Comment 0: Hi, sorry this is meant for dual-stacked hosts only.\r\n\r\nYou can however link addresses based on specified database fields, for example hostname? Check under settings\r\n```\r\nLink addresses\r\nDisplay linked addresses from another subnet if it matches selected field\r\n```\n Comment 1: thank you for your fast answer :)\n Comment 2: Great. Reopen if you have any more questions.",
  "Issue title: Set Agg backend?\n Issue body: Does it make sense for pytest-mpl to set the backend to \"Agg\" in there somewhere? I don't see a usecase where it doesn't make sense, but that doesn't mean I'm not missing something. I just want to make my tests able to run headless a bit more easily.\n Comments: \n Comment 0: @dopplershift - I agree that would make sense.\n Comment 1: So I'm not sure what the best approach is here, and I've played with a few today:\r\n1. Put `matplotlib.use('agg')` right after `import matplotlib`\r\n    It has to be that early because `import matplotlib.testing.decorators` triggers an import of `pyplot`, which will lock the backend setting. I feel a little odd of locking in a particular setting disallowing pdf, ps, etc.\r\n\r\n2. Add a `'backend'` kwarg to `mpl_image_compare` and use `pyplot.switch_backend` \"experimental\" functionality.\r\n    Will only work for non-GUI backends, but at least makes things flexible. This would involve repeating code that's in `matplotlib.testing.switch_backend`, but unfortunately that version imports `nose`. Not sure about basing it on functionality that's called \"experimental\", but it really should be fine with the image backends.\r\n\r\n3. Just avoid having pytest-mpl trigger an import of `pyplot`.\r\n    Remove the import of `matplotlib.pyplot` at the top level since `style` can be accessed directly from the `matplotlib` import; remove the unused import of `cleanup` from `matplotlib.testing.decorators`. Copy in the implementation of `remove_text` from matplotlib. At this point, this will at least allow tests to be able to call `matplotlib.use()` and have it work.\r\n\r\nThoughts on which way you prefer? I'm somewhere between 2 and 3 I think.\n Comment 2: Thinking about this some more, I think 1 is definitely out - it is possible that codes that have e.g. Qt GUIs with Matplotlib (e.g. Glue) might also want to have image tests, and therefore might not want to use the Agg backend globally throughout the tests. So I think 2 or 3 sound more promising.\n Comment 3: While the purist in me likes 3, I kind of like 2 so that I don't have to worry about anything if I just want Agg (and we make that the default). I think in that case I would add a `matplotlib.use('Agg')` to `ImageComparison.__init__` so that in that default case we can actually check and avoid doing the switching if nobody asks for anything else.",
  "Issue title: Watermark font\n Issue body: How to change watermark font??\n Comments: \n Comment 0: I need to change menu font. Do you know how can i do?\n Comment 1: I think just replace font path in gui.cpp\n Comment 2: Please someone help\n Comment 3: create font \n Comment 4: What do you mean create font\n Comment 5: use vgui_spew_fonts to look for a builtin font. when you choose one go to SDK/Surface.h and replace font value. \n Comment 6: ISurface has a virtual function called `CreateFont`, returning an unsigned int as an id.\r\nISurface then uses this ID in another vfunc called `SetFontGlyphSet`, assigning it to a windows font.\r\nfind where the equivilent of `SetFontGlyphSet` is getting called and change the font name to what you want.",
  "Issue title: Folding still slow sometimes during insert mode\n Issue body: Slow inserting due to folding has improved a lot since #77 has been fixed.\n\nHowever, there is still an issue: Some other plugins (e.g. ultisnips) have insert mode bindings which seem to shortly leave insert mode to do things. E.g. the <tab> binding triggers expansion of a snippet. This is still slowed down, since the folding is recomputed as insert mode is left.\n\nHow can it be fixed? Maybe we can (somehow) add a delay before the foldmethod is changed (a simple sleep won't cut it, the change needs to be done in the background)? Alternatively, the foldmethod could be sped up?\n\n Comments: \n Comment 0: Maybe this could work:\n\n`autocmd InsertLeave *.tex augroup FoldMeth | autocmd FoldMeth CursorHold * setlocal foldmethod=expr | autocmd! FoldMeth CursorHold`\n\nThis basically delays setting the fold method to the next CursorHold event (which happens after 4s of idle cursor) and then deletes the CursorHold hook. \n\nDownside is that the user needs to keep idle for 4 seconds for the folding to be pjones@example.org.\n\nAlso, the code needs to be optimized. Currently, a new CursorHold hook is inserted whenever insert mode is left. It would be cleaner to remove the InsertLeave autocmd and only re-add it from the CursorHold autocmd.\n\nIt feels dirty, altogehter, but works. What do you think?\n\n Comment 1: I agree the idea seems to work, but I also agree it feels dirty.\n\nI'm trying to see if we could use a cache instead. If that does not work, then I think your solution might be ok.\n\nBtw: Have you tried Snipmate? I have no problems with folding and Snipmate. I have not tried ultisnip, so if you have tried both, I would be happy to hear why you use ultisnip instead. :)\n\n Comment 2: Hi,\n\nI've created a function that uses cache, and it seems to work reasonably well. There are short delays, but nothing as severe as the \"original\" version. Could I send you the function on email, and could you test it? I don't want to push it until we're sure it is an improvement.\n\n Comment 3: Hi,\n\nI just pushed a development branch called `cached-folding`. Please test it and see what you think. Notice I still use the FastFold autocommands. Please test also without that autocommand group. At least with me this new cached folding is faster than the old one when pasting in insert mode.\n\n Comment 4: I just tried it out, I see no difference (i.e. no speed up). However, I did take a quick look at the code. It seems like for lines that retain the fold level of the previous line (line 180-184 of folding.vim), there is never a cache hit. This may be the majority of the lines (but I haven't really dug into the previous lines of Latexbox_FoldLevel() to see whether they are covered elsewhere).\n\n Comment 5: I don't know how vim variables are initialized, but is the initialization in line 129 done each time the function is called? That would negate any benefit of the cache I assume.\n\n Comment 6: I think the only thing saved is that it prevents the recursive behaviour of the original version. Thus it should be faster than the original (and it is with me), but I agree it is still not fast enough. In other words, it may be wrong to use the term \"cache\". :\\\n\nOne of the problems with improving this idea is that I don't really know when the fold function is called. It seems to me that it is called for every line of the file, every time the folds are refreshed. Perhaps that is wrong, and perhaps it is only called on a given line if the line has changed.\n\nAnother improvement could be to also save every line in the cache. This would enable us to check if the line has changed, and if not, then we can return the old fold level. However, things get complicated, since the fold level of one line almost always depends on the fold level of the previous line.\n\n Comment 7: Hmm. I am also not sure when the fold function is called, but I assume (from the slow down) it is quite often (i.e. at least once per line). I added some echom to the function, it does seem every line is visited once after an update (i.e. leaving insert mode). This is congruent with the help:\n\n`Note: Since the expression has to be evaluated for every line, this fold method can be very slow!`\n\nFor each line that does not change the folding level (normal text), there are at least 8 pattern matches I counted (assuming all fold features are enabled). This is probably what's costly. To improve this, we should have a (simple) check at the beginning of the function whether we have a 'plain text' line. Something like this (added at line 131) yielded acceptable speed:\n\n`if line[0]!= '\\'\n        let b:LatexBox_FoldCache[a:lnum] = s:GetFoldLevel(a:lnum-1)\n        \"echom \"cache miss for line \".a:lnum. \" is \". b:LatexBox_FoldCache[a:lnum] \n        return b:LatexBox_FoldCache[a:lnum]\n    endif`\n\nThe test only checks the first character, we should make it a bit more sophisticated. It doesn't need to be perfect in the sense that it may yield false negatives (which would be caught further down), but must not generate false positives (which would screw up the folding). The current test probably does yield false positives (although folding looked ok in my file). Maybe you can come up with something better.\n\nNote that the fold function still will be called once per line and these function calls already cause some overhead. The syntax fold method (used by vim-latex) could be faster here.\n\nThe help also hints at avoiding the use of '=', 'a', and's' return values, as these may cause recursive searches until an independent fold level can be found in the lines above the current one. But I don't know if you are still using those.\n\nRegarding caching, it seems like a good idea to remember previously calculated fold levels. However, I am not sure how we know when to invalidate the previously computed (cached) fold level. When a line of text is changed (is there a hook for this?), all fold levels above this changed line should remain valid, only those below need to be invalidated... But it could be complicated in the end and maybe not necessary.\n\nOK, I will go to bed now :)\n\n Comment 8: You are right, the foldlevel function is called on each line of the file, every single time the folding is updated (which is often). Thus we should try to make it return as quickly as possible in most cases.\n\nI think my \"caching\" idea does work a little bit, though, since it removes the \"=\", \"a\", and \"s\" return values. These are, if I understand correctly, recursive, and thus very expensive. The cache variable I introduced should simpliy \"=\", \"a\", and \"s\" to simple look-up-tables, which is much less expensive.\n\nI'll look at this more tomorrow, but I think your idea of having a check in the beginning for \"normal\" lines is good, since there are O(n) \"normal\" lines in a file, and only O(1) \"special\" lines. I'll try it tomorrow and make a version that should not yield false positives, and push it to the devel branch (cached-folding).\n\nBtw: vim-latex, or latexsuite, does not use syntax folding. They use manual folding with a very fancy plugin on top, which works similar to syntax folding but not quite. I guess this makes much more effective, but at the same time the plugin is kind of bloated in my opinion.\n",
  "Issue title: New GitHub Sponsors program + Bountysource integration not working\n Issue body: Hello everyone!\r\nGitHub just launched the beta of its new Sponsors program. Basically, in the future, you will be able to send money to anyone on GitHub **free of charge**, as long as its associated to a repository, issue or PR. Also, for the next 12 months, GitHub will equal every donation! Details are here: https://github.blog/2019-05-23-announcing-github-sponsors-a-new-way-to-contribute-to-open-source/.\r\nConcretely, what it means for OT is that a sponsor button could be added at the top of the repository, and up to four contributors could be listed for individual donations. The setup is automatic: https://help.github.com/en/articles/displaying-a-sponsor-button-in-your-repository.\r\n@shun-iwasawa Could you look into this, please? There is also the Bountysource integration that is not working anymore, which is problematic because there are still active bounties. Thank you!\n Comments: \n Comment 0: tagged this with'resource' and 'roadmap' as funding of development is an ongoing concern.\n Comment 1: The Github Sponsors program is said to be live now but no developer to date has signed up to be sponsored.\r\n\r\nWill keep this open for now and reference it via the primary Bounties Listing.  Then even when closed developers can reference it.\r\n\r\n\n Comment 2: @jpturcotte Did we ever discover why BountySource integration wasn't working?\n Comment 3: It seems to me that bountysource integration was/is working but only in specific cases where the reporter leaves the code for the bountysource plugin (added via template) in the report.  If they remove the entry then the plugin isn't called.\r\n\r\nWill investigate.\n Comment 4: I have to ask...\r\n\r\nI don't suppose you could add a 'Join' option where if the snapping of control points is to the end of a spline/line then the ends would automatically be joined.  @shun-iwasawa just now added some code relating a little to that with the Tape Tool.  That PR will not be merged until after v1.4 goes final release also.\n Comment 5: wrong thread\n Comment 6: The following is the markdown that appears necessary for a post to be linked to BountySource:\r\n\r\n```\r\n<bountysource-plugin>\r\n\r\n---\r\nWant to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/39331590-suspicious-incorrect-use-of-abs?utm_campaign=plugin&utm_content=tracker%2F33713530&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F33713530&utm_medium=issues&utm_source=github).\r\n</bountysource-plugin>\r\n```\n Comment 7: Here's what it looks like:\r\n\r\n<bountysource-plugin>\r\n\r\n---\r\nWant to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/39331590-suspicious-incorrect-use-of-abs?utm_campaign=plugin&utm_content=tracker%2F33713530&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F33713530&utm_medium=issues&utm_source=github).\r\n</bountysource-plugin>",
  "Issue title: Twenty Twenty-One: No global style option on Atomic Sites\n Issue body: ## Summary\r\n\r\nTwenty Twenty-One has no option to change Global Styles. If we have changed the custom font while using a different block based theme, and now we want to change the font to the default theme font we need to change the theme, reset the font to default, and change our theme back to Twenty Twenty-One.\r\n\r\nUPDATE: This issue is limited to Atomic Sites.\r\n\r\n## Steps to replicate\r\n\r\n1- Go to any page editor while using Twenty Twenty-One\r\n\r\n## Result\r\n\r\nGlobal styles option won't appear. \r\n\r\n## Expected\r\n\r\nTo see the Global Styles option like any other block based theme. \r\n\r\n![Markup 2021-02-06 at 12 47 38](https://user-images.githubusercontent.com/24919469/107127117-954b3e80-6879-11eb-9ae9-378dced68871.png)\r\n\r\n\r\n* User report: #3712817-zd\r\n\r\n\n Comments: \n Comment 0: This looks like an issue with the Editing Toolkit and corresponding features, not a themes issue, so I've moved it to wp-calypso.\n Comment 1: +1 33429033-hc\r\n\r\nTheme: Exford\r\n\r\nGlobal Styles showed up after activating plugin WordPress.com Editing Toolkit.\n Comment 2: Another issue it seems. \r\n\r\n4712079-ZEN\r\n\r\nTheme: Twenty Twenty One\r\n\r\nUser has active Editing Toolkit plugin:\r\n\r\n<img width=\"791\" alt=\"Screenshot 2022-01-23 at 17 17 09\" src=\"https://user-images.githubusercontent.com/71094068/150685437-8ac6e28a-ac7d-4070-a877-e14a8f9d3062.png\">\r\n\r\nStill no option for Global Styles in the editor. \r\n\r\n\n Comment 3: @Sandkorner For your user's case with `twentytwentyone`, this is because the site had the incorrect version symlinked.\r\n\r\nThe Atomic platform serves two versions of the theme, the upstream version from WordPress.org and a special WPCOM version.\r\n\r\nIn some cases a WPCOM site might end up with the WPORG version symlinked.\r\n\r\nTo resolve, we can break the symlink and then install the theme from Calypso -- the proper WPCOM version is installed.\r\n\r\nI fixed it for that specific site and discussed with the HE working on the issue at the time @ahmadbaig1 \r\np1643046046173000-slack-C3GP81E05 \r\n\r\n#### Workaround\r\n\r\n1. Remove the folder for twentytwentyone to break the symlink.\r\n2. Reinstall twentytwentyone via Calypso, WP-Admin, or `wp theme install twentytwenty.` \r\n\r\nThis will get the proper WPCOM-specific version symlinked on your WoA sites.\r\n\r\n#### Internal discussion\r\n\r\nMore on this internally here: p9o2xV-1LC-p2#comment-5395\r\n\r\ncc @jeffikus @scruffian it can be a theme issue, I suspect it is in most cases. But, more of a platform symlinking issue. \n Comment 4: @kriskorn pinging you to see if you get the impression this is a platform level issue which still needs addressing? I'm only seeing one additional report in the past year...\n Comment 5: **Support References**\n\n*This comment is automatically generated. Please do not edit it.*\n\n\n- [ ] 3712817-zen\n- [ ] 3759469-zen\n- [ ] 3801920-zen\n- [ ] 3802882-zen\n- [ ] 4343666-zen\n- [ ] 4370483-zen\n- [ ] 4712079-zen\n\n Comment 6: @jordesign I can see that with a properly symlinked Twenty Twenty-One theme, the Global Styles option is there, so it seems the issue might mostly happen only when there is a.org version of the theme active on a site, [as Joshua has described here](https://github.com/Automattic/wp-calypso/issues/59396#issuecomment-1020380212). \r\n\r\nWith that said, I think we can go ahead and close this one and help customers out with properly activating a symlinked theme to see Global Styles. \n Comment 7: Awesome - i'd agree with that too. Thanks for the gut check - consider it closed!",
  "Issue title: Feature Request: Display members in explorer\n Issue body: It would be great to drill down to members of a component within the explorer tree or in an outline view of the selected file. This is extremely useful when you have many objects in one file and you're struggling to find that one function that you need to finish a task. See below for example from VS:\r\n![image](https://cloud.githubusercontent.com/assets/3504712/18017173/4275f9de-6b9e-11e6-8b65-0143b5143fc9.png)\r\n\r\n\n Comments: \n Comment 0: This feature request will not be considered in the next 6-12 months roadmap and as such will be closed to keep the number of issues we have to maintain actionable. Thanks for understanding and happy coding!",
  "Issue title: Field assigned with non-nullable `out` in constructor should count as initialized\n Issue body: The following should not produce any warning.\r\n\r\n``` csharp\r\n#nullable enable\r\n\r\nusing System;\r\npublic class C \r\n{\r\n    string field; // warning CS8618: Non-nullable field 'field' is uninitialized. Consider declaring the field as nullable.\r\n    \r\n    public void M() \r\n    {\r\n        M2(out field); \r\n    }\r\n    \r\n    static void M2(out string s) => throw null!;\r\n}\r\n```\r\n\r\nThis was encountered while annotating `PEFieldSymbol`.\r\n\r\nFYI @sharwell @cston \n Comments: \n Comment 0: The warning looks correct - `field` is not initialized in the (default) parameter-less constructor.\n Comment 1: @cston but it is initialized. If `field` was a local variable declared at the start of the constructor, it would be considered definitely assigned at the end of the constructor due to its use as an `out` variable.\n Comment 2: There is no constructor in the example above. If `M()` is changed to a constructor, there are no warnings.\n Comment 3: Updated OP with an actual repro. The problem occurs with a `try/catch`.\n Comment 4: The limitation here is that `if (x is null) x = value;` does not definitely assign `x`. It does update its state to not-null, though, so the new analysis will handle this properly.",
  "Issue title: dom-bind needs updated for lazy registration\n Issue body: ### Description\r\n`dom-bind` currently has an override of the `_registerFeatures` method which restricts the initialization of the element to a minimum. However, with the addition of the lazy registration feature in Polymer 1.4, a portion of the base functionality of `_registerFeatures` was split off into a separate method named `_finishRegisterFeatures`. The `dom-bind` code was not however updated to override the new `_finishRegisterFeatures` method. While I have not seen this have a negative affect on base Polymer code, I work on a project that has an element that mimics `dom-bind` and we were running into issues with template property accessors being referenced before `__data__` had been initialized. We've fixed this in our code by overriding `_finishRegisterFeatures` with an empty function and figured it was worth opening an issue here to at least make it known for consideration.\r\n\r\n### Browsers Affected\r\n<!-- Check all that apply -->\r\n- [x] Chrome\r\n- [x] Firefox\r\n- [x] Edge\r\n- [x] Safari 9\r\n- [x] Safari 8\r\n- [x] IE 11\r\n\r\n### Versions\r\n- Polymer: v1.4+\r\n\n Comments: \n Comment 0: @deedubbu It seems like you said that `dom-bind` is actually working for you? Is this just reporting a perceived inconsistency, or an actual bug with your use of `dom-bind`?\n\n Comment 1: Only perceived based on the issues our element had. I have not run into issues using `dom-bind`, though to be honest I don't directly use it very often. If there is no need to modify `dom-bind`, feel free to close this issue. Just wanted to make sure it was intentionally not updated when the API split.\n\n Comment 2: This has been removed in Polymer 2 (https://github.com/Polymer/polymer/blob/master/lib/elements/dom-bind.html) and should not be an issue any longer.",
  "Issue title: Feature Request: Zabbix Agent Auto registration\n Issue body: Hi, guys.\n\nWe have tested Zorka 1.0.13 with zabbix active checks.\nIt works nice, but I've tried to use Zorka for host auto registration \nhttps://www.zabbix.com/documentation/2.4/manual/discovery/auto_registration\nand it works but it has some problems:\n\nAccording  to specification \nhttps://www.zabbix.org/wiki/Docs/protocols/zabbix_agent/2.2\n\nyou don't send port zabbix.listen.port\nin active check request \n\nAnd you don't send\nHostMetadata. An optional parameter that defines host metadata. If not defined, the value will be acquired from HostMetadataItem.\nSo it will be great to have a new configuration parameter\nzabbix.hostmetadata = \"string\"\n\n{\n    \"host\": \"Host name\",\n    \"ip\": \"116.69.203.115\",\n    \"port\": zabbix.listen.port,\n    \"host_metadata\": zabbix.hostmetadata,\n    \"request\": \"active checks\"\n}\n\nI very hope you will implement this, we need very much to auto-register our websphere application servers.\n\nThank you.\n\n Comments: \n Comment 0: good, I want to need this function.\n Comment 1: Fixed earlier (1.0.14 AFAIR). Closing issue.",
  "Issue title: Error with multiple ng-repeat-start in v1.5.0 and Chrome browser\n Issue body: ***Note*: for support questions, please use one of these channels: https://github.com/angular/angular.js/blob/master/CONTRIBUTING.md#question. This repository's issues are reserved for feature requests and bug reports.**\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\nBug\r\n\r\n\r\n**What is the current behavior?**\r\nI have two `ng-repeat-start` and one `ng-repeat`. They should render a table. Sometimes it works but in some cases i get an angular error\r\n\r\n```\r\nVM2058 angular.js:13236 Error: [$compile:uterdir] Unterminated attribute, found 'ng-repeat-start' but no matching 'ng-repeat-end' found.\r\nhttp://errors.angularjs.org/1.5.0/$compile/uterdir?p0=ng-repeat-start&p1=ng-repeat-end\r\n    at VM2058 angular.js:68\r\n    at groupScan (VM2058 angular.js:8387)\r\n    at applyDirectivesToNode (VM2058 angular.js:8507)\r\n    at compileNodes (VM2058 angular.js:8149)\r\n    at compile (VM2058 angular.js:8048)\r\n    at VM2058 angular.js:8440\r\n    at boundTranscludeFn (VM2058 angular.js:8244)\r\n    at controllersBoundTransclude (VM2058 angular.js:9020)\r\n    at ngRepeatAction (VM2058 angular.js:28571)\r\n    at $watchCollectionAction (VM2058 angular.js:16529)(anonymous function) @ VM2058 angular.js:13236(anonymous function) @ VM2058 angular.js:9965Scope.$digest @ VM2058 angular.js:16682Scope.$apply @ VM2058 angular.js:16928(anonymous function) @ VM2058 angular.js:18753completeOutstandingRequest @ VM2058 angular.js:5804(anonymous function) @ VM2058 angular.js:6081\r\n```\r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem via https://plnkr.co or similar (template: http://plnkr.co/edit/tpl:yBpEi4).**\r\n\r\nHere is the plunker: http://plnkr.co/edit/2iX4RvGF5526NbVy72PJ?p=preview\r\n\r\nAs the problem occurs randomly the best way to reproduce it is to change the variable `i` in the `app.js` in plunker.\r\n\r\n\r\n**What is the expected behavior?**\r\nThe table should be rendered without problems.\r\n\r\n\r\n**What is the motivation / use case for changing the behavior?**\r\n\r\n\r\n\r\n**Which versions of Angular, and which browser / OS are affected by this issue? Did this work in previous versions of Angular? Please also test with the latest stable and snapshot (https://code.angularjs.org/snapshot/) versions.**\r\n\r\nThe issue only occurs in Angular >= 1.5.0 and Google Chrome / Chromium / Chrome Canary. Angular < 1.5.0 works fine in all browsers. And other browser have also no problem with Angular 1.5.0\r\n\r\n\r\n**Other information (e.g. stacktraces, related issues, suggestions how to fix)**\r\n\n Comments: \n Comment 0: Looks like a dupe of https://github.com/angular/angular.js/issues/14041 ",
  "Issue title: How to set tab width?\n Issue body: monaco-editor npm version: 0.7.0\r\nBrowser: Chrome 54.0.2840.99 \r\nOS: Windows 10\r\n\r\n\r\nI want custom code tab width, use 2 spaces or 8 spaces.\r\n\r\n\n Comments: \n Comment 0: Paging @alexandrudima.\n Comment 1: [`model.updateOptions({ tabSize: 8 })`](https://microsoft.github.io/monaco-editor/api/interfaces/monaco.editor.imodel.html#updateoptions). You can create a model yourself via [`monaco.editor.createModel(...)`](https://microsoft.github.io/monaco-editor/api/modules/monaco.editor.html#createmodel) or use the one created by the editor on your behalf [`editor.getModel()`](https://microsoft.github.io/monaco-editor/api/interfaces/monaco.editor.istandalonecodeeditor.html#getmodel)\n Comment 2: Thanks a lot!\n Comment 3: @alexandrudima Is your solution deprecated now? Because for me it works when I call `updateOptions` on the editor itself, not on the model.\n Comment 4: @chinchang seems that tabSize is a language consideration rather than the editor itself: \r\nhttps://microsoft.github.io/monaco-editor/api/interfaces/monaco.languages.formattingoptions.html\n Comment 5: @chinchang `tabSize` is a model property, so one must call `updateOptions` on the model instance in order to change `tabSize`.",
  "Issue title: [BUG] only certain whitelisted hosted gits support shadow cloning\n Issue body: https://github.com/npm/cli/blob/dc001afb71336968ef865fd37bd61cc8dca335ba/node_modules/pacote/lib/fetchers/git.js#L169-L178\r\n\r\nI know this may be on purpose, but why we need to limit shallow clone for those hosts? It makes `npm install` very slow when we have large self-hosted git dependencies.\r\n\r\n\r\n\r\n\n Comments: \n Comment 0: Yeah, we went with safety over power here.  The `@npmcli/git` module has a way to override it with the `gitShallow` option, but we aren't exposing that in the npm config object, and it's mostly just there for testing purposes.\r\n\r\nI don't want to change the default, but I would like to give you a way to specify that a host supports shallow cloning.  Maybe we could add a `--git-shallow-host=git.internal.mycompany.com --git-shallow-host=otherhost.com...` type of option, where you can specify a list of hosts supporting it?  A more convenient (but slightly dangerous) way to do it would be just a top-level `--git-shallow=[always, true, false]` option kind of like we do for `--color`, where `always` means \"always do it no matter what\", `false` means \"never do it, even for known hosts\", and `true` means \"use the default\".\r\n\r\nCould even do both things, I guess?  `--git-shallow-host=<hostname>` to add a host to the list, and `--git-shallow=always/true/false` to even bother with it.\r\n\r\nWhat do you think?\n Comment 1: Looks good. I think `--git-shallow-host` is enough as it is good to know what is allowed for security's consideration.",
  "Issue title: Issue with clicking cards after using Endless Hunger\n Issue body: Used Endless Hunger to break a subroutine on Quandry to get into a remote server, after passing 1 piece of unrezzed ice. Server had a SanSan and a Melange Mining in it. Game told me to click on cards to access, but wouldn't let me click on anything. I jacked out, re-did the run and then it let me click.\r\n\r\nBut then the click issue continued for the rest of the game. Using heartbeat, I couldn't select cards to trash to prevent meat damage. Once, it wouldn't let me install a card facedown at the start of the turn as Apex, etc.\r\n\r\nBoard state:\r\nCorp was NBN making news. They had 2 ice on R&D (1 rezzed data raven, one un rezzed), 1 unrezzed ice on HQ, no ice on Archives, no other remotes. They had 1 breaking news scored\r\n\r\nI was Apex. Had Endless Hunger/Heartbeat/E3/Harbinger out and 2 facedown installed cards. No agendas scored on runner side.\n Comments: \n Comment 0: Thanks for the *very* detailed reproduction steps and board setup. I am not able to reproduce this on an initial attempt, but this \"can't click on cards in remote\" sounds awfully similar to part of the problems reported in #2242. \n Comment 1: Did you have On the Lam installed at any point? \n Comment 2: Had to think about this one. I didn't have it installed face up, but it was probably one of my face down Apex installed cards at some point. Can't be 100% sure, but I didn't need it in the match up so I would have used it to feed Apex's cards.\n Comment 3: If you still have this deck, it might be worth trying again now that On the Lam has been fixed. Even if you were feeding it to Apex as a facedown card it still might've been screwing with things. ",
  "Issue title: Unicode issue\n Issue body: **Describe the bug**\r\nUnicode issue when handling folders with non-standard characters (such as Swedish)\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to IP:port/series\r\n2. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nError: 500 Internal Server Error\r\nSorry, the requested URL 'http://116.69.203.115:6767/series' caused an error:\r\n\r\nInternal Server Error\r\nException:\r\nUnicodeEncodeError('ascii', u'/mnt/4TB/tvseries/V\\xe4rldens s\\xe4msta indier', 19, 20, 'ordinal not in range(128)')\r\nTraceback:\r\nTraceback (most recent call last):\r\n  File \"/home/marten/bazarr/libs/bottle.py\", line 862, in _handle\r\n    return route.call(**args)\r\n  File \"/home/marten/bazarr/libs/bottle.py\", line 1740, in wrapper\r\n    rv = callback(*a, **ka)\r\n  File \"/home/marten/bazarr/bazarr.py\", line 140, in wrapper\r\n    return func(*a, **ka)\r\n  File \"/home/marten/bazarr/bazarr.py\", line 291, in series\r\n    output = template('series', __file__=__file__, bazarr_version=bazarr_version, rows=data, missing_subtitles_list=missing_subtitles_list, total_subtitles_list=total_subtitles_list, languages=languages, missing_count=missing_count, page=page, max_page=max_page, base_url=base_url, single_language=single_language, page_size=page_size)\r\n  File \"/home/marten/bazarr/libs/bottle.py\", line 3619, in template\r\n    return TEMPLATES[tplid].render(kwargs)\r\n  File \"/home/marten/bazarr/libs/bottle.py\", line 3409, in render\r\n    self.execute(stdout, env)\r\n  File \"/home/marten/bazarr/libs/bottle.py\", line 3396, in execute\r\n    eval(self.co, env)\r\n  File \"/home/marten/bazarr/views/series.tpl\", line 75, in <module>\r\n    %if os.path.isdir(row[2]):\r\n  File \"/usr/lib/python2.7/genericpath.py\", line 49, in isdir\r\n    st = os.stat(s)\r\nUnicodeEncodeError: 'ascii' codec can't encode character u'\\xe4' in position 19: ordinal not in range(128)\r\n\r\n**Software (please complete the following information):**\r\n - Bazarr: [116.69.203.115]\r\n - Sonarr version [116.69.203.11552]\r\n - OS: [Debian stretch]\r\n\r\n**Other useful information**\r\nManually installed using git clone https://github.com/morpheus65535/bazarr.git\r\nSeries works fine in sonarr\n Comments: \n Comment 0: Are you able to open bazarr.db in a SQlite editor? I would like to know if the path is stored correctly in `table_shows` table.\n Comment 1: sqlite> select * from table_shows where tvdbid = 353670;\r\n353670|V\u00e4rldens s\u00e4msta indier|/mnt/4TB/tvseries/V\u00e4rldens s\u00e4msta indier|['en', 'ja','sv']|0|19|||/MediaCover/19/fanart.jpg|English|v\u00e4rldens s\u00e4msta indier\n Comment 2: What's the output of `locale -v`?\n Comment 3: LANG=en_US.UTF-8\r\nLANGUAGE=en_US:en\r\nLC_CTYPE=\"en_US.UTF-8\"\r\nLC_NUMERIC=\"en_US.UTF-8\"\r\nLC_TIME=\"en_US.UTF-8\"\r\nLC_COLLATE=\"en_US.UTF-8\"\r\nLC_MONETARY=\"en_US.UTF-8\"\r\nLC_MESSAGES=\"en_US.UTF-8\"\r\nLC_PAPER=\"en_US.UTF-8\"\r\nLC_NAME=\"en_US.UTF-8\"\r\nLC_ADDRESS=\"en_US.UTF-8\"\r\nLC_TELEPHONE=\"en_US.UTF-8\"\r\nLC_MEASUREMENT=\"en_US.UTF-8\"\r\nLC_IDENTIFICATION=\"en_US.UTF-8\"\r\nLC_ALL=\n Comment 4: Are you running behind a separate HTTPD? Is that `locale` output from the exact same shell bazarr runs in?\n Comment 5: Can you try adding `LANG=en_US.UTF8` to `/etc/environment`?\n Comment 6: > Are you running behind a separate HTTPD? Is that `locale` output from the exact same shell bazarr runs in?\r\n\r\nI think you are onto something. I'm starting it from /etc/init.d/bazaar and get this issue. When I start directly from my user it is working correctly.\r\n\r\n**Content of /etc/init.d/bazaar**\r\n### BEGIN INIT INFO\r\n# Provides: Runs a Python script on startup\r\n# Required-Start: BootPython start\r\n# Required-Stop: BootPython stop\r\n# Default-Start:  3 4 5\r\n# Default-stop: 0  6\r\n# Short-Description: Simple script to run python program at boot\r\n# Description: Runs a python program at boot\r\n### END INIT INFO\r\n\r\ncase \"$1\" in\r\nstart)\r\n  echo \"Starting Python\"\r\n  sudo -u bazaarUser python /home/marten/bazarr/bazarr.py\r\n  ;;\r\n\r\n*)\r\n  echo \"Usage: /etc/init.d/bazarr {start}\"\r\n  exit 1\r\n  ;;\r\nesac\r\n\r\nexit 0\r\n\r\n> Can you try adding LANG=en_US.UTF8 to /etc/environment?\r\nThat file is empty for me but I created it, added the line and restarted bazarr with no change.\n Comment 7: Try adding `export LANG=en_US.UTF8` to the init script. \r\nYou could also try to add bash to the sudo call, I think there are multiple ways to fix this. \n Comment 8: `sudo -u user bash -c 'python bazaar.py'` might do the trick, if your default bash environment is properly configured. \n Comment 9: Your comment about same shell made me wonder why sonarr/radarr was working. While waiting to hear back I looked around on my own as well and managed to figure out how to use systemctl to start it instead instead and ran it that way. It seems that makes it run in a shell with correct locale.\r\n\r\n> Try adding `export LANG=en_US.UTF-8` to the init script.\r\n\r\nI found that suggestion on another page and tried it without success.\r\n\r\n**My solution**\r\nedit `/etc/systemd/system/bazaar.service`\r\n\r\nPaste the following (with changes to user, group and path)\r\n```\r\n[Unit]\r\nDescription=bazarr Daemon\r\nAfter=syslog.target network.target\r\n\r\n[Service]\r\nUser=bazarrUser\r\nGroup=bazarrUser\r\nType=simple\r\nExecStart=/usr/bin/python [path-to-bazaar]/bazarr.py\r\nTimeoutStopSec=20\r\nKillMode=process\r\nRestart=on-failure\r\n\r\n[Install]\r\nWantedBy=multi-user.target\r\n\r\n```\r\nThen run `systemctl daemon-reload`\r\nThen run  `sudo systemctl enable bazarr.service`\r\nTo try it run `sudo systemctrl start bazarr.service`\r\n\r\nThank you very much for the help, especially since it was a problem on my end! And thank you for making bazarr!\n Comment 10: That's pretty much what we have on the wiki. :-)\r\nhttps://github.com/morpheus65535/bazarr/wiki/systemd-service-file-for-Debian-Ubuntu\r\n\r\nIt's a pleasure to give you Bazarr.\r\n\r\nThanks to @pannal for the debug session! I'll let you guys close the issue when you'll be ready.\n Comment 11: Eerily similar, I still don't understand why I didn't get it working the first time and went down the init.d road instead. Again, thanks @pannal for the assistance!",
  "Issue title: ReleaseNotes link results in 404\n Issue body: The 1.1 release notes link points to https://go.microsoft.com/fwlink/?LinkID=799421 per https://github.com/dotnet/corefx/issues/8758#issuecomment-221048601, but that link is currently broken.\r\n\r\n@leecow owns this link, can you please update as appropriate.\r\n\r\n/cc @gkhanna79 \n Comments: \n Comment 0: Link target updated to https://github.com/dotnet/core/blob/master/release-notes/1.1/1.1.0-preview1.md.",
  "Issue title: How can i get this (look inside)\n Issue body: So i had a look arround the web and i saw that some people are Streaming on their website ESPN2 for free. With just HLS (.m3u8), their hls looks like this: http://ak-hls-brs-espn2.espn.go.com/hls/live/218615/p/espn2-p.m3u8\r\n\r\nAnd a lot of people can watch it. How is it possible? Also i noticed that i need some \"Keys\". Is this right?\r\n\r\nHere is a screenshot of the website Source code: http://prntscr.com/jr2iuo\r\n\r\nThanks\n Comments: \n Comment 0: They are sharing one ESPN account by rewrite the encryption key path in the M3U8. \r\n\r\nThis is not something that we will support in Streamlink.",
  "Issue title: Add support for multiple containers in ECS task definition\n Issue body: ### Issue Summary:\r\n\r\nAt the moment it is possible to define only one container image with it's options when using ECS.\r\n\r\n### Cloud Provider(s):\r\n\r\nECS\r\n\r\n### Environment:\r\n\r\nAll Spinnaker versions.\r\n\r\n### Feature Area: \r\n\r\nPipeline configurations\r\n\r\n### Description:\r\n\r\nI'd expect to have the possibility of defining multiple container images with their settings instead of just one.\r\n\r\n### Additional Details:\r\n\r\nUse case here: Datadog realtime monitoring of Fargate containers. But the sidecar support in general would be very valuable.\r\n\n Comments: \n Comment 0: This issue hasn't been updated in 45 days, so we are tagging it as'stale'. If you want to remove this label, comment:\n\n> @spinnakerbot remove-label stale\n Comment 1: @spinnakerbot remove-label stale\n Comment 2: Any updates on this issue?\r\nWe are facing the same issue, which makes spinnaker unusable for us at the moment.\r\n\n Comment 3: This issue hasn't been updated in 45 days, so we are tagging it as'stale'. If you want to remove this label, comment:\n\n> @spinnakerbot remove-label stale\n Comment 4: @spinnakerbot remove-label stale\n Comment 5: We've bumped into first performance hiccups while migrating applications from EC2 to Fargate - which means - we've now stopped the migrations to Fargate until this is fixed - as we cannot risk it.\n Comment 6: This issue hasn't been updated in 45 days, so we are tagging it as'stale'. If you want to remove this label, comment:\n\n> @spinnakerbot remove-label stale\n Comment 7: @spinnakerbot remove-label stale",
  "Issue title: closeMenuOnSelect=false doesn't work on mobile chrome\n Issue body: # Are you reporting a bug or runtime error?\r\nBug\r\nhttps://codesandbox.io/s/z6xlovo34?module=/example.js\r\n\r\nI'm not sure if this is intended or not, but the menu doesn't stay open when I use it on my mobile phone.\r\nAndroid, Chrome mobile.\r\n\r\nThank you for this great component, let me know what I can do to help.\n Comments: \n Comment 0: I suspect the fix for this will be similar to the fix for https://github.com/JedWatson/react-select/issues/2577\r\n\r\nhttps://github.com/JedWatson/react-select/pull/2762/commits/69abb3f515a90354d465cdeafba13d42dc1eb094\r\n\r\n\n Comment 1: I tested out the `2.0.0-beta.7` tag and this is still broken in Chrome on touch screen devices (Apple, Android & MS surface).\n Comment 2: After some playing around, I found that setting `blurInputOnSelect={false}` fixed this issue for me. Hope that helps you as well.\n Comment 3: > After some playing around, I found that setting `blurInputOnSelect={false}` fixed this issue for me. Hope that helps you as well.\r\n\r\nThis helps me. I am using matthew26@example.net^. I had an issue in mobile multi-select drop-down. Every time I use to select one item it closes. But in desktop it was working properly. Now after using this method. It is working fantastic. \n Comment 4: FYI; If anyone is looking for solution to this, this is still broken in 3.0.8. Adding `blurInputOnSelect={false}` fixed this for me. Thank you!\n Comment 5: > FYI; If anyone is looking for solution to this, this is still broken in 3.0.8. Adding `blurInputOnSelect={false}` fixed this for me. Thank you!\r\n\r\nI used a customized way:\r\n`constructor(props) {\r\n    \tsuper(props);\r\n\r\n    \tthis.state = {\r\n    \t\tstay_open: false,\r\n    \t\tselected_option_sport: null,\r\n    \t\trecent_changed: false\r\n    \t};\r\n\t}\r\n\r\n_onSelectSport = (value) =>{\r\n\t\tlet stay_open = false;\r\n\t\tif( value!==null && value.length>0 ) stay_open = true;\r\n\t\tthis.setState({selected_option_sport:value,stay_open:stay_open,recent_changed:true}, function () {\r\n\t\t});\r\n\t};\r\n\r\n\t_onSelectSportClose = () =>{\r\n\t\tif( this.state.selected_option_sport==null ) this.setState({stay_open:false});\r\n\t\telse if( this.state.recent_changed ) {\r\n\t\t\tthis.setState({recent_changed:false});\r\n\t\t}\r\n\t\telse this.setState({stay_open:false});\r\n\t};\r\n\r\n<Select\r\n\t\t\t\t\t\t        value={this.state.selected_option_sport}\r\n\t\t\t\t\t\t        onChange={this._onSelectSport}\r\n\t\t\t\t\t\t        isMulti={true}\r\n\t\t\t\t\t\t        options={options_sport}\r\n\t\t\t\t\t\t        placeholder=\"CHOOSE SPORTS\"\r\n\t\t\t\t\t\t        isSearchable={false}\r\n\t\t\t\t\t\t        closeMenuOnSelect={false}\r\n\t\t\t\t\t\t        menuIsOpen={this.state.stay_open}\r\n\t\t\t\t\t\t        onMenuClose={this._onSelectSportClose}\r\n\t\t\t\t\t\t        onMenuOpen={this._onSelectSportOpen}\r\n\t\t\t\t\t\t    />\r\n`\n Comment 6: Hi all,\r\n\r\nThank you everyone who had a part in addressing this question.\r\n\r\nIn an effort to sustain the `react-select` project going forward, we're closing issues that appear to have been resolved via community comments.\r\n\r\nHowever, if you feel this issue is still relevant and you'd like us to review it, or have any suggestions regarding this going forward - please leave a comment and we'll do our best to get back to you!\n Comment 7: It would be nice to address this even though the workaround by @Tecktron works just fine. I've spent a bit of time searching as why it didn't work on mobile, before I came accross this issue. There are also probably some people who didn't even test it and just assumed it worked on mobile, and are still not aware of the bug. \r\n\r\nIf this can't be implemented, we could at least update the docs with this workaround",
  "Issue title: RFC: Changes in Paket Global Tool\n Issue body: ### Problem\r\n\r\nAt the moment we can install Paket as a global.Net Core tool with `dotnet tool install paket -g`. It's really nice delivery strategy consistent with the direction in which whole.Net world is moving and consistent with the tool distribution strategies in many other ecosystems. \r\n\r\nHowever it currently installs particular version of Paket which means \r\n1. You can't pin version of Paket in the repo - it's not respecting Paket version pinning in `paket.dependecies` file\r\n2. You don't get updates if you don't pin Paket - getting updates often was thing in Paket since I started using it - either by old school build scripts calling `paket.bootstrapper.exe` back in the days, or by using Bootstrapper in magic mode nowadays. \r\n\r\nThis is hugely problematic because it's different from the \"normal\" Paket behavior. \r\n\r\n### Proposed Solution\r\n\r\nMy proposal would be distributing Paket.Bootstrapper (in magic mode, called `paket`) instead of Paket as a global tool. \r\nThis would solve per-repo versioning problem we have right now - Bootstrapper in magic mode is either respecting pinning in `paket.dependencies` files or getting latest version. In such case updates of the Paket.Net Tool (`dotnet tool update paket -g`) would be necessary only when we have Bootstrapper update (which is not as often as Paket update)\r\n\r\n### Work plan\r\n\r\n- [ ] Update Bootstrapper to.Net Core, pack as tool (Partially already done - https://github.com/fsprojects/Paket/blob/master/src/Paket.Bootstrapper.preview3/Paket.Bootstrapper.csproj)\r\n - [ ] Distribute Bootstrapper on Core as a Global Tool called `paket` (due to behavior of the Bootstrapper Magic Mode this **shouldn't** be a breaking change for users)\r\n - [ ] Update documentation to make Bootstrapper on Core as Global Tool suggested way to use Paket - I personally think it's step forward from current state, will ensure that Paket is working \"as expected\" in modern.Net ecosystem. Pushing global tools seems to be working well for FAKE too.\r\n - [ ] Make some developer advocacy effort (blog post, talks on the conferences, etc) to promote this new way of distributing Paket. As shown by some recent twitter conversations people don't even know about Magic Mode and it's been introduced years ago.\r\n\r\nCC: @forki @isaacabraham @baronfel @vbfox @enricosada \n Comments: \n Comment 0: Shouldn't we just wait for SDK v3 which apparently introduces repro-local tools or something like that?\r\n\r\nWould the bootstrapper download the mono/framework dependent tool as today? -> You still need mono/Windows?\r\nIf not which version of paket does it download and run?\r\nIf \"portable\", how does the bootstrapper find a `dotnet` runtime, and which version should we take?\n Comment 1: > Shouldn't we just wait for SDK v3 which apparently introduces repro-local tools or something like that?\r\n\r\nI think current proposal for repo-local tools has its own problems but, TBF, I think it's orthogonal issue - I'm worried about people using/wanting to use global installation and having bad behavior. \r\n\r\n> Would the bootstrapper download the mono/framework dependent tool as today? If not which version of paket does it download and run?\r\n\r\nI think we should download Core version of Paket (something something \"Core is new.Net Framework\"). Latest or pinned, just like magic mode bootstrapper does it nowadays.\r\n\r\n> how does the bootstrapper find a dotnet runtime, and which version should we take?\r\n\r\nWe probably could use the same version of dotnet runtime that bootstrapper is running on, I guess we should be able to get this information (?)\n Comment 2: > We probably could use the same version of dotnet runtime that bootstrapper is running on, I guess we should be able to get this information (?)\r\n\r\nyou also have the CWD of the user when they would run `paket` globally, and the bootstrapper should invoke `dotnet paket` from that directory so that the user's configured.net sdk preferences are adhered to.\n Comment 3: Ok let's do this!\n Comment 4: On a build server, I have some concerns with the global tool. It may run different jobs, requiring different versions of paket.  Honestly, I'm quite happy with the isolated, self-contained nature of the local paket. Allowing different versions of the.NET-Runtime in parallel as well as self-contained application deployment is also a huge benefit of.NET Core.\r\n\r\nRegarding the two problems pointed out in this issues description:\r\n> 1. You can't pin version of Paket in the repo - it's not respecting Paket version pinning in paket.dependecies file\r\n> 2. You don't get updates if you don't pin Paket - getting updates often was thing in Paket since I started using it - either by old school build scripts calling paket.bootstrapper.exe back in the days, or by using Bootstrapper in magic mode nowadays.\r\n\r\nI'd like to propose a different approach:\r\n1. stay with the local `.paket` dir, containing the `paket` executable.\r\n2. using the `paket.bootstrapper.proj` approach from @enricosada (see #3183), simplified in that it `dotnet tool install paket --tool-path.` directly, instead of installing the bootstrapper. You don't need to check any executable into your repo any more, just the msbuild files.\r\n3. Update http://fsprojects.github.io/Paket/paket-and-dotnet-cli.html to promote `paket.bootstrapper.proj` instead of `paket.bootstrapper.exe`/magic mode, as the later requires mono on Linux. This again prevents you from using Microsoft's NetSdk-docker images out of the box.\r\n\r\nThe first issue, of not being able to pin paket's version *within* the repo is addressed: Use a `paket.bootstrapper.props` instead of `paket.bootstrapper.exe.config`. Reading from paket.dependencies from msbuild should be possible, too, but I haven't look into it.  \r\nThe second issue that comes from the global tool, not getting updates unless pinning paket's version, is addressed to: Just don't use a `paket.bootstrapper.props` (or at least, don't set the paket version in it) and each time no `paket` executable is present, the latest version with be downloaded during `dotnet restore`. For the local project only, i.e. not interfering with anything else on the system.\r\n\r\nI have such a setup running on a mixed Windows/Linux environment and I'm quite happy with it.\r\n - No global setups upfornt\r\n - Isolated settings per repo/project\r\n - Usable from Windows Worksations as well as Linux build agents, using vanilla.NET SDK docker images,\r\n - usable with private/internal nuget feeds from machines without internet access\r\n - one `dotnet build` to rule them all\r\n\r\nI can prepare a PR with my bootstrapper.exe-free variant of `paket.bootstrapper.proj` (just tell me where to place it; needs to become an additional release artifact, too) and updates to the above mentioned docs (this is what #3516 is all about, right?)\n Comment 5: Now that local tools have arrived and work reasonably well, I think we should get rid of the bootstrapper and if anything make Paket update/edit the manifest version.\r\nIs there really any need to keep the bootstrapper?\n Comment 6: 1. As far as I know they don't provide always update ('*' version) mode that bootstrapper does when used without pinning\r\n2. They're not using pinning from `paket.dependencies` file which is obviously better than some random json file created by MSFT... and is breaking change for many users \n Comment 7: > As far as I know they don't provide always update ('*' version) mode that bootstrapper does when used without pinning\r\n\r\nUsers should get into the habbit of pinning the version anyway. We cannot keep telling people to use a lockfile and then use a floating version in paket.\r\n\r\n> They're not using pinning from `paket.dependencies` file which is obviously better than some random json file created by MSFT... and is breaking change for many users\r\n\r\nIt isn't breaking, we'd just change the recommendation at this point. The rest is not really an argument. Can you say \"why\" having a 'common'/standardized way to add dotnet based tools to your repository is a bad thing? Or \"why\" we should continue investing time building our own?\r\n\r\nHaving the version in the deps file was imho always a \"hacky\" way",
  "Issue title: BackgroundImageDesignable not working\n Issue body: I wanted to go ahead by adding `BackgroundImageDesignable`, but when reading the code, something seems off to me: we create a view, but we don't add / remove it anywhere. So, I tried it (in case I missed something), but it didn't work (normal or bad usage?). Is that expected @phimage?\r\n\r\nAlso, while writing the documentation, I started to wondering why is `BackgroundDesignable` necessary? It's just adding an `UIView` for the `BackgroundImageDesignable`, so why not letting `BackgroundImageDesignable` that view itself?\r\n\r\nNote for the future PRs, I think (wasn't thinking that before) we should definitely not merge before finalising completely the feature (example, docs, changelog...), otherwise, we are just adding complexity for maintening and have incoherent / incomplete docs / examples. That said, even if it's in the same PR, we can help each other by working on the same branch!\n Comments: \n Comment 0: The function to add or remove image view is call in `didSet` of image view fields\r\n(like refresh control, that could be too soon if apple do not allow to play with view hierarchy when affecting attributes)\r\n\r\nI am testing now on demo app for table cell \r\n- I go into demo app scene with 4 statics cells (Work, Food,..) \r\n- remove the ImageViews, children of Content View\r\n- I go to the table cell view and choose a backgroud view\r\n- run the simulator and it seems ok\r\n\r\nI will do a test with table too\r\n\r\n`BackgroundDesignable` allow to conform to other needs on background view of table and collection views. `BackgroundImageDesignable` is one of them but we could imagine others.\r\n\r\nJakeLin comment on it in https://github.com/IBAnimatable/IBAnimatable/pull/416 \"It took me a while to understand this...\"\n Comment 1: I will test this again following your instruction, I may miss one. Thanks fort he explanation!\r\n\r\nIt would be interesting to comment the `BackgroundDesignable` since it's not straightforward to understand.",
  "Issue title: Include IPFS Companion and Google Translate views in main Countly dashboard\n Issue body: Right now, the main Countly dashboard only captures visits from the domain proto.school, and other domains get logged in the test dashboard. The original intention of this was to ensure that developers using localhost, Fleek or Netlify previews, etc., could play around without affecting the real data. However, we're now finding activity in the test dashboard that doesn't appear to be from devs, suggesting that we should add at least two more domains to the main dashboard: \r\n\r\n- the domain used by folks visiting via IPFS Companion (need to confirm this will always be consistent)\r\n- the domain used by folks visiting with Google Translate turned on (discovered this use case because we're seeing `/translate_c` in page views)\n Comments: \n Comment 0: @lidel As our resident IPFS Companion and localization expert, you might be able to help us confirm... \r\n- Will the domain used by folks visiting ProtoSchool via IPFS Companion always be consistent (ie no CID as part of it that's always changing, etc.) \r\n- Do you know of any translation services other than Google Translate that would use a different domain to serve up our content? \n Comment 1: Regarding the domain of IPFS Companion users, those usually run local gateway on local port that can be changed. I would look for these patterns:\r\n- `http://*.ipfs.localhost:*/`\r\n  - Someone loaded a static snapshot of the website from a local gateway (CID before `.ipfs.` was changing).\r\n    (This happened for a while until Fleek removed X-Ipfs-Path header)\r\n- `http://proto.school.ipns.localhost:*/`\r\n  - Someone loaded the website from a local gateway at the time when DNSLink was enabled\r\n    (I think this happened for a while, and is something we want to support in the future)\r\n\r\n\r\nAs for translation websites, most likely all of them do this, but targeting the biggest players should cover the most of uses:\r\n- **Bing** delegates translation to URLs like https://www.translatetheweb.com/?ref=TVert&from=&to=zh-Hans&a=https%3A%2F%2Fproto.school%2F\r\n- **Yandex** is even more bizzare:\r\n  - https://translate.yandex.com/translate embedds iframe which is loaded from URL that looks like this: https://z5h64q92x9.net/proxy_u/en-zh.en/https/proto.school/\r\n- **Baidu**\r\n  - https://fanyi.baidu.com well.. I tried but failed \u00af\\_(\u30c4)_/\u00af\r\n  - unsure if it supports full-page translation, but worth looking into due to the size of our community in Asia (perhaps ask folks what is the most popular English-to-Chinese-Simplified translator they use)",
  "Issue title: Reload with an ecosystem config, parallel param invalid\n Issue body: <!--\r\nYour issue may already be reported!\r\nPlease search on the [issue tracker](https://github.com/Unitech/pm2/search?type=Issues) before creating one.\r\n-->\r\n\r\n## What's going wrong?\r\n\r\nWhen I reload a [app name] with `parallel`, it works like a charm. But if I put app to an ecosystem.config.json, the `parallel` param seems don't work.\r\n\r\n## How could we reproduce this issue?\r\n\r\n```js\r\n// ecosystem.config.json\r\n{\r\n  \"apps\": [\r\n    {\r\n      \"name\": \"master\",\r\n      \"script\": \".index.js\",\r\n      \"instances\": \"12\",\r\n      \"exec_mode\": \"cluster\",\r\n      \"wait_ready\": true,\r\n      \"kill_timeout\": 7200000\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nFirst, start a app using `pm2 start ecosystem.config.json`.\r\nSecond, reload it using `pm2 reload ecosystem.config.json --parallel=12`\r\n\r\nIt will reload 2 processes each time, other than reload all processes once.\r\n\r\n## Supporting information\r\n\r\n<!--\r\nPlease run the following command (available on PM2 >= 2.6)\r\n-->\r\n```\r\n$ pm2 report\r\n```\r\n\n Comments: \n Comment 0: This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n",
  "Issue title: Problems view filter box overflows header in panel\n Issue body: Two different themes shows the issue:\r\n\r\n![image](https://user-images.githubusercontent.com/22350/81085581-ac7a8b80-8ef7-11ea-93c2-9603c271cc00.png)\r\n\r\n![image](https://user-images.githubusercontent.com/22350/81085587-aedce580-8ef7-11ea-91e2-10470c2891e2.png)\r\n\n Comments: \n Comment 0: Duplicate of #96726\r\nAlso created #97438 that fixes it",
  "Issue title: allow constants for string literals types\n Issue body: ```typescript\r\nconst vow = 'will never change';\r\nlet promise: vow;\r\n```\n Comments: \n Comment 0: We can't do this since it would be a breaking change -- `vow` has not previously introduced an entry in the type namespace, so doing so now would mean random types would start getting shadowed.\r\n\r\n`typeof vow` should do what you want here (if we made `const`s be of their string literal type  @DanielRosenwasser please confirm?).\n Comment 1: > typeof vow should do what you want here (if we made consts be of their string literal type\r\n\r\nin the expression context `typeof vow` gets me `\"string\"`\r\nin the type expression context it gets me \"will never change\", but it's a **type** which I cannot assign to a variable\n Comment 2: Like @RyanCavanaugh said, in order to do `typeof vow`, you'd need #5796. That said, I don't know if that PR will go in. The behavior isn't entirely ideal because it's not clear when you want the literal type and not `string`.\n Comment 3: Here is the proposal: https://github.com/Microsoft/TypeScript/issues/6167#issuecomment-171455369\n Comment 4: What about allowing interpolated strings as string literal types.  So:\r\n```\r\nconst vow = \"will never change\";\r\nlet promise: `${vow}`;\r\n```\n Comment 5: The issue in the OP should be fixed by https://github.com/Microsoft/TypeScript/pull/10676\r\n\r\nAllowing string interpolation, or any form of string manipulation in type positions is not something we are looking to allow.\r\n\r\nfor this specific example, use `typeof` operator, e.g. `let promise: typeof vow;`  and this should be `\"will never change\"`.\n Comment 6: @aleksey-bykov do you agree this proposal is covered by #10676 and `typeof`?\n Comment 7: yes, it's solved, please clise",
  "Issue title: Sysinfo freezes the ESP8266 (Wemos D1)\n Issue body: If I integrate the plugin \"Generic - System Info\" and set WiFi RSSI, the ESP stops responding.\r\n\r\nGreetings Peter\n Comments: \n Comment 0: Can you give a bit more information?\r\nLike build version and perhaps also some screenshots of the settings?\r\nI have a similar setup here, with the Wemos D1, and WiFi RSSI and it is working fine.\r\n\r\nMake sure you don't set the Delay value too low. (default = 60)\n Comment 1:![esp-207-config_01](https://user-images.githubusercontent.com/2838584/35523160-7dc6d812-051e-11e8-9ab2-a5ebb4d0c10b.jpg)\r\n![esp-207-config_02](https://user-images.githubusercontent.com/2838584/35523161-7de5a7ce-051e-11e8-93ed-7746f4a8de5a.jpg)\r\n![esp-207-config_03](https://user-images.githubusercontent.com/2838584/35523163-7e01c788-051e-11e8-86ee-e4645dc0ffb8.jpg)\r\n\r\nHi,\r\n\r\nDelay ist 60. Software is always the newest Trunk from Github, Core 2.4.0\r\n\r\nMy Rules are:\r\n\r\n// ----- ESP-207 Ki\r\nOn System#Boot do    //When the ESP boots, do\r\n\tPublish %sysname%/IP,%ip%\r\n\ttimerSet,1,60      //Set Timer 1 for the next event in 60 seconds\r\n\ttimerSet,2,20\r\nendon\r\n\r\nOn Rules#Timer=1 do  //When Timer1 expires, do\r\n\tPublish %sysname%/IP,%ip%\r\n\tPublish %sysname%/Time,%systime%\r\n\tPublish %sysname%/Uptime,%uptime%\r\n\ttimerSet,1,60       //Resets the Timer 1 for another 60 seconds\r\nendon\r\n// -----\r\n\r\non Motion#Pir>0 do\r\n\tIf %systime% > 08:00:00  // nur tagsueber anzeigen\r\n\t\tIf %systime% < 20:00:00 \t\r\n\t\t\tgpio,14,1  // Led2 pink ON\r\n\t\tendif\t\r\n\tendif\t\r\nendon\r\n\r\non Motion#Pir=0 do\r\n     gpio,14,0  // Led2 pink OFF\r\nendon\r\n// -----\r\n\r\nOn MH-Z19#PPM<700 do\r\n    NeoPixelAll,0,50,0,0  // gruen\r\nendon\r\n\t \r\nOn MH-Z19#PPM>700 do\r\n\tif [MH-Z19#PPM]<1200\r\n\t\tNeoPixelAll,50,50,0,0 // gelb\r\n\telse \r\n\t\tNeoPixelAll,50,0,0,0 // rot\r\n\tendif \r\nendon\t\r\n// -----\n Comment 2: We haven't tested with 2.4.0 core lib.\r\nCan you also check with a build using 2.3.0?\r\nSee definitions in PlatformIO.ini with platform set to:\r\n`platform = lutzsarah@example.com`\r\n\r\nAdding %rssi% isn't such a bad idea, since it can be used in a lot of other use cases and using a Task/Plugin for it is maybe a bit overkill.\n Comment 3: Gijs, i use Arduino and all my other Projects are Core 2.40.\r\nI do not want to go backwards.\r\n\r\nI hope you can install the %rssi% parameter.  :)\r\n\r\nPeter\r\n\n Comment 4: Can you check it?\r\nIt is only one line of code as can be seen in the PR.\n Comment 5: Yes - it woks!\r\nMany thanks.\r\n\r\n20:12:01 ESP-212/status Connection Lost\r\n20:12:01 ESP-212/status Connected\r\n20:12:02 ESP-212/IP 116.69.203.115\r\n20:13:02 ESP-212/Time 20:13:01\r\n20:13:02 ESP-212/Uptime 1\r\n20:13:02 ESP-212/RSSI -69\n Comment 6: Just as a note if someone ever stumbles upon this.\r\nI have still no idea why the ESP froze  when adding the SystemInfo plugin.",
  "Issue title: Replace \"PodCount\" with a generic \"Count\" dynamic UI widget\n Issue body: Wondering if it would make sense/be easy to decouple the podCount widget to a generic count widget where we get the same behavior but without the implicit object type (\"pods\"). Not a huge change on the face of things, but might be more complicated under the hood, so figured I'd ask. \r\n\r\n\n Comments: \n Comment 0: Issues go stale after 90d of inactivity.\n\nMark the issue as fresh by commenting `/remove-lifecycle stale`.\nStale issues rot after an additional 30d of inactivity and eventually close.\nExclude this issue from closing by commenting `/lifecycle frozen`.\n\nIf this issue is safe to close now please do so with `/close`.\n\n/lifecycle stale\n Comment 1: Stale issues rot after 30d of inactivity.\n\nMark the issue as fresh by commenting `/remove-lifecycle rotten`.\nRotten issues close after an additional 30d of inactivity.\nExclude this issue from closing by commenting `/lifecycle frozen`.\n\nIf this issue is safe to close now please do so with `/close`.\n\n/lifecycle rotten\n/remove-lifecycle stale\n Comment 2: Rotten issues close after 30d of inactivity.\n\nReopen the issue by commenting `/reopen`.\nMark the issue as fresh by commenting `/remove-lifecycle rotten`.\nExclude this issue from closing again by commenting `/lifecycle frozen`.\n\n/close\n Comment 3: @openshift-bot: Closing this issue.\n\n<details>\n\nIn response to [this](https://github.com/openshift/console/issues/3362#issuecomment-731589769):\n\n>Rotten issues close after 30d of inactivity.\n>\n>Reopen the issue by commenting `/reopen`.\n>Mark the issue as fresh by commenting `/remove-lifecycle rotten`.\n>Exclude this issue from closing again by commenting `/lifecycle frozen`.\n>\n>/close\n\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>",
  "Issue title: Unable to hand in quest\n Issue body: Hi,\r\n\r\nI completed the quest \"Doctor Theolen Krastinov, the Butcher\" from \"Eva Sarkhoff\" outside Scholomance, but not able to hand it in.\r\n\r\nWhen speaking to NPC, she only tells the pre-story, after that nothing happens.\r\nI've deleted WDB and WTF folder, same issue.\r\nTried abandon quest and take it again, but now I'm not even to pick up the quest, only listen to the story.\r\n\r\nCould you please help me out?\r\nThanks in advance!\r\n\r\nVandacke\r\nWarsong\n Comments: \n Comment 0: That sounds like a server issue to me, nothing that has to do with ccox@example.net. Can you turn in the Quest, when Questie is turned off?\n Comment 1: No.\r\n\r\nI'll report to server.\r\n\r\nThank you!",
  "Issue title: [Bug] \"Add From Gallery\" no longer visible on Amazon Build Flavor\n Issue body: Cause: 6d68424cd48ab0a702da949bd49a70eeb05f0dfd\r\n\r\nEven though we can't use the camera, we can still use the gallery, which is contained in the \"Add Image\" screen\r\n\r\nThe \"add image\" permission is requested:\r\n\r\nhttps://github.com/ankidroid/Anki-Android/blob/c84cf4b151cfe460fd820d4cdf90c5daec4f43e1/AnkiDroid/src/main/java/com/ichi2/anki/NoteEditor.java#L1566-L1570\n Comments: \n Comment 0: Cause: 6d68424cd48ab0a702da949bd49a70eeb05f0dfd\r\n\r\nEven though we can't use the camera, we can still use the gallery.\n Comment 1: so, i understand that \"add image\" must be visible, but what do you exactly want?\r\nobviously, if I comment these lines, add image will work properly(without a camera)\r\nwould you please give some hints?\n Comment 2: The permission check should be removed from that spot and put into a more specific spot.\r\n\r\nIt appears that for amazon builds (that is, if camera permission is not in the android manifest), this view should not be added https://github.com/ankidroid/Anki-Android/blob/39a226842004e9f329304bd227fee9bace7d5f37/AnkiDroid/src/main/java/com/ichi2/anki/multimediacard/fields/BasicImageFieldController.java#L183\r\n\r\nAnd the permission check for camera here should be avoided https://github.com/ankidroid/Anki-Android/blob/39a226842004e9f329304bd227fee9bace7d5f37/AnkiDroid/src/main/java/com/ichi2/anki/multimediacard/activity/MultimediaEditFieldActivity.java#L146-L152\r\n\n Comment 3: I'm willing to work on this!\n Comment 4: @huenical I just reviewed the PR and it looks pretty good pending test results, in general it appears that @yasin459 was working on this already and you did not wait to see their response or any one else's response. Your solution appears good but by jumping in front of @yasin459 the collaboration is a little bit lacking. In the absence of confirmation that an issue really has no pending effort, please look for issues that are *definitely* not taken up by people so we don't duplicate effort unnecessarily, there is certainly plenty to do :-)\n Comment 5: Thank you for pointing this out.\r\nSorry for any inconvenience caused @yasin459 ",
  "Issue title: sed error when loading.bashrc\n Issue body: I installed bash_it follow the instruction. When I run source ~/.bashrc, there may be some error in sed. and I get:\n\n\u25cb \u2192 source ~/.bashrc\nsed: invalid option -- E\nUsage: sed [OPTION]... {script-only-if-no-other-script} [input-file]...\n\n  -n, --quiet, --silent\n                 suppress automatic printing of pattern space\n  -e script, --expression=script\n                 add the script to the commands to be executed\n  -f script-file, --file=script-file\n                 add the contents of script-file to the commands to be executed\n  -i[SUFFIX], --in-place[=SUFFIX]\n                 edit files in place (makes backup if extension supplied)\n  -c, --copy\n                 use copy instead of rename when shuffling files in -i mode\n                 (avoids change of input file ownership)\n  -l N, --line-length=N\n                 specify the desired line-wrap length for the `l' command\n  --posix\n                 disable all GNU extensions.\n  -r, --regexp-extended\n                 use extended regular expressions in the script.\n  -s, --separate\n                 consider files as separate rather than as a single continuous\n                 long stream.\n  -u, --unbuffered\n                 load minimal amounts of data from the input files and flush\n                 the output buffers more often\n      --help     display this help and exit\n      --version  output version information and exit\n\nIf no -e, --expression, -f, or --file option is given, then the first\nnon-option argument is taken as the sed script to interpret.  All\nremaining arguments are names of input files; if no input files are\nspecified, then the standard input is read.\n\nE-mail bug reports to: vsingh@example.net.\nBe sure to include the word `sed'' somewhere in the`Subject:'' field.\n\n Comments: \n Comment 0: Which OS and which version of `sed` are you running? Bash-it contains a couple of instances where `sed` is used with the `-E` option for extended regex syntax. Looks like you have a version of `sed` that does not support `-E`.\n Comment 1: The `-E` flag is only available in the OSX sed version (BSD), the GNU sed equivalent is `-r`.\n Comment 2: Oh great! Is there a cross-OS way of handling this?\n Comment 3: As far I know, the \"usual\" solution is:\r\n\r\n```\r\ncase $OSTYPE in\r\n  darwin*)\r\n    # OSX specific code\r\n    ;;\r\n  *)\r\n    # Other OS, GNU/Linux (commonly)\r\n    ;;\r\nesac\r\n```\r\n\r\nI have done a \"quick\" search, and there are some places where this \"issue\" need to be managed.\r\n\r\nI will try to fix it.\n Comment 4: I use\r\nsed (GNU sed) 4.2.2\r\nRed Hat 4.1.2-50\n Comment 5: @edubxb Here's an idea on how to make this less invasive: How about doing the check for the OS only once, e.g. in `lib/helpers.bash` and then setting an environment variable there, e.g. \r\n\r\n```bash\r\ncase $OSTYPE in\r\n  darwin*)\r\n    # OSX specific code\r\n    BASH_IT_SED_EXTREGEX=\"-E\"\r\n    ;;\r\n  *)\r\n    # Other OS, GNU/Linux (commonly)\r\n    BASH_IT_SED_EXTREGEX=\"-r\"\r\n    ;;\r\nesac\r\n```\r\n\r\nand then wherever we use `sed`, we use this variable, e.g.\r\n\r\n```\r\nsed $BASH_IT_SED_EXTREGEX...\r\n```\r\n\r\nThis will be less invasive than having the check several times.\r\n\r\nBTW: Here's a nice way of detecting whether `sed` supports the `-E` flag without testing simply for the OS (e.g. in case someone has installed the GNU version of `sed` on OS X): https://developer.apple.com/library/mac/documentation/OpenSource/Conceptual/ShellScripting/PortingScriptstoMacOSX/PortingScriptstoMacOSX.html - scroll down to the `sed` heading:\r\n\r\n```bash\r\nSTRING=\"$(echo 'xy' | sed -E's/(x)y/\\1/' 2> /dev/null)\"\r\nif [ \"$STRING\" = \"x\" ] ; then\r\n    SEDERE=\"-E\"\r\nelse\r\n    SEDERE=\"-r\"\r\nfi\r\n...\r\nsed $SEDERE...\r\n```\r\n\r\nHow about using that?\n Comment 6: Like the idea! :+1: \n\n Comment 7: About this issue, I found that need to be fixed in these places:\r\n\r\n```\r\ncompletion/available/gh.completion.bash:326:    sed -E's#^remote\\.([^.]+)\\.url +.+[:/](([^/]+)/[^.]+)(\\.git)?$#'\"$format\"'#'\r\ncompletion/available/hub.completion.bash:323:    sed -E's#^remote\\.([^.]+)\\.url +.+[:/](([^/]+)/[^.]+)(\\.git)?$#'\"$format\"'#'\r\nplugins/available/alias-completion.plugin.bash:25:    eval \"local completions=($(complete -p | sed -Ene \"/$compl_regex/s//'\\3'/p\"))\"\r\nplugins/available/alias-completion.plugin.bash:32:    local completion_loader; completion_loader=\"$(complete -p -D 2>/dev/null | sed -Ene's/.* -F ([^ ]*).*/\\1/p')\"\r\nplugins/available/alias-completion.plugin.bash:80:    done < <(alias -p | sed -Ene \"s/$alias_regex/\\1 '\\2' '\\3'/p\")\r\n```\r\n\r\nFor the gh and hub completion, IMO, the fix need to be done in the upstream versions, and we only need to update it when the correction is ready, and only in the alias completion the fix will be made by us.\n Comment 8: Wow, just discovered that the `-E` flag is POSIX and silently supported in GNU sed (I dived a bit into [sed code](http://git.savannah.gnu.org/cgit/sed.git/tree/sed/sed.c#n313), also mentioned in a [Changelog file](http://git.savannah.gnu.org/cgit/sed.git/tree/ChangeLog-2014#n47)).\n\nSo the problem is other, please @maplewizard, can you provide more info about your Bash-it settings to help us to reproduce it?\n\nThanks!\n\n Comment 9: Are there GNU `sed` versions that don't support `-E`? Looks like @maplewizard has one of those...\n\n Comment 10: jep. sed (GNU sed) 4.2.2 on debian jessie doesn't support it.\r\n\n Comment 11: Just tested in a vagrant box with Debian Jessie, and the flag -E works.\n\n Comment 12: yes. you are right. i didn't tetst it. sed --help and the manpage of sed doesn't mention the option. but it works for me, too. sorry.\n Comment 13: Yes, this is the reason I looked up in sed source code :stuck_out_tongue_winking_eye: \n Comment 14: @maplewizard we need more information to help you, can you please provide the following:\r\n\r\n- plugins, completions and aliases activated in Bash-it\r\n- your bash config\r\n\r\nThanks!\n Comment 15: I'm use \nCentOS release 5.11 (Final)\nsed version 4.1.5                  June 2006\n\nThe same error. sed does not support `-E` option.\n\n Comment 16: The sed version that comes installed with Centos 5 don't support the `-E` flag.\n Comment 17: @edubxb I see.\nBut, I cannot change the version of OS and install softwares myself(No permission).\nSo, what you mean is, I've no way to use Bash-it, am I right?\n\n Comment 18: Hey, guys,\r\n\r\nI tried fixed this problem myself.\r\n\r\n`cd.bash_it/`\r\n\r\n`find. -name \"*.bash\" -type f | xargs sed -i \"/sed -E/ s/sed -E/sed -r/g\"`\r\n\r\nI replaced all `sed -E` with `sed -r` through above commands.\n Comment 19: This will not work, since the default `sed` tool on Mac OS X does not support the `-r` flag. Your change might have fixed it for Linux/Gnu versions, but broke it for Mac OS X users.\n Comment 20: We had the same issue on SUSE Linux 11 64-",
  "Issue title: Edit channel/playlist url\n Issue body: Hi,\r\n\r\nI've tens of channels and I want to edit channel/playlist url but ui doesn't accept this behavior. \r\nMay you please enable editing channel/playlist url\r\n\r\nSide question:\r\nWhat's the type of TT database? I suppose it's not SQLite, is it true?\n Comments: \n Comment 0: The Tartube database file is created by the [python pickle module](https://docs.python.org/2/library/pickle.html), so it's not SQLite or anything like that.\n Comment 1: Changing the URL of channels/playlists was added in v2.1.051.\n Comment 2: > The Tartube database file is created by the [python pickle module](https://docs.python.org/2/library/pickle.html), so it's not SQLite or anything like that.\r\n\r\nI don't know what's the reason of using this module but I find it not a good/safe choice. SQL much better for modifying the options (in my case I want to modify many links) and much safer in case of crashing (my TT database corrupted many time and I'm sure if you used SQL it's nearly impossible to corrupt)\n Comment 3: > Changing the URL of channels/playlists was added in v2.1.051.\r\n\r\nThanks a lot\n Comment 4: >I don't know what's the reason of using this module but I find it not a good/safe choice. SQL much better for modifying the options (in my case I want to modify many links) and much safer in case of crashing (my TT database corrupted many time and I'm sure if you used SQL it's nearly impossible to corrupt)\r\n\r\nI describe a \"Tartube database\", but it's not really a database. It's just a collection of data stored as dictionaries/associative arrays. Pickle is the standard python module for loading/saving this kind of data.\r\n\r\nAbout SQL, I have nothing but bad experiences with it. I haven't experienced the TT database corruption you describe. You can create a new Github issue for that, if you like. \n Comment 5: > You can create a new Github issue for that, if you like.\r\nUnfortunately this issue is frequently occurs the bad thing I couldn't catch how this occurs to be able to create a ticket for it!\n Comment 6: Go ahead and create a ticket. Until now, it was not worth adding support for SQL. But if Tartube crashes a lot, while saving the database, then that's a good reason to add SQL support.",
  "Issue title: Tutorial Services and Utilities: Unit Tests Don't Pass for location-map\n Issue body: In the beginning of the [Fetching Maps With a Service](https://guides.emberjs.com/v2.6.0/tutorial/service/#toc_fetching-maps-with-a-service) section, the tutorial mentions that \"Now we have a passing component integration test\" we can continue on.  The test for this component isn't working for me, even after I copy and paste the test code and component code to ensure accuracy.  All of my other tests are passing.\r\n\r\nGiven that I'm new to Ember, I don't know how to correct this. I don't know anything about services (or mock services).\r\n\r\nFor reference, you can check out my current place in the tutorial at my [github project](https://github.com/ryanolsonx/super-rentals) for it or for this section of the tutorial, [this commit](https://github.com/ryanolsonx/super-rentals/commit/d1fad1bd6ee3ee670ce5b36bdd97c21311ad5a1b) that I made with the changes listed in this section.\n Comments: \n Comment 0: Can you paste the message of the failing test please?\n Comment 1: Sorry, I meant to add that.. here it is: \r\n\r\n> Global error: TypeError: undefined is not an object (evaluating 'this.get('maps'\r\n> ).getMapElement') at http://localhost:7357/assets/super-rentals.js, line 69\n Comment 2: @ryanolsonx the tutorial is in github at https://github.com/emberjs/super-rentals and all tests pass.  Hopefully that can give you some insight into what's going wrong.\n Comment 3: I'll also try to see if there's a discrepancy between the github repo and guides\n Comment 4: The failing test is the acceptance test. That test is fixed later in the section [Stubbing services in acceptance tests](https://guides.emberjs.com/v2.6.0/tutorial/service/#toc_stubbing-services-in-acceptance-tests).\r\n\r\nThe paragraph you link states:\r\n\r\n> Now we have a passing component integration test, but no maps showing up when we view our web page.\r\n\r\nBut does not say that the acceptance test now is failing. Maybe adding a few words about it would make it clearer. What do you think, @toddjordan, @locks?\n Comment 5: Thanks @Serabe!  Yeah I'm for clarifying there.  We can keep this issue open to track making this clearer.\n Comment 6: OK this makes sense. Thanks for looking into this @Serabe. It just really confused me and I would imagine that it could confuse others as well.  I think that it would make things much more clear to mention that our other test will be failing now.\n Comment 7: closing as fixed...",
  "Issue title: not found vpcs on gns3\n Issue body: Hi, Void community..\r\n\r\nhttps://i.imgur.com/ILqYjjL.png; In this image, vpcs not worked on gns3 after I had installed gns3-server gns3-gui putty dynamips ubridge vpcs.\r\n\r\nmy mail: smithjason@example.org\r\n\n Comments: \n Comment 0: @tsndqst could you take a look?\n Comment 1: @ericonr @xlwyx I can take a look but I can't focus on this until this evening.\r\n\r\n@xlwyx Is this a new install or did you upgrade from an earlier version?\n Comment 2:  \u00a0Is new instalation and vpcs not found on /bin/vpcs. But, with Void terminal start, vpcs well. Into gns3 not worked\n\n    On Monday, 17 May 2021, 07:57:39 GMT-5, Tim Sandquist ***@***.***> wrote:  \n \n \n\n\n@ericonr @xlwyx I can take a look but I can't focus on this until this evening.\n\n@xlwyx Is this a new install or did you upgrade from an earlier version?\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or unsubscribe.\n  \n Comment 3: vpcs is a separate package from gns3-server.  Try installing it with `xbps-install -Su vpcs`.\n Comment 4: Sorry @xlwyx, I just reread your original comment and I see you did install vpcs.  I am looking into this more now.\r\nAre there logs that you can share?  gns3-server logs to stdout I believe.  In the project directory there should be logs for vpcs and ubridge in `~/GNS3/projects/untitled/project-files/vpcs`.\n Comment 5: On Mon, May 17, 2021 at 18:24, Tim Sandquist ***@***.***> \nwrote:\n> \u2014\nYesss..  on \n~/GNS3/projects/untitled/project-files/vpcs/556163df-8f50-437e-95cd-11cfe6acedd0/ \nshow me one log.\nYou can do help me...?\nHow to do I solve it...?\nI use AgarimOS (Void Linux derivated) and my AgarimOS is updated.\n\n\n Comment 6: See it: <https://i.imgur.com/ZpCpvz3.png>;  \n<https://i.imgur.com/zNVbvPV.png>\n\nOn Mon, May 17, 2021 at 22:47, tuxito ***@***.***> wrote:\n> On Mon, May 17, 2021 at 18:24, Tim Sandquist \n> ***@***.***> wrote:\n>> \u2014\n> Yesss..  on \n> ~/GNS3/projects/untitled/project-files/vpcs/556163df-8f50-437e-95cd-11cfe6acedd0/ \n> show me one log.\n> You can do help me...?\n> How to do I solve it...?\n> I use AgarimOS (Void Linux derivated) and my AgarimOS is updated.\n\n\n Comment 7: does the vpcs.log file have anything in it?\r\nThere is a GitHub [issue](https://github.com/GNS3/gns3-gui/issues/3110#issuecomment-768105648) with the same error message as you report. It looks like that particular issue was fixed but perhaps there is another case that was not solved by the fix.\r\n\r\nIs the vpcs process running\r\n\r\nI am having trouble reproducing the issue as my `vpcs` command fails with a segfault.  I'll keep trying but I'm not sure how long it will take to figure out.\r\n\r\nPerhaps you can switch from VPCS to ipterm or another end device in the mean time.\n Comment 8: Issues become stale 90 days after last activity and are closed 14 days after that.  If this issue is still relevant bump it or assign it.",
  "Issue title: How to deploy it on router?\n Issue body: So how to deploy it on my router?\r\n> There is my router info :\r\n` System Version :  the lastest Openwrt/LEDE build  with x64 `\r\n\r\nWould you tell me how to make this or would you like to release  installation package?\r\n\n Comments: \n Comment 0: Please see here for supported operating systems:\r\nhttps://docs.pi-hole.net/main/prerequesites/\r\n\r\nIf your Openwrt/LEDE router runs docker, then we have a docker image \r\n\r\nhttps://github.com/pi-hole/docker-pihole\n Comment 1: Your docker image url is 404.\n Comment 2: https://github.com/pi-hole/docker-pi-hole"
]
